Some ideas for the project:

* As training data, we can probably look here: https://archive.org/details/stackexchange
* As for the topic, perhaps philosophy? This way we can probably get away with minor nonsense, as we are discussing metaphysics anyway...
* Markov n-grams look nice for generating text. Not really clear how to use them to actually answer questions though. We can 'train' one per tag, so that different networks can generate different texts based on the topic chosen by the user.
* An implementation of seq2seq for python can be found here: https://github.com/farizrahman4u/seq2seq
* We can also consider more pattern-based approaches, e.g. by using AIML: https://en.wikipedia.org/wiki/AIML

In general, I think it would be useful to have some predetermined, hand-crafted responses to account for standard questions/replies such as greetings or to steer the conversation, etc.:

`"Hi, My name is <botname>. I can do this and this and also that. To see a list of commands type /help."`

`"Hello, I'm Daniele. Let's talk about existentialism"`
  
_...the bot look up existensialism in a db of tags..._

`"That seems to be a pretty big topic. Can you be more specific?"`

`"Something about Kierkegaard's vision of life?"`

Of course, we'd need to find a way for the bot to understand the question:
* First, we can probably just stem everything after having removed stopwords, so that we are left with the most important words (in this case _something_, _about_, _Kierkegaard_, _vision_, _life_). 
* From here, we could try to look for names, perhaps to further narrow down the topic (in this case we are really looking for an answer which relates to Kierkegaard).
* The answer could then be generated by either picking a network or training one on-the-fly, depending on the amount of space it takes.

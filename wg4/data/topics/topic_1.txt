Perhaps a better question to ask is the inverse: whether traditional religion is compatible with existential philosophy; Kierkegaard's existential beliefs certainly affected his view of the role of religion, to the point that his theology was extremely controversial among his contemporaries. Existentialism doesn't necessarily require the outright rejection of the possibility that a God exists; just the rejection of the notion that we must place God before all else in choosing how to live our lives.
First it must be said that hedonism in the modern sense was not the core of Epicurism: Epicurus used the word http://archimedes.fas.harvard.edu/cgi-bin/dict?name=lsj&lang=el&word=h%28donh/&filter=CUTF8 ἡδονή (hêdonê, "pleasure") in a less obvious sense.

Epicureans strove after ataraxia, "unperturbedness" of the soul: a state of mind where neither pain nor pleasure affected the soul too much. This was the highest "pleasure".

Mild pain and mild pleasure were acceptable; but great pleasure was ill advised, because it would eventually end, and thus lead to longing for more, which constitutes pain. When we long for something, our heart aches.

Because moderate pleasure did not compromise ataraxia, casual sex and good food were allowed. But falling in love and unhealthy gluttony led to pain and were anathema.

The Stoics practised apatheia, "absence of feeling": a state of mind where the soul experiences no emotion at all. That was the only way in which the soul could be completely free. Any emotion would bind it to the body.

Life is a cart pulled by dogs; you, as a dog, have a choice between struggling against it, thereby causing yourself grief, or simply running along, going neither too fast nor too slowly

Any sexual escapade or other enjoyment compromised one's apatheia. In addition, even moderate pleasure could destabilize the soul, subjecting it to greater pleasure by consequence, which would ultimately end in pain. There are some similarities to Buddhism.
Nietzsche has a tenuous relationship with free will. His theories here are fairly difficult, conceptually, to grasp, and I certainly won't claim that I have a thoroughly complete understanding of it. Also, it's worth bearing in mind that it isn't unheard of to find contradictions across Nietzsche's various works. Even putting aside the very late stage in his life where he becomes maniacal, his books were written at different times, and you can see his thought developing and becoming more refined in the later books, which occasionally contradicts sweeping claims that he made in the earlier books. That's in part why academic studies of Nietzschean philosophy generally center on a single text.

But as I understand it, the point he's trying to make in Beyond Good and Evil  is that there is really no such thing as free will. No one can ever be a truly free agent (i.e., no one can truly be sufficiently free to be morally responsible) because such would require that one be causa sui  (or, the cause of oneself), and since we are not causa sui , we cannot be free agents.

There are a couple of different ways that he goes about proving this in BGE, but they're fairly complex and not particularly relevant here. As a short summary, the first is that it's logically impossible to be causa sui  (merely claiming that the very concept is "fundamentally absurd" and "the best self-contradiction that has been conceived so far"), and the second is that, based on his previously-developed notion of human agency, that we don't have sufficient control over our actions in order to claim that we acted out of free will. Or, in other words, that human beings are not self-caused in a sense that is sufficient to underwrite ascriptions or claims of moral responsibility.

He argues that both our moral and religious traditions (particularly Christianity, of which he holds a particularly bitter resentment) conspire to prevent us from ever truly having free will. In fact, he says that what we possess are causally determined wills. One of the aphorisms he uses to prove this asks the question, "Does a Christian want to sin?" Nietzsche disagrees, arguing that a true Christian can never truly want to sin, thus concluding that the Christian never truly has free will, as he was never free in the first place to do whatever he wished.


However, in (primarily) Twilight of the Idols  (and Genealogy of Morals), Nietzsche beings to develop a more positive, productive sense of free will, and more generally, freedom itself. He says that free will is not, in fact, characterized by the ability to do whatever you want, whenever you want, because if it were, it would be a meaningless concept. One who indulges their every whimsy is really just one who is a slave to her own impulses. Suffice it to say that Nietzsche doesn't think this is a particularly desirable state of affairs.

Instead, he asserts that true free will is more accurately characterized by ambition and achievement. Really, he says, it's the ability to set a goal and act in such a way as to achieve it. This is also known in his works as the "Will to Power" (not to be confused with the corrupted form later espoused by his sister). Striving to reach the highest possible position in life is the ultimate goal of the will to power, and is in fact itself a manifestation of the will to power. In other terms, the will to power is just agency free will, as opposed to deserts-based free will. And he takes such agency free will to be a rare achievement, as opposed to the natural endowment that is deserts free will, the most commonly conceived form.

Examined again in this light, it becomes apparent that the quote you've taken from TI  is really just a restatement or reprisal of the will to power:


  Freedom is the will to be responsible for ourselves. It is to preserve the distance which separates us from other men. To grow more indifferent to hardship, to severity, to privation, and even to life itself.


True freedom, from a Nietzschean perspective, is really the will to affirm and to be responsible for oneself. It requires struggle against hardship and an acceptance of life's pain and suffering in a positive, life affirming way (amor fati ). But it explicitly does not  mean the denial of one's impulses and instincts. Indeed, it's the freedom from having to rely on them, but at the same time, the freedom from having to categorically reject them.

(In summary: I think that the two quotes are really talking about two completely different things, although Nietzsche labels them both "free will". In fact, there are two entirely different notions of free will at play here, one of which Nietzsche harshly criticizes and the other, he exalts.)
Political words tend to change the meaning, but the original meaning of http://en.wikipedia.org/wiki/History_of_communism#Early_Development_.281840-1916.29 communism meant common ownership of all property. As such it was during all of the 19th century in practice equivalent to socialism and could be used more or less interchangeably. 

Although the http://en.wikipedia.org/wiki/Capitalism#Etymology_and_early_usage early usage of the word "Capitalism" meant having stock exchanges and investors, since the 19th century the word has acquired the more fundamental meaning of "http://en.wikipedia.org/wiki/Capitalism private ownership of property".

In these senses of the word, capitalism vs communism is indeed a dichotomy, as something  either is owned communally or not. Either everyone has a say over the http://en.wikipedia.org/wiki/Ownership usage of the property or not everyone has a say. (Although you can have both common ownership and private ownership at the same time, but of different things. As such hospitals may be owned by the state, but car factories not, for example).

In this viewpoint the left was definitely not stuck between a false dichotomy, as the dichotomy was true, and they had chosen one side of it.

However, the meaning of the word communism started changing after the Russian revolution. Socialism continued to mean common ownership, but http://en.wikipedia.org/wiki/Communism Communism more and more meant a specific path to socialism, namely Marxism including it's bloody revolution and dictatorship of the proletariat. 

As such, the dichotomy starts being false. Although the dichotomy between socialism and capitalism remains, communism then became just one form of socialism, with most notably reformist and democratic social democracy as a major option. But the "the left" was not caught in this false dichotomy, because social democrats tried that option. Only that part of the left (which got smaller and smaller every year) that still supported the communist dictatorships could be said to be confined in a false dichotomy. A confinement completely of their own choosing, of course.

After the fall of communism and the gradual realization that social democracy hasn't delivered, the word "communism" has again started to change meaning. "Social democracy" increasingly means what before would be called "social liberalism", capitalism with a strong protective state, "socialism" increasingly means "politicians being nice to people" and "communism" is starting to revert to its original meaning of "common ownership". As such, the dichotomy between communism and capitalism is again becoming a real one.

I would therefore say that:

No, the European left was not confined in a false dichotomy between capitalism and communism, unless you with "The European Left" means only those who supported or still support the communist dictatorships because they dislike capitalism. But that is a very narrow definition of "The European Left" (although undoubtedly some of this left was and is so sectarian that they wouldn't hesitate to agree with it).
[Edited:] Voltaire meant it the way you have interpreted it: you shouldn't always be looking for something better if you have something good; it's hard enough to keep what you have.

Here are the relevant lines from the poem, with my translation à l'improviste:


  Dans ses écrits, un sage Italien [In
  his writings, an Italian sage]
  
  Dit que le mieux est l’ennemi du bien
  ; [Says that the better is the enemy
  of the good;]
  
  Non qu’on ne puisse augmenter en
  prudence, [Not that we cannot grow in
  wisdom,]
  
  En bonté d’âme, en talents, en science
  ; [In the goodness of our soul, in talents,
  in knowledge/science;]
  
  Cherchons le mieux sur ces
  chapitres-là ; [We should search the
  better in those fields;]
  
  Partout ailleurs évitons la chimère.
  [Everywhere else, we should avoid that chimera.]
  
  Dans son état, heureux qui peut se
  plaire, [In his state, that man is
  happy who is content with
  himself,]
  
  Vivre à sa place, et garder ce qu’il a
  ! [Knows his place (live at his place), and protects what he
  has!]


Voltaire based this on the Italian proverb, Il meglio è l’inimico del bene, which means exactly the same. The origin of the proverb appears to be unknown.

http://www.voltaire-integral.com/Html/17/art_dramatique.htm He uses the Italian phrase himself in his Art dramatique. First he describes how the work of Lulli is misinterpreted by a certain encyclopaedia of art; then he "proves" how wrong it is (if I understand the text correctly), and ends with the proverb. I don't think it could be read otherwise than Lulli being the good, and the all-too artificial encyclopaedia being the "better".

Incidentally, I ask, how did Voltaire learn this proverb? He must have heard someone else use it. And either that person must have used it the same way Voltaire uses it, or Voltaire must have misunderstood. Is the latter likely? I imagine this person used it in a context that let Voltaire interpret it this way; it seems possible, but unlikely, that he misinterpreted it. 

Suppose there were two women, Cleopatra and Xanthippe. Suppose Cleopatra were the enemy of Xanthippe. Who would you say was more aggressive? I say we know that Cleopatra is probably aggressive, but Xanthippe might be either aggressive or merely fearful of Cleopatra. Being someone's enemy is often reciprocal, but not necessarily so. In any case, if one party is called an "enemy", emphasis lies on that party's ill will.

Analogously, the better harms the good, but we aren't told whether the good harms the better as well. It seems clear that it is the harmful effect of the better that has focus, not the other way around. Moreover, the main statement is dans son état, heureux qui peut se plaire; the phrase non qu'on ne puisse augmenter en prudence etc. ("not that...") is an exception he makes. The main statement is reinforced by the evocative word chimère. What comes before non que... belongs to the main statement.

Any text can be interpreted in various ways, many of which would be the opposite of what the author meant. If an author inspires you to contemplate something you know he didn't intend, that is of course fine and well—as long as you don't try and read it into his other lines. We are not Voltaire's servants: if we should like the wordplay of this expression's meaning "the good is the enemy of the better", we are free to do so.
I would compare it to someone believing that if a tree falls in a forest and no one is around to hear it, it does not make a sound.

The definition of the question limits us to not being able to answer it, and both silent-tree-believers and solipsists opt for the most sceptical position, that is opposed to our common sense understanding of the world.

Our model of the world is based on imperfect information, and we constantly make inferential leaps. Most of us believe that we aren't dreaming, that when things are hidden behind obstacles they are still there, and that the sun will rise again tomorrow. Most of us also believe that other minds exist.

This series of assumptions turns out to be a really useful model for understanding and predicting our environment, and modifying our behaviour to meet our ends.

The fact that these cannot be proven, does not mean that they are false, or that it would be beneficial to consider them false.

One can say that they are not sure, and indeed, some versions of solipsism state simply that the only mind's existence the individual is sure of is their own. This really doesn't go very far, as at this level of scepticism, there's very little to be sure of at all - maybe each 'instant' we're recreated in a totally new world with a different history, and our memories and identities are fabricated.

I think the reason solipsism seems more important to argue against than a disbelief in e.g. object constancy is rooted in our conception of 'the ghost in the machine' and the mind-body problem. We're rather self-centred.

Some background and historical arguments:

Solipsism is a world view extrapolated from the problem of other minds. Simply stated, the problem of other minds is that we cannot know (or prove) that others have minds like our own.

The Stanford Encyclopaedia of Philosophy has an http://plato.stanford.edu/entries/other-minds/ in-depth article about it. It presents a series of solutions to the problem (and by extension, to solipsism). The following is the uncomfortable conclusion:


  This article has been almost entirely
  concerned with the epistemological
  problem of other minds. What generates
  the problem has been carefully
  delineated. The standard solutions
  have been outlined and the various
  critical responses discussed. What is
  clear is that there does not seem to
  be what might be called a received
  solution to the problem. It has been
  argued that the problem cannot be
  removed, nor can it be made easier to
  solve, by embracing any particular
  philosophy of mind.

Your example can be more simply stated by not involving the future:


  Can god create something that is so
  heavy that he can not move it?


The answer of course is "Yes". But then, you say, he would not be omnipotent as he can not move it. But that's wrong. He can. Because he is omnipotent. Hence:


  An omnipotent being is able to move
  that which he is unable to move.


If you want to call this consistent or not is up to you. It is inconsistent as seen from a logical framework. But it is consistent with the standpoint that an omnipotent being by definition can do anything, including breaking the laws of logic.

God is generally claimed to have created everything, including logic, so he is not susceptible to them, or any form of reason. That also per definition makes God unknowable, unreachable and unscientific. He can not even be discussed in any form of meaningful way with human words, rendering your question and my answer equally meaningless.
Both the English and American legal systems are based in large part on the writings of http://en.wikipedia.org/wiki/Social_contract Social Contract theorists, like http://en.wikipedia.org/wiki/John_Locke John Locke and http://en.wikipedia.org/wiki/Jean-Jacques_Rousseau Jean-Jacques Rousseau. Legally and politically speaking, this is one of the most influential notions to arise during the Enlightenment.

The United States Constitution and Declaration of Independence draw heavily from the writings of Locke. Large portions of both documents read as if they were quoted directly from some of his works. And the concepts espoused, both implicitly and explicitly, by both documents are backed by concepts he advanced. In particular, things like natural rights, collective sovereignty, religious tolerance, the necessity to impose restraints on the exercise of arbitrary power of the executive, etc.

He even preached specifically in favor of the right to revolution, claiming that because all people have the fundamental rights to life, liberty, and property under the natural law, they could instigate a revolution against the government whenever it verifiably acted against those interests of its citizens. In some cases, Locke even insisted that revolution was an obligation, insofar as it provided a bulwark against tyranny.
This, as you can well imagine, was often cited as a justification for the American Revolution.

If you're interested in reading more about this, the best place to start is with Locke's extremely well-known Two Treatises of Government, paying particular attention to the second treatise, which is his polemic in favor of a civil society based on natural rights. The entire book is even available as a free download (in various formats) from http://www.gutenberg.org/ebooks/7370 Project Gutenberg.


Others of our laws, particularly those in the juridical realm, like those you cite (intent, burden of proof, no cruel or unusual punishment, jury of your peers, no double jeopardy, etc.) are based on the writings of the French Enlightenment thinker, http://en.wikipedia.org/wiki/Montesquieu Montesquieu.

We of course didn't apply everything that he advocated, but there's no denying his strong influence. His The Spirit of the Laws was widely read by the American "founding fathers" and widely disseminated throughout the original British colonies, where they seemed to capture mass appeal because of the growing tensions with England over things like representation in taxation and the right to political liberty.

In particular, James Madison, Alexander Hamilton, and John Jay, in their collected set of writings that were published as http://en.wikipedia.org/wiki/Federalist_Papers The Federalist Papers and argued in favor of the new Constitution, cited Montesquieu at length. Madison famously wrote in The Federalist, number 47:


  The oracle who is always consulted and cited on this subject, is the celebrated Montesquieu. If he be not the author of this invaluable precept in the science of politics, he has the merit at least of displaying and recommending it most effectually to the attention of mankind.


He was also very much responsible for what became known as the http://en.wikipedia.org/wiki/Separation_of_powers Separation of Powers doctrine, enshrined in the U.S. Constitution, derived from his commentary on Britain's tripartite constitutional system.
According to the Wikipedia http://en.wikipedia.org/wiki/Argumentum_ad_lapidem definition:


  Ad lapidem (Latin: "to the stone") is a logical fallacy that consists in 
  dismissing a statement as absurd without giving proof of its absurdity.


The Latin name is doubly confusing in that it has a fairly modern origin and in that it relates to a specific example:


  The name of this fallacy is attributed to Dr. Samuel Johnson, who refuted
  Bishop Berkeley's immaterialist philosophy (that there are no material objects, 
  only minds and ideas in those minds), by kicking a large stone and asserting, 
  "I refute it thus."


Now as an effective and memorable rhetorical tactic, Dr. Johnson found an excellent way to make his point.  The problem comes when examining the content of his logical argument.  What he suggests by his demonstration is that of course there are material objects: we can feel them and see them and interact with them.  But if Bishop Berkeley objected that the sensation of feeling, seeing and interacting with objects could simply be the result of, for instance, imagination, Dr. Johnson would need to deal directly with that objection.  (I don't know either if Bishop Berkeley made such an objection or if Dr. Johnson offered a response, but for the sake of the illustration, let's assume the first did and the later didn't.)

It's not always incorrect to use arguments that are in the form of logical fallacies, as the example of kicking a stone illustrates.  For most of us, the simple demonstration is effective at getting the point across.  But when you consider the opposite viewpoint, ad lapidem does not satisfy an objection or compel agreement.  It may be useful for scoring points in a debate, but not useful in either finding common ground or discovering the truth.  Pointing out a fallacious argument should redirect the proponent of the position to try another method of arguing that does not entail a logical fallacy.

Dr. Johnson could have corrected his argumentum ad lapidem (and perhaps he did) by suggesting some other reason not to accept immaterialism.  
There is no way to take a non-moral "is" and from that extract a moral "ought". (http://en.wikipedia.org/wiki/A_Treatise_of_Human_Nature ref) This separation is usually called "Hume's Law". This has been not only a pretty self-evident, but also generally accepted law within philosophy, but nevertheless it regularly pops up http://en.wikipedia.org/wiki/Ayn_Rand wanna-be philosophers trying to break it and failing. 

As science can only concern itself with what is, it can not talk about what ought it is impossible to scientifically determine any moral issue, including god and bad and evil. 

http://en.wikipedia.org/wiki/Is%E2%80%93ought_problem More.
I am tempted to adopt a Wittgensteinian tack on this one - not saying that it is right but it seems to me an interesting approach for this type of question. For reference, my argument is based on Wittgenstein's observations in the Philosophical Investigations §193-§195.

To ask whether the proposition 


  (P) This coin is fair


is falsifiable is to confuse two pictures we have of coins. One is the picture we have of the coin as a symbol for all its future applications - that is to say the picture of a physical coin symbolizing an ideal random process that gives one of two results with 50-50 probability. The other picture is that of the coin as an actual physical object - e.g. made of copper, round, thin, liable to friction and tear.

Now the proposition (P) adopts the first picture - the property 'fairness' refers to the symbolic understanding of the coin as encapsulating the whole of its future application (i.e. flips) as a random process giving one of two results with a 50-50 chance.

On the other hand, the following proposition


  (Q) Is P falisfiable?


refers to the second picture, i.e. the actual physical realization of the coin. And here the confusion should become apparent. (Q) asks of a symbolic property whether it is empirically falsifiable. And no such answer is forthcoming.

We are often tempted to confuse these pictures in philosophy. It seems as though 'fairness' is somehow in the coin - that it is somehow a property that we ought to be able to uncover. The reason we are "led into temptation" is because we do not take care to separate the two pictures.

The grammar of the word 'fair' is what is at issue here. What makes your question seem meaningful is that what you have in mind is the grammar of fair when we employ it symbolically - e.g. when trying to explain probability to someone. But the only grammar that actually makes the question meaningful is the practical one, i.e. the one that takes into account what compels us to call a loaded dice 'unfair' and a weighted coin 'fair' - namely measurements, production methods etc. And if this grammar makes the question meaningful, it also makes it trivial and the problem, it seems to me, disappears. 
I'll use "liberal" (in the European sense) instead of "pro-capitalist" here, as I think it's more relevant.

Socialist philosophy is based on seeing faults and injustices in society and wanting to fix them by implementing total equality of outcome. Its aim and desire is to make people equal. It as such tends to attract people who want everybody to be the same. There is a safety and a comfort in the homogeneous group, where people understand each other and there is little conflict. Socialist philosophy strives for harmony and unity.

Faults and injustices:


  The history of all hitherto existing society is the history of class struggles.
  
  Freeman and slave, patrician and plebeian, lord and serf, guild-master and journeyman, in a word, oppressor and oppressed, stood in constant opposition to one another, carried on an uninterrupted, now hidden, now open fight, a fight that each time ended, either in a revolutionary reconstitution of society at large, or in the common ruin of the contending classes. 
  
  -- Karl Marx and Friedrich Engels: The Manifesto of the Communist Party


Equality of Outcome:


  The point being that an essential feature of a decent society, and an almost defining feature of a democratic society, is relative equality of outcome-not opportunity, but outcome.
  
  -- Noam Chomsky: http://www.cooperativeindividualism.org/chomsky_commongood.html The Common Good


Make people equal:


  From each according to his ability, to each according to his needs! 
  
  -- Karl Marx: Critique of the Gotha Programme 


Safety and comfort in the group:


  ...the individual ceases to be himself; he adopts entirely the kind of personality offered to him by cultural patterns; and he therefore becomes exactly as all others are and as they expect him to be. The discrepancy between 'I' and the world disappears and with it the conscious fear of aloneness and powerlessness.
  
  -- Erich Fromm - The Fear of Freedom


Liberal philosophy is based on seeing potential and freedom in humans. It wants to reach this potential by implementing equality of opportunity. Its aim and desire is to make people free. It therefore tends to attract individualists. There is a stifling pressure and lack of freedom in the homogeneous group where you are not allowed to be different. Liberal philosophy strives for diversity and complexity.

Potential:


  Adam Smith's central insight remains true today: there is no greater generator of wealth and innovation than a system of free enterprise that unleashes the full potential of individual men and women.
  
  -- Barack Obama


Equality of Opportunity:


  Equality of opportunity, like personal equality, is not inconsistent with liberty, on the contrary, it is an essential component of liberty. 
  
  -- Milton Friedman


Freedom


  [E]ach person is to have an equal right to the most extensive basic liberty compatible with a similar liberty for others.
  
  -- John Rawls: A Theory of Justice


Lack of freedom in homogenity


  See "http://en.wikipedia.org/wiki/Brave_New_World Brave New World" and "http://en.wikipedia.org/wiki/We_%28novel%29 We". 


End result in economic policy

Socialist economic policies focus partly on a direct desire to fix injustices which results in large redistributions of wealth, and often price controls in a misguided attempt to keep fundamental needs affordable (with the result that they instead becomes more scarce). It also is affected indirectly by it's desire for equality of outcome, which is to be implemented by common ownership of the means of production. This results in state control and state ownership and homogeneous state owned health care and education.

Liberal economic policies focus partly on a desire to even out the opportunities in life, which results in redistributions of wealth (but smaller than the socialists), and partly on a desire for freedom, which results in privately owned and heterogeneous health care and education, which however, to support equality of opportunity, may be state funded (for example French healthcare and Swedish schools).

The difference between economic theories like Labor Theory of Value vs Marginal Utility Theory of Value is best saved for another question, I think. 
Speaking very generally, materialism has been waxing sharply, and idealism has been waning for a good long time.

Berkeley studies have definitely suffered on account of this, but he would seem to be least among the "Idealist idols" also relegated to the "dustbin" of history by modern philosophy. In particular, a rancorous anti-Platonism has been one of the more consistent characteristics of the last century's major philosophers, as well as the more prescient thinkers of the century previous to that -- with exceptions of course.

So sadly, Berkeleyan immaterialism is quite commonly held to be some kind of insane absurdity, mostly on a misunderstanding of the central premise "to be is to be perceived." Recall that matter and other abstractions don't properly exist for Berkeley; one way to put it is that they are "philosophically-constructed," but this isn't quite right -- in a way they are purely virtual, real without being actual, like a memory or dream -- incorporeal and not directly perceived, in a way similar to Forms. But true existence or 'actuality' belongs solely to perceptions and perceivers, not to abstractions.

In a way there would seem to be something incredibly modern and forward-looking in this immaterialism; and indeed taken seriously it is incredibly rewarding work. I too lament the decline of serious work on idealism as opposed to the endless and trivial critiques which tend not to address crucial distinctions involved.
Nothing written in a book could convince anyone that it has been written by god.

3 reasons:

Because any extraordinary written stuff could have been coincidentally  written.

A book with thousands (or more) of different ideas (not necessarily predictions) has a good chance that some of them could later be interpreted as real predictions or as ahead of its time impossible scientific discoveries.

Because any book can be written randomly by a computer.

A book is only a combination of limited letters (or symbols, ideogram etc. depending of the language) and any powerful machine can randomly create all possible books (if the book is not unlimited).

So if you showed me a particular book and you told me it has been written by god, then I'd respond that a machine could have written this book or similarly that a human could have randomly created the book.

The designer of the ideas in that book would then be chaos/chance/randomness which is far away from any god definition.

Because we could live in a http://en.wikipedia.org/wiki/Simulated_reality simulated reality in which any data could be produced by a super intelligent being in order to manipulate us.

In this case, any extraordinary content displayed in the book (as predictions) could be explained as manipulations from the super-intelligent designers of this "matrix".
That theorem (http://www.cs.auckland.ac.nz/~jas/one/freewill-theorem.html overview) is often taken out of context. His suggestive naming of the behavior or elementary particles as "free will" irked a lot of people, especially as the connection to what we consider free will is phenomenally vague. It's almost akin to noting that Heisenberg Uncertainty suggests a lack of determinism (for the more quantum-mechanically literate, look into Bell's Theorem).

So the theorem is taken very seriously, but not necessarily having anything to do with what we consider free will. 
Rules are in place for those who aren't capable of being good citizens without some sort of consequence.  An example of this would be someone who robs and steals during riots in a moment of weakness in law enforcement or someone who murders because he thinks he can get away with it.  

In fact, there's no reason to assume there's any higher moral basis for rules and laws, because if there were, there would be no such thing as conflicting laws in different countries yet there are.  It might be illegal to smoke marijuana in one country and it might be perfectly legal in another, for instance.  Therefore, they're put in place to maintain order, nothing more.  

Of course, the catch 22 is, how do you know when you're doing the right thing then?  If you break the law to do what, according to you, is the right thing, then there would be many others who would argue the opposite despite any attempts to prove them wrong.  Someone might think killing the guy that slept with his wife as perfectly normal and sane, for instance.  Yet, we know that laws themselves don't always uphold higher moral ground.  Taxing a family out of their last dime is far from morally correct, yet it gets enforced for the simple reason that laws must apply to all.

Abraham Lincoln was paraded as a hero, though in not even such different circumstances, he would have been considered one of the worst presidents America had ever known.  It might have been enough that the south had won the war, for instance.  Therefore, as trivial as it sounds, whether it is right to break the rules is entirely dependent upon which moral compass you're holding at the time.  
Plato's use of two persons with opposite opinions, Heraclitus and Parmenides or say the sophists and friends of his time, were for centuries taken too literately. Today we shouldn't fall in the same trap.

If we take the dialogues too literately, calling it usage of strawmen is fair. There are a few objections that are important. Interpretations by Friedrich Schleiermacher (1768-1834) and G. W. F. Hegel (1770-1831) gave a deep insight on how Plato actually was being both ironic and serious at the same time. 

Ironic in the joyful sense. Imagine that scholars for hundreds of years had poured over the dialogues, taken them literate and not understood the playful irony, even though Heraclitus was referred to with quotations like "everything flows" and Parmenides with "change is impossible", the act of figuring out why they said what they did and how the discussions the partners in the dialogue ended up with nonsense arguments themselves. We see this happening over and over: in politics with democrats and republicans, for and against climate change. How do we go about dealing with opposite opinons?

The point of having to opposed opinions and "rubbing them together" until a spark of fire emerges is part of Plato's http://en.wikipedia.org/wiki/Dialectic dialectical method. This is serious stuff. His method is not ridiculing both of the claims in order to reach a higher insight, but just as much an exercise in thinking, the connection between things being said and physical circumstances that could prove them right or wrong - a method of logical reasoning to discern between truth and falsehood.
It's a part of how we think about or answer the question "what is it"? Aristotle asked the question and tried to answer it in the Categories, an important foundation of classical logic. Hegel is basically answering the same questions, but with the insight from Kant's transcendental idealism.

For example: this thing (substance) over there, it's a horse (a good example of existent determinateness, being a horse is a defining quality).

We could also say: it's fast (existent quality). Or: it's never afraid (negative determination, i.e. the non-existing quality is helping in determining what kind of horse it is). And: I'd wish this horse could live forever (where immortality is a non-existent infinite quality).

References:
http://en.wikipedia.org/wiki/Dialectic http://en.wikipedia.org/wiki/Dialectic (a few examples with water)
http://en.wikipedia.org/wiki/Quality_(philosophy http://en.wikipedia.org/wiki/Quality_(philosophy) (Hegel's logic is in many was a continuation of Aristotle's line of thought in http://en.wikipedia.org/wiki/Categories_(Aristotle) Categories) 
http://en.wikipedia.org/wiki/Logical_quality http://en.wikipedia.org/wiki/Logical_quality (Kant/Hegel: positive/negative, but also infinite judgements)
This is an appeal to Bayesian statistics.  The speaker cannot possibly mean that it is logically impossible for someone to make up whatever-it-is, so they must be meaning that it's extremely improbable.  Thus, what they are saying is, effectively, when you are computing the chance of various models given the data, make sure you weight your prior for the "made it up" case appropriately (i.e. very low).  Given that, a priori, it's very unlikely that anyone made that thing up, other explanations (even very improbable ones) begin to look correspondingly more favorable.

So it's entirely valid logically (albeit indirect via statistics).

However, although it's potentially valid when doing statistical reasoning, it's not necessarily the case that people intend for you (or themselves) to do it that way.  People could be hoping that you will have the same emotional reaction they did: "OMG!  No way!!" and then set the a priori probability to zero and thus promote some other perhaps-even-more-wildly-unlikely scenario to be the "best explanation".  The correct thing to do may be to recognize that although it's unlikely that someone could come up with such things, everything else is even more unlikely, and thus it-was-made-up is the best explanation (given available evidence).

I'm not sure that a scenario this complicated is well captured by the terms logos, pathos, or ethos.  It is like ethos in that arguments from ethos are also arguments about weighting a priori probabilities in a Bayesian framework, but there is no trustworthiness involved here.  (Trust is one reason you might adjust your priors.)  Although there is logically sound information contained in such an argument, it is usually presented in a very different form than typical appeals to the intellect.  Almost no-one is consciously aware of their distribution of prior probabilities, so a more intuitive presentation tends to be more effective (though this says nothing about the validity...).

  Keep in mind my question is about the general ability to use a "lack of knowledge" claim to invalidate a positive claim. Determinism/apple pies are just examples. 


In that case, let's start with your specific examples, and then move on to the general case.

You claim that:


  I don't see how my uncertainty about the nature of the apple pies has any effect whatsoever on the actual possibility of the composition of the pies. Either the apple pies are made from handpicked apples, or they aren't. My uncertainty about it does not make either possibility more or less probable.


And this is true--of apples.  Observation of apples has no significant effect on apples.

Things are different at the quantum level, however.  Observation of particles has a definite effect on the particles.  Thus, any notion of determinism that relies upon the observability of particles has a problem, as the act of observing interferes with the experiment (and may alter what would have occurred had the observation not taken place.)  So, certain attempts to demonstrate determinism are stymied by the uncertainty principle.

So, from there, we can move on to the general case:


  My question is in reference to people who hold that the lack of complete understanding in a particular field can invalidate a positive claim.


The answer is that this can occur only in cases where "the lack of complete understanding" is of a structural (i.e., transcendental) nature and not of a purely contingent or accidental nature.  In other words, where we are dealing with situations where X is viewed as a necessary condition for the possibility of Y, uncertainty about X can invalidate positive claims about the presence of Y.

In practical terms, you're unlikely to run into this problematic outside of the quantum level, or other unusual edge cases.
There are several factors at play in your question.

It appears that you have (re-)discovered the distinction between implicational and non-implicational negation (also sometimes known as "choice negation" and "exclusion negation").  

The literature on this topic goes back to ancient times: for example, Indian logic (both Buddhist and Nyāya) draws a distinction between prasajya negation (i.e., "This is not a brahmin") and paryudāsa negation (i.e., "This is a nonbrahmin").  In the former case, we are negating a proposition; in the latter case we are negating a term.

So, when we say "The number seven is not green", we are not implying that it is some other color.

Note that this is completely orthogonal to the subject of "meta-logic."  

In other words, your choice of the word "illogical" as an example seems to be leading you to second-order logic (which may be your goal), but it is not necessarily linked to your questions about negation (which also apply to first-order logic.) 

I'd recommend a good undergraduate introductory logic textbook, but I'm afraid I don't know what's in current use these days.
Because it is such a recent work, I doubt you're going to find a lot of literature beyond book reviews.

If you have access to an academic library, I suggest that you do a search in the Philosopher's Index, which will help you find any reviews or articles published in the major journals.

The only review I've found online is http://ndpr.nd.edu/news/23278-second-philosophy-a-naturalistic-method/ this (largely positive) one from the NDPR.
In examining any claim, you always have at least two options: checking validity and checking the truth. In layman's terms, this means you can:  


Examine the logical structure of the argument. Does the conclusion follow from the premises?  
Examine the content of the argument. Are the premises in the
argument true?


In your case, it seems you lack knowledge of the content, but anyone who understands logic should be able to—even with no understanding of the topic being discussed—critique the logical structure of an argument and check whether it is valid. Your examination would be entirely free from the influence of confirmation bias because logical coherence has nothing to do with content but of form. On the other hand, if you were to question the truth of the premises in the claim, you would be susceptible to (but not necessarily fall prey to) the confirmation bias, because the confirmation bias deals with the truth/falseness of information.
A straight answer is difficult as this is very open ended, I can give examples for one side (that philosophy matters in the 'real' world) and limited argument for the other (it doesn't matter).

For the relevance/impact of philosophy:


the study of ethics matters quite a bit. One source of jobs for a philosophy PhD grad (as limited as it might be) is direct employment by a hospital as a bio-ethicist (having relevant background of course.
philosophy of science directly affects the conduct of experiments.
the study of mind directly affects the treatment of psychiatric problems (what does it mean to have a piece of your brain injured?)
I claim that the undergraduate study of philosophy in general is a better preparation for study of law than other humanities (literature or history) because it directly exercises arguments.
I can't think of any particular recent philosophical theories of government (actually I can't think of any recent ones at all) that inform current political movements, but certainly all major revolutionary movements in Europe since... let's say the Glorious Revolution were informed by (OK maybe soon thereafter justified) philosophical movements.
(this list can keep going)


Now for the other direction. Yes, you're right, philosophy really is pretty disconnected from the 'real' word, with its synthetic a priori and categorical imperative. Really, it is the height of ivory tower ethereality. Only academics read their publications. The great majority of words written is commentary on commentary, and the few original works are about made up problems. (this may sound sarcastic but it is as sincere as the first part).

Now rather than try to weigh these two sides, I'll deflect...consider other faculties of the modern university, say those mentioned before, literature and history. I think it is obvious that literature has less impact than philosophy. As to history, I feel the need to justify the same claim. How can study of the American Revolution possibly have an impact actions taken today? All you really need to study is the newspaper -now-; the news -now- is what makes an impact on next week.

It would be boringly self-supporting here to say that philosophy matters. And it's too easy a target to say philosophy is irrelevant; there're no facts there. Let's be philosophical and empty (they're almost the same!) and say the truth lies somewhere between the two.
The classification of a definition might refer to


What is defined (an entity, a tangible thing, a word etc...)
How is it defined


In terms of what, in brief (since it's not directly relevant to the question but it's important in order to understand what follows) a definition may be:


Realistic: When it defines a tangible being in the sense that the definition refers to the object rather that to the word we use to describe it or its reflection in our mind (conception).
Conceptualistic: When the defined being is a concept or our concept about a being.
Nominalistic: When the defined being is a word and the focus is on the e explanation of the word (etymology, meaning etc)


A definition, regarding how we define things/entities/words etc... can be:


By Recursion: Well known in mathematics. For example the Fibonacci sequence is defined recursively. It is a sequence whose first and second elements equal 1 (x1 = x2 = 1) and all other elements are retrieved from the formula x(k+2)=x(k+1)+x(k) for k=1,2,...  Constructively, we say that a recursive definition consists of the following:


Determination of a number of elements that belong to the set we define
A recursive rule or formula using which all other elements of the set emerge
An explicit or tacit assumption that the set contains no other elements.

Analytical: A definition in which we plumb the logical depth and the essential characteristics of the underlying entity are analyzed. For example Euclid, provides the definition of surface as (Euclid, Elements, Book I)


  A surface is that which has length and breadth only. 

By Enumeration: This kind of definition examines the logical width rather than the logical length of the underlying entity to be defined. The definition is carried out by referring to the elements of the defined set one by one. For example, we say that one-digit numbers are the numbers {1,2,3,4,5,6,7,8,9,0}.
Interpretational: A definition is interpretational when it analyses the semantics of the entity to be defined. For example from the http://www.thefreedictionary.com free online dictionary, one definition of weight is 


  "A measure of the heaviness of an object".

Etymological: The root of the word is analyzed and explained. For example the etymological definition of "etymology" from Wikipedia is 


  The word "etymology" (pronounced /ɛtɨˈmɒlədʒi/) derives from Greek
  ἐτυμολογία (etumologíā); from ἔτυμον (étumon), meaning "true sense",
  and -λογία (-logía), meaning "study"; from λόγος (lógos), meaning
  "speech, account, reason".

Demonstrational: Definition by providing example. For example 


  Red is the colour of this pen (pointing at the pen at the same time).
  This is an avocado

Constructive: A definition that provides a way to generate the defined object.
Implicit: The singleton {0} is implicitly defined as {x|x^2 + 10*x^4 = 0 and x is real}.
Operational(ist): The defined entity is what accrues from a measuring procedure, either physically and practically or merely mentally and only that. An operational(ist) definition runs something like that (hypothetical quotation):


  Length of an object is the result of placing a ruler along this object and we read 
  the measurement on the ruler. This number accompanied by the units of the ruler 
  is the length of the object.

GPDS definition (Genus Proximum and Differentia specifica): Is a definition that outlines the key differences (Differentia specifica) between the entity to be defined and a proximal genre (Genus Proximum) in whose logical width the defined entity is included. For example:


  In Euclidian Geometry a square is a surface (Genus Proximum) which is both equilateral and right-angled (Differentia specifica).

By convention: A definition that intentionally restricts the range of the defined notion to a particular field of application. There are numerous such examples in science. For example in mathematics an in particular in Finite-Dimensional Analysis one can find the definition that inner product is the binary relation:


  In finite-dimensional Euclidean spaces (Re^n where n is a non-zero integer) we call inner product the binary relation <.,.>:Re^n x Re^n -> Re, such that =SUM x(i)*y(i)


This is fine for finite-dimensional vectors (as it is mentioned in the definition).  Sometimes such assumptions are not mentioned and the reader has to wary.
By connotation: Definition by connotation outline the main and most important characteristics (this is subjective of course) of the entity to be defined and intentionally omit other attributes. An example is the definition of http://www.thefreedictionary.com/lizard lizard from thefreedictionary.com:


  Any of numerous reptiles of the suborder Sauria or Lacertilia, characteristically having a scaly elongated body, movable eyelids, four legs, and a tapering tail.  

Usage-driven: A definition explaining the context, conditions or situations when the defined entity is used. For example:


  Oh! :Used to express strong emotion, such as surprise, fear, anger, or pain.
  Screwdriver: A tool used for turning screws.

Tautological: A mapping between a notion to be defined and another well-defined one. For example:


  Fiddle := Violin

Contextual: A definition from the context, formally having the structure "Def(Q): Not P Then Q" (Definition of Q). Example:


  Unstable System: If a dynamical system is not stable then it is called unstable.



All these kinds of definitions appear in Science. Some of them are employed for merely pedagogical purposes. For example it is not easy to explain temperature to a primary school child as the partial Legendre transform on Internal Energy with respect to Entropy so you will concoct some less strict definition like "Temperature is the measure of hotness of a body" (Interpretational). Later on, one learns that "Temperature is the measure of mobility of the molecules of a body" (No different that the previous one - an interpretational definition). 

Important: It is important to understand that there in not a single way to draw definitions. Some classes of definitions might not look not Scientifically valid.

Relations between classes of definitions: The provided classification of definitions covers a wide range of definition one finds in all fields of science (from mathematics and chemistry to social sciences and history) but does not necessarily cover all kinds of definitions. Moreover, this classification is overlapping in the sense that a particular definition might lie in more that a single class. As a conclusion... it's hard to give or understand a definition.

References:

K. Masavetas, "Introduction to Philosophy of Thermodynamic Method", Athens, 1999, pp. 22-42, NTUA Press (in Greek).
Jacques Derrida, in an interview entitled "Afterword: Toward an Ethic of Discussion" suggest that in order to discuss a work, one has a responsibility to actually read it.  This might appear to be de minimis, but it is shocking (to Derrida, and also to myself) to see how many statements have been made concerning his work (in journalistic articles, for example) by people who have plainly not read the texts in question-- or read them so poorly as to amount to the same thing.

If we broaden this a bit, I think we can say that while a reader is not morally bound by an author's intentions (to the extent that they are recoverable), at the same time, it is the responsibility of the reader to at least be aware of them (to the extent that they are recoverable).
I can't say it better than the http://plato.stanford.edu/entries/types-tokens/#DisBetTypTok SEP article:


  The distinction between a type and its tokens is an ontological one
  between a general sort of thing and its particular concrete instances
  (to put it in an intuitive and preliminary way).  


All events which actually occur, therefore, are token events.
The same exact way we determine if anyone is being truthful; the fact that the beings are "not bounded by this world, but can come to this world" is completely irrelevant.

EDIT:

Since the question has been reframed, I'll elaborate on my answer.

As you have seen, there are a lot of different epistemologies out there; one that I find very useful for these purposes is a theory dating back to medieval India, to the Nyāya school.  They posit four different ways of gaining reliable knowledge, which they call pramāṇa-s.

The first pramāṇa is direct perception.  As you have already noticed, this is a very useful way to evaluate the truthfulness of claims; if I say that the sun is shining, you can stick your head out the window and see for yourself if I am telling the truth or not.  As you have also noticed, there are a couple of problems with this, as well: one is that perception is not always reliable (as evidenced by optical illusions); another is that there are many claims made about things which cannot be easily perceived (i.e., what color of underwear I am wearing here in Norway.)

The second pramāṇa is inference.  If every time I have perceived smoke, I have also perceived a concomitant fire, I can use this knowledge to infer that the smoke rising from the chimney across the street is due to a fire, despite the fact that I cannot directly perceive the fire at the moment.  Naturally, inference is not infallible: it is possible (albeit unlikely) that the smoke is coming from some non-fire-related source that I am unaware of.

The third pramāṇa is analogy; here we can use previous experience to allow us to reason that something is similar to something we already know (i.e., to argue from the known to the unknown.)  Again, this is not infallible, as the analogy may be deficient.

Finally, the fourth pramāṇa is authority; here we take the word of someone we have determined to be trustworthy by other means.  For example, very little of my knowledge of physics comes from direct perception of experiments; rather, I take the word of relevant authorities (professors and textbook authors, etc.) 

Now, according to the Nyāya, all reliable knowledge comes from one or more of these pramāṇa-s.  Thus, if I were to tell you that I am wearing blue underwear, since you are unable to confirm this via direct perception, you need to rely on other means; you can use your knowledge (via previous perception) that blue underwear is commonly sold in stores, and you can rely (if you wish) upon me as an authority concerning my own clothing choices.  If, on the other hand, I said that I was wearing underwear made from blue unicorn hide, you would likely not accept my testimony, as this conflicts with other knowledge you have reliably built up (that unicorns do not, in fact, exist.) 

Note that in both cases, it is still a matter of judgment; we are still talking about what you are willing to believe, not about what has been proven beyond conceivable doubt.  And, since all four pramāṇa-s have been shown to be fallible, one can reasonably ask whether it is possible to ever prove anything beyond conceivable doubt. (There are differing opinions on this, but that's a matter for another day.)

So, to return to your question: when faced with truth-claims from any source (including those from entities not bounded by this world) one must use the aforementioned methods to evaluate the coherence of those claims with other knowledge previously found to be reliable by those same aforementioned methods.
No, "evolution" has not reached a plateau

It doesn't make sense to conceive of a "plateau" when it comes to http://en.wikipedia.org/wiki/Natural_selection evolution by natural selection outside of a situation where a particular species is subject to relatively little evolutionary changes over a long period of time because the environment is relatively stable. Only in that sense does the term "plateau" make sense (and is actually used) in evolutionary biology.

Evolution by natural selection cannot be halted or turned off, slowed down or sped up. Those concepts do not have such properties. Adaptation, on the other hand, can be slowed down or sped up, depending on the speed at which the environment changes as well as the rate of reproduction, and the rate at which mutations which occur. Adaptation is the property of species I think you mean to refer to. What I think you are really getting at is:

Is it possible for a species to adapt in such a way that is not beneficial?

The answer to this is tricky.  


First, recall that "fitness" is a relative term. Generally speak, organisms are more fit if more of their offspring survive to reproduce than than others. It doesn't really have anything to do with the "fitness level" of the parent organism, i.e. how long they live, how strong they are, etc. It's all about the successful propagation of genetic material.  
Second, recall that adaptation to an environment is based on an essentially random process: mutation, crossing over,  etc, are essentially arbitrary, such that even when an environment changes, it may not always happen that a species has the correct mutations that will benefit it and allow it to survive the new change. More often than not, when relatively radical changes come, the species simply dies; this is call exictinction. You don't hear about it as much so people generally assume most species adapt successfully to their environment, but this is simply not true. It is estimated that http://www.lassp.cornell.edu/newmme/science/extinction.html 99% of all species that ever lived are extinct.


With these in mind, is it possible for a species to evolve in such a way that their adaptations are not suited for the environment? Absolutely, and this is particularly true in rapidly changing environments. With advances in medicine, we prevent the deaths of millions of people every year who would have otherwise died from some crippling genetic deficiency, and in many cases they grow up and pass on those genes.

The question which remains is whether this is a good or bad thing. I actually wrote a paper on that... Unfortunately, it's really outside the scope of this question, but see http://www.eugenics.net/papers/caseforeugenics.html Marian Van Court for a start of where I think your reasoning is taking you... (Note that her reasoning is not entirely solid and I definitely don't prescribe to her views)
"Worth Knowing" is not an objective notion, it is entirely relative

The notion of "worth knowing" is entirely dependent on circumstance. It is not worth knowing to me that there is 600 mbps of traffic going through Server X right now, but to the administrator of that server, that's probably a huge deal. Not worth knowing to me, very much worth knowing to him.

The weight of knowledge acquisition

Are all facts worth knowing? At zero cost, sure (i.e. omniscience), but as Michael points out, as soon as there is even the slightest burden acquiring any facts, there become a huge (essentially infinite) number of facts which are no longer worth knowing.

The weight of knowledge maintenance

The human brain, being a finite physical entity, actually has limits in terms of the amount of raw data it can store. No one has ever reached that limit yet (as far as we know), but theoretically schools are going to pack more and more knowledge into kids brains and newspapers will be packed with more than country or global news but galactic news, and perhaps one day storage may be an issue. Even if you were somehow privy to all the facts in the universe, you would lack the space to store them all. Some facts would simply take a lifetime to acquire or not even be possible in practice (http://en.wikipedia.org/wiki/P_versus_NP_problem P = NP).

Your additional questions not already addressed above:


Is it possible to quantify the number of facts a person knows?
Theoretically, yes, as the brain is a physical organism it is not outside the scope of observation. In practice, we do not have this technology and we probably won't have it for at least another 100 years. You could do it the old fashion way and get a rough count that would provide a relatively consistent measure across the board though; simply have people take every single subject test in the world and count up the questions they got correct. It would be very rough, but have internal consistency. (No, it would not get at little facts like "my sisters blanket has 2 juice stains on it", etc, but general stuff, yes).
If an event that has not yet occurred, can knowledge of that event be considered a fact? That is, is the future deterministic?
If the world is deterministic, then yes, it would be a fact. This is, of course, highly debated however (whether the universe is deterministic or not).

A work I would highly recommend is a book by Gilles Deleuze called http://rads.stackoverflow.com/amzn/click/0231056699 Nietzsche and Philosophy, which is a cautious, systematic and intensely earnest reading of Nietzsche's oeuvre. Brisoline writes about this work (in her review of the text in The European Legacy) that "[t]he fecundity of this reading and the breadth of its implications can hardly be overestimated." 

Since it is rather central indeed, the question of suffering is addressed in some depth. Google says the word shows up on 24 pages; I'll quote part of the first result to give you an idea of the style:


  In Dionysus and in Christ the martyr is the same, the passion is the same. It is the same phenomenon but in two opposed senses (VP IV 464). On the one hand, the life that justifies suffering, that affirms suffering; on the other hand the suffering that accuses life, that testifies against it, that makes life something that must be justified. For Christianity the fact of suffering in life means primarily that life is not just, that it is even essentially unjust, that it pays for an essential injustice by suffering, it is blameworthy because it suffers. The result of this is that life must be justified, that is to say, redeemed of its injustice and saved. Saved by that suffering which a little while ago accused it: it must suffer since it is blameworthy. These two aspects of Christianity form what Nietzsche calls 'bad conscience' or the internalization of pain (GM II). They define truly Christian nihilism, that is to say the way in which Christianity denies life; on the one side the machine for manufacturing guilt, the horrible pain-punishment equation, on the other side the machine to multiply pain, the justification of pain, the dark workshop. Even when Christianity sings the praises of love and life what curses there are in these songs, what hatred beneath this love! (Gilles Deleuze, Nietzsche and Philosophy 7)


Keith Ansell Pearson also has http://rads.stackoverflow.com/amzn/click/039332821X an excellent entry on Nietzsche in the "How to Read" series that is well worth a look.
Rovelli claims that time is an illusion, deriving from the incompleteness of knowledge.

Since that incompleteness of knowledge is a permanent (and necessary) state of affairs, his hypothesis does us no good at all-- we are still firmly stuck inside of time, illusory as it may be, with no hope of escape.  And thus, for us trapped within the illusion, Zeno's paradox remains unaffected.  The fact that his theory maintains that the difference between the past and the future is illusory doesn't change the fact that we perceive (and cannot help but perceiving) a significant difference between them.

Put another way: Rovelli appears to have proposed an untestable hypothesis which, even if true, would have no bearing on the majority of philosophy as practiced.  

A few general rules of thumb: 1) getting your philosophy from a physicist is akin to getting your physics from a philosopher; 2) Forbes magazine is not a good source for physics or philosophy: 3) if it has the word "Quantum" in it, it can usually be safely ignored.
Obviously, the way one approaches this question will vary depending on the epistemological tradition one is working within.  

From the standpoint of the Nyāya school of classical Indian epistemology, there are exactly four epistemological warrants (Pramāņa -s):


Direct Perception
Inference
Analogy
Authority


Now, clearly Perception is not in play in this case, but the other three form the means of justification available to us when reading an answer.

Inference and Analogy are relatively straightforward: if the argument in the answer is logically cogent and sound, we can accept the answer, and we can similarly evaluate the answer by means of analogy to other knowledge we already have. Neither of these are specific in any way to StackExchange, of course-- they are the means we would use to evaluate any answer given to us by any third party.

What is somewhat different here is the means of evaluating authority.  Although external credentials (such as graduate degrees or publications) are not made prominent here, the upvoting and reputation system give a means of evaluating the relative authoritativeness of the answer (and answerer) in the eyes of the community.  And that community evaluation, of course, is in turn based upon the same list of Pramāņa -s  as above.   
First of all, I'm surprised this was migrated from mathematics; it seems to me to be a much better fit there than here in philosophy.  That being said:


  In short, his point is that it doesn’t make sense to talk about the set of even numbers and the set of all integers as if they were two separate sets. They are essentially the same set, only with different names, or rather, the same set as seen from different points of view.


That's not a refutation of Cantor, that's a restatement of it.  If the set of even numbers is the same size as the set of integers, Cantor prevails.

There is an enormous cottage industry of Cantor cranks-- amateurs without a substantial background in mathematics who think they have a way to refute Cantor.  I am not familiar with Olavo de Carvalho, but a perusal of his Wikipedia entry suggests that he falls firmly into this category.

EDIT:

Since the question was updated to draw attention to a specific part of de Carvalho's argument, let's look at that in more detail.


  In short, his point is that it doesn’t make sense to talk about the set of even numbers and the set of all integers as if they were two separate sets. They are essentially the same set, only with different names, or rather, the same set as seen from different points of view. According to him, this is the fallacy upon which Cantor’s proof is based. Is he right? 


Is he right?  No.  What is is involved in is mere wordplay.  The set of even numbers is a set, and it has the same cardinality as the set of integers.  The set of prime numbers is also a set, with the same cardinality, and this is clearly not a case of "counting by twos".  His objection is nonsensical.

Again: de Carvalho has all the earmarks of a crank.  Until his "refutation" is published in a peer-reviewed mathematical journal (and if it were a valid refutation, the math journals would be fighting over the publication rights) I see no reason to take it seriously.

If you are interested in Cantor crankery in general, you'll find some amusing reference cases http://scientopia.org/blogs/goodmath/tag/cantor-crank/ here and http://web.archive.org/web/20120507034149/http://scienceblogs.com/goodmath/bad_math/cantor_crankery/ here.
No.  Lying implies an intent to deceive.  To speak a falsehood is not necessarily to lie.

As for the truth-status of the statement, it's not at all paradoxical; it's just temporally bound.
Since you raise the question in terms of what makes sense, I think you are looking for a meaning theory as opposed to an ethical theory.  Pragmatist theories of meaning are those which derive meaning from the consequences or commitments of assertions.  Those consequences and commitments can themselves be linguistic (in which case they are inferential commitments) or can be commitments to non-linguistic actions.  Meaning is constituted by these.

Michael Dummett first identified the possibility of a pragmatic theory of meaning in his paper 'Truth and Meaning'.  He contrasts the theory against a verificationist theory of meaning, a theory which derives meaning from what would be required to justify an assertion.  The two are actually compatible, as long as they are in harmony in terms of the meanings that each one determines.   Harmony is a desideratum of such theories.

The problem with verificationist theories of meaning as they existed in positivism and operationalism was that they were inherently reductionist - verification was taken to be reducible to sensory or scientific terminology (what Carnap called 'protocol statements'), and such reduction is now thought impossible. More recent verificationist theories of meaning make no such attempt at reduction but define verifications in broader epistemological terms.  

Carnap et. al. wanted to show that metaphysical statements, like the ones about free will, are meaningless because they are unverifiable.  The more recent verificationist and pragmatist theories explored by Dummett et. al. are inherently antirealist, Dummett argues, because they make truth dependent upon an act of verification or on the outcomes of assertions, i.e. dependent on human knowledge.  Metaphysics now turns out to be a consequence of the theory of meaning, not meaningless.  Dummett argues this at length in his brilliant book The Logical Basis of Metaphysics.

In favour of pragmatist and verificationist theories of meaning, Dummett argues that other theories which make truth independent of human knowledge cannot explain what knowledge of language (and meaning) consists in.  Against them, their antirealism suggests that the past is only as real as the imprints it leaves upon present observers and language users. Both positions are extremely problematic.

Pragmatist theories of meaning are not to be confused with pragmatist theories of truth such as those proposed by William James and Richard Rorty.
I'm far from an expert on the matter, but here's my take:

Overall, myths play a very large role in Plato's writings, and it seems to me that the closing myths serve as a sort of "Noble Lie," a concept discussed in The Republic. 

For example, the myth of Er in The Republic likely does not represent Plato's view on the matter (the myth being fairly arbitrary in the details of its epistemology in comparison to the rest of the book). Rather, I think it's something Plato would like the greater population to hear to understand his general idea on morality and perhaps even eschatology. 

From his writings, it's apparent that Plato believes in a soul, and the purpose of these myths is to encourage people who need motivation to work on improving their souls, with the promise of a good future after death. 

The http://plato.stanford.edu/entries/plato-myths/#Myt Stanford Encyclopedia of Philosophy has a page on Plato's myths, and in part 6, comments that


  He would have had strong reasons for avoiding the use of myths: they are not argumentative and they are extremely visual (especially those he invented, which contain so many visual details as if he would have given instructions to an illustrator). But he didn't. He wanted to persuade and/or teach a wider audience, so he had to make a compromise.


Similarly, the http://www.iep.utm.edu/phaedo/#SH3d Internet Encyclopedia of Philosophy's page on the Phaedo, part 3 d., makes a note about the closing myth:


  At the end of his tale, Socrates says that what is important about his story is not its literal details, but rather that we “risk the belief” that “this, or something like this, is true about our souls and their dwelling places,” and repeat such a tale to ourselves as though it were an “incantation” (114d).  Doing so will keep us in good spirits as we work to improve our souls in this life.  The myth thus reinforces the dialogue’s recommendation of the practice of philosophy as care for one’s soul.


In summary, the purpose of the closing myths in Plato's dialogues is likely to convey a message to the general public and educate them on his philosophy, and influence them to follow Plato's moral model. 
As I understand it, Theaetetus offers that 'knowledge is perception.' Socrates then adopts that assumption and explores the implication of such a world where knowledge is perception. In this world it follows that, as protagoras says, 'man is the measure of all things.' this is because man is doing the perceiving. It also follows that the world is never still and constantly changing because their perceptions last momentarily, the way we perceive a thing is constantly changing. So one theory (the latter - protagoras' theory) is an implication of the other theory (the former - knowledge is perception). The examples all describe/give insight to a world governed by the fact that knowledge is perception, ie. what we know is based on our perceptions. 

In this world, you are right, nothing is absolute. An example Socrates uses to emphasize this point is the taste of wine when one is healthy as opposed to the taste when one is ill. The same wine taste differently, so we have a dilemma of deciding how the wine 'truly' tastes (is there a 'true' taste for that wine?). But in a world where knowledge is perception, we are always unerring. This is because everything is pragmatic. For example the wine tastes bitter for me. We don't contradict each other if the wine tastes different, because it tastes different for you. 

From these examples and descriptions we anticipate many problems and innadequacies. But the discussions (subsequent theories and examples) are just implications of the definition 'knowledge is perception.'
In my opinion, you were asked a very good question about when NOT to use conditional probability.

The first thing to think about when being tempted to use conditional probability is: are the two events actually correlated?

If they are correlated, you can go on and do all the complicated math.

If they are not correlated, that is, if the two events are totally independant, then you only have to care about the probability of the one event, regardless of the other.

In the problem you were given, the fact that the shrouded person has a brother is totally independant from his/her sex determination. These are totally not correlated. So the probability that he/she is male/female is the same as for the rest of the human population: about 50,3% for male 49,7% for female.
The first situation is an exhaustive disproof of existence, and is (if I understand what you have written) sound in its logic. The second is perhaps reasonable, and (again if I understand your writing) is called http://en.wikipedia.org/wiki/Induction_%28philosophy%29 inductive reasoning, it is however not logical- not a valid deduction, as was explosively pointed out by Hume in http://en.wikipedia.org/wiki/An_Enquiry_concerning_Human_Understanding An Enquiry Concerning Human Understanding. As such, in 'the finite case' they are profoundly different, one being logically valid, the other not.

When the bag of balls becomes infinitely large, however, the situations become nearly identical in practice, as in finite time one can never check every ball to see that it is not red, and so some inductive reasoning is necessary in both cases. 

In the latter case, however, they are not entirely the same- for the first situation is still slightly better than the second. In the first situation, we make a hypothesis 'there are no red balls in the bag' that we subsequently test in a way that could falsify it: in the second, since we do not repeat the experiment after we make our hypothesis, our hypothesis is not fallible (this is important http://en.wikipedia.org/wiki/Falsifiability for reasons articulated by Karl Popper amongst others).

http://en.wikipedia.org/wiki/Gary_Francione Gary Francione is a strong critic of the idea that humans can own animals - a master-slave relationship that you may want to read about in his works.
Animal Rights and Wrongs, by Roger Scruton, approaches the idea from a legal (social contract) point of view.
In his Discourses, Descartes established the idea that animals are automatons; this was perhaps the first time that the relationship between humans and animals was considered, with Descartes' asserting that humans are superior because of their emotions.
Readings in Animal Cognition, by Marc Bekoff and Dale Jamieson, offers 24 different essays, many with philosophical approaches.
The Human-Animal Relationship, by Francien Henriëtte de Jonge and Ruud van den Bos, analyzes many different cultures.
Ethics, Humans and Other Animals, by Rosalind Hursthouse, is a useful analytic work, although perhaps a bit low-level.

Your second premise could be http://en.wikipedia.org/wiki/Vacuous_truth vacuously satisfied- i.e. there might be no illogical men in the world: without a http://en.wikipedia.org/wiki/Witness_%28mathematics%29 witness (guaranteed only when you add the aditional premise ∃x~L(x)), the existential quantifier in your conclusion would not be true (in the sense of Tarski). As this remains a possibility, Caroll's argument is indeed not formally logical- this is, I suppose, what one might expect from someone writing 40 years before sentential calculus was formally axiomised.  
There are many explanations about the epistemology from a variety of sources. I suggest you read this http://plato.stanford.edu/entries/epistemology/ introduction about epistemology.

To make your reading easier, i will try to explain related to this introduction. I will try to explain the simple structure of epistemology with simple explanation as well. Hopefully you can understand the basic structure of epistemology and further having ability to expand understanding at any directions with reasonable open minded.

Epistemology is the branch of philosophy that is expected to help us to understand anything at all about knowledge.

The final goal of the study of epistemology is expected that we can know the existence of a knowledge.

Some limitations of epistemology can be determined by understanding:


What is knowledge?
Relation to belief
Also how to obtain it.
And the farthest limits that can be achieved by epistemology.


http://plato.stanford.edu/entries/knowledge-analysis/#JTB What is knowledge? Knowledge is justified true belief.


  
  Something is true and we believe it proven (justified) to be useful or we believe (and justified) that something is true, therefore we found knowledge.
  We believe in something, because something is justified as true and useful, then it's a knowledge
  


http://plato.stanford.edu/entries/knowledge-analysis/#Bel What is belief? If knowledge is justified true belief, then how can someone exclude "belief" to make a separated definition? (since "belief" already within knowledge)

Some philosophers assert knowledge can be gained without belief. Something can be considered as knowledge without obligation to belief it.


  
  Whether a statement is true or not, or whether something is true or not (because lack of awareness), but once we perceive it, then it's already a knowledge.
  By defining knowledge as something true or false, a belief has its own place to be defined. It's a true knowledge. What i believe is a true knowledge.
  


http://plato.stanford.edu/entries/knowledge-analysis/#JUS Justified

It's about the way we believe in something. We believe in something because something can be justified reasonably.

The discussion about how to provide better justification is debatable. From http://plato.stanford.edu/entries/knowledge-analysis/#GET The Gettier Problem, http://plato.stanford.edu/entries/knowledge-analysis/#REM Reliabilism and many more.

But the essence is, because something may be considered to be true at different point of view, therefore there is different justification whether something is true for someone may be different for someone else. There is no general aggreement of what is the correct justification.

Concludes:


  
  Knowledge is something true because we believe it through justification (reasonable justification), OR
  Knowledge is something true or false and belief is the true knowledge.
  


How to obtain knowledge?

Further we can expand our understanding about justification on knowledge by understanding how to obtain knowledge through http://plato.stanford.edu/entries/apriori/#NatPriJusKno a priori & http://plato.stanford.edu/entries/apriori/#WhaSorProPriJusKno a posteriori justification.


Kant said that a priori knowledge is “knowledge that is absolutely independent of all experience” (Kant 1787, 43)

We can have a correct understanding because we know something is correct without experiencing something outside ourselves to justify the correctness.
“Water is H2O” is a necessary truth, but it can only be justified empirically, that is, a posteriori

We are sure of something because something must be justified through empirical experiences.


What is the farthest limits that can be achieved by epistemology?

It depends on how far for someone define empirical. If empirical is anything that can be perceived by our five senses, then our knowledge may be widen as far as what can be perceived by our five senses. But if someone believe in sixth sense then knowledge can be more widen then usually known through the five senses. We can learn this through http://plato.stanford.edu/entries/illumination/ divine illumination.

My criticism is to remind us to define proposition as dependency to avoid us from contradiction and paradox. These are my point of view to make a better comparison to widen our possibilities to understand epistemology. https://philosophy.stackexchange.com/a/3113/1955 Knowledge & Belief, http://seremonia.blogspot.com/2012/07/dependency-of-proposition_06.html Dependency of Proposition & http://seremonia.blogspot.com/2012/07/is-priori-knowledge-possible.html Is a priori knowledge possible?.

It's not a complete introduction on epistemology, but may be it's a start to make easy understanding to explore further within possibilities of epistemology.
First, I think it's important to point out a flaw in one of your conclusions:


  Yet, if he is able to destroy himself, then he is no longer omnipotent because he can be destroyed. This, therefore creates a paradox.


This is in fact (to my logic) not true. It is not a paradox for an all-powerful being to no longer be all-powerful by destroying himself; then, he would simply no longer exist, so it would not be a case of "an omnipotent God that is not omnipotent (which is a paradox)," but rather "an omnipotent God that no longer exists (not a paradox)." 

Thus, something omnipotent (and only omnipotent as a premise) should be able to destroy itself, because it has the power to do so, and would not cause any logical paradoxes in doing so.

However, that is only if omnipotence is the sole premise. Conversely, you mentioned several premises to the definition of God, one of which seems particularly important. I think what renders the statement "God destroys himself" problematic is your following statement:


  Eternal and necessary existence.


This is where your paradox comes in:


  What happens when an unstoppable force meets an immovable object?


This now becomes:


  Can a necessarily eternal God destroy himself?


This is the crucial statement that your question is asking (when reduced to the relevant premises).

As presented, the answer is intuitively no: God necessarily being eternal, he cannot cease to exist. However, this implies that he is not omnipotent, and so your question is a variation of:

The Omnipotence Paradox

The omnipotence paradox, in short, is this:


  Can God create a stone that he cannot lift?


If the answer is "yes," then God will have created something out of his own power to control, therefore no longer being omnipotent. If the answer is "no," then God is simply not omnipotent to begin with.

The Wikipedia page on the http://en.wikipedia.org/wiki/Omnipotence_paradox Omnipotence Paradox explains this paradox and several approaches to it. It is apparent that the question itself is a matter of controversy. As far as I am aware, there is far from a universally accepted answer. However, I will present several responses in some detail:

Logical Fallacy:

Some believe that the question itself is logically flawed. Although "childish loophole" may not be the appropriate term, this is indeed an illogical product of the English language. 

It's not that an eternal God cannot destroy himself and therefore is not omnipotent, but that the proposition itself is logically impossible. Because your definition of God is one that must be eternal, it is logically absurd to ask if this God could destroy himself. It is akin to asking what the radius of a square is, or to apply the quadratic formula to a cubic function (as far as my education goes these are logically flawed).

Absolute Omnipotence:

Others believe that an absolutely omnipotent God is higher than the rules of logic and that such paradoxes are irrelevant. It does not matter what does or does not make sense to us, because our language simply cannot represent the idea of omnipotence. Thus, regardless of our logic and intuition, God simply can do whatever he wants, no exceptions. 

Impossibility of Premise:

An entirely opposing approach taken by many is the idea that the paradox itself is unresolvable. This group sees the paradox as significant evidence against the existence of an omnipotent God; since the concept of omnipotence raises many contradictory situations, it is simply the case that an omnipotent entity cannot exist. To assert that it can is to allow for Omnipotence Paradox, an absurdity.

These are the primary responses to your question, and it is important that you consider each against another in your further reflection. If I may add some subjectivity, I prefer the first response :)



Other References: 


The Stanford Encyclopedia of Philosophy has an extensive page on http://plato.stanford.edu/entries/omnipotence/ Omnipotence.

It's a statistical question. You have X cards which are spread among X slots. 

Every card has the same probability to fit into the first place, the second, the third and so on. 

You can simplify the board to fit only 2x2 cards, and then exhaustively enumerate all possibilities: 

4*3*2*1=24


You can write the possibilities down, in a systematical manner: 

1 2 3 4
1 2 4 3 
1 3 2 4 
1 3 4 2
1 4 ...
2 ...
3 ...
4 ...


The digits are combined, building a 4-digit number in increasing order. Every number would symbolize one of the specific cards (Wood, Sheep, ...), even if they are repeated.

Every number represents one different way, how the cards can be placed, which all occur with the same probability. For the gameplay, it wouldn't matter which of the wood-cards comes first - they are all equal. But to compare the distributions - spreading all cards over the table or mixing them, and playing them sequentially, leads to the same result and is more easy to understand. 
I'd go for a combination of #1 and #3.

The context is polemical; Nietzsche is showing an argument between him and (one or more) putative interlocutors, who Nietzsche responds to.  The "free thinker" or "free spirit" in the quoted passage is an opponent who Nietzsche is in the process of dismissing, and does not represent his own views-- and the scare quotes around "free spirit" helps indicate this, if there was any doubt from the context.

As an aside, this is one of the most difficult things about reading Nietzsche-- for almost any passage (taken out of context), one can find a corresponding passage (taken out of context) that argues the exact opposite.  Thus, to attempt to assess Nietzsche's intent, one must read the arguments with an assiduous attention to context-- hence Nietzsche's claim that "philology is the art of reading slowly."
The (https://en.wikipedia.org/wiki/Bakhshali_manuscript https://en.wikipedia.org/wiki/Bakhshali_manuscript) [Bakhshali manuscript] is one of the oldest(3rd century AD) recorded Indian mathematics. It was discovered by a local peasant in the Pakhtunkhwa region of Pakistan. The region was under the control of Buddhism (see (http://whc.unesco.org/en/list/140 http://whc.unesco.org/en/list/140) [Takhtbai ruins]). It dates back from 500 years before Brahmagupta. The zero dot symbol is used in the manuscript instead of a ring symbol.https://i.stack.imgur.com/v13JJ.jpg 
To answer your question, or at least get at some sort of picture, let's consider the following. What is random? Hmmm. Without getting into the details of the matter, or philosophical implications, we may define "random" in a very intuitive manner as this will mostly do for a discussion of this scope. Let us then propose that an event which is "completely" random is one for which it is logically (or formally, i.e. in the sense of mathematical rigor) impossible to associate any rule, pattern, or reason. This is, of course, where it all gets tricky.

In the way "random" has now been defined, it may be possible to generate an event, at least cognitively, which would be viewable as truly random. To take your example a bit furhter, let us conduct a thought experiment. Imagine we're walking down a busy city street. We decide to ask every person that passes by, and decides to stop and give us five seconds of their time, to pick a number. By this, we may construct two sets. Let set X denote the numbers we record, in the order we encountered them; and let Y denote the set of indicies of the people who stopped and gave us a number. So, for example, if the third, seventh, and twelfth person we asked stopped and gave us a number, Y = {3, 7, 12}. Certainly, the sets X and Y may not be random in the sense that we have defined. 

But, then we may ask the question why the sets have the particular pattern or rule associated with it. Could there not have been different sets? And so, by our criterion for true randomness, the reason the sets X and Y are what they are, is random. I can't come up with the proof for the criterion off-hand, but I suspect Goedl's theorem's in there somewhere.

It is worth noting that by our definition, it may be the case that no event which occurs in nature could be viewed as random. So, that may answer your question about there being anything truly random in the universe. On the other hand, we may very easily have events that qualify as truly random as long as they exist in some "virtual" reality as the one discussed in the example above. But, it's truly an understatement when I say that that's a topic to be discussed another time.
There's a passage in The Gay Science (136) that may help to illuminate what Nietzsche means by referring to the moral genius of the Jews.  He states their genius consists of a "more profound contempt for the human being in themselves than any other people."  Also, later (in 140), Nietzsche regards Jesus as "not refined enough...being a Jew" to undertand that a God that is an arbiter of justice is not an object of love.  I suppose that Nietzsche in one sense admires the Jews insofar as they are not as hypocritical as he deems Christians.

My understanding of Nietzsche's view on Judaism is influenced in large part by Walter Kaufman's insightful annotations and suggested cross references.  He reminds the reader to recall the historical context of Nietzsche's comments:


  ...some of Nietzsche's comments on Jews... are bound to strike many of today's readers very differently from they way they struck - and were meant to strike - Victorian readers.  The modern reader is apt to find evidence of anti-Semitism where Victorian readers were shocked by the suggestion that Jesus was considered a Jew not only in name... in The Antichrist: Jesus and Christianity were "Jewish" precisely in the sense in which nineteenth-century Christians used to look down on what was "Jewish."


Kaufman then goes on to suggest referencing 248, 250, and 251 in Beyond Good and Evil as well as 135 and 140 in The Gay Science.  

Also, later in The Gay Science (348) I found a passage on scholarship in which Nietzsche expresses his belief that Jews hold "a high regard for logic" and that "Europe owes the Jews no small thanks for making people think more logically, and for establishing cleanlier intellectual habits."  He goes on:


  Wherever Jews have won influence they have taught men to make finer distinctions, more rigorous inferences, and to write in a more luminous and cleanly fashion; their task was ever to bring a people "to listen to raison."


Although this has less to do with any sense of moral genius, it still shows a respect or admiration, perhaps, by Nietzsche for Jews.
So in mathematics we measure the cardinality of a set with bijective functions/maps or one to one correspondences.

For example suppose you know that there are 100 seats in some movie theatre. When the movie starts, suppose it is a hit movie and fills up. In other words, there is a person for every seat in the theatre. Without counting the number of people, we can deduce that there are 100 people in the theatre. This is an example of a one to one correspondence (also known as a bijective function or map) between people and seats in the theatre, i.e. the cardinality of the people is the same as the cardinality of seats because for every seat there is one person sitting in it, and for every person there is one seat that they are sitting on.

There are two types of sets, countable and uncountable sets. Countable sets can either be finite or infinite, but uncountable sets are always infinite just a 'larger' infinite. 

More precisely, A set X is finite if there is a bijection between the set X and the finite whole numbers, N_n={1,2,3,...,n}. If X is not finite, then X is infinite (they mean the same thing). Now concerning infinite sets, there are two types, countable and uncountable (here is the difference you seek). An infinite set is defined as countable if it is in one to one correspodence with the natural numbers, N={1,2,3,...,n,...}. An infinite set X is uncountable if there exists no bijective map between X and the natural numbers N. Note: Finite sets are also countable.

I think examples will be helpful here: 

The set A={1,2,3,4,5} is finite and countable.

The set of integers is considered *infinite *and countable.

The set of real numbers (rational numbers and irrational numbers) is infinite and uncountable.

You can, informally, think of a countable set as a set where you are able to potentially list all of the elements of the set, and think of an uncountable set as saying there is no list that contains all the elements of the set. Naively, we can see that the real numbers are uncountable, because between any two real numbers there is another real number. Whereas there is no integer between the numbers 1 and 2.

Hope this helps!

Links for further reading:

http://gowers.wordpress.com/2011/11/28/a-short-post-on-countability-and-uncountability/ http://gowers.wordpress.com/2011/11/28/a-short-post-on-countability-and-uncountability/

http://en.wikipedia.org/wiki/Cardinality http://en.wikipedia.org/wiki/Cardinality
No expert on the subject, waiting for some great answers myself. This is my take: 

I would sustain your interpretation. The claim that "learning to be able not to be good" is an ethical precept is odd. The Prince is all about cutting off political philosophy from moral precepts, a mix that was customary in virtually all Catholic and scholastic conceptions before him. From this older perspective Machiavelli's move was seen as highly immoral, of course. The possibility of metaethical moral nihilism simply wasn't considered a conceptual option in ethics at the time.

Thinking of it, I see the possibility that an additional interpretation is possible: Machiavelli does not only advocate an instrumental use of reason (most effective means to given ends regardless of moral precepts), but he also puts forward a set of moral goods (the ends of self-maintenance, power, etc.) that the prince should hold. Now, if this is a normative move (i.e. if Machiavelli advocates those moral goods himself) depends on the question whether Machiavelli is introducing them on its own or if they where already customary in the political philosophy of his time. The former is a normative claim, the latter would make The Prince a simple conditional argument ("Given these ends, what are the most effective means?"). I don't know what the answer is here though.

This additional interpretation, to be sure, is not the same as your teacher's. In a nutshell, your teacher seems to attribute to Machiavelli the view that to employ exclusively instrumental reason is a moral good (as opposed to simple effectiveness). Again, this seems to me an odd claim to make. What this additional interpretation considers is whether Machiavelli presupposed or advocated the valued ends attributed to the prince.
Marx didn't think that the state should have any role in the economy. The essence of his philosophy is that in the ultimate classless society, the state will have "withered away":


  "State interference in social relations becomes, in one domain after another, superfluous, and then dies out of itself; the government of persons is replaced by the administration of things, and by the conduct of processes of production. The State is not "abolished". It dies out...Socialized production upon a predetermined plan becomes henceforth possible. The development of production makes the existence of different classes of society thenceforth an anachronism. In proportion as anarchy in social production vanishes, the political authority of the State dies out. Man, at last the master of his own form of social organization, becomes at the same time the lord over Nature, his own master — free."
  – Engels (http://www.marxists.org/archive/marx/works/1880/soc-utop/index.htm Socialism: Utopia and Scientific, 1880)


He and Engels both argued that the state was just the executive committee of the upper classes, and that once the evils of capitalism were eliminated, the state would go along with them.

Marx's earlier writings were even more clear in their avowed hatred of the state. For example, in the Communist Manifesto, he argued that the state was a "parasitic" institution that was http://en.wikipedia.org/wiki/Base_and_superstructure built upon the superstructure of the economy and that actively worked against the public interest. In particular, the Marxists charge that the state is the primary instrument of repression of the lower classes, serving primarily to prop up the power of the ruling (elite) classes:


  Each step in the development of the bourgeoisie was accompanied by a corresponding political advance of that class. An oppressed class under the sway of the feudal nobility, an armed and self-governing association in the medieval commune: here independent urban republic (as in Italy and Germany); there taxable “third estate” of the monarchy (as in France); afterwards, in the period of manufacturing proper, serving either the semi-feudal or the absolute monarchy as a counterpoise against the nobility, and, in fact, cornerstone of the great monarchies in general, the bourgeoisie has at last, since the establishment of Modern Industry and of the world market, conquered for itself, in the modern representative State, exclusive political sway. The executive of the modern state is but a committee for managing the common affairs of the whole bourgeoisie.
  – Marx (http://www.marxists.org/archive/marx/works/1848/communist-manifesto/ch01.htm Communist Manifesto, 1848)


  However, this supposes that the structure of reality should be explainable or understandable, for which I see no a priori reason.


That's the problem, or rather, the reason why infinite regress isn't a problem to you.  Infinite regress doesn't explain anything, which is why it is a problem for people looking for explanations.

Note that this problem isn't limited to infinite regress; in fact, all explanatory systems will ultimately reduce to one of http://en.wikipedia.org/wiki/Agrippa%27s_trilemma three (unsatisfactory) cases, of which infinite regress is but one. 
What I would say about the above quote is that is is based upon an etymological error.

Māyā and mātrā are based upon two completely different Sanskrit roots.

I certainly hope his physics is based upon more careful research than this. 

Attempting to essentialize the differences between "the West" and "the Orient" is a bad idea to begin with, but to do so based upon a spurious etymology seems reckless beyond comprehension.
I would add to Joesph Weissman's mention of Thrasymachus that http://en.wikipedia.org/wiki/Glaucon Glaucon (who comes later in The Republic) presents the story about the http://en.wikipedia.org/wiki/Ring_of_Gyges Ring of Gyges and argues that ethics is just a sort of social convention.

The SEP's entry on http://plato.stanford.edu/entries/moral-relativism/ moral relativism says:


  In the classical Greek world, both the historian Herodotus and the sophist Protagoras appeared to endorse some form of relativism (the latter attracted the attention of Plato in the Theaetetus)... Among the ancient Greek philosophers, moral diversity was widely acknowledged, but the more common nonobjectivist reaction was moral skepticism, the view that there is no moral knowledge (the position of the Pyrrhonian skeptic Sextus Empiricus)


In addition to Sextus Empiricus, some other famous Greek skeptics were Pyhrro and Carneades. 
The quotation is from Guru Nanak, the founder of http://en.wikipedia.org/wiki/Sikhism Sikhism—a monotheistic religion originating in the 15th century as an offshoot of Hinduism and Islam.

Guru Nanak was a mystic, which, in a religious context, is one who advocates the practice of pursuing and has the knowledge to themselves achieve a personal relationship (or "one-ness") with God. Mysticism concerns aspects of reality that lie beyond normal human perception, including experiencing the presence of and communion with God. As such, Guru Nanak naturally emphasized solitary meditation.

The specific quotation you've found simply reflects Guru Nanak's view that it is not possible to realize either God or one's self without the aid of a "guru", or experienced religious guide. Breaking it down piece by piece…


  Let no man in the world live in delusion.


You should not be fooled into thinking something else than that which I'm about to say. The following point concerns an essential truth, and no one should allow themselves to be misguided into believing something different.


  Without a Guru none can cross over to the other shore.


You need the aid of a guru (an experienced religious guide/teacher/master) who can teach and guide you. Without such a person, you nor anyone else will be able to achieve salvation or a relationship with God. 

Basically, to put it in vulgar terms, Guru Nanak is saying that you've got to have a guru, or else you're going to be screwed (i.e., not be able to fulfill their ultimate religious destiny in the afterlife).
(I'm not an expert on Sikh beliefs regarding the afterlife. My research indicates that they believe in reincarnation, as opposed to a heavenly paradise. So in that context, the quotation probably means that you will be unable to be reborn.)

The teachings of Guru Nanaka live on in the Sikh religion. Just before his death in 1539, he appointed one of his followers as his successor, entrusted with carrying out the principles he had elucidated. These principles and responsibilities were them passed down through a long line of Sikhi gurus. Followers of Sikhism believe that all subsequent gurus possess the divinity and religious authority of Guru Nanak, and therefore guide one to both self and God.
Skinner, of course, believed that http://en.wikipedia.org/wiki/Beyond_Freedom_and_Dignity free will is an illusion, so there's nothing to take away. (Hence this conditioning is not immoral.) His book http://en.wikipedia.org/wiki/Walden_2 Walden 2 describes a society in which social engineering techniques (like you describe) are used to create a utopia.

Your question is timely because a popular ethics book called http://en.wikipedia.org/wiki/Nudge_%28book%29 Nudge has recently promoted some of these ideas. Nudge argues that there are some (relatively benign) ways we can change our environments to "nudge" people towards making the right decision.

The SEP's entry on http://plato.stanford.edu/entries/autonomy-moral/ autonomy might be a good place to start. It sounds like you may be new to the wonderful world of differing ethical opinions, but suffice it to say there are several competing schools of thought with diametrically opposed views on the matter.

If you are interested in reasons why losing autonomy might be a morally relevant action, you might consider whether rational (autonomous) thought is important for ethical reasoning, whether losing autonomy will make it harder for you or those around you to satisfy your preferences, or whether making autonomous decisions is important for being a "good person". 

Some classics in the area would be Kant's http://en.wikipedia.org/wiki/Groundwork_for_the_Metaphysics_of_Morals Groundwork of the Metaphysics of Morals (see e.g. http://en.wikipedia.org/wiki/Categorical_imperative#Freedom_and_autonomy The Categorical Imperative - Freedom and Autonomy) and Mill's http://en.wikipedia.org/wiki/On_Liberty On Liberty. 

Contemporary thinkers tend to be distrustful of the idea of "freedom" in general. (Frankly, I am surprised this question hasn't been answered with a flood of posters questioning whether one can ever make a "free" decision to begin with.) I heartily recommend http://rads.stackoverflow.com/amzn/click/0802118399 The Latest Answers to the Oldest Questions which is an introductory-level book to some important philosophical ideas, including questions of freedom.



To declare my conflict of interest: I tend to be on the Skinner side of things. If you want to be free come what may, more power to you. But if you'd like to be coddled and nannied, then I see no reason why we should worry about trivial things like "autonomy." So I probably am not doing Kant et al. justice.
I suspect Cody's comment is somewhat out of context - certainly philosophers should care about emotions, if only to not be labeled a sociopath!

Notably, an entire branch of philosophy (aesthetics) is devoted to the study of "sensori-emotional values" (at least as defined by http://en.wikipedia.org/wiki/Aesthetics wikipedia).

Emotions are also clearly relevant in philosophy of mind and metaphysics in general. (e.g. if we are guided by our emotions, what impact does that have on free will?) In ethics, a theory known as http://en.wikipedia.org/wiki/Emotivism Emotivism claims that ethical statements represent emotive judgements, and of course the emotions caused by our actions are critical for consequentialist thinkers. (e.g. what defines 'pain'? What defines 'pleasure'? Are there 'better' or 'more valuable' states of happiness?)

And I'm guessing you were asking about analytic philosophy, but just in case emotions play a role in continental philosophy as well, though I am not as familiar with this. For example, you can see Sartre's http://rads.stackoverflow.com/amzn/click/080650904X The Emotions. (Whether or not Sartre should have left this psychologizing to the psychologists as you suggested I will not say...)
I'm not terribly good with economic theory, but it seems a little unjust that no one was able to step up on this one last year. Still, it deserves an answer.

...

If we took only the reason that "a [flat] tax contributes to the welfare of the Netherlands", then it's fairly obvious that this is not a capitalist concern, and certainly doesn't pick out enough of a difference between individuals by the definition you've provided, that "Everybody should be rewarded [by] their [...] contribution." That tricky word you included "equally", in reference to capitalism, means to say that each person should receive some benefit equal to their contribution, not equal to everyone else.

It gets problematic once you include that clause which states the Netherlands will be benefitted "because there is a direct relation between someone's contributions and his net reward" (emphasis added). My concern here is that when I look up "flat tax", it does seem to imply equal treatment in the strictly capitalist sense, specifically because it rewards greater productivity in just the way that your question claims is the reason it benefits the Netherlands on the whole. There's no sense that this involves anything other than a very capitalist sort of view.

...

So honestly? I think you're absolutely right. Your guide's answer 'D' may have simply been a typo, and you should check with the author or editor. The question's also a bit wonky without the text it's taken from to define what kind of tax it means by saying "flat tax." I'm inferring the meaning from the definition that your question gives. However, if it's taken to mean a strict flat marginal rate, then it ceases to have the same capitalist qualities - but then it would satisfy choice A, not D. So I can't really say.

On the other hand, can any version of the "Flat tax" possibly be utilitarian? That's an entirely different question, and one I'm not really capable of answering. I'm inclined to say that it could be construed as utilitarian, but only on the premise that capitalism benefits all at the expense of the individual. Yet that still presupposes capitalist justice (by your definition) as the motivating reason.
Yes, prevention. 

For example, there are two broad reasons why people steal items:


they were unable to obtain the item,
they have a mental disorder (i.e. kleptomania)


with the first reason, you have the following options:


make the item more accessible (e.g. make the item cheaper, or lift any bans and stigma with the distribution of the item)
eliminate the need for the item (e.g. provide a substitute)


Therefore, to reduce thefts, the state should start by eliminating poverty and providing sufficient resources for everyone.

Another example, rape. There are two broad reasons why people rapes:


they were unable to obtain their preferred sexual gratification,
they have a mental disorder (i.e. predisposed to violence or power conquest)


with the first reason, you have the following options:


make their preferred sexual gratification more accessible (e.g. eliminate any bans and stigma associated with out-of-wedlock, same-sex, polygamous, underage, inter-generational, inter-race, incest, fetishes, BDSM, etc)
eliminate the need for sexual gratification (e.g. castration, or hormone drugs)


Another example, murder. There are two broad reasons why people murder:


they were unable to fill their hatred,
they have a mental disorder (e.g. psychopaths)


with the first reason, you have the following options:


make the hatred easier to fill (e.g. fair and efficient justice system)
eliminate the need for hate (e.g. prevent hate)


Now this lefts us with only mental disorders. You can't really blame someone from having a mental disorder, and most (all?) mental disorder cannot be cured, however you can provide support to prevent them from actioning on their disorder. You can probably eliminate the existence of mental disorders though, by eliminating the bans and stigmas associated with abortions and making prenatal DNA testing of all genetic mental disorder more widely available.

I think the pattern starts to get obvious here, all crimes happens either because there is a need for something or because they have mental disorder. If the crime happens because of a need, then there is two ways to solve it, either by making it easier to fulfil the need or by eliminating the need.

I think by now it's also fairly obvious that it's going to be really difficult for a State to completely eliminate illegalisation. Way too often, making needs easier to fulfil or eliminating those needs is either impossible to achieve or conflicting with widely held moral frameworks or contradicts with the State's goals.
I think I can contribute some points even though I have to admit limited knowledge about Nietzsches philosophy.

What I do know from biographical information ("Godess of the market" by Jennifer Burns) is that she was familiar and quite sympathetic to Nietzsche in her younger years.

From that biography I also have the following quotation:


  [...]as when she wondered, if perhaps "the rational faculty is the dominant
  characteristic of the better species, the Superman."


(The text before the double quotes is by Burns and she gives the sources as Journals, 291, 281 and 285.)

As someone who is extremely appreciative of Rand and at least superficially familiar with Nietzsche I venture to guess that they indeed both understood by that the same (and to me rather obvious) idea: That only very few people achieve great things while a majority likes telenovelas.

A more well-known connection to Nietzsche can be found in the foreword of "The Fountainhead", where Rand admits to have considered putting the following quotation in her novel:


  It is not the works, but the BELIEF which is here decisive and
  determines the order of rank--to employ once more an old religious
  formula with a new and deeper meaning--it is some fundamental
  certainty which a noble soul has about itself, something which is not
  to be sought, is not to be found, and perhaps, also, is not to be
  lost.--THE NOBLE SOUL HAS REVERENCE FOR ITSELF.


(From beyond Good and Evil by Nietzsche.)

Rand tells us that she decided against using the quotation because it "proclaims psychological determinism" - something she abhorred.

I believe that the quotation might be a key commonality between Nietzsche and Rand in contrast to most philosophers and intellectuals: To give one's own life importance rather than sacrifice it to something or someone else.

In the foreword she goes on to say about the quotation:


  This view of man has rarely been expressed in human history. Today, it
  is virtually non-existent. Yet this is the view with which—in various
  degrees of longing, wistfulness, passion and agonized confusion—the
  best of mankind’s youth start out in life. It is not even a view, for
  most of them, but a foggy, groping, undefined sense made of raw pain
  and incommunicable happiness. It is a sense of enormous expectation,
  the sense that one’s life is important, that great achievements are
  within one’s capacity, and that great things lie ahead.


This view might be one of the crucial intersection of Nietzsche with Rand and thus give the impression of her being a blend of Nietzsche with something else.

These points of contact nonwithstanding, the claim of Rand's philosophy being a blend of Nietzsche with American individualism is wrong. Since American individualism isn't an actual philosophy, it suffices to show philosophical work that has no precedence in Nietzsche.

I've picked three articles that together spread over a range of fields in philosophy and should be comprehensible and intriguing. They should show that there are numerous gems of ideas in Rand's philosophical work - gems that (to my knowledge) are not of Nietzschean origin.

I also made sure to pick unusual ones (as opposed to writings dealing with selfishness, capitalism and reason, which are the usual suspects when it comes to Rand).


'The anatomy of compromise' in 'Capitalism: The Unknown Ideal'
'Art and moral treason' in 'The Romantic Manifesto'
'The establishing of an establishment' in 'Philosophy, who needs it?'


I strongly recommend reading these articles.
Can't say I like the 3 laws as you state them  - the 3 laws as I know them to be:


Every object in a state of uniform motion tends to remain in that state of motion unless an external force is applied to it. 
The relationship between an object's mass m, its acceleration a, and the applied force F is F = ma. The direction of propagation is equal to the direction of the sum of the forces applied to it.
To every action there is an equal and opposite reaction.


Now, it is easier to see how we can apply the same logic to more metaphysical theory.


People need a carrot or a stick to do anything. There has to be a reason that is in some way beneficial to that person (even if it is transferred).They will keep doing what works for them until a bigger carrot or stick causes them to change.
People will always attempt to take the easiest path for the same reward (or avoidance of punishment). The more effort made, the greater the satisfaction or disappointment.
Cause and affect.


By the way Hooke was a great mathmatician and scientist - the equal of Newton (and there were many arguements of plagurism and lack of credit against Newton for his gravity work as well as on light/optics). It was Newton as President of the Royal Society after Hooke's death that did everything to push his name from history - even going so far as to destroy his portrait which hung alonside those of other founding members). 
A letter by Jean-Michel Kantor, Bourbakis Structure and Structuralism at springerlink.com/content/x60030547jl61071/that throws a great deal of light on this:

he says,'When I asked Claude Levi-Strauss about the origin of the word ‘‘structure’’ in his work, he answered (letter to the author, Nov. 16, 1990): ‘‘Ne croyez pas un instant que Bourbaki m’ait emprunte´ le terme ‘‘ structure’’ ou le contraire, il me vient de la linguistique et plus pre´cise´ment de l’Ecole de Prague.’’ (Do not believe for one minute that Bourbaki borrowed the word ‘‘structure’’ from me, or the contrary; it came to me from linguistics, more precisely, from the School of Prague.'' '

Bourbaki was a society of mathematicians that were intent on putting the whole of mathematics on a rigourous foundation. The idea of Structure pervaded their thinking, in particular the idea of homomorphism=structure preserving map.

It looks like that the idea of Structure becoming pervasive and prominent in two unrelated fields at roughly the same time can be put down to the workings of the Zeitgeist. 
Wittgenstein famously http://en.wikipedia.org/wiki/Private_language_argument argues that there can be no private language; that language, in order to be language, must be (at least theoretically) public.  I've not come across a convincing refutation.

There have been a number of philosophers (such as http://en.wikipedia.org/wiki/Essay_on_the_Origin_of_Languages Rousseau) who have written (speculatively) on the http://en.wikipedia.org/wiki/Origin_of_language origin of language, although this field is more currently the domain of anthropologists and biologists.

One of the complicating factors, from a philosophical perspective, is determining the limits of "communication" and "language" in this context; for example, one could argue that a flower is indeed sending a message of sorts to a bee, by means of color markings and scents.
i think the problems of free will/determinism and personal decisions of this nature are of such different orders that it wouldn't invalidate the importance of patients giving uncoerced, lucid consent to medical procedures  

As in the example given by John Searle, if I'm out to dinner and the waiter asks 'Would you like the chicken or the steak?', saying 'sorry love I'm a determinist, i don't believe in choice' - won't really cut it. Even if the answer to 'will you undergo this surgery?' is at some level determined prior to its being asked, I find it hard to imagine a scenario where the neccesity of consulting the patient is invalidated. As in Searle's example, within our current way of relating to the world, even if conceptually we don't believe in free will, people kind of have to act as though they do anyway in situations like this.
The question you're asking is the main reason Kant wrote the Critique of Pure Reason. According to Kant, causality is one of the pure concepts ie the set of categories included a priori in our understanding abilities (along with modality, quantity, etc.).

So Kant's answer would be : yes and we can never know if the causality we see is real or not.
I agree with you that philosophy is not a field of knowledge. This, however, does not mean that one should not attempt to seek answers to its questions - it means that, most of the time, one cannot find any one definitive answer. Typically, a philosophical question will be answered differently depending on whose philosophical ideas you find valuable and from which you are then deducing an answer.

Therefore, even after receiving an "answer", one has not attained knowledge, but rather gained new insight and perspective into different ways of attempting to answer the question which assists your "endeavour and spiritual exercise".
You can find a good overview of the field of Buddhist Economics, and a preliminary bibliography, on the http://en.wikipedia.org/wiki/Buddhist_economics Wikipedia page on the subject.

  Is First Order Logic (FOL) the only fundamental logic?


Short Answer

No. It's just the most popular logic among mathematicians and philosophers for primarily historical and cultural reasons.

Long Answer

Since you wrote a long question, here's a long answer :-)

Originally, Frege proposed a form of second order logic as a foundation for mathematics in his Grundlagen der Arithmetik (1884).  This foundation fell out of fashion after Russell famously found a contradiction in this system (you can read all about it on http://plato.stanford.edu/entries/russell-paradox/ SEP).

Since then, very few philosophers and mathematicians have argued the revival of second order logic as a foundation for mathematics. The only know of three: Jouko Väänänen, Stewart Shapiro, and George Boolos.  Stewart Shapiro has a book about it: http://rads.stackoverflow.com/amzn/click/0198250290 Foundations without Foundationalism: A Case for Second-order Logic (2000).

SOL is ugly, though. It has no complete axiom system for its standard semantics; the only complete calculi are for non-standard models (see http://projecteuclid.org/euclid.jsl/1183730860 Henkin (1950)). Also, the compactness theorems fails for SOL's usual semantics; model theory for FOL can generally be regarded as more well behaved. http://www.math.helsinki.fi/logic/people/jouko.vaananen/VaaSec.pdf Väänänen (2001) has a nice summary of the properties of second order logic. Also, while the Löwenheim-Skolem theorem fails for SOL's standard semantics, it holds for Henkin's non-standard semantics. Väänänen argues "If second-order logic is construed as our primitive logic, one cannot say whether it has full semantics or Henkin semantics, nor can we meaningfully say whether it axiomatizes categorically ℕ and ℝ." 

Abraham Robinson probably agreed with Väänänen on this point. In his opus Nonstandard Analysis (1960), Chapter 2, he presents Henkin's semantics for higher order logic. He goes on to prove compactness, Löwenheim-Skolem, and Łoś's Theorem.  Robinson hardly pays any attention at all to the class of standard higher order models, (which he refers to as "full models").  That Robinson would embrace Henkin's non-standard semantics makes sense, of course. All of nonstandard analysis' bite comes from the fact that ℝ isn't categorical and Łoś's Theorem works.

Apart from Robinson (and maybe Väänänen) nobody really considers Henkin's semantics as a foundation. Neither is anybody working on foundations all that interested in systems which are not axiomatizable.  The whole point of Harvey Friedman's http://en.wikipedia.org/wiki/Reverse_mathematics reverse mathematics research program is that we have various axiomatic systems and we can reason about their provability power.

Of course, the idea that it's FOL vs. SOL for the foundations of mathematics is a false dichotomy anyway. 


  Why, so, is FOL invariably chosen as the underlying logic on top of
  which the set theoretical axioms are established, in any potentially
  foundational formalization of mathematics?


It's not invariably chosen.  It's primacy in mathematics and philosophy is due to it's early success and rapid development compared to its competition.



Research by mathematicians and philosophers into the foundations of mathematics schismed in several directions after the dismissal of Frege's Grundlagen.  You can read about them in Heijenoort's anthology http://rads.stackoverflow.com/amzn/click/158348597X From Frege to Gödel: A Source Book in Mathematical Logic (1999):


The First Order Logicians: the early, vast majority.  These include Guisseppe Peano, C.S. Pierce, David Hilbert, George Cantor, Richard Dedekind, Skolem, Löwenheim, Zermelo, Fraenkel, Herbrand, the Bourbaki guys, Quine, Tarski, (early) Wittgenstein, etc.
The Many Sorted Logicians: Russell, Whitehead, and (sometimes) Gödel.
The Fathers of Computation: Moses Schoenfinkle, Alonzo Church and his students.
The Constructivists: Kronecker, Kolmogorov, and Brouwer and his students.


It should be pointed out that Peano, Pierce, and Hilbert all developed First Order Logic roughly independently; this lends credence to the idea that FOL is a natural foundation for mathematics.

While the other approaches are not gone, they all faced early difficulties.

Type theory was poorly developed: Everyone knows how Russell and Whitehead's Principia Mathematica is legendarily opaque.  Russell struggled for a long time before developing ramified types, which were challenging and hard to work with.  Ultimately Leon Chwistek and Frank Ramsey demonstrated that the system could be simplified, resulting in the theory of simple types in the 1920s. Tragically, Ramsey died very young, so any contributions he might have made were cut short.  On top of that Russell abandoned logic after writing the Principia, and his student Wittgenstein made no effort to develop it.

The "fathers of computation" also met challenges, although it also came later than FOL and ZF set theory.  After publishing On The Building Blocks of Mathematical Logic in 1924, Moses Schönfinkel found himself trapped behind the iron curtain and never published again.  His work was later picked up by Church who connected it to his λ-calculus. The λ-calculus, while more expressive than FOL, was never really suitable as a foundation for mathematics. A number of foundational systems built on the λ-calculus were proposed in the 30s by Church and others. The most popular of these systems were shown to be contradictory by what is now known as the Curry Paradox (see http://www.jstor.org/discover/10.2307/1990124 Curry (1941)).

Finally, constructivism and intuitionism had its own issues.  The obvious defect with constructivism is too restrictive.  A mathematician will always accept a constructive proof, but finding a non-constructive proof is easier also generally acceptable. Another issue is logic: intuitionistic logic and arithmetic were not axiomatized until Heyting in the late 1920s.  Adequate semantics for intuitionistic predicate logic (IPC) also remained an open problem for a long time. http://www.jstor.org/discover/10.2307/2964110 A weak completeness proof was provided by Kreisel in the 1950s, using Brouwer's intended semantics (ie, http://en.wikipedia.org/wiki/Choice_sequence choice sequences).  Kripke later gave https://www.princeton.edu/~hhalvors/restricted/kripke_intuitionism.pdf a strong completeness proof for IPC in the 1960s, using Kripke structures.  The "hayday" of intuitionistic model theory in the 50s and 60s was 30 years too late to have any impact on the foundations of mathematics.



Meanwhile, as rival foundations struggled, FOL/ZF ultimately won the hearts of mainstream mathematicians and philosophers. Modern foundational mathematicians mostly explore fine tuning the existing foundation.  After Paul Cohen demonstrated the independence of the continuum hypothesis (http://www.ncbi.nlm.nih.gov/pmc/articles/PMC221287/?tool=pmcentrez 1963), mathematicians began exploring independence of various propositions in ZF and certain extensions. One important axiomatic extension is Gronthendieck's http://en.wikipedia.org/wiki/Grothendieck_universe Universe Axiom, which is equivalent to the existence of a strongly inaccessible cardinal.  This axiom is widely popular in algebraic geometry, and was used by Wiles' in his proof of Fermat's Last Theorem (although http://www.cs.nyu.edu/pipermail/fom/1999-April/002983.html here Harvey Friedman argues the use of the axiom is not really essential).  Speaking of Harvey Friedman, another important foundational research program is reverse mathematics, which studies the proof power of systems extending Peano Arithmetic but weaker than ZF.

First order model theory has also developed. An old triumph of model theory is Hrushovski's model theoretic proof of the Lang conjecture (http://www.ams.org/journals/jams/1996-9-03/S0894-0347-96-00202-0/S0894-0347-96-00202-0.pdf 1998).  Despite the categoricity of ℕ and ℝ in SOL, few mathematicians have studied second order model theory since the 50s. There's categoricity results in FOL, too: for instance (ℚ,<) is ω-categorical in FOL.

And in philosophy, no philosopher has evangelized FOL more than Quine.  I'd say Quine's preeminence is probably why philosophers only know FOL and ZF and don't know about anything else.



While mainstream mathematicians and philosophers were ignoring them, the other foundational research programs consolidated, and ultimately flourished.

After the failure of using the λ-calculus as a foundation, Church and many of his students turned to using simple-types.  What emerged combined Russell's research program into Church's program.

A further development was an unexpected, non-Dutch interpretation of intuitionistic logic: the constructable types in the simply typed λ-calculus exactly correspond to propositional intuitionistic logic.  This is the so-called http://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence Curry-Howard Correspondence.

The Curry-Howard Correspondence ultimately inspired Per Martin-Löf to invent http://en.wikipedia.org/wiki/Intuitionistic_type_theory Intuitionistic Type Theory in the early 70s, as a novel alternative foundation for mathematics.  The original formulation suffered a defect known as http://en.wikipedia.org/wiki/Girard%27s_paradox Girard's paradox, although the system was salvageable and Martin-Löf didn't abandon it.

It is generally well known by students of computer science that the λ-calculus inspired John McCarthy and Steve Russell to invent LISP.  A similar thing happened to the simply-typed λ-calculus in the early 70s. Dana Scott, a former student of Alonzo church invented The Logic for Computable Functions for reasoning about the denotation semantics of typed functional programs in the late 60s. In 1973 Robin Milner and company implemented LCF as the first computer proof assistant. This was done after developing the first simply-typed functional programming language ML ("MetaLanguage") that it was written in.

Ever since, non-FOL/ZF foundational research has largely worked with the computer science community.

One example is HOL, or "Higher Order Logic", roughly modeled after Church's simply-typed lambda calculus (http://www.classes.cs.uchicago.edu/archive/2007/spring/32001-1/papers/church-1940.pdf 1940).  After a number of revisions, Mike Gordon released HOL88, intended for hardware verification.  As Gordon admits in his short history on the subject that his code hacked parts of LCF when it was convenient, and was rather ad hoc (http://www.cl.cam.ac.uk/~mjcg/papers/HolHistory.pdf 1996).  HOL was later polished by John Harrison and Konrad Slind into http://www.cl.cam.ac.uk/~jrh13/hol-light/ HOL-Light; HOL-Light has 9 elementary rules which look vaguely like http://mathworld.wolfram.com/EquationalLogic.html Equational Logic, and three axioms (the http://en.wikipedia.org/wiki/Axiom_of_infinity axiom of infinity, the http://plato.stanford.edu/entries/epsilon-calculus/ axiom of choice using Hilbert's ε, and http://en.wikipedia.org/wiki/Leibniz%27_law Leibniz' Law).

Another extension is http://www.cl.cam.ac.uk/research/hvg/isabelle/ Isabelle/HOL, which conservatively extends the type system of HOL with "context".  Still another system is Homeier's https://github.com/mn200/HOL HOL-Omega, which conservatively extends the type system even further.

Another development is http://www.nuprl.org/ NuPRL from Cornell university, which implements Martin-Löf's intuitionistic type theory.  http://wiki.portal.chalmers.se/agda/pmwiki.php Agda is similar.  A related system out of INRIA is http://coq.inria.fr/ Coq, which implements Thierry Coquand's http://en.wikipedia.org/wiki/Calculus_of_constructions Calculus of Constructions that extends intuitionistic type theory.

Development of new systems has slowed in the last decade or so, but it hasn't stopped.  The few FOL/ZF systems (namely, http://www.cl.cam.ac.uk/research/hvg/isabelle/dist/library/ZF/index.html Isabelle/ZF and http://en.wikipedia.org/wiki/Mizar_system Mizar) are comparatively inactive.



I would summarize my position as thus: saying that FOL invariably chosen as the underlying logic is like saying that Windows is invariably chosen as the underlying platform for PC games.

In both cases, it's a cultural thing.

  the ... negation of Dunn/Belnap's 4-valued system [is] componentwise definable by negation ... of classical logic, i.e. this 4-valued system is a product of two copies of classical two-valued logic. [my emphasis]


This means that, in order to apply negation to the different truth values, you apply it (classically) to each of its components:


When you apply it to {⊤}, you end up with {~⊤}, that is, {⊥}
When you apply it to {⊥}, you end up with {~⊥}, that is, {⊤}
When you apply it to {⊤,⊥}, you end up with {~⊤, ~⊥}, that is, {⊤,⊥} (remember that these are sets, not ordered duples).
When you apply it to ∅, you apply it to all of its components (that is, none), which leaves the empty set as it is.




EDIT: The above is how one can see that negation as suggested by Belnap and Dunn is reasonable. But I agree with the questioner that it is unclear that the logic, so described, is a product system.

A bit more detail on how to see Dunn/Belnap's system (DB henceforth) as a product system:

In DB we have four truth degrees:


∅ -- this means: there is no information concerning a certain state of affairs [SOA henceforth]
{⊤} -- this means: there is information saying that the SOA obtains
{⊥} -- this means: there is information saying that the SOA fails
{⊤,⊥} -- this means: there is information saying that the SOA fails and information saying that it obtains.


What the author of the SEP article claims (Siegfried Gottwald, incidentally the author of a popular http://www.uni-leipzig.de/~logik/gottwald/treatise.pdf Treatise on Many-Valued Logics) is that BP can be profitably understood as a product system: we take BP's truth degrees as evaluating whether 

a. There is positive information about the truth of the SOA.

b. There is positive information about the falsity of the SOA.

We can track these two aspects with an ordered duple: ; a will be true [t] iff there is positive information about the truth of the SOA, and false [f] otherwise. Mutatis mutandis for b. If so, there is the following mappings of BP truth degrees onto the ordered pairs (represented with square brackets and not the habitual corner brackets; mysteries of the SE markup) of our product system:


∅ maps onto [f,f] -- no positive information about the truth of the SOA, nor about its falsity.
{⊤} maps onto [t,f] -- positive information about the truth of the SOA, no positive information about its falsity.
{⊥} maps onto [f,t]
{⊤,⊥} maps onto [t,t]


But, of course, if this is the intended mapping and, e.g., negation is to be calculated as classical negation over the two components, ~ ∅ is {⊤,⊥} and vice versa, as the question rightly claims. 
What is the question, here?  

Certainly there are philosophers who have argued against free will and for determinism. 

If determinism holds, and we find out this is true, we can't expect any changes, as everything continues to be determined as it was.  Our passion will be the same as it is destined to be, by definition.
There is a problem with such a flow of logic. 
And the answer lays in calculus and limits. (and looking at which infinity is bigger) 
As well as actually looking what timetravel means. 

If universe is infinite and time and space travel is possible for complex matter then there would be beings capable of such travel.

However infinite universe would also mean that there is infinite number of exact copies of earth. One infinity is not equal to another. Moreover if we know that one infinity is twice as big as another we can divide the two and get a finite number (for example if you divide 1+1+1+... by 2+2+2+... you get 2. The probability of you getting visited by a time/space traveling being would be determined by [number of beings that are capable and want to visit earth]/[number of earths]. Because most likely time traveling beings are much more complex then humans they will also occur much less often (not to mention the fact that some of them might not want to visit us) so the ratio is going to be less then 1 so the probability is less then one. 1 alien / 100 earths means only 1% probability.

Unless we assume that each of these aliens would travel to multiple earths in which case it all depends how much effort it takes them to travel to another planet. The loWer the effort the higher the chances of such alien visiting. If its effortless for such an alien and they want to visit everyone probability of us being visited would be 100% and we already would be visited. But there are always some constrains. 

However time and space travel most likely is not possible in all times in the existence of the universe. At the beginning of our universe for example there were no atoms and after that there were no stars. As universe progresses through time there might be strange behaviors as well that prevent time travel or existence of intelligent life. (although I dont trust any of our current models that predict what will happen to the universe as we cant even predict the weather very accurately) This means that it would take some time for time/space traveling beings to evolve and then they would have limited time to travel back in time. 
(there might be further limitations to time travel which we dont understand) 

This means that the time traveling beings dont exist at all times throughout the universe (unless of course they travel there) 
That decreases the probability of meeting the aliens further because they can time travel to any time but they can come from only one finite time. 
Its possible that we exist before the time where time traveling aliens are possible to evolve (because evolution takes time). 

And you might think that it wouldnt matter because such a being can always time travel back and back and back so in a way he is at multiple places at the same time, but the way we think about time travel would need to change. 
Because if we simply travel back in time we could change the past so we do not exist and therefore we never travel back in time. 

So it would have to mean either that some time travel possibilities are impossible. Or that we create a parallel universe every time they would time travel. 
http://en.wikipedia.org/wiki/M%C3%BCnchhausen_Trilemma Agrippa's Trilemma demonstrates that all systems must ultimately be grounded in one of three way: infinite regress, circular reference, or unsupported axioms.  So, ultimately, you are going to have to resort to one of those options.

Reliability, then, is generally redefined appropriately.  

To give a more detailed answer would require reference to a specific philosopher or philosophical tradition.
The literature on the aleatory is enormous; to begin with, I'd point you to the http://plato.stanford.edu/entries/chance-randomness/ SEP article on the subject, and, if you are interested in Continental Philosophy, Jacques Derrida's essay "My Chances / Mes Chances: A Rendezvous with Some Epicurean Stereophonies" which, beyond the Epicurean notions hinted at in the title, also addresses Mallarme's dictum Un coup de dés jamais n’abolira le hasard.
Formally, it probably looks like this:

N ⇔ C   // a nickle is a two-sided coin with a 50-50 chance of flipping heads/tails
Q ⇔ C   // a quarter is a two-sided coin with a 50-50 chance of flipping heads/tails
N ∧ ¬Q  // I'm willing to flip a nickle and not flip a quarter
________
C ∧ ¬C  // A coin is not a coin -> contradiction (nonsense)


No primes necessary and no analogies necessary. A nickle is not like a quarter, it's the exact same thing (a two-sided coin with a 50-50 chance of flipping heads/tails) - a fact which Jane seems to accept. The inconsistency is a simple contradiction akin to saying it's the year 2012 and the year 1012 or up is down. As some of you may have noticed, my sketch is slightly incorrect (I sort of mix up prepositions with predicates). A more correct implementation would be:

N ⇔ C   // a nickle is a two-sided coin with a 50-50 chance of flipping heads/tails
Q ⇔ C   // a quarter is a two-sided coin with a 50-50 chance of flipping heads/tails
N → F   // a nickle has a flipping preference
Q → ¬F  // a quarter does not have a flipping preference
________
F ∧ ¬F  // a flipping preference is not a flipping preference -> contradiction
C ∧ ¬C  // a coin not being a coin can also be derived -> contradiction


The above conclusions can be derived in a number of ways (material implication pops out as an obvious solution). Of course, things would be more complicated if Jane would argue that the coins are not, in fact, "the same thing." Here is where you may need an analogy. In short, if Jane would argue that:  


(N ⇔ ¬C) ∨ (Q ⇔ ¬C),


there would be some problems. But that is outside of the scope of the question.
I haven't read too much about the subject, and I invite anyone that knows more than I do to correct or amend my answer. Most of the information is synthesized from http://plato.stanford.edu/entries/coercion/ the SEP article on coercion, but as always, I suggest reading the primary sources.

To answer your question, you first need to precisely define coercion as things are not as simple as they appear. There are, generally speaking, several schools of thought regarding coercion, purported by Aquinas, Hobbes, Locke, Kant, Mill, and Nozick.

Aquinas - The 'inclination of the will' and non-coerciveness of threats

For Aquinas, the result of coercion is the disconnect between what he calls the 'inclination of the will' and the action taken by the agent. Simply put, it looks something like this:


I want to go to the store -> [no coercion] -> I voluntarily go to
the store
I want to go to the store -> [coercion] -> I involuntarily do not go to the store


The first column being the 'inclination of the will.' It's also of note to say that, according to Aquinas, in case A, the agent is responsible for his actions, whereas in case B, he is not. Lets go back to your original question; if you agree with Aquinas, you don't really 'influence' anything, anyway. It's as if you make the coercee your puppet (you control them but 100% of the responsibility falls on you).

"But how far can we go without coercing?" you may ask. Aquinas makes a very interesting distinction. He argues that anything non-violent cannot be construed as coercive. So you could technically threaten, terrorize, or otherwise non-violently 'influence' someone to do your bidding and Aquinas would say two things: a) it's not coercion (yay!), and b) the agent is, in fact, 100% responsible for the actions they may take.


  
  If you don't vote for me, I'm going to kill you.
  I will rape your wife unless you give me your wallet.
  Every second you don't sign the contract, your company loses $1,000,000.
  


Are all not non-coercive according to Aquinas. 1 and 2 are threats and Aquinas doesn't believe threats can possibly be coercive. 3 is not a threat (your company is losing money as we speak!) but it's non-violent so, again, it's not coercive.

If you run a government and subscribe to this kind of philosophy, you're in luck. You can do just about anything. Violent torture, punching someone in the face, or otherwise being violent while attempting to undermine someone's 'inclination of the will' is the only way of being coercive. Raising gas prices is the least of your worries. Primary source reading: http://www.sacred-texts.com/chr/aquinas/summa/index.htm Summa Theologica.

Hobbes, Locke, Kant, Mill - Justice and the role of the state

Hobbes, Locke, and Kant mainly thought of coercion as a tool of the state that ought to be conducive to justice. Even Aquinas thought that a governor needed certain coercive powers to ensure order. Hobbes, in particular, thought it to be an essential part of government:


  [W]here there is no coercive Power erected, that is, where there is no
  Commonwealth, there is no Propriety; all men having Right to all
  things: Therefore where there is no Commonwealth, there nothing is
  Unjust. So that the nature of Justice, consists in keeping of valid
  Covenants: but the Validity of Covenants begins not but with the
  Constitution of a Civil Power, sufficient to compel men to keep them:
  And then it is also that Propriety begins (Hobbes 1651, Ch. 15).


All four (also Bentham and others) believed, like Aquinas, that a 'covenant from fear was valid,' so fear is, therefore, not coercive. The limits of coercion seem to align closely to what Aquinas laid out. Mill, however, argued that coercion consists of more than violence and threats thereof. He made several leaps:


  
  Social institutions (not the government) possess coercive methods
  that are much more powerful than the state's. He cites marriage as
  an example.
  Fines, laws, taxes, etc. are all instances of coercion. He doesn't say these things are bad per se, but they are coercive.
  


If you agree with Hobbes, Locke, and Kant, you're more or less golden as their views on what is and is not coercive agree with Aquinas'. You're not coercive until you have to violently impose something on someone.

Mill is trickier. Even having fines for say, littering, implies coercion. Of course, he argues that it's necessary, but it's coercive nonetheless. It would be difficult to influence anyone one way or another without any leverage. Primary source reading: Mill's http://www.bartleby.com/130/ On Liberty.

Nozick - Coercive threats and (no) unsuccessful instances of coercion

Nozick http://plato.stanford.edu/entries/coercion/#NozNewAppCoe says a lot about coercion and I would do you a great disservice if I tried to simplify his position here. Parts of his argument that I think are relevant (and revolutionary) are the following:


Threats can be coercive.
An instance of coercion occurs if and only if the coercee does what she is told to do.


So, according to Nozick, you can influence anyone insofar as you don't threaten them (or obviously don't actually violently abuse them) IFF the threat leads to their action being dictated by you.

It seems like a silly thing to say, but it makes a lot of sense. Check out this simple thought experiment.


  You run a country but hard times fall on it. Crops die out, many are
  emigrating, etc. You are forced to pass austerity measures that many citizens aren't fond of but you're doing your best and you've always been a fair
  leader (a). However, there's a small dissident group forming (lets call them
  the Rebels). You eventually capture their leader, Bob. Bob is a
  zealot. He truly believes that you're a horrible leader. First you try
  to have a conversation with him. You try to reason with him, you try
  to make him understand that it's hard being in power and that not
  everything is black and white. As mentioned, he's a zealot. He rejects
  any rational argument, so you move to the next step. You torture him
  and attempt to force him to renege his allegiance to the Rebel force,
  but no dice (b). He's convinced he's right. The next morning, you decide
  to do the next best thing: you publicly execute Bob. The Rebellion
  soon dies as many fear and decide to sever their ties with the
  dissidents (c).


Primary source reading: http://books.google.com/books?id=XOVelCewRMIC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false Socratic Puzzles.

Conclusion - How far is too far?

Looking at the example above, we see various milestones of coercion:


According to Mill, you coerced citizens with austerity measures in
(a).
According to Aquinas, Hobbes, Locke, and Kant, you coerced Bob with torture in (b).
According to Nozick, you coerced the Rebel onlookers in (c).


So, the answer your question of "how far can you go," depends on two things: 1) how, exactly, you define coercion and 2) the potential coercee's willingness to change their mind.
Popper described his rejection of the Kantian a priori http://www.criticalrationalism.net/2010/02/02/karl-popper-on-kant-and-a-priori-ideas/ here.

A reply from a Kantian perspective can be found in http://www.friesian.com/samra.htm this student paper.
"Authenticity" is a concept that is often assumed and rarely defined; some notable responses to this problem are Adorno's The Jargon of Authenticity and Marshall Berman's The Politics of Authenticity: Radical Individualism and the Emergence of Modern Society.

In short: you are not mistaken-- "authenticity" (and it antonym "alienation") is often used in a manner that gives the impression that the author intended them in a technical sense which is not rigorously defined.
There is a paper titled "Why did Wittgenstein read Tagore, to the Vienna Circle?" by Peter French, published in Protosociology. It's reprinted in a book Protosoziologie im Kontext.

Here are my impressions:

The author makes the familiar points that Wittgenstein was trying to move past "Platonistic" theories of meaning and also wanted to downgrade traditional epistemology. Already according to the Tractatus, it makes no sense to try to justify logic: "logic must take care of itself".
In his later philosophy this theme continues: "This language-game just is like that" (On Certainty).  

In W's later anthropological understanding, meaning is founded on communal agreement. For epistemology this means that there is no privileged God's-eye-view and justification always presupposes a system of agreement and a form of life that give knowledge and doubt their sense.        

French following Rorty says that the Heideggerians and the pragmatists break from the tradition that sees philosophy as science (or continuous with science) where beliefs are changed because of perception and inference, and consequently "the logical space of epistemology is infinitely expanded" (p.242): following Rorty the author suggests that now metaphor can be seen as a way to modify beliefs. 

French seems to think that something like this entails the Wittgensteinian view of language (p.242) where meanings are not held fixed by Platonic essences but should be explicated only from within an understanding of the practices with words. And already in the Tractatus Wittgenstein too  rejected the philosophy as science model, French speculates he was also tempted to make the Heideggerian poetic turn.

So reading Tagore was in part a way to make something like this point. Apparently this happened in 1927 and soon after this Wittgenstein was already formulating some of his new views about grammar, though as said there were continuities between his earlier and later phases. It's hard to deny that a prank like that would be a snappy way of undermining some of the philosophical views of the Circle. 

I find this somewhat plausible. Wittgenstein's methods take language very seriously, many problems seem to take the form of riddles for him, he wanted to write a book based on jokes, and in a conversation with Schlick he said "Everything we do consists of trying to find the liberating word." And the Tractatus tries to make the reader see, by using aphorisms that have no sense.
Human being is freedom.

The external world is filled with in-itself being. Consciousness is the only anomaly, and consciousness only manifests itself through human being, insofar as we are aware of it. So, the starting point for an account of human being is in the account of the being of consciousness.  We know that the being of consciousness is the consciousness of being, and it will follow that the being of consciousness of humans is the consciousness of being human.  This consciousness of being human entails a consciousness of consciousness, and the immediately apparent features of consciousness. Conscious is infinite which means that the options for manifestations of human consciousness are infinite. The feature of having an infinite amount of options for the manifestation of one’s consciousness is what Sartre calls freedom. So, we have determined that the human being is freedom and that humans must be aware that their being is freedom.

This does not mean that human beings have an essence of freedom. “Man does not exist first in order to be free subsequently; there is no difference between the being of man and his being-free” (BN: 60). Freedom is the reason that human beings do not have an essence.  “Human freedom precedes essence in man and makes it possible; the essence of the human being is suspended in freedom” (BN: 60). The freedom of human being manifests itself as the limitless choice of human action. No matter what the situation is, a human being can always choose to act and his action will define his being. Even in extreme situations of coercion (such as being threatened with death), a human being still has the ability to choose his action and to choose the conscious attitude with which he apprehends the world. This ability to choose is actually an inability not to choose. Sartre tells us that “we are a freedom which chooses, but we do not choose to be free” (BN: 623). We are not free beings. We are freedom itself.

Citations refer to http://rads.stackoverflow.com/amzn/click/0671867806 this translation of Being and Nothingness 
I am not sure there is a context in Nietzsche for the concept of hubris.  He uses words like 'excessive' or 'overweening' to describe aspects of a real thinker's personality, and those adjectives are sometimes applied to pride, but the sense remains positive.

Most pointedly, in the Gay Science he complains how his poor health and this overweening spirit and pride are at odds, wearing him out and wearing him thin.  The image I get is of an overly energetic child or pet that is purposeful and amusing in going beyond what the parent or owner would choose, or even what he can easily tolerate, leaving him taxed for his own good.  He seems to gratefully rebuke them for their inconsideration and their refusal to let him be an invalid.

Discussing Wagner, He has much to say of the overuse of noticeable excess as a symbol of power (the force of the vibrations, the intricacy of the melody, etc.) which represent false self-evaluation.  But this is not about power itself.  It seems to be linked more to a sense that it does not represent the real pursuit of art, and instead compensates with false impressions and distractions or cunning manipulations.

Wagner is vain in the proper sense of the English word, but it is not hubris in the Greek sense, as I see it. It is the giddiness of being flattered, and the willingness to be shaped toward more flattery.  He just does not know where his honest power would lie, and how much kinder and more edifying he could be to his audience if he found it.

It is hard to see where he thinks anything that truly arises from within can be bad or limiting, including the natural childish narcissism that bases vanity.  One can fail, and one probably should, but learning to expect failure does not fit on the agenda for a powerful spirit.

At many points in the Genealogy of Morals it seems that in some sense, one's own sense of one's own value is never wrong.  Those who devalue themselves become useless and parasitic, and those who do not bring forth their genuine will, which creates opportunitY.  Those who misattribute their value to some cause are truly mistaken, but it is about that cause and not about the value itself.
The main issue here is the explicit self reference at a semantic level: the question talks about semantic properties of itself (the correct answer) which depend on what the question says which in turn depends on these properties. This kind of loops can generate a rich set of related paradoxes that you can find http://en.wikipedia.org/wiki/List_of_paradoxes#Self-reference here. 
http://www.freedominion.ca/phpBB2/viewtopic.php?p=505592 This article quotes ten prior laws:
http://www.maths.nott.ac.uk/personal/ibf/some.html (alternative source)


  
  Large numbers of things are determined, and therefore not subject to change.
  Anticipated events never live up to expectations.
  That segment of the community with which one has the greatest sympathy as a liberal inevitably turns out to be one of the most narrow-minded and bigoted segments of the community.
  Always pray that your opposition be wicked. In wickedness there is a strong strain toward rationality. Therefore there is always the possibility, in theory, of handling the wicked by outthinking them.  
  
  
    Corollary 1: Good intentions randomize behavior.
    Corollary 2: Good intentions are far more difficult to cope with than malicious intent.
    Corollary 3: If good intentions are combined with stupidity, it is impossible to outthink them.
    Corollary 4: Any discovery is more likely to be exploited by the wicked than applied by the virtuous.
  
  In unanimity there is cowardice and uncritical thinking.
  To have a sense of humor is to be a tragic figure.
  To know thyself is the ultimate form of aggression.
  No amount of genius can overcome a preoccupation with detail.
  Only God can make a random selection.
  Eternal boredom is the price of constant vigilance. 
  

The answer to your first question is "yes". http://plato.stanford.edu/entries/consequentialism/ Consequentialism, from the perspective of http://plato.stanford.edu/entries/ethics-deontological/ deontological ethics, lacks justification. If you do accept the idea that a person is and always must be treated not "merely as a means to an end, but always at the same time as an end" (Kant, Groundwork of the Metaphysic of Morals), then you can't defend a moral concept of maximizing happiness (or the like), because this is a consequence of actions that might come into conflict with your premise. Easy example: ship sinks, there aren't enough lifeboats, do we risk our boat sinks, or do we drop somebody to drown? If one dies, the other live, happiness is maximized, but dropping a person to their freezing death conflicts with our moral premise that a person must be treated as an end. Consequentialism and Kant don't go along.

To understand what the Humanity Formula of the Categorical Imperative means I recommend reading point 6. of http://plato.stanford.edu/entries/kant-moral/ this article.
The http://alessiomoretti.perso.sfr.fr/NOTLogicalCube.html cube exists, is known (shockingly recently, though!), and is one of an infinite series of such constructs.  As you say, it's not obviously of much use; just a mathematical curiosity (and a pretty obvious one at that IMO, but maybe the intersection of philosophers and algebraists/topologists is not well inhabited).
Daniel Dennett (among others) advocates a type of moral responsibility with only as much free will as you can get with determinism or determinism + unwilled randomness (more or less compatible with Sam Harris' assumptions).

There's a pretty good summary post http://www.westminstercollege.edu/myriad/index.cfm?parent=2514&detail=7134&content=7584 here.

In brief, the argument ends up redefining terms somewhat while claiming that this is what we actually mean anyway (or is good enough): you, as a complex information-processing agent, are said to be responsible for those actions that you have computed to be the ones you want to take (with provisos for being subject to decisions made by others).
My background is in Computer Science, so when I started reading philosophy seriously, I had a similar reaction.

A lot (maybe most) of what I've read (that is not that much, I admit) from the great philosophers usually ends up falling into one or more of those kind of problems, specially the ones regarding logical rigorousness. But some philosophers like Hegel, Wittgenstein, Russel, etc did know a lot about logic.

So let me say how I think this can be handled (although it's not completely solved to me):


Assume they got something right. Even if it doesn't seem at first, the great philosophers are great for a reason. I'm not saying that you should value them just because they're called "great", but the fact that they are still read by very smart people is at least an indication that there is something of value in their writings. That also doesn't mean you need to read everything by everyone of them, but that you should strive to see what they got right (see below), because no single philosopher got everything right. 

1.1. When you read something that bothers you as nonsense, "note down mentally" the criticism, but leave open the possibility that the writer has a point that you simply didn't see. It's very hard to criticize the whole of an author's work without knowing exactly what one is trying to convey, and it's very hard to know what that is without reading a lot from and about the person. Of course, that doesn't mean we shouldn't criticize, simply that we should be careful.
Keep in mind that knowledge (in the broad sense) is built on the shoulders of the previous thinkers. I'd take a risk and say that the smartest people today are probably smarter than the smartest people of before. But one of the reasons for that is the legacy the previous people left. So, at the very least their work should be valued for that. Then you have two options (not exclusive):

a. If your aim is to understand the history of ideas (or some idea), then you'll probably have to read everything. Understanding completely the ideas of a philosopher is very hard without knowing his context, the ideas he was sunk into and the ideas he was trying to fight. And that branches out very quickly.

b. If your aim is exposing yourself to new ideas, then you can be more selective. It is still very useful to know a philosopher's context and surrounding ideas, but you don't have to put up with every BS they sometimes say. No, you probably won't agree with Aristotle's view on "natural slaves", but you still can benefit from his ideas on ontology. In this case I see no problem in reading contemporary writings for the sake of quality density and efficiency.


I personally fit better in 2b. I'd love to read everything about every philosopher, but I have neither the motivation nor the time. So usually I prefer to read about previous philosophers by contemporary ones, and read from the originals when I think an idea is worth understanding better.

And remember, in philosophy even logic is open for debate, so you will find that sometimes what you have with some philosophers is a different set of premises, including the ones that do not value logic that much.
In modern physics, forces don't "exist" in the Newtonian sense.

If you take the principle of inertia quite seriously, then by definition a force is a bookkeeping device (not unlike "potential energy") which accounts for the fact that objects occasionally accelerate. It proved to be useful to describe objects as accelerating to the extent that there is a net force on it, and also to suppose that forces can act on objects over distances, as with gravity. Newton didn't posit any particular reason why there should be such an influence without direct contact, and so it became somewhat natural to think of forces as non-local but real elements of the world, in a sense 'agents' to effect some influence from a body which was elsewhere. The importance of the notion of 'force' is exactly that: even if there isn't anything obvious which is causing an acceleration, we nevertheless assume that there is some external reason for the acceleration, and we only have to find out what. In this purest sense, 'force' could be parsed as "potentially unseen influence", where 'unseen' is meant to be interpreted literally, i.e. we may not have yet ascertained the reason.

In the time of Michael Faraday, especially in trying to understand magnetic forces, it proved useful to elaborate on the notion of force with the notion of a field. In this context, 'force' is just the word we use to describe the effect of a field on an object. In this reading, the 'force' is not exactly a thing unto itself, just as 'temperature' is not a thing unto itself, but rather a partial description of an interaction between things which do exist — fields and objects.

In modern physics, the fields which we considered previously are now understood to consist of http://en.wikipedia.org/wiki/Force_carrier gauge bosons (such as photons, gluons, etc.) which are transmitted between those particles which experience different forces — or in the case of gravity, space-time itself bends in response to the passage of matter, so that rather than fields in space interacting with matter we have space itself interacting with matter. Thus, for the moment, we seem to have closed much of the gap which was confusing in Newton's time; most forces are the effect of particles which are emitted and are absorbed or scattered, while gravity itself is reduced to geometry. "Fields" are used to describe collections of particles, including now matter particles which we have discovered have some things in common with those force-carrying fields which we imagined previously.

In each case, we have a theory of the world, and within that theory there are elements which we regard as "things which exist", and others which we regard as "features of the behaviour or interaction of the things which exist". Metaphysical naturalism — to the extent that it is not merely an ontological-flavoured proposition that the words 'real' and 'natural' are synonyms — can be regarded as an epistemological proposition, that nature is comprehensible in a systematic manner such as the three schema I've sketched out above: that is, for any collection of actual phenomena that you might care to consider, there is a model which encompasses all of those phenomena, in which we have a description of objects which interact. Were this true, it would follow that reality is governed by some set of "natural laws" (where the term 'law' denotes that there is structure in the behaviour of the universe), or at least can be represented as the limit point of some sequence of natural laws (with each 'law' in the sequence encompassing more phenomena than the last).

"Forces" are still around in our newer models of physics, but they are no longer regarded as things which 'exist', but rather a derived feature of the interaction of things that do. And indeed, many things which we now regard as "real" may turn out only to be effective descriptions of subtler phenomena. But these things which are "merely" effective descriptions of the world still reveal the world as a place of structure, and the point of naturalism is to reject that there are any aspects of reality which cannot be encompassed by any comprehensible structure.
Foucault writes (p54):


  [The discourse on sex] assumed other powers: it set itself up as the supreme authority in matters of hygenic necessity, taking up the old fears of venereal affliction and combining them with the new themes of asepsis, and the great evolutionist myths with the recent institutions of public health; it claimed to ensure the physical vigor and the moral cleanliness of the social body; it pormised to eliminate defective individuals, degenerate and bastardized populations.  In the name of a biological and historical urgency, it justified the racisms of the state, which at the time were on the horizon. It grounded them in "truth."

Introductions

First of all, make you sure you have a good knowledge of general philosophy before you start reading political philosophy. This is not mandatory, but I think you may encounter some problems if you don't know the very basic terms, philosophers and ideas.

To get started with political philosophy, I would recommend the following:


http://oyc.yale.edu/political-science/plsc-114 Yale Opencourseware: Introduction to political philosophy
http://www.thegreatcourses.com/tgc/courses/course_detail.aspx?cid=443 TTC: Power over People: Classical and Modern Political Theory
http://rads.stackoverflow.com/amzn/click/019929609X Book: An Introduction to Political Philosophy
http://rads.stackoverflow.com/amzn/click/0199215529 Political Thinkers: From Socrates to the Present  (terrific introduction)


Reading original texts

Once you know enough about political philosophy in general, you can start reading original texts. The very first you should read, is Plato's Republic. Whether you like it or not, other philosophers will refer to it over and over again and it is important to understand it well. A companion is recommended too to make sure you get the most out of it. I've included a TTC-course and a book. 


http://rads.stackoverflow.com/amzn/click/1613823703 Plato's Republic (http://archive.org/details/PlatosRepublicallanBloomTranslation free version)
http://www.thegreatcourses.com/tgc/courses/course_detail.aspx?cid=4537 TTC: Plato's Republic
http://rads.stackoverflow.com/amzn/click/052154842X Cambridge Companion to Plato's Republic


Once you know this book really well, you are ready to move on. There are many texts and I don't really know which one to recommend, so I'll list a few. It's up to you which ones you pick. It may very well be that by this time, you already have your own preferences and therefore don't really need this list anymore. Many, if not all of these will already have been introduced by introductory books.


http://rads.stackoverflow.com/amzn/click/0486414248 Politics by Aristotle
http://rads.stackoverflow.com/amzn/click/1613823940 The Prince by Niccolo Machiavelli
http://rads.stackoverflow.com/amzn/click/0872201775 Leviathan by Thomas Hobbes
Books by John Rawls, most notably http://rads.stackoverflow.com/amzn/click/0674017722 A theory of justice
Open Society and its enemies, http://rads.stackoverflow.com/amzn/click/0691019681 vol 1 and http://rads.stackoverflow.com/amzn/click/069101972X vol 2 by Karl Popper
http://rads.stackoverflow.com/amzn/click/0761941843 Contemporary Political Theory: A Reader (not for "beginners")
http://rads.stackoverflow.com/amzn/click/0871404656 On Politics: A History of Political Thought: From Herodotus to the Present by Alan Ryan (magnificent overview)


  Will fundamental physics become an art? According to Popper
  scientific theories are never true but are always falsifiable.
  ...of course there aesthetic considerations play a large part even if
  they're not nominally thought of in that way.


The answer bellow was before the change of the question to "...is driven solely by aesthetics?" My answer and time did not deserve this new question.

Fundamental physics has beauty as a selection criterion of a theory, and falsificationism is falsifiable.

Theories or hypotheses can only be subjected to empirical testing in groups or collections, never in isolation. The idea here is that a single scientific hypothesis does not by itself carry any implications about what we should expect to observe in nature; rather, we can derive empirical consequences from an hypothesis only when it is conjoined with many other beliefs and hypotheses, including background assumptions about the world, beliefs about how measuring instruments operate, further hypotheses about the interactions between objects in the original hypothesis' field of study and the surrounding environment, etc. For this reason when an empirical prediction turns out to be falsified, we do not know whether the fault lies with the hypothesis we originally sought to test or with one of the many other beliefs and hypotheses that were also needed and used to generate the failed prediction. It forms a criticism of methodological falsificationism.

Holist underdetermination ensures there cannot be any such thing as a “crucial experiment”: a single experiment whose outcome is predicted differently by two competing theories and which therefore serves to definitively confirm one and refute the other. Our response to the experimental or observational falsification of a theory is always underdetermined in this way. When the world does not live up to our theory-grounded expectations, we must give up something, but because no hypothesis is ever tested in isolation, no experiment ever tells us precisely which belief it is that we must revise or give up as mistaken. All of the beliefs we hold at any given time are linked in an interconnected web, which encounters our sensory experience only at its periphery.

It would be possible for us to preserve it “come what may” in the way of empirical evidence, by making sufficiently radical adjustments elsewhere in the web of belief. It is in principle open to us to revise even beliefs about logic, mathematics, or the meanings of our terms in response to recalcitrant experience; it might seem a tempting solution to certain persistent difficulties in quantum mechanics, for example, to reject classical logic's law of the excluded middle, allowing physical particles to both have and not have some determinate classical physical property like position or momentum at a given time. 

Underdetermination then is when the available data do not permit us to make a decision between two or more rival theories. There are two forms of underdetermination: strong and weak. Strong tells us that there is no way to distinguish between theories with the same observable consequences – called empirical equivalence – and points to the existence of an infinity of possible theories consistent with any finite data set. We do not claim to be able to choose between empirically equivalent theories on the basis of empirical criteria, which is impossible by definition. It forms other  criticism of methodological falsificationism. Moreover, it relies on an implicit separation of theory and observation: We cannot distinguish between theory and observation in a straightforward fashion, we cannot appeal to or rely on observations without theories and make a choice. All the observations that give us this problem of underdetermination are themselves theory-laden. Then strong underdetermination makes theory choice impossible because we already use theory in obtaining the observatory evidence that leads to underdetermined theories.

To the weaker underdetermination is always possible to construct alternative theories which are empirically equivalent and also choise one with many of the characteristics we desire in scientific theories: parsimony; internal consistency; beauty. Weak underdetermination is the recognition of the limits of evidentialism and falsificationism, the notion that we hold to our ideas insofar as they are supported by evidence. We do not accept or reject theories based solely on the evidence for them but also on account of many non-empirical criteria, such as parsimony; internal consistency; beauty. 

The underdetermination is inductive, but science can believe in entities that are not directly observable, such as electrons. Not only the observables are relevant to believing a scientific theory. Simplicity, explanatory power or some other feature of a theory is criterion for it over its rivals. 
There is no concept of creation in Eastern philosophy. Creation is a Judeo-Christian concept. Eastern philosophy says that that what we see as the universe is a 'projection'. What we see as the universe is a projection of God. You can't create something out of nothing, there is no logic in that. To see the universe as it truly is - God - is what is meant by enlightenment. The projection always was and always will be - it has no beginning and no end. It is eternal. You were born in a human body and your senses have been bombarding your mind since birth that what you senses present to your mind is real. The illusion is eternal, to escape the illusion is what is meant by enlightenment - to become aware of your true nature. When you achieve this you see the world as God, not what your senses have been mistakenly seeing it as. Control the mind, cut off the senses.

To ask why God created the world or why there is a projection is not a question that can be posed outside the sensual world. There is no why. "Why" only exists in the world of time space and causation. God is beyond the sensual world of time space and causation. For God to have a 'why' implies that God has a purpose in the creation - or projection - of the world, for God to have a purpose implies that God is not perfect. The syntax of your sentence is correct - Why did God create the world? - but good syntax does not imply good logic.    
Harvey Mansfield's http://rads.stackoverflow.com/amzn/click/0226500446 translation. I would strongly suggest reading the Discourses on Livy after you finish the Prince. It gives a much fuller picture of what Machiavelli is doing with his political works. I would also suggest Mansfield's http://rads.stackoverflow.com/amzn/click/0226500365 translation. 

As far as translations of older texts go, I would try to stay away from Penguin. 
Since you have asked only the "how" part, I'd explain here only the "how" part of the well-known phenomena.

Economics 101.

That future isn't known implies that, (in economics) future is uncertain.
Since future is uncertain no one knows if the expected future income will actually materialize  or not when the future is actually here. Thus the one lending money against assumption of an having payment in the future carries a risk of non-payment. To compensate that risk the borrower agrees to pay "interest" to the lender.

That is how one is able to borrow from the future: by promising to pay extra in the future.

Thus it is just inexact language, for money is borrowed from the present only (in exchange of a promise to pay future money to lender). The borrower is borrowing money from lender who could had put money to some other use
You might check out Michael Potter's "The Logic of the Tractatus" in the Handbook of the History of Logic Vol. 5: From Russell to Church.

In that he discusses Wittgenstein's logical atomism, his presentation of truth-tables for Fregean logic, among other things.

In it, Potter claims that Wittgenstein's system is not only quantificational, but admits of higher-order quantification. This is not surprising, since the Tractatus was heavily influenced by Frege who developed a higher-ordered logic in his Begriffschrift.

Potter compares the Tractatus's utilization of ever more inclusive metalanguages to a Russell-Ramsey type theory, where each level of metalanguage represents an ascent to a new order within the type theory.

There is a discussion of quantification as well as an exposition of Wittgenstein's class theory.

In short, Potter is able to pull out an impressive amount of technical material from what is an undoubtedly quite obscure work.

  One should never claim that "God doesn't exist" because one cannot prove this nonexistence.
  
  Is this an example of argumentum ad ignorantiam?


No, it's not an argumentum ad ignorantiam. It only says that one should never claim that God doesn't exist [with absolute certainty] because there is indeed no way to prove this nonexistence. One can make claims about the likelihood of the existence or nonexistence of God, but there is no way to disprove with absolute certainty that he doesn't exist. If someone said that he is absolutely, 100% certain that God does not exist, he would make a mistake, and that is all your quote says.
Under the understanding of a prioricity at issue pre-Two Dogmas of Empiricism, a priori truths were largely conflated with necessary truths. So, if you could recognize the possibility of the failure of the parallel postulate, that would constitute a falsification of its necessity and thus (given the conflation) a falsification of the claim that it was a priori.

Where Kant went wrong, if this was indeed what he held, was in thinking that our intuition of space and time represented the world as it actually is. Frege famously made the same mistake in one of his later articles, "Foundations of Geometry".

http://philmat.oxfordjournals.org/content/14/1/44.short This article, if you can get around the pay-wall, discusses Frege's Kantian views on geometry and provides ways to charitably interpret them.

Now, regarding your second question, I don't think you need to see this as showing that geometry or the categories of understanding had changed. I could see someone holding that it isn't the categories that have changed, but merely the classification of certain truths as falling under one or another of the categories.

So, a Neo-Kantian could consistently hold that the categories of understanding remain fixed and what non-euclidean geometry shows us is that geometry doesn't fall under the category Kant thought it did.

A quick look at the http://plato.stanford.edu/entries/categories/#KanCon SEP article on categories confirms that there are many philosophers, notably P.F. Strawson, who took up the Kantian project under the heading of "descriptive metaphysics". These philosophers were certainly aware of the developments of non-euclidean geometry.

Additionally, the article suggests (rightly) that this sort of empirical falsification wouldn't undermine a Kantian conception of the categories. See, for example:


  Nonetheless, it is clear that for Kant the categories find their original source in principles of human understanding, not in intrinsic divisions in mind-independent reality, and are discoverable by paying attention to possible forms of human judgment, not by study of the world itself, nor by study of our contingent manners of speaking.


Thus, even if we have discovered that the mind-independent world doesn't answer to our euclidean geometric conception of it, it does not follow that there is some fault in the division made between categories.
NOTE: This answer was given to a previous incarnation of this question. The block quotes I am responding to come from this incarnation. If I have the time I will modify my answer to respond more directly to this version of the question.


  When a person is placed in a position of absolute power, is it necessarily true that this power will condemn that person to commit evil acts?


No, it isn't necessarily true, and that isn't a part of the claim Acton is making. Note the use of the word "tends". Many people have defended the possibility of a benevolent dictator. Plato's Republic advances an oligarchy of "Philosopher Kings", which he thought would produce the best society.


  In effect, does power restrict free will?


I don't think there is any very interesting connection between these two concepts, if anything it seems to be the opposite. Someone with absolute (unchallengeable) power would be faced with no external compulsions and so (assuming the possibility of free will) would have the best chance at freely acting.

NOTE: The following is a bit of an aside that is only indirectly relevant, but which you may, nevertheless, find interesting.

There is, however, an interesting claim that Socrates makes in Plato's Gorgias:


  I say, Polus, that both orators and tyrants have the least power in their cities, as I was saying just now. For they do just about nothing they want to, though they certainly do whatever they see most fit to do. (Gorgias, 466e)


This weird claim has to do with Socrates' denial of akrasia, or weakness of will, where you act against what you believe to be best. Essentially, the claim he makes here is tyrants who commit evil are, in fact, slaves to their stupidity (to put it rather crudely). For, Socrates contends, they are making mistakes in measurement and wrongly considering the evil act to be the best.

This is, in fact, a bit of a caricature of the view, at least it doesn't explain it fully. I just thought it was interesting in connection with your question and presents a view on which "doing whatever you see fit" is not to have great power. It is also a view on which someone with the ability to do whatever they see fit actually does very little that they want to do.
The difficulty here seems to be that in order to do probability, you need to
know what space you're sampling from, and by construction, Sleeping Beauty
requires you to pay attention to that space.  There are two "intuitive"
spaces, and if you mix both, you end up confused.  Niel de Beaudrap has
already said as much, but given the amount of confusion expressed over this
"problem", I'd like to try being more explicit:

What "really" happens is this:

p=1/2    heads    awaken
p=1/2    tails    awaken    awaken


The funny thing about this is that you get two outcomes from one of the
branches.  This not infrequently happens in probability and statistics,
and it's no problem at all, but you have to decide what to do about it.

The Sleeping Beauty problem is typically formulated as Miss Beauty essentially
conducting an experiment each time she is woken up.  (Maybe you'll give her
a cookie if she's right.)  So half the time you get one experiment, half the
time you get two, and by construction in the problem you're supposed to lump
all of these together.  (If you had an army of Sleeping Beauties and you 
were tallying all the answers, this is what you'd want to do.)

So now we have three awakens in our sample space:

heads-awaken   tails-awaken-1   tails-awaken-2


which are all identical.  So if we do your calculation:

P(H|awaken) = P(awaken|H)*P(H)/P(awaken) = 1*(1/3)/1 = 1/3


Wait, what was that?

P(H) = 1/3


That's pretty weird--but look, we didn't have to go through the calcuation to
find that.  We have a sample space that by construction has heads only one
time out of three (cleverly constructed from a process that has 50% heads!).
So this is exactly right: the prior probability of heads is 1/3.

And Miss Beauty and everyone else would agree on this in advance of the
experiment ever being run (at least if they were up on their statistics).

Alternatively, if the formulation is such that there actually is an implicit
difference between the different awakenings (e.g. because the last one is
part of Miss Beauty's permanent experience, or because if she's right once and
wrong once on the tails branch you'd want to only give her half a cookie, and you don't want to break cookies, so you only ask her one of the two times on the tails branch), then she
(and everyone else) should perhaps do a different calculation:

p=1/2    heads    awaken
p=1/2    tails
     p=1/4        awaken
     p=1/4                   awaken


The logic here is that if you're on the tails branch and you wake up, 50%
of the time you'll be on the first instance, and 50% of the time you'll be
on the second.  In this case, you can calculate things like

p(H|awaken#1) = p(awaken#1|H)*p(H)/p(awaken#1) = 1*(1/2)/(3/4) = 2/3


meaning that if you know you're in the midst of the experiment and it's the first time you woke up, there's a 2/3 chance you're on the heads branch.  (p(H|awaken#2) = 0, and p(H) = 1/2 by the construction of this sample space.)

This is actually a more flexible framework to use--it is just as true as the
other one; it's just a different formulation suited for calculating different
things.  The key is recognizing how the sample space maps onto what may have
actually happened; if your sample space doesn't match the question you're
asking, you'll get the wrong answer.

For example, if Miss Beauty wants to maximize the number of cookies she's
awarded, and she gets one per correct guess, she will reason:

// I can pick only one option: H or T
// I will gain no information later so I may as well pick now

E(cookies) = sum(p(cookies)*#cookies)
If I pick H:
  p=1/2  right!         1 cookie
  p=1/2  wrong, wrong!  no cookie
  E(cookies) = (1/2 * 1  +  1/2 * 0) = (1/2 + 0) = 1/2
If I pick T:
  p=1/2  wrong!         no cookie
  p=1/2  right, right!  2 cookies
  E(cookies) = (1/2 * 0 + 1/2 * 2) = (0 + 1) = 1


Double the payoff if I pick T, even though I think P(T) = 0.5.

The real problem comes when one mixes the two sample spaces.  First, one thinks
that of course the three events are indistiguishable by construction, so
that p(H|awaken) = 1/3.  And of course a coin is fair, so p(H) = 1/2.
And then p(awaken|H) = 1 and p(awaken)= and 1/3 != 1/2 and...what the
heck?

Know the sample space, stick to it, and probability will make sense, even if
you are Sleeping Beauty.

[Note: http://chat.stackexchange.com/rooms/7645/discussion-between-rex-kerr-and-xodarap see also my chat transcript with Xoxarap.]
This looks like an interesting aspect of the general concept of http://plato.stanford.edu/entries/moral-luck/ Moral Luck, which I'm sure you would find worth investigating.  The most commonly cited first paper on this stuff is Thomas Nagel's http://philosophyfaculty.ucsd.edu/faculty/rarneson/Courses/NAGELMoralLuck.pdf Moral Luck, where he discussed the idea of the Control condition:


  Without being able to explain exactly why, we feel that the appropriateness of moral assessment is easily undermined by the discovery that the act or attribute, no matter how good or bad, is not under the person's control.


Nagel wanted to argue that the role of luck in assessment threatened to undermine not just individual apportionings of blame but the whole project of making moral judgements.  That's because there are some cases where we do and some where we don't want to think that control over the outcome is important - for instance, you don't lose responsibility for your actions just by being under the influence of hallucinogenic drugs.

One worthwhile response is to consider that "luck" may play much less of a factor in assessments of responsibility, and I think this is generally the case in your example.  A Kantian would say that you're responsible not because of how your actions have brought about consequences increasing or decreasing the likelihood of the correct outcome, but because of your intentions when acting.  Regardless of the question of whether I win the roll or not, you are responsible for the choice you made to pass the 8-sided dice rather than the 6-sided one.  This in a harmful action for which you bear responsibility, with no sense of there being a "degree" of responsibility lessened by appeal to luck since the actual outcome of the roll didn't impact whether what you did was morally correct or not.

But there are different kinds of moral luck that Nagel discusses, and all of these need addressing in order to get over the suggestion that our concept of holding people responsible might be in trouble.
Space as an objective, sui generis reality was held by


the ancient atomists
Descartes (with his res extensa, "extended substance")
Newton (with his geometric substance, which he endowed with divine attributes)


For a discussion on the plenum and the vacuum according to the ancient atomists, and how they were ulta-realists about the reality of absolute space, see P. Duhem's https://archive.org/stream/lesystmedumond01duhe#page/32/mode/2up Système du monde, vol. 1, pp. 33-5 or D. Nys's https://archive.org/stream/lanotiondespac00nysd#page/18/mode/2up La notion d'espace, ch. 1.
As Joseph Weissman stated in the comments, at the root of it is a false dichotomy. I'll look at this formally, but if you think about the sort of polarised spirit that is usually to be found behind statements such as "If you're not part of the solution, you're part of the problem", you can begin to see yourself.

An equivalent formulation to ¬S(u) ⇒ P(u) in classical logic (being a material implication) is S(u) v P(u): that is, either you are a part of the solution, or you are a part of the problem — leaving no room for anything which is neither (but, incidentally, leaving room for things which are both, which for societal problems might have examples in well-meaning but uncritical zealots). A dichotomy is exactly such a proposition which holds of all variables: in this case, ∀x: S(x) v P(x), which in the old saw is instantiated with the value x = u = you. If the universal statement is unsound, however, it is a false dichotomy.

In informal usage, a "false dichotomy" is still essentially the same as what I've said above, because the phrase 'false dichotomy' is only common currency among those who study logic, or rhetoric (e.g. in the form of law). How many problems are there, which are so clean-cut and simple that everyone is always either making the problem clearly better or worse, and never acting in such a way that either has no impact, or more perhaps having an impact whose value is quite ambiguous? Not to mention the often unrecognised complexity of assessing what the actual impact of someone's behaviour is.

Of course, statements such as "if you're not part of the solution, you're part of the problem" are not really intended to be formally sound. They're catchy phrases which are meant to stick in your head in order to make you more conscious of your behaviour — and the content of the idea precisely is that if you're not conscious of your behaviour, you're likely to be perpetuating some problematic system. So oversimplified statements such as this perhaps serve a positive role: they are part of the solution.

But the value of such stock phrases come from not evaluating the phrase itself very critically, when uncritical thinking is exactly what it is meant to combat. (The consequences of assuming that it must have formal, critical value is the basis for Wienersmith's joke.) If one assumes that such stock phrases represent critical thinking, one can become preoccupied with interpreting them as received texts, rather than doing original and free thinking about whatever subject may be at hand. Phrases as "if you're not part of the solution, you're part of the problem" can itself be part of the problem, if one is concerned with critical evaluation of one's behaviour. But if one already accepts that the impact of behaviour can be complicated and difficult to assess, the recognition that using a stock phrase has ambiguous utility shouldn't be too shocking. 
This is touched on (but not at great length) in Thomas McEvilley's The Shape of Ancient Thought.
I don't see the “self-refuting”. ‘Scientism’ is a term of abuse. Therefore, perhaps inevitably, there is no one simple characterization of the views of those who are thought to be identified as prone to it. Perhaps open to the charge of scientism is to think that  philosophical problems are scientific problems and should only be dealt with as such. A successful accusation of scientism usually relies upon a restrictive conception of the sciences and an optimistic conception of the philosophy as hitherto practiced. Nobody espouses scientism. A proposition is epistemic if and only if it has some implication for what, in some circumstances, is rationally worthy of belief. Scientific's  propositions are epistemic propositions.

I do not see science as a progress toward THE FINAL TRUTH. Many past theories were not approximately true or truthlike. Ptolemy's geocentric theory was rejected in the Copernican revolution, not retained in the form “approximately Ptolemy”. Indeed, the progressive steps from Ptolemy to Copernicus or from Newton to Einstein are not only matters of improved precision but involve changes in theoretical postulates and laws. There is no theory-independent way to reconstruct phrases like "really there", each theory has its own ontology. Convergence to the truth scientific progress seems to be impossible, if ontologies change with theories observations, and ontologies are relative to theories. Science is progressive only on values other than the truth, such as simplicity, predictive accuracy, comprehensiveness, and requirements for consistency. Scientific theories are hypothetical and always corrigible in principle. They may happen to be true, but we cannot know this for certain in any particular case.
You can see the (old but still authoritative) book of Benson Mates, https://books.google.it/books?id=3jmQoAEACAAJ Stoic Logic (University of California Press, 1953) at pag.84, on the Liar Paradox in Stoic Logic.
Here is what I wound up selecting for my course, grouped into the units I'll be teaching them in:



Unit 1: What is a Theory?

Hilary Putnam, "What Theories Are Not"

Bas van Fraasen, The Scientific Image ch. 3

Unit 2: What is Scientific Realism? 

Richard Boyd, "What Realism Implies and What It Does Not"

Unit 3: Underdetermination of Theories by Data

Pierre Duhem, "Physical Theory and Experiment"

Larry Laudan, "Demystifying Underdetermination"

Dana Tulodziecki, "Breaking the Ties: Epistemic Significance, Bacilli, and Underdetermination"

Unit 4: Theoretical Entities and Unobservables

Grover Maxwell, "The Ontological Status of Theoretical Entities"

Bas van Fraasen, The Scientific Image, ch. 2 sec. 2

Dicken and Lipton, "What Can Bas Believe?"

Muller and van Fraasen, "How to Talk About Unobservables"

Dicken, "On the Syntax and Semantics of Observability"

Unit 5: The Pessimistic Induction

Laudan, "A Confutation of Convergent Realism"

Psillos, "Scientific Realism and the 'Pessimistic Induction'"

Unit 6: Realism's Main Rival

Gideon Rosen, "What Is Constructive Empiricism?"

Bas van Fraassen, "Gideon Rosen on Constructive Empiricism"

Unit 7: How Does Realism Stack Up?

Musgrave, "Realism Versus Constructive Empiricism"



As you can see, I settled with only one anti-realist view for reasons of time and accessibility. A few of the articles I included because of their historical significance (Putnam, Duhem, and Maxwell). The Boyd article is a great introduction to scientific realism. I also found that the Laudan article on underdetermination provided a really good overview of that topic. Most of these articles aren't too technical and should be accessible to students with only a light background in logic. A few of my favorites are the Boyd, Tulodziecki, Musgrave, and Psillos. 
I think that this is actually a good question that could be made better by asking are humans risk averse.

Many human Beings gamble with their health - smoking and drugs.

Some people will knowingly and willingly go to certain death - suicide bombers.

Some people will knowingly and willingly seek out dangerous thrills - gambling, mountaineering and other extreme sports.

The 20th century documents in great detail - War and violence - these are not risk averse activities.

I don't know a great deal of economic theory - but my understanding is that risk is positively correlated with gain. The greater the risk the greater the possible gain. Behavioral economics critically examines the assumption that human beings are rational agents - on the face of it this does not seem to be true. It seems to be a generally assumed axiom for the fortuitous flow of nice economic results that follow rather than one upheld by critical observation. Human beings are far more often irrational than rational. 

Rationality is a key concept for developing the idea of risk-aversion rigorously. After all to be risk averse one has to coolly weigh the risks involved in decisions. 

The other concept that requires critical examination is the idea of perfect availability of information to all participants - just looking cursorily at any market shows that there are huge information asymmetries. These are two solid pillars of classical economics which upon examination really are quite risible. Its fairly obvious that once one begins to look at how classical economics is constructed that it has been carefully modelled on physics.

The rational agent - compare with the rational atom which collates all its collisions and then calculates the trajectory that it must embark on.

Perfect information - the perfect fluid or perfect gas of classical 19th century physics. With no viscosity and no friction. These assumptions are made to make the physics easy. If for example the atmosphere was a perfect gas we would have no weather. By analogy, one could suppose that building this assumption in classical economics one may have nice theorems but no actual - that is real economics.

There is an old adage in programming folklore - garbage in, garbage out. There is a converse that is appropriate here - perfection in, perfection out. 
Assuming that in your understanding 


In "steady state" universe practically (in a large enough time period) things would repeat itself, and, in this sense, nothing new happens. But this would call some kind of finiteness. Just the opposite of your inferrence.Maybe you need to justify why only a steady-state universe would allow infinities? Actually even in a steady state universe, things can still "change" as in the way i will describe below allowing infinities.
Just assume that the way things change in an "always-changing universe" (or even in a "steady-state universe") happens to be related with decimal expansion of  Pi (3.141592...). We know that there will be no repetition in this sequence no matter how long you count (or wait). Isn't this a room for a kind of infinity in both kinds of universes? The sequence of Pi decimal digits starts with a 1 and this may (for the sake of discussion) correspond to the "big-bang" moment. Still, you miss the other end. Kind of infinity, even if one-sided? Probably.


I would say that steady-stateness seems to have nothing to do with allowing or disallowing infinities. In both cases, for instance, the space itself or its geometry, or the fabric of the matter, would allow infinities.
From the Seminar on Heraclitus, pg.21


  Heidegger: Our German word Ein (one) is fatal for the Greek En (One) To what extent?
  
  Fink: In the relatedness of En (One) and Panta (Cosmos) it is not only a matter of a
  counterreference, but also of a unification.


Likewise in describing the concept of the Greek En (One), it is easy to be led astray by the mathematical concept of one, as something singular, unique, alone and the generator of succession. 

In a sense, these senses are within it, but the sense is better understood if its called the Unifying for it unifies the many wholly together, and the name itself signifies this, as something unified must have implicitly and potentially a manifold of many, even though it is seemingly a one. 
Take for an example the following two sentences:


At 12.03.2013 at 12 o clock Lukas was standing on the Golden Gate Bridge.
Yesterday I was standing at the Golden Gate Bridge.


In sentence 1 it is clear about which day and which time we are speaking. It is also clear who is standing and where he stands.

In sentence 2 the meaning (and truth) depends upon various things: The speaker, since "I" refers to whoever utters the sentence. The date, because "Yesterday" refers to the day before today. In some cases it might be true, but in some cases it will probably be wrong (except for the case of the utterer standing there everyday).

Terms like "Yesterday", "I", "there", "here" etc. are called indexical, because they can refer to different things.
The answer naturally depends heavily upon your own ethical model.

If you're working from some sort of http://plato.stanford.edu/entries/consequentialism/ Consequentialist theory, such as utilitarianism, then whether you should prevent the suicide normally depends on the weighting of the outcome. Assuming that being dead does not have some absurdly negative (perhaps infinitely so) weight, then someone who has few relations and would not cause much pain by taking their own life should be allowed to commit suicide. On the other hand someone who is loved by many and would be grieved for immensely should be kept from suicide even if there is no hope. Obviously these are rough terms, but generally this is the sort of position a consequentialist model would take.

If you're working by a http://plato.stanford.edu/entries/ethics-deontological/ Deontological theory I think the answers will be mostly consistent. Kantian ethics, for example, would probably hold that suicide is always unethical and should always be prevented, because of Kant's http://en.wikipedia.org/wiki/Kantian_ethics#Categorical_imperative Categorical Imperative. Other deontological models will generally involve some sort of hard moral absolutism where certain actions are always good or bad, and in these models suicide will normally be bad: factors that go into this judgment would be things such as the inherent value of life, consideration for one's loved ones, and arguments from contradiction that if suicide weren't bad, everyone would be allowed to do it and that this is ridiculous. However, there may be some wacky deontological theories which say that suicide is always acceptable, but these would be pretty uncommon.

Of course there are many nuances to each position, and not all ethical models fall under either consequentialism or deontology, but the majority of ethical theories will follow one of the arguments above.

  However, can your actions already be determined before those other actions have been performed?


According to a strictly deterministic view, yes. The amount of fuel in your gas tank determines how far you can travel, even though you haven't yet done that traveling. If a computer program is designed with a memory leak, the program will fail when memory is exhausted, even though the program has not yet been run. 

To my understanding, the essence of classical determinism is that the actual events do not have to take place for their outcomes to be determined. 

Perhaps scholars who dwell on these subjects will disagree - I am admittedly not familiar with all the scholarly literature. I can certainly accept the notion of what I would call soft or fuzzy determinism: A system in which pre-existing conditions would constrain outcomes such that they would fall only within certain parameters, but not definitively determine precise outcomes. 

A rather prosaic example of such  fuzzy determinism might be if someone has a genetic makeup that dictates that their height will be at minimum, 7 feet, 4 inches tall. It is absolutely determined that this person will have a hard time finding a suit that fits well. It is not absolutely determined that they will never have a suit that fits well. But perhaps "having a hard time finding a suit that fits well" is already a deterministically defined outcome.....
I'm personally sympathetic to the idea of Egyptian influence on Greek philosophy.  But the problem with using Plato as evidence for anything is that he is officially on record as endorsing the creation and promotion of wholesale fictions in the service of higher truth --his (in)famous concept of the https://outre-monde.com/2010/10/22/platonic-myths-the-myth-of-the-metals/ "Noble Lie" as introduced in the Republic. He also seems to have had an antipathy towards taking credit for his own ideas and therefore always places them in the mouths of other speakers (typically, but far from exclusively Socrates).  While this could be accurate, the ideas tend to have an idiosyncratic unity that argues against them actually being the unaltered arguments of so many diverse persons. He's generally considered to have wholly invented myths such as the "Lost City of Atlantis," and must accordingly be treated as an unreliable narrator with regards to historical fact.  It's worth comparing and contrasting him with his classmate https://en.wikipedia.org/wiki/Xenophon Xenophon, who is considered to be a more trustworthy historical source, but a much inferior philosopher.

However, your question was not "should" he be taken as evidence, but has he been taken as evidence.  The concept that Greek philosophy was borrowed from the Egyptians is a central tenet of http://www.asante.net/articles/26/afrocentricity/ Afrocentric scholarship, and is the core premise of British scholar Martin Bernal's influential but controversial three volume work, https://en.wikipedia.org/wiki/Black_Athena Black Athena.  The concept draws heavily on the work of the ancient historians https://en.wikipedia.org/wiki/Herodotus Herodotus and https://en.wikipedia.org/wiki/Diodorus_Siculus Diodorus Siculus who did in fact take Plato's statements (as well as other ancient sources) as evidence of actual Egyptian influence.  

This belief is currently discredited in more mainstream historiography, but as is always the case with history, it can be difficult to say with certainty http://www.newcriterion.com/articles.cfm/Stealing-history-3624 which interpretation is the biased one, and which one is objective.  While the Afrocentric viewpoint does have a clear political/cultural agenda, it is difficult to claim that the mainstream viewpoint could conceivably be entirely free of ethnocentric political/cultural biases either.  In my own opinion, the truth probably lies somewhere in the middle:  It's impossible to believe that Plato was entirely free of Egyptian influences, but a distortion to minimize the impact of his own original contributions to the ideas he synthesized.
(b) happens often enough.

"I prefer Gore to Bush.  But, I just heard Nader talk, and now I prefer Nader to Gore."

If you have 51% support for Gore, 49% support for Bush, and 0% support for Nader, but some Gore supporters decide they like Nader even more than Gore, the numbers will go to e.g. 48%, 49%, 3%, and Bush will win the election, even though nobody changed their Gore vs. Bush preference.

(The current system in the U.S. violates (b) a lot more than is mandated by Arrow's theorem--an alternate system wouldn't have this "spoiler" effect manifest quite so easily.)
For virtually all of your philosophical needs, I would recommend the http://plato.stanford.edu/ Stanford Encyclopaedia of Philosophy. It has excellent and rather concise summaries of most important topics in philosophy, and if you're looking for a quick intro, it's an excellent source.

Other than that, there may be scattered summaries of various ideas, but to address your main concern: philosophy is often about being as clear as you can be, and generally that requires extensive elaboration. What seems (and usually is) superfluous is also essential to avoiding misinterpretation, since of all the people who read a work it's almost inevitable that one of them will need more than the bare minimum explanation. However, "trivia" as you put it is not universal in philosophy and there are many philosophers who will leave it out. In contemporary writings it's a tad more common to see random facts being used, but in older works that sort of thing is much more rarer. In general I don't think philosophical writings are as unnecessarily long as you say.

For example, http://en.wikipedia.org/wiki/Niccol%C3%B2_Machiavelli Machiavelli's http://en.wikipedia.org/wiki/The_Prince The Prince is a concise (about 80 pages, if memory serves) book on political philosophy, and though it uses many examples these are all essential to his points. http://en.wikipedia.org/wiki/Nietzsche Nietzsche's writings are also often presented in concise form, though they do bear literary embellishment, and also Nietzsche is one of the most opaque philosophers around. http://en.wikipedia.org/wiki/Wittgenstein Wittgenstein's http://en.wikipedia.org/wiki/Tractatus_Logico-Philosophicus Tractatus is perhaps the most concise work you'll find, but this comes at the price of being very difficult to understand.

So in short, I recommend the SEP for short summaries, and I don't think the situation is quite as bad as you make it out to be since there are a good number of philosophers who do manage to be concise.
There are three Sanskrit editions freely available.

http://fiindolo.sub.uni-goettingen.de/gretil/1_sanskr/6_sastra/3_phil/buddh/nagmmk_u.htm Here is the J.W. de Jong edition; http://www.dsbcproject.org/node/8237 here is the P.L. Vaidya edition; and https://www2.hf.uio.no/polyglotta/index.php?page=fulltext&vid=27&view=fulltext here is the edition by Louis de Vallée-Poussin.

The difference between them are minor.

If you allow infinitary rules like the omega-rule, more becomes provable so PA plus the omega-rule proves the Gödel-sentence for PA. But PA plus the omega-rule still isn't complete -- a result that goes back to Rosser's 1937 JSL paper on Gödel theorems for non-constructive logics. Dan Isaacson's paper on the omega rule might be helpful here: "Some considerations on arithmetical truth and the ω-rule", in Michael Detlefsen (ed.), Proof, Logic and Formalization, Routledge, London, 1991, pp. 94-138.
Gentzen's proof of the consistency of PA is done in a framework which assumes a certain amount of transfinite induction (more transfinite induction that is available via coding within PA itself). But proofs by transfinite induction are still finite strings of sentences (consider such proofs in ZF, for example!).


  Couldn't anybody find some reasons for proving/disproving it?


I think it is "dissolved" and not "unsolved".

http://en.wikipedia.org/wiki/Radical_skepticism Radical skepticism with regard to the possibility of ultimate philosophical grounding is based on an abstractive fallacy. It is somewhat misleading coherence  to present the radical skeptic position in terms of an argument, because in presenting an argument one is usually committed to the truth of its premises and conclusion, whereas radical skeptics would suspend judgment with respect to them. Problems remain regarding the coherence of anyone who accepts the soundness of an argument whose conclusion is that we are not justified in believing anything. The so called http://en.wikipedia.org/wiki/M%C3%BCnchhausen_trilemma Münchhausen trilemma can be overcome by recognizing that some presuppositions are necessary for the very possibility of intersubjectively valid criticism and argumentation. The “principle of http://en.wikipedia.org/wiki/Fallibilism fallibilism” which holds that any claim can, in principle, be doubted is only meaningful within an framework where some pragmatic rules and norms are not open to question. The Wittgenstein’s words are about throwing the ladder after using it to climb.

Whereas language is a medium for the communication of thought which exist independently of language, language is a vehicle of  thought. What our words mean - hence what thoughts we have - is a function of what sentences we hold true. To entertain all the thoughts we currently have, while universally doubting their truth, is not straightforward. Anything may be dubitable, but not everything at once. 

Ideas from Karl-Otto Apel, Wittgenstein.
I think the issue here is your definition of infinity. You are correct in your last sentence that infinity is a mathematical imaginary convenience. It it's not possible to have an infinity of anything in the real world. In mathematical terms, infinity is not considered a "real" number. It is a useful concept to help conceptualize certain otherwise impossible operations.

For example, 1 divided by 0 is technically undefined because you can't divide something into no segments. However, this case comes up frequently when dealing with many math forms, so the concept of infinity is useful. As you divide 1 by smaller and smaller numbers, the result is a larger and larger number. Dividing 1 into any real number of segments will yield some real amount in each segment. But you can get zero in each segment if you have an unreal infinity of segments. So, technically you would say that 1/0 is undefined, but it approaches infinity.

So, to answer your question, you can make an infinite amount of infinities out of a single infinity. Mathematically, 2 times infinity is just infinity. All of the contradictions go away once you let go of infinity being a real thing.
After reading a little bit more on this issue, I think I can write a full answer.

Stephen Law's Evil God Hypothesis is about that if you can have an omnibenevolent god and the problem of evil, then you can also have an evil god with a problem of good. Furthermore, you can use all the classic explanations for the problem of evil that occurs when assuming a benevolent god, to explain the problem of good when assuming an evil god. It is not about proving or disproving the existence of God; it's about once you assume the existence of god, then why assume he is omnibenevolent?

Stephen Law says that many people say the universe shows signs of design, for a number of reasons which I will not expand upon here, since that's a whole other topic. However, if you assume that god exists based on this argument, then how can you assume that he is omnibenevolent? Evidence of design is no evidence of moral goodness, Law argues.

If you do assume an omnibenevolent god, then you have to deal with the problem of evil. It is clear there is a lot of suffering in the world, which many find a compelling argument against the existence of god. Bertrand Russell famously said: "No one can sit at the bedside of a dying child and still believe in God."

There are a number of ways to address this problem. One is the free will solution. In a nutshell, God gave us free will, and therefore, we can do good things and bad things. He had to do so to create creatures who are free. This is known as https://en.wikipedia.org/wiki/Alvin_Plantinga%27s_free_will_defense Alvin Plantinga's free will defence. The main point of criticism is that it only deals with moral evil (people choosing to do bad things), not natural evil (for instance, earthquakes or children dying from horrible diseases). 
Another is character building. People need to go through some negative experiences to grow as a person and for that, some evil is required.
Yet another one is that you simply can't have good without evil. You cannot be charitable if there are no people in need, for instance.
And some people say that "God acts in mysterious ways". It would simply be arrogant to suppose that we can comprehend God's mind. What seems to be evil to us, is actually good for us, but we're simply not intelligent enough to see this.

Stephen Law uses these arguments (in a slightly different way) to explain the problem of good if we assume an all-evil god. Some examples below:


  Free will
  
  BOOBLEFRIP: God gave us free will.
  
  GIZIMOTH: Free will?
  
  BOOBLEFRIP: Yes. God could have made us mere automata that always did the wrong thing – the evil thing. But he didn’t do that. He gave us the freedom to choose how we act.
  
  GIZIMOTH: Why?
  
  BOOBLEFRIP: Because, by giving us free will God actually increased the amount of suffering there is in the world. He made the world far more terrible than it would otherwise have been!
  
  GIZIMOTH: How?
  
  BOOBLEFRIP: Think about it. God could have just tortured us with a red hot poker for all eternity. But that would have got rather dull for him rather quickly. How much more satisfying to mess with our minds – to inflict more sophisticated psychological forms of suffering. 
  
  Natural beauty
  
  GIZIMOTH: Well, what about the glories of nature: sublime sunsets, stunning landscapes, the splendor of the heavens? We’re not responsible for these things, are we?
  BOOBLEFRIP: No. God is.
  GIZIMOTH: But why would an all-evil God create something that gives us pleasure? Also, why does he give us beautiful children to love? And why does he choose to give some people extraordinary good fortune – health, wealth and happiness in abundance? Surely the existence of these things provides us with overwhelming evidence that, even if the universe has a creator, he’s not all bad?
  The “character-destroying” solution
  
  BOOBLEFRIP: You’re mistaken, Gizimoth. Such things are exactly what we should expect if God is supremely evil.
  
  GIZIMOTH: But why?
  
  BOOBLEFRIP: Some natural beauty is certainly to be expected. If everything was uniformly ugly, we wouldn’t be tormented by the ugliness half as much as if it were laced with some beauty. To truly appreciate the ghastliness of the environment most of us inhabit – a urine stained, concrete and asphalt wasteland peppered with advertising hoardings, drug addicts and dog dirt – we need to be reminded every now and then that things could have been different. God put some natural beauty into the world to make our appreciation of the ugliness and dreariness of day-to-day life all the more acute.
  
  http://www.investigatingatheism.info/stephenlaw.html source


So, what this effectively shows is that, if you derive moral goodness from the argument of design (or any other argument from which you shouldn't/can't derive moral goodness), then you can also derive moral evil from that same argument, i.e. you cannot draw any conclusions about whether god is omnibenevolent or not based on this argument alone. Therefore, deriving whether god is (supremely) good or not requires other arguments. 
Might I suggest:


http://personal.lse.ac.uk/ROBERT49/teaching/ph201/Week03_Craver.pdf C.F. Craver (2001) “Structures of Scientific Theories,” for P.K. Machamer and M. Silberstein eds. Blackwell Guide to the Philosophy of Science. Oxford: Blackwell. (with editorial corrections not in the published copy).

The historical notion of success derives from the desire for fame which was an eschatological response to the loss and replacement of transcendence or the divine ground as the ultimate orientation of the soul.  In Plato’s book X of the Republic there is the Myth of Er which recounts the destiny and drama of the soul as an account of rewards and punishments in the afterlife.  This Greek version of success gets extended and Christianized through Boethius’ The Consolation of Philosophy and Dante’s Divine Comedy.  With the apex of Thomas Aquinas’ philosophical theology we reach the immortality of the soul turned into the beatific vision and friendship with God.  In mid-fifteenth century, Poggio Bracciolini introduced fame as a symbol for the triumph of a world-immanent soul who seeks salvation through remembrance beyond one's historical epoch, not in the eternal civitas Dei.  Eric Voegelin states:  “The intramundane afterlife of fame is replacing the life beyond.  Salvation by fame, however, is precarious, just as is salvation by Grace; many are called, but few are the elect.  The orientation within the world requires no less a theology of fall and redemption than does the transcendental orientation” (Religion and the Rise of Modernity, in volume 23 of The Collected Works of Eric Voegelin, 139).  This speculation enters under the impact of the Reformation and competitive society.  “By the nineteenth century the biological formula of the survival of the fittest has replaced the Renaissance speculation on the fortuna secunda et adversa, and the survival of the fittest implies the plebian assumption that he who survives is the better man.  Poggio is still aware of the tension between fate and value; he is sensitive to the tragedy of history; and there is something alive in him of the Polybian shudder in the face of victory.  In the later adoration of success the two dimensions of action, victory and value, are made to coincide and the flow of action becomes untragically progressive; the plebian victor does not like to see the shadow of fortuna; he wants to be the victor by his merit” (ibid., 139-40).       

Success is transformed from other-worldly to the secular intramundane in modernity; this is one of the consequences of embracing human mortality and finitude.  It also enhances the alienation and estrangement, along with Angst of modern selves because they look to subjective immortality through others who seek the same thing.  That the historians will tell the people about their great deeds and achievements and this should give further satisfaction for those willing to follow or connected to them in some inspirational way.  Praise for military, literary, or entertainment greatness culminates into living in the hearts and minds of future generations.  But like Polybius we will “shudder” in the reality that the people will forget or that just as we conquer a people today, the same demise will visit our people someday.  

Therefore, I see success more to do with the “adventure” of one’s existence along the rhythms of victory and defeat, fame and shame.  This adventure also applies to cultures and can be interpreted aesthetically, religiously, morally, and so on.  Civilizational advancement would not be enough to be persuaded by the spirit of progress alone.  It lies more in the effort and tenacity one is able to achieve through intensity and the accretion of value as stablized in sets of harmonies conducive to its environments.  This includes the consideration and integration of exclusive or negative relations (prehensions) and the inhibitive nature of disharmonies, including their potential stagnation and destructiveness for the organic society or (non-) social nexus.      

As Whitehead writes at the end of Science and Modern World:  “But in nature the normal way in which trees flourish is by their association in a forest. Each tree may lose something of its individual perfection of growth, but they mutually assist each other in preserving the conditions for survival. The soil is preserved and shaded; and the microbes necessary for its fertility are neither scorched, nor frozen, nor washed away. A forest is the triumph of the organisation of mutually dependent species. Further a species of microbes which kills the forest, also exterminates itself. Again the two sexes exhibit the same advantage of differentiation. In the history of the world, the prize has not gone to those species which specialised in methods of violence, or even in defensive armour. In fact, nature began with producing animals encased in hard shells for defence against the ills of life. It also experimented in size. But smaller animals, without external armour, warm-blooded, sensitive, and alert, have cleared these monsters off the face of the earth. Also, the lions and tigers are not the successful species. There is something in the ready use of force which defeats its own object. Its main defect is that it bars coöperation. Every organism requires an environment of friends, partly to shield it from violent changes, and partly to supply it with its wants....The Gospel of Force is incompatible with a social life. By force, I mean antagonism in its most general sense.
Almost equally dangerous is the Gospel of Uniformity. The differences between the nations and races of mankind are required to preserve the conditions under which higher development is possible. One main factor in the upward trend of animal life has been the power of wandering. Perhaps this is why the armour-plated monsters fared badly. They could not wander. Animals wander into new conditions. They have to adapt themselves or die. Mankind has wandered from the trees to the plains, from the plains to the seacoast, from climate to climate, from continent to continent, and from habit of life to habit of life. When man ceases to wander, he will cease to ascend in the scale of being. Physical wandering is still important, but greater still is the power of man’s spiritual adventures—adventures of thought, adventures of passionate feeling, adventures of aesthetic experience. A diversification among human communities is essential for the provision of the incentive and material for the Odyssey of the human spirit. Other nations of different habits are not enemies: they are godsends. Men require of their neighbours something sufficiently akin to be understood, something sufficiently different to provoke attention, and something great enough to command admiration. We must not expect, however, all the virtues. We should even be satisfied if there is something odd enough to be interesting.” (New York:  The Free Press, 1967, 206-07).           
One thing I would note is that speaking in unwarrantably broad terms of movements such as 'existentialism' or 'German Idealism' (therefore esp. continental philosophy) in general does little other than allow a person to say a lot things about a lot of authors whose works they've never actually read ..


  What are some good introductions to the variety of movements that
  constitute "contintental" philosophy?


One which I have never read, but would endorse through the quality of it's authors is Simon Critchley and William Schroder's A Companion to Continental Philosophy


  Which forerunners of these movements might be most helpful in terms of
  understanding their theoretical and historical context?Which
  forerunners of these movements might be most helpful in terms of
  understanding their theoretical and historical context?


I think the big one in terms of forerunners is Heraclitus, for the reason that in pre-Socratic philosophy he is the the first significant figure to privilege becoming over being. For a good short intro I would suggest http://www.albany.edu/~rn774/fall96/philos3.html this short article on Heraclitus and Parmenides 

One important forerunner of phenomenology is http://plato.stanford.edu/entries/brentano/#Intentionality Franz Brentano, as it was his conception of intentionality that was a major influence on Husserl developing the phenomenological method

German idealism is a hard one to pinpoint specific forerunners, however familiarity with Locke, Berkeley, as well as David Hume's criticisms of the latter, are a good place to start in seeking to understand the problems which Kant's philosophy address'.

Trying to pinpoint forerunners of Nietzsche, because of the scope of his reading, can be like seeking a candle flame inside the sun. Schopenhauer is the obvious one, but much of his learning stems from his reading of the Greeks, for example where Callicles asserts that justice is "the rule of the strong", Nietzsche sides with the interlocutor of Socrates who believes justice is merely the weak imposing their way of life upon the strong. My personal suggestion, and of course not everyone would agree, but in looking for an entry point into contemporary continental philosophy, is to begin with Nietzsche. For a clearly written introduction which is fairly orthadox in its interpretation I would suggest http://rads.stackoverflow.com/amzn/click/0691019835 this book   

Ultimately the list could be almost endless, but these are the few that I would suggest.

Happy reading :)
Kant is interested in space as you see it when you open your eyes. When I look out of my window I do not see parallel lines meeting at infinity (perspectivally we do, but that is a completely different question). Kants isn't investigating either theoretical questions of geometry nor of space & time - he's more concerned about our immediate perception of space & time. He's specifically interested in where consciousness meets space and time (not the two together - that is spacetime - we don't immediately perceive the space time metric).

No doubt he would have been interested in the theoretical possibility of non-euclidean geometry and also of the curvature of physical space-time had they been discovered then - he had been scientifically inclined until he moved decisively towards philosophy. In fact it was Humes critique about the possibility of science that woke him up from his 'dogmatic slumber'.
Recast in a classical logical framework, you could start with a family M of models for which your truth-statements are interpretable (i.e. they refer to things in those models); if these models are all reasonable approximations of reality (even if they differ in some details), then "in some ways it is" means "there exists m in M s.t. p is true in m".  Let D be a decidability function (i.e. D(p,m) implies that there is a proof of p given model m--whether you want to work with different models or different sets of truth statements is a more complex issue than I have time to think through).  Then "in some ways it is indescribable" means that "there exists m in M s.t. !D(p,m)" (where ! means "not")--it might be true or it might not, but you can't show it.

So then we have these three fundamental statements:

A: exists `m` in `M` s.t. `p`
B: exists `n` in `M` s.t. `!p`
C: exists `r` in `M` s.t. `!D(p,r)`


And the seven propositions are just an exhaustive combinations of these:

A
B
A & B
A & C
B & C
A & B & C
C


(omitting the trivial case of no statement at all).

I am not sure this exactly maps onto the Jain propositions, but at least it's a start in that direction.
From what I understand, there is actually a lot of disagreement about the chronology of the dialogues. After a bit of searching, I did come up with this link that lists some the dialogues sorted chronologically. Hope it helps.

http://www.mesacc.edu/~davpy35701/text/plato-chrono.pdf Plato's Dialogues

EDIT

The above link lists them, as Keshav Srinivasan pointed out, in order of writing. The below is one person's listing of the dramatic order, or the order in which they occurred.


LAWS (460)
EPINOMIS
PARMENIDES (450)
PROTAGORAS
ALCIBIADES I and II
CHARMIDES
LACHES
HIPPIAS MAJOR and MINOR
SYMPOSIUM (416)
PHAEDRUS
ION
CLITOPHON
REPUBLIC (411)
PHILEBUS
TIMAEUS-CRITIAS
THEAGES
EUTHYDEMUS
LYSIS
GORGIAS
MENO
THEATETUS
EUTYPHRO
CRATYLUS
SOPHIST
STATESMAN
APOLOGY
CRITO
PHAEDO
MENEXENUS


This list is listed in PLATO’S PHILOSOPHERS by Catherine Zuckert.

The numbers signify the date they were written, for a reference.

Source: http://www.solopassion.com/node/7198 http://www.solopassion.com/node/7198
It can be said that while Marx takes the structure of Hegel´s dialectics and then invert it, Schelling criticises a more fundamental principle of his thought. For Schelling (his late philosophy) Hegel is a panlogician-pantheist. His God/Absolute moves from the concept to the Idea with a irrevocable necessity. Schelling opposes then a "living God", that is, a God that can come or not into being. A God that can be "B" in a moment, and then become "not B" (for example). A God that has an in-conscience Grund. A God that has a Past (!) and an history of his revelation.  
I can imagine that it may often be difficult for responses on philosophy.stackexchange to be correctly called 'answers' since there must always be room for interpretation and evaluation in philosophical matters, but allow me to give you my views on your question and from it perhaps you will be able to discover an answer for yourself if not for everyone.

Continental philosophy has profoundly—albeit misguidedly—influenced art, literature and film throughout the world. Analytic philosophy has inspired developments in mathematics and computer science, shaped the scientific method, and informed quantitative approaches to psychology and sociology. Both branches have elicited developments in linguistics. What continental philosophy has not done is continue developing in its original spirit; even since Sartre, continental philosophy has rather begun to regress or become blended with analytic flavours, with such notions as embodiment blending ideas from Kant, Husserl, Heidegger, Merleau-Ponty and others. Conversely, analytic philosophy has continued developing in the same way but in increasingly insignificant increments as it gradually cedes much of its original lines of inquiry to the sciences.

This is the primary distinction between the two branches of philosophy: analytic philosophy walks hand in hand with science and scientism; continental philosophy focuses on the poetic and metaphysical understanding of the world. Analytic philosophy divides the world into subject and object; continental philosophy seeks to unite observer and observed to reach a fundamental and unbounded picture of both. Analytic philosophy seeks to simplify philosophy through demarcation, whilst continental philosophy is concerned with questions that are intuitively more fundamental even than science or logic. 

Analytic philosophy might be said to have had the more profound influence in contemporary academic circles, but what does that actually mean? Analytic philosophy has no purpose, because its goals are either impossible or fall to scientific endeavours to complete. Continental philosophy has arguably seen less academic attention (or at least less academic understanding/improvement) but the ideas of phenomenology, existentialism and deconstruction have disseminated globally and inspired vast amounts of creative work—though often the ideas are distorted or misinterpreted in such works, as is usually the case when an academic concept reaches the populace.

Judging which branch of contemporary philosophy has had the more profound influence will depend on what you personally think is more profound: the sciences or the humanities. Or perhaps not, if you think as I think: that analytic philosophy is not philosophy at all, but rather an auditing process for scientific enterprise. Continental philosophy represents, to me, a truer philosophy, especially through Heidegger and the break with the Cartesian tradition of subject/object opposition and through Derrida's subsequent refinement of destruktion as deconstruction.

Within the academic discipline of philosophy itself, it is difficult to judge which branch had the more profound impact. Philosophy finds itself in troubled water these days, unsure of whether it is a science or an art; you will find academics undertaking scientific studies of a psychological/neurological character calling it philosophy, and likewise you will find people still agonising over Aristotle, Chrysippus, Kant, Hegel, Husserl, and so on—and as Derrida certainly demonstrated, no philosophers will truly lose their significance, because their ideas were defined and remain defined by their opposition to each other and to the times, and that these definitions are traces of a genealogy of meaning that will not end. 

We might say that Continental philosophy affirms philosophy as a subject and gives it life, paves the way for future study and creation. In contrast, analytic philosophy might be said to be less constructive, narrowing philosophy down according to scientific standards over which philosophy ought to preside. I do not mean to say that analytic philosophy is only logical positivism, but analytic philosophers do not do what philosophers must by definition do: question themselves and their methods.
Virtue ethics are not proposed as a solution to defining what is good.  Rather, it is in contrast to, for example, (direct) utilitarian ethics where it doesn't matter what virtue you may or may not be following; all that matters is outcome.

Virtue ethics spares you from considering all eventualities, and instead says: it is good to act like so, even if things don't always turn out the way you'd hope.

Both virtue- and consequence-based systems have problems in objectively defining what is a good virtue or good consequence (and how to measure it, if needed).
Rhetoric is the appeal to emotion when it is clear that the audience is not amenable to logic and reason. As such, advertising, especially (but not only) those that contain starving children and the suggestion that only literal spastics don't buy a certain product (as depicted in infomercials), frequently ventures into the realm of rhetoric.

Rhetoric is simply an appeal to emotion and/or vanity disguised as reasoning. The best examples can be found in epic speeches before a football game, a battle, at a political rally, or in courtroom dramas.

From The opening passage of http://classics.mit.edu/Aristotle/rhetoric.3.iii.html Part 1 of Book III (from MIT's archive, translated by W.Rhys Roberts):


  In making a speech one must study three points: first, the means of producing persuasion; second, the style, or language, to be used; third, the proper arrangement of the various parts of the speech. We have already specified the sources of persuasion. We have shown that these are three in number; what they are; and why there are only these three: for we have shown that persuasion must in every case be effected either (1) by working on the emotions of the judges themselves, (2) by giving them the right impression of the speakers' character, or (3) by proving the truth of the statements made. 


as (3) is more commonly referred to as Dialectic, RHetoric is focused more on (1) and (2).

The chapter goes on the describe the ways in which "theatrics" can be employed to sway the opinion of the audience (meaning the target of the rhetoric).

http://rhetoric.eserver.org/aristotle/ Source 1 : Treatise on Rhetoric

http://books.google.co.za/books?id=ESbCR-2HnncC&printsec=frontcover&dq=plato%20rhetoric&hl=en&sa=X&ei=WH0jUvOFE9CRhQewnYCQBQ&ved=0CC4Q6AEwAA#v=onepage&q=plato%20rhetoric&f=false Source 2 : Plato on Rhetoric
The basic thrust of Plantinga's argument is that God is not all-powerful (omnipotent); He cannot create a world where free will exists and not allow them to choose between evil or good. He doesn't specifically address the conflict between foreknowledge and free will, but it is implied that God lacks such foreknowledge (he is not omnipotent) because otherwise it could be argued that free will couldn't exist (in a universe in which there is only one possible future).

Plantinga's summary:


  A world containing creatures who are significantly free (and freely
  perform more good than evil actions) is more valuable, all else being
  equal, than a world containing no free creatures at all. Now God can
  create free creatures, but He can't cause or determine them to do only
  what is right. For if He does so, then they aren't significantly free
  after all; they do not do what is right freely. To create creatures
  capable of moral good, therefore, He must create creatures capable of
  moral evil; and He can't give these creatures the freedom to perform
  evil and at the same time prevent them from doing so. As it turned
  out, sadly enough, some of the free creatures God created went wrong
  in the exercise of their freedom; this is the source of moral evil.


He concludes with:


  The fact that free creatures sometimes go wrong, however, counts
  neither against God's omnipotence nor against His goodness; for He
  could have forestalled the occurrence of moral evil only by removing
  the possibility of moral good.


This is patently wrong, however. Of course it counts against his omnipotence. Either God can do anything, or he can't. Omnipotence is not up for debate.

So he doesn't actually resolve the conflict. The Problem of Evil, I'm afraid, is still a problem.
There are some arguments that Nietzsche's slave/master-morality (Sklaven- und Herrenmoral) and Hegel's master-slave dialectic (Herrschaft und Knechtschaft) is intimately linked:

Philip J. Kain. 1996. Nietzschean genealogy and Hegelian history in 'The Genealogy of Morals'. http://www.jstor.org/discover/10.2307/40231939?uid=3738744&uid=2129&uid=2&uid=70&uid=4&sid=21103427447023 Canadian Journal of Philosophy 26(1).

William Callison. 2011. Nietzsche and Hegel: Identity-formation and the Slave/Master dialectic. https://artsciweb.concordia.ca/ojs/index.php/gnosis/article/view/102 Gnosis 9(3) NB! Post-grad journal.

I would posit that GM I represents a re-writing (sublation/aufheben) of master-slave dialectic expanding recognition and power with identity and morality, yet expunging the Hegelian teleology. However, much depends on wether or not you accept Deleuze's argument portraying Nietzsche and Hegel as opposites. (Hegel was a systematiser, and Nietzsche disapproved of that).

It would be a mistake to think of Nietzsche or Hegel in the simple terms of whether they thought the master or the slave was better. Take Nietzsche for example. He does not merely side with the master: "The history of mankind would be far too stupid a thing if it had not had the intellect [Geist] of the powerless injected into it" (GM I: 3). Combine that with his contempt for 'the haters of Christianity' also, and a much more complex Nietzsche emerges than one who simply wants to re-assert Master-morality.
We have a good number of fragments that are attributed to Parmenides himself. Specifically regarding the void, Parmenides asserts that you cannot separate what is from what is, because doing so impliesa something that is not. Since  what is not is not, it can't be used as a property of difference. Thus, there can't be any difference in the world, which implies a pure monism. It then further implies that there is no motion, because that would require a difference in location, but we can't have difference of any kind. By the same logic, we have no motion, indivisiblity, one-ness, and sameness of all things. In Plato's Parmenides, we see Plato's take on Zeno as a type of negative proof for Parmenides' monism, but that's a slightly different story. When reading Plato's book though, there are some questions surrounding if what is referred to in Part I and Part II are the same thing (Parmenides' Monad vs Plato's One-ness the form). I would suggest reading the fragment's of Par's poem and Zeno's paradoxes prior to reading Plato's Parmenides.
Ontological categories are categories of being. If 'exists' means 'is in spacetime' or 'exists physically', then abstract objects can still be considered an ontological category, without any patent contradictions with the view that such objects don't have (physical) existence. If, however, 'exists' means 'exists simpliciter', then how can one deny abstract objects any existence and then claim that they belong to a category of being? Under this interpretation, your definition of nominalism is indeed incompatible with the claim that abstract objects constitute an ontological category.
Qn 1. No. Here's the correct equivalence:


  ¬∃x(Nx ∧ Axc) 


is equivalent to  


  ∀x¬(Nx ∧ Axc) 


for pushing a negation pass a quantifier flips the quantifier to its dual. And that's equivalent to


  ∀x(Nx → ¬Axc)


by the classical equivalence of ¬(A ∧ B) with (¬A v ¬B) with (A → ¬ B). 

Qn. 2 You find out whether ∀x(Sx → (Ox ∨ Px)) by finding out whether everything in that store is either overpriced or poorly made. That might be a practical problem, but it isn't a logical one!
"Is anything essential lost" or are the shortcomings of Meyer's system in "the exotic outer reaches of what is possible in traditional PA"? 

PA proves that formula if p > 2 is prime, then there is a positive integer y which is not a quadratic residue mod p; that is, 


  ∃y ∀z: ¬(y ≡ z^2 (mod p)).


That looks like a pretty unexotic bit of number theory to me. Fails in Meyer's system though. Bad news?

See R. Meyer and H. Friedman, Whither Relevant Arithmetic?, JSL 1992, 824–831.
It would be interesting to have some passages to compare from these authors that you speak about. I too would say, intuitively, that they can't mean exactly the same. So I put my head into some books (not really) to see what I can come up with. I do not find my finding interesting enough to earn a bounty, but nonetheless I prefer to share.

What I did find interesting was this distinction by Cicero from the http://en.wikipedia.org/wiki/Duty Wiki on "duty": 


  Cicero, an early philosopher who discusses duty in his work “On Duty", suggests that duties can come from four different sources:[2]


as result of being human
as a result of one's particular place in life (one's family, one's country, one's job)
as a result of one's character
as a result of one's own moral expectations for oneself


It also states: 


  Various derivative uses of the word have sprung from the root idea of obligation, a concept involved in the notion of duty; thus it is used in the services performed by a minister of a church, by a soldier, or by any employee or servant.


The concepts thus seem to be interwoven. The Wiktionary on http://en.wiktionary.org/wiki/obligation obligation and http://en.wiktionary.org/wiki/duty duty provided me with information on the etymology of the words.


  Obligation: From Latin obligatio, from obligatum (past participle of obligare), from ob- to + ligare to bind, from Proto-Indo-European *leig- (“to bind”).
  
  Duty: From Middle English duete, from Old French deu (“due”), past participle of devoir (“to owe”), from Latin debere (“to owe”), from de (“from”) + habere (“to have”).


But what's really interesting is http://www.google.de/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&ved=0CDkQFjAC&url=http%3A%2F%2Fwww.legiscompare.fr%2Fsite-web%2FIMG%2Fpdf%2F10._CH_2_Obligation_and_duty.pdf&ei=FLxJUvqaBMjVswbsg4CIBQ&usg=AFQjCNEZaOEqfZUiZK4nIgXwimfcwMjyDg&bvm=bv.53217764,d.Yms this Pdf on legal terminology I found. It states that even from a legal point of view, there is uncertainty about the use of these terms. I quote: 


  The terms ‘obligation’ and ‘duty’ are sometimes used as synonyms. They refer either to the
  entire contractual relationship between the parties or, more narrowly, to what is due by the
  obligor to the obligee.
  
  Under American law and English law, as under French law, an informal consensus would
  appear to have emerged, to the effect that the terms ‘duty’ and ‘obligation’ are synonymous.
  
  For instance, the term ‘obligation’ in the singular or ‘obligations’ in the plural is univocal
  when it refers to what one party has agreed to perform under the terms of an agreement. In this
  sense, the positive counterpart of the obligation is the right (‘rights and obligations’), that is to
  say what the creditor is entitled to receive from the debtor. This is a classical view of the term
  ‘obligation’ seen as ‘a tie which exists between at least two individual persons which enables
  one person to request something from the other’1. The obligation should therefore be perceived
  as including a legal tie, a legal tie between at least two persons and a coercitive power enabling
  the enforcement of the obligation.
  
  The area covered by duties is wider than that covered by obligations. A duty may be owed to a
  person other than the other party to the contract. This distinction is in fact applied in English
  law, in order to define the duty of confidentiality.


It would be useless to quote the whole paper, though I really think that it might answer your question. That leaves me to say that, though it might have seemed to you that they're not used synonymously, both the encyclopedia and the legal praxis claim they pretty much are. As you already figured out, your first thought, namely that "duty" might entail an action, is not right, because of the negative duties. Both concepts can refer to the human as human or to specific qualities. Both have, even etymologically, a reference to the object of the duty/obligation. No difference, even there. There might be a little legal difference, for it seems you can have duties that aren't part of the contract's obligations, but that should have no impact on philosophical jargon, I reckon.
This is more properly a question for Biology.SE, but in brief, the genome of a species is substantially shaped by its environment and the environment of its ancestors.  So there is certainly information about the environment there (in http://en.wikipedia.org/wiki/Information_theory the mathematical sense).  Indeed, http://en.wikipedia.org/wiki/Genetic_algorithm genetic algorithms (an optimization technique used in computer science) work precisely because evolution, or a generalization thereof, stores information about the environment.

However, knowledge is usually considered to be some sort of http://plato.stanford.edu/entries/knowledge-analysis/#KnoJusTruBel justified true belief.  Although the information in DNA is in some sense justified on average in that the creature containing that DNA existed, this isn't what is meant in the philosophical context.

So information: yes.  Knowledge: no.  (At least using those terms as understood by philosophers.)
In one sense, the answer to your question is "no, complex numbers are the end of the line", and that is in the sense of being an algebraically, closed field. The next step in the sequence of algebraic field extensions is to ask, "Do all complex algebraic equations have at least one complex root?" Turns out they do (this is known as the http://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra Fundamental Theorem of Algebra, if that rings a bell from your high school days). So it appears we finally both have all the numbers we need (at least for these purposes) and have exhausted this method as resource for constructing new numbers. Time to get more creative if we'd like more toys to play with.

One well known route is the Cayley-Dickson construction which generates a sequence of algebras over the real numbers. Each step produces and real algebra with twice the dimension of the previous step. While the previous kind of extensions centered on the idea of broadening the variety of operations we may perform on numbers (subtraction, division, infinite summations, algebraic roots), the Cayley-Dickson extensions revolve around generalizing the variety of structures numbers may represent (from the number line, to the complex plane, and then higher dimensional spaces after that). After the real and complex numbers, there are quaternions, octonions, and sedenions. Now our chain of number sets and their subsets is up to: 


  ℕ ⊆ ℤ ⊆ ℚ ⊆ ℝ ⊆ ℂ ⊆ ℍ ⊆  ⊆ .


And it wouldn't stop there. This process actually can be carried out ad infinitum. And are precursors of vector spaces and related structures of modern linear algebra.
Arguably, if you want to be truly Socratic, you don't debate towards any given goal, you simply ask questions that guide your interlocutee towards greater clarity and understanding of their own ideas and beliefs.  
After you start looking into the neurology of pain, questions like these don't really make sense any more.  It's neurons all the way through, you know.

You could identify people who have relatively few or low-activity thermal pain receptors.  And you'd identify people who have different levels of signaling or regulation at a bunch of other levels of processing.  (Along the way you'd probably get to http://www.ncbi.nlm.nih.gov/pubmed/12237181 shoot people with lasers.)  There are differences in thermal tolerance, if that's what you're asking.  And there are differences many other places also.

But you don't have to go very far before the neurobiology becomes murky.  What exactly is regulating what, and how?  That's hard to say even when the signals reach the spinal cord.  And what, precisely, is "grit"?

You will instead--after appropriate research has been done--find yourself making statements like, "This chap has an amazing (p < 0.001) ability to maintain attention despite high levels nociceptive input to the dorsal horn."

So the phenomena are objective.  (http://science.howstuffworks.com/life/inside-the-mind/human-brain/pain.htm Here's a walkthrough.)

Figuring out what counts as "grit" is subjective for the time being.
If you are only looking for a sketch of how you might travel in time without determinism, and you equate free will with determinism, then one can easily sketch a world which admits both free-will and time travel, and in which physical systems and events have apparent causes.

Allow me to sketch a bifurcating time-line admitting time travel. If we suppose that by and large matter/energy is conserved in the usual way, except when engaging in the mechanisms of time travel, then just because you have travelled back in time to kill your grandparent does not mean that you will stop existing. If you absolutely require chains of causality to be traceable over long stretches of time and beyond the process of time-travel itself, then it simply suffices for there to be one continuity (a) in which you are born, and another continuity (b) in which you arrive from the future:

Time t=-51.
Your grandparent meets their future spouse for the first time.

Time t=-50(a).
Your grandparents start a serious relationship.
Nobody particularly interesting appears from the past.

Time t=-49(a).
Your grandparents get married.

Time t=-25(a).
Your mother is born to your grandparents.

Time t=0(a)
You are born to your mother.

Time t=30(a)
You have invented a time machine, and travel back to time t=-50.

Time t=31(a)
Your disappearance remains an unsolved case by the police, and you are presumed dead. 

Time t=-50(b)
Your grandparents start a serious relationship.
You appear from the past.

Time t=-49(b)
You kill one of your grandparents, preventing your mother from being born. Being a physical system which has a past which can be traced back some amount of time, and whose appearance in the past can in any case be explained by the mechanism of time-travel to a continuity in time in which this assassination did not occur, you continue to exist, because physics is not in the habit of simply allowing macroscopic physical systems to vanish.

Time t=-25(b)
You are freed from prison for your crime of murder, on parole, due to good behaviour.

Time t=0(b) You privately and wryly commemorate your own zeroeth birthday.

Time t=25(b) You celebrate your 75th in-continuity birthday.

Time t=30(b) You die in a car accident.

To an observer experiencing the world without a time-machine, they would with some probability observe time-line (a), and with some probability observe time-line (b). There would be a copy of that observer for each time-line, observing each; this does not require duplication of matter (or entire universes) in principle, and can be achieved in configuration space by a similar mechanism as the so-called parallel worlds of the Many Worlds Hypothesis of quantum mechanics.

You might complain that I don't give you any way to determine the probability with which a subjective observer would see you appear from the past, or that merely with some probability appearing in the past isn't good enough. I actually suppose that your time-travel mechanism is 100% successful, conditioned on you engaging it; but this doesn't mean that a past observer actually sees you emerge with probability 100%. You could more fairly complain that it's not clear how to interpret probability without ensembles or repeated trials, which would be a very good criticism in fact; but we don't have to suppose that there's any actual numerical probability attached. There is just a nondeterministic event in which a past observer either sees you emerge from the future or doesn't, and potentially either lives to see you born, or to see you kill your grandparent; and as a subjective participant you are assured of finding yourself emerging in the past.

Does this represent the freedom of event-space required for what you want to call "free will"? So long as you are identifying F ≡ ¬D, it doesn't matter — in this hypothetical physical ontology, nature is not deterministic, which (by your assumption) means that "free will" is true by definition.

Of course, this answer is entirely speculative; you have not actually learned anything about time-travel from this, except that it is possible to imagine a way that it is compatible with a non-deterministic universe.
The statement "The King of France is bald" would usually mean "The King Of France exists, and has no hair".  It could be taken to mean a few other things, but this is the meaning I will assume for this answer, and regardless of what you assume it to mean, you can use the same method I will use below to derive the opposite.

Let X = The King of France
Let A = X exists 
Let B = X has no hair 

Truth Table:
     BT     BF
AT    .
AF    

The dot in that truth table represents the situation "The King of France is Bald".

The opposite would be 
     BT     BF
AT           .
AF    .      .

Which is (A&!B) or (!A&B) or (!A&!B)
which simplifies to (!A or (A&!B)) 
It can also simplify to (!B or (!A&B)) 

which in english is "The King of France does not exist, or he exists and has hair"
or "The King of France has hair, or he does not exist and has hair".

As the second translation doesn't really make sense, we take the first.  (As, in this case, the second sentence only has a value if the first is true).

If you interpret the original sentence to be a different combination of facts, or some dependency between the two sentences, then your original truth table is different, but to find the opposite, you take the truth table with every combination being opposite, and interpret from there.  

Another popular interpretation would be "There exists a King of France such that it is bald."  The opposite of that one is "There does not exist a King of France such that it is bald," which is quite clearly true.
The Munker Illusion: Science and Philosophy by Jack Schwartz 
http://bioperipatetic.com/the-munker-illusion-science-and-philosophy/ http://bioperipatetic.com/the-munker-illusion-science-and-philosophy/

The Munker Illusion is offered as yet another example of a so-called optical ‘illusion’.  Illusions have historically been offered as proof that we cannot trust our senses and that all ideas that depend upon sense-perception are therefore unreliable, leading to absolute skepticism, solipsism, and subjectivism, ideas that dominate modern philosophy.

The interpretation of the Munker effect as an instance of perceptual illusion,  is the consequence of failing to grasp the true nature of perception, the nature of what our senses are ‘designed’ to detect and process, and attempting instead to rewrite the laws of perception to meet the philosophical demands for ‘valid’ contact with the ‘real world’, typically implying unmediated or unprocessed interaction with the real properties of the physical world.  A typical example of such a demand is the assertion that if our senses were valid they would allow us to sense the real colors, temperatures, density, geometry, odors, sounds of objects ‘in themselves’ and not be limited to the subjective experiences that are the result of processing and filtering the ‘information’ sent to our senses by external objects.

Property Identity Fallacy versus the Proper Nature and Function of Perception:

This demand (a species of the psycho-physical property identity fallacy) is totally misguided, both biologically, and epistemologically.  The facts are these:  (1) The purpose of the senses is not to apprehend absolute physical properties of external reality, but to provide us with a set of processes for identifying only those properties of the external world, and our relationship to it, that allow us to effectively engage the world in order to  explore it and live in it.   (2) How this is accomplished involves a complex process depending on the simultaneous interactions between  energy gradients, propagation mediums (air and water for example), sensory organs that register, process and filter the dynamic structure of simultaneous contrasting energy gradients across energy patterns and boundaries.  (3) Necessary for this processing is an active conscious organism that is able to simultaneously engage with and respond to the object-specifying patterns in the energy flux registered by the organism’s sensory system, such interaction constitutes the necessary condition of sensory/perceptual ‘exploration and discovery of the environment.’   (4) As a consequence of the sensory/perceptual processing, what we perceive are not the simple energy mapped properties of the external world (i.e., their absolute energy values corresponding to physical wavelength, thermal intensity, acoustical frequencies, or baric pressure).  Instead, our perceptual systems identify  complex information features such as dynamic invariants within simultaneous contrasting energy values across sharp energy gradient ‘cliffs’.  If this sounds like J. J. Gibson, it is because my views are deeply informed by that great perception scientist and by his brilliant wife and scientific collaborator E. J. Gibson. (See more about their work below. Also see my master’s thesis entitled The Causal Basis of Perception,  based on Gibson’s theories of perception.)

To what do Perceptions Correspond?

As a consequence, the psychological experiences of such conscious events as ‘color’, ‘sound’, ‘touch’ correspond to complex relational physical constancies (contrasting rations of long to short wavelengths across a visual edge), rather than simple physical local constancies (wavelength, for example).  Thus the perception of ‘red’ corresponds not to the detection of light waves in the 620–750 nm range (as many physicists and philosophers would have it), but rather the contrasting ratios of wavelength (or frequencies) across a physical ‘edge’ or ‘optical boundary’.  That perception of ‘red’ is always reliable and always tells us exactly what long-short contrasting rations exist at that moment in that given optical direction in the real world.  Thus, surprisingly, perception tells us far more than we expect it to tells us.  It identifies a physically complex fact and not a physically simple one.

The Causal Basis of Perception as a Scientific Question:

While a valid philosophy can tell us that our perceptual awareness of the world is reliable and the necessary basis for conceptual ideation, it is the job of science, not of philosophy to study and understand the underlying causal nature of perception as a psycho-physical-biological developmental capability of the conscious organism.  In other words, it is the job of science to discover how our perception of ourselves and the external world, specifically ourselves in relation to the external world, is achieved.

Gibson as the Key to Understanding the Causal Basis of Perception:

There is much science to learn before understanding how the senses give us true reliable perceptual knowledge of the external world.  A good place to begin is by reading the works of J. J. Gibson, especially his brilliant and challenging thesis: The Senses Considered as Perceptual Systems  as well as his magnum opus, The Ecological Approach to Visual Perception.   J. J. Gibson is an advocate of epistemological realism (as contrasted with the many flavors of idealism on the one hand and materialist reductionism on the other).

In his 1967 paper New Reasons for Realism,  Gibson wrote:


  If invariants of the energy flux at the receptors of an organism
  exist, and if these invariants correspond to the permanent properties
  of the environment, and if they are the basis of the organism’s
  perception of the environment instead of the sensory data on which we
  have thought it based, then I think there is new support for realism
  in epistemology as well as for a new theory of perception in
  psychology.  – Gibson - New Reasons for Realism, Synthese, 17:2
  (1967:juni) p. 162.


In the Summary of this paper, Gibson wrote:


  Both the psychology of perception and the philosophy of perception
  seem to show a new face when the process is considered at its own
  level, distinct from that of sensation.  Unfamiliar conceptions in
  physics, anatomy, physiology, psychology and phenomenology are
  required to clarify the separation and make it plausible.  But there
  have been so many dead ends in the effort to solve the theoretical
  problems of perception that radical proposals may now be acceptable. –
  op. cit., p. 171.


J. J. Gibson began working on the problems of visual perception with his future wife and collaborator Eleanore J. Gibson whose major extensions of J. J. Gibson’s work was her deep research into perceptual learning.  E. J. Gibson extended J. J.’s work reflected in his  The Senses Considered.  Her first important book was Principles of Perceptual Learning and Development.  Later her collaboration with J.J. on ecological visual perception inspired her magnum opus  An Ecological Approach to Perceptual Learning and Development.

Sensory ‘Illusions’ as a Species of Functional Isolation and the Argument from Pathology

Returning to the issue of sensory illusions, the most important concept to realize is that no theory of perception can be built on theories of perceptual or sensory illusions.  Why? For the very same reasons that no theory of biology or physiology can logically be built on the basis of biological functional pathology.   Pathological systems are by their very nature malfunctioning systems.  Pathology is explained as corruptions of healthy or properly integrated and functioning physical, biological or psychological systems. Illusions are the consequences of the carefully contrived  ‘unnatural’, ‘deficient’, ‘constrained’ or ‘restrictive’ presentation of isolated visual (tactile, auditory, etc) sensory ‘stimuli’.  It is the very fact that these presentation techniques prevent adequate exercise of the subject’s full perceptual capacities that leads to the ambiguity and vagueness that characterize so-called sensory illusions.  When inadequate sensory information is presented to the subject, it should not be surprising that the resulting experience is to that very extent non-veridical and always associated with the feeling of ambiguity and uncertainty.

Similarly in the realm of neurophysiology, experimenters typically isolate some part of the nervous system (often using severe isolation) so that only the most primitive sensory-motor phenomenon can occur and be accurately observed and measured.  It is a methodological illusion to believe that the results of such anatomical/physiological isolation, such as the extensive experimental work on ‘the reflex arc’,  represent the primitive bases for and are revelatory of the neuromuscular principles underlying normal integrated behavior.   This approach fails to recognize and appreciate the implications of  The Integrative Action of the Nervous System (Sir Charles Sherrington, 1906)  .

Similar errors occur in the study of embryological development, where local isolated phenomenon are mistakenly taken for fundamental biochemical elements of biogenesis.  See the work of Paul A. Weiss,  an innovator and mentor in the field of neurophysiology.  Weiss once wrote: “Of what do we deprive a system when we dismember it and isolate its component parts, whether bodily or just in our minds? Plainly, of the interrelations that had existed among the parts while they were still united.” – from  Paul Weiss, “One Plus One Not Equal Two” in The Neurosciences: A Study Program, pp. 801-821.

This fallacy of construction by structural or functional decomposition permeates much of science, particularly biological science leading to may false doctrines and theories.  Underlying this general methodology is the dogma of mechanistic reductionism and functional or elemental reductionism, which holds that a system can be fully understood as the additive product of the actions of its individual parts.

Isolating sensory receptors thus preventing sensory exploration and proper sensory function can only lead to sensory-motor inadequacy and the common phenomenon of sensory ‘illusions’.  We conclude that this method of sensory isolation commits the same methodological errors cited above, leading to fallacious conclusions regarding the functioning of our sensory-motor systems.
This is a very late answer and doesn't really substantially differ from the previous answer, nevertheless, I thought I could at least add a few pointers to places in Leibniz's texts.

Roughly speaking you are correct. Leibniz, to my knowledge, never states that this is the best of all possible worlds, but it is the conclusion that Voltaire---not without reason---thinks he must reach.

Leibniz tends to argue much as you phrase it from what he takes to be the fact of God's perfection. His argument, however, is not that God could not have acted less perfectly in creating this world, but that there is no reason why God should have acted less perfectly than he was able to in creating this world. (If God had acted less then perfectly, then there would be a sufficient reason for him doing so and not otherwise). (Something like this argument appears in both his correspondence with Clarke and his text known as the "Discourse on Metaphysics").

But, of course, as you state, there is obviously evil in the world, much of which seems unnecessary. For Leibniz, however, we only have a limited perspective on things and what seems unnecessary to us may be necessary precisely because it is the only thing "compossible" with the maximal amount of goodness. In other words, God didn't create a world free from evil because there is a reason that such a world would not be compossible with the maximal amount of goodness, and hence God would've acted less perfectly than he could've.

Compossibility actually gets us much closer to why Leibniz talks about "possible worlds"---it has little to do with a need for comparison. One of Leibniz's earliest mentions of this comes early on in his correspondence with Arnauld where he is discussing the creation of Adam. Leibniz argues (in his "Discourse on Metaphysics" which prompted the correspondence) that having conceived of Adam, God, being omniscient, necessarily conceived of all that would happen from creating Adam, i.e., the entirety of human history. Arnauld objected that this would seem to make God responsible for all the evil that came into the world starting with Adam. Leibniz's response is along the lines of yes, but even knowing the evil that the creation of this Adam (out of all possible Adam's) would bring, God still chose to create this Adam. Since God has no reason to act less perfectly than he is capable of, he must have chosen the best of all possible Adams, which is to say the Adam whose history is compossible with the maximal possible goodness.

This is where Voltaire who, importantly, lived after 1755, saw a problem with Leibniz's arguments. Since, above all else, the earthquake in Lisbon seemed to have caused more damage than could possible justified by any amount of future goodness. (And recall the quake is central to the horrors of Candide). We can only speculate how Leibniz might've responded.

Nevertheless, Leibniz, quite famously, is never happy with just one way of arguing for things, and often will in one place present arguments for what in other places he takes as axioms and so on. Leibniz's arguments for God having created the world in the most perfect way are thus, for him, compossible with a range of other arguments. All of which is to say that any attempt to give "Leibniz's knock-down argument" is doomed to failure from the start.

I'll make one last observation, however, which is that Leibniz never understood himself to be engaging in theology. The problem of evil, as he addresses it, is a real problem, but a philosophical, rather than theological problem. (It's worth pointing out that Leibniz resuscitated a version of the ontological argument and so took God's perfection to be philosophically demonstrable). At one point in his correspondence with Clarke, he mocks Clarke for relying on miracles to explain the natural order which, according to Leibniz, philosophy always tries to avoid.
Feyerabend makes a detailed demolition of the so called "received view" of philosophy of science (i.e.Logical Empiricism and Popper) and its attempts to discover rules of scientific method. 

In his book Against Method (1975) he uses historical case studies (i.e. the transition from older scientific theories, like Aristotle's theory of motion, to the scientific revolution of Galileo) to argue that there are no universal and exceptionless methodological rules governing the progress of science or the growth of knowledge. 

According to F, the history of science is so complex that if we aim at a general methodology that is applicable in every historical context and to all objects of study, the only “rule” that is applicable will be the trivial one: “anything goes”. The phenomenon of incommensurability between different "points of view" renders the standards which the “rationalists” (like Popper) use for comparing competing theories inapplicable. 

The critics of F's book accused him of beeing an “irrationalist”. 

See: Paul Feyerabend, in Stanford Encyclopedia of Philosophy.
Kant raises a distinction between what he calls perfects duties and imperfect duties in the Groundwork of the Metaphysics of Morals and again in the Metaphysics of Morals: Doctrine of Virtue. You have the basic definition in hand: a perfect duty is one which one must always do and an imperfect duty is a duty which one must not ignore but admits of multiple means of fulfillment.

Kant specifies two imperfect duties: the duty of self-improvement and the duty to aid others. To understand why Kant thinks of these as imperfect duties, we need to first understand the nature of duty for Kant. The literature on this is vast, so I'm going to skip over some parts of the mechanics and summarize it as follows: a duty is something that we are obligated to by the Categorical Imperative. In other words, it is something that that we can see as a universal rule for all of humanity necessary for a morally just society (mixing together all three major types of formulations of the Categorical Imperative).

It's difficult to come up with completely non-problematic duties due to some issues related to the basis on which we act "maxims" and the means through which we universalize these, but I will skip over this for the purposes of this question (If interested, I suggest reading Allen Wood's Kant's Ethical Thought).

Let's say that I want to lie to someone. If we universalize this, then every rational creature will lie whenever it is convenient. This will turn out to be self-defeating because no one will believe what anyone says. Since we have a constant need of truth in our dealings, this is something we must practice at all times. (i.e., we cannot add an exception "except when telling the truth is inconvenient). This makes this a perfect duty in the Kantian system. Most perfect duties turn out to be negative duties -- i.e. don't do X. On Kant's system, every rational being is obligated by perfect duties.

Imperfect duties reflect the nature of human rational existence. We are born weak and frail,  we cannot do everything by ourselves, and we die. These realities create interesting non-rational features of our reality: I needed someone to feed me when I was a baby. I need someone to help me when my car is stuck. I need a surgeon when my liver fails. These needs are not universal either in time or duration nor are they purely rational laws. To make these desires moral, Kant needs us to universalize them. Thus, we transform I need help at times into every [limited] rational creature has a duty to help other rational creatures at times. Thus, I have a requirement to aid others at times reflective of my own need for help at other times. This is one of the two imperfect duties for Kant.

The second imperfect duty is to perfect myself. This duty arises because when I need help, I need experts. Thus, the only way that rational creatures can have their needs met is if rational creatures are developing their talents. So I too have a need to develop my talents in order to create a universalizable rule that would make it so aid is available when I need it of sufficient ability. 

Moved to the level of the particular, imperfect duties are things like: study chemistry, practice the violin, learn Japanese, volunteer at an orphanage. These are duties I don't need to constantly and that I somewhat pick from among. Thus, they are imperfect duties since they are not constant obligations, but they remain obligations.

What Kant does not answer is how often. He punts this question somewhat in the Doctrine of Virtue. You can read more about this in Creating a Necessity out of Virtue by Nancy Sherman.



I also gave a more thorough argument for this account in my dissertation.
It's anyone with the capacity to use reason to decide what to do, who decides well, and then develops good habits by repeatedly doing the right thing. ("Agent" just means someone/something who is capable of doing things. It comes from the Latin word for "doing.") Such people can use reason to act in one way or another, and thereby acquire the habit of doing things that cause them to be happy and flourishing (virtues), or the things that cause them not to be, which are vices. So to actually be virtuous such a person needs to use his or her reason and will to choose the right things to do, and thereby develop the habit of doing those things.
Certainly. Simply because one cannot both know position and velocity through measurement, for example, doesn't prevent the idea that if one did know both, then they could present with certainty the outcome. One might suggest a metaphor: if you were trying to aim a cannon and you measured exactly one of the angle of inclination or the amount of powder in the cannon, you would be presented with a range of possibilities and it might seem random. But if you did know both the angle and the powder, then you could predict the behavior of the shot with great accuracy.  In the context of quantum mechanics, these theoretical additional pieces of information are called http://en.wikipedia.org/wiki/Hidden_variable_theory hidden variables.

Of course, this is a flawed metaphor. It happens to be more common for physicists to not believe this, or rather that it does not make sense to talk about both the position and the velocity of a particle with certainty, and instead you must think of them stochastically. Focusing on smaller subsystems causes certain parts to suddenly be more in focus and others collapse entirely. This is referred to as http://en.wikipedia.org/wiki/Wave_function_collapse wave function collapse, and it seems to be at the core of both indeterminism in measurement and the indeterminism of a system. If we followed the heart of the argument, it might actually be the case that inability to measure things precisely is exactly what leads to quantum indeterminism, but I must admit that I do not know this.

There is some confusion on this, and this talked about at physics.se https://physics.stackexchange.com/a/63815 several different https://physics.stackexchange.com/q/7 times (clicking on the related links on those is a good avenue for further exploration). There are even https://physics.stackexchange.com/questions/18586/deterministic-quantum-mechanics#18598 different interpretations of the same sets of facts.

Perhaps most important here is http://en.wikipedia.org/wiki/Bell%27s_theorem Bell's Theorem, which says roughly that a theory incorporating local hidden variables will never agree fully with quantum mechanics (note the local bit here). So following our local model of quantum mechanics, it truly does not make sense to talk about knowing both the position and the velocity (for example) of a particle, and thus wave function collapse is inevitable. And this brings us back to the http://en.wikipedia.org/wiki/Measurement_problem Measurement problem.

So in short, the fact that we can't measure all quantities arbitrarily well leads to indeterminism, which leaves room for free will.

On the other hand, if we were capable of measuring all quantities arbitrarily well, and if the resulting model were completely deterministic (which it might be, as then there would be no need for wave function collapse), then it might not make sense to talk about free will. And thus much of what your physicist friends have said have a kernel of truth to them.
The biologist Ernst Mayr described http://www.webofstories.com/play/ernst.mayr/142 five types of teleological thinking:


Teleomatic - events which happen because of physical laws, e.g. an apple inevitably falls to the ground when released from my hand.
Teleonomic - activities which unfold due to genetics, such as the human body developing eyes.
Adapted Entities or processes - things which are adapted to facilitate a particular capability, e.g. the eye is adapted for seeing. The conflation of this with Cosmic Teleology is the basis for the argument from design. 
Purposeful Activities - Actions which require planning and coordination, e.g. a pride of lions splitting to surround its prey.
Cosmic Teleology  - doesn't exist.


Now perhaps Mayr is wrong about the non-existence of Cosmic Teleology. But that doesn't mean that we have free will, or that we can use any of the other four to prove it's existence.
Your question leads directly to 2 important considerations. 

First, whether the physical laws we discover through science are merely 'resemblances' - that they reflect but are not actual natural realities; and Second, that the laws of physics do reflect physical content or constituents themselves as it is like in nature. This in turn depends on your own metaphysical view of what is possible to be known by the human senses.

The problem with the term 'Laws of Nature' that is often used in science today (or in textbooks) is that it is a misleading way of putting what in actuality are our best theories. These theories are what, after multiple tests and confirmations, verified as they are separately in experiments, are considered to be true because they give us the best results. They are not considered final.

In this sense, 'Laws' as they are used, are actually tentative theories, they are not the final say in any descriptions of reality. This is because even the most well tested and described laws, such as Newton's Laws of Motion and gravitation, have limits. For instance, after Einstein, the laws do not give predictable results at high speeds or small quantities.

Thus, Laws can never be Laws in our modern sense of certainty because they are incomplete. They raise further questions about physical phenomena that require further experimentation and testing. These questions are raised when we synthesize it with other laws that we know from other experiments, or from before.

For example the recent discovery of the Hiigs Boson can be considered a result that has been built upon not just our knowledge of quantum mechanics, but also our understanding of electromagnetism and classical mechanics.

The lack of a unifying theory does not mean that we do not understand nature. Often, we are dependent on these theories to built upon our understanding of reality and nature. It is fundamentally important then to distinguish between the metaphysical question of whether nature can really be discovered as it is by our senses, and whether there are laws of nature that are scientific theories to be discovered through experimentation, that are dependent on our senses.
A fallacy is a structural flaw in an argument.  An argument based on a fallacy is a bad argument --in a technical sense-- regardless of the details of the argument.

In this case, it's not clear that the team is committing a fallacy at all.  In fact, in the case that there were more than two alternatives, and Peter illegitimately reduced them to two, then he would have been the one committing the fallacy ("Black or White").

If there were in fact only two alternatives, than Peter is stuck in a "Catch 22" where he would have been blamed by his team no matter what choice he made.  This is not, however, a fallacy, just a symptom of the unfairness of life.  

If the team argues that Peter should be blamed because his decisions made them worse off than they would otherwise have been, then their argument is bad because it is based on a factually incorrect premise, not because it is structurally flawed.
A few other people have noticed this. Karl Jaspers calls it the http://en.wikipedia.org/wiki/Axial_Age axial age when he says that several civilisations laid down the spiritual foundations of humanity.

One should note I think that the phenomena is restricted to the Eurasian continent. 
I've looked at Rhetoric (translated by W. Rhys Roberts with footnotes) thanks to my local library. Aristotle is ambiguous for stylistic ease---he varies between referencing Posterior Analytics and Prior Analytics when he says "the Analytics". Sometimes he means one of the two, other times he means both. In other words, he is not consistent.
By "my book" you mean a book you wrote or a book you are reading? :) 

In any case, the book is wrong regarding Xenophanes being the 1st monotheist. The first known monotheistic religion was developed by http://en.wikipedia.org/wiki/Akhnaten Akhenaten, centuries before Xenophanes was born. And, according to a few historians, Akhenaten's religion either evolved into Judaism (and later Christianity and Islam) or substantially influenced early development of Judaism.

Regarding Xenophanes' pantheism: he maintained a distinction between the God and the Universe; so he was kind of between deism and pantheism. 
We use "nature" in at least three related ways, to mean:


the intrinsic properties of things, as in "it's in the nature of copper to conduct electricity," and sometimes what is normal for them. We might say in this way that it's not in the nature of pigs to fly, and that it is unnatural for pigs to have five legs, meaning just that it is abnormal;
the universe as it is, especially with respect to its own intrinsic properties, as in "Nature includes everything that exists." Here, "nature" contrasts only with what's supernatural, if it contrasts with anything at all;
the parts of the universe which are not created or produced or significantly modified or impacted by humans. In this sense, it is simply the opposite of "artificial" or "artifact," which means something created by us. In this sense of nature, what we call "nature" is a subset of nature in the second sense.


Human creations and our destructive effects on the non-human world are natural in the second sense and are not natural (or unnatural) in the third sense. The first sense is not especially relevant. The potential confusion here arises from equivocation, which means using the same word in two different ways.

We see that there is something in common among these different usages, in that the second two are related to what I think is the oldest meaning—the first, about intrinsic or essential properties. The connection is that we sometimes think of intrinsic properties as properties not changed by us. For example, an oak tree isn't blue unless someone paints it.

So, these meanings are related. However, I think when people use "nature" clearly, they make it plain that they are using it in one of these ways. The trouble is that some people are sloppy about usage. This word "nature" is very easy to be sloppy with because it sounds appealing, and so it gets used to advertise manufactured cleaning supplies, and advertisers want you to notice connotations, not clear meanings.

This is a nice example of how trying to understand the various ways people use words helps us distinguish genuine philosophical puzzles from things that needn't puzzle us once we're clear.
There's a sense in which, if you want to do away with the ontology then the completeness theorem (along with pretty much the rest of mathematics) would be strictly speaking false. Expressing the theorem in terms of validity:


  If T |= φ then T |- φ


is trivially equivalent to expressing it in terms of models:


  If T is consistent then T has a model


But, if you believe that there are not infinitely many objects (in the form of numbers, abstract syntactic objects, or whatever) -- which you may well do if you are a nominalist -- then you should believe that this is false. For there will be theories (such as Peano Arithmetic), which are consistent, but which can not have a model (since there aren't enough objects to go around).
There are a few things to unpick, here.

First, there's a difference between provability in a formal system, and "truth", which is a question of the relationship between language acts and facts. The statement "Juh mapple Neele" is neither true nor false, but nonsense, unless it is recognised as a poorly pronounced version of the French phrase Je m'appele Niel. The existence of a correspondance between the utterances and facts is necessary to have a meaningful notion of spoken truth. Similarly, your string $$$$$ which is obtainable by transformations from $$$$ is not 'true', except if you provide some correspondance between it and some model. That is to say, you haven't provided any thing for $$$$$ to be true of, nor a notion of what it would mean for it to be true.

Of course, French — and English, and all other natural languages — don't have a formal specification of how they correspond to reality. We more or less learn the relationship between the language and reality by correlations, and by depending on one another to mostly co-operate in reinforcing the conventional correspondance between language and reality. If we tried to describe the correspondance, it would just be with more language; just as we tend to use mathematics to make statements about meta-mathematics, and sometimes try to describe logic by boolean algebras. Our formal use of logic is a carefully honed skill of associations, a refined sort of activity of the same sort as natural language usage is, sharpening that more common skill to scalpel sharpness and rigidity. 

Having said this, how do we know that we reason correctly, logically? Lewis Caroll (of Alice in Wonderland fame) wrote precisely on this subject about logical regress in certainty of provability in http://fair-use.org/mind/1895/04/what-the-tortoise-said-to-achilles "What the Tortoise said to Achilles". The moral of the story is: if you are sufficiently skeptical of how to apply logical rules of inference, then any logical conclusion is impossible to reach, because you cannot prove that you have correctly proven something without putting the skepticism about proof simply at one more remove. The rules of inference are best practises for obtaining transformations of sentences in such a way that it minimally increases the error of the statement. In its role in formal derivations, it may be regarded as https://philosophy.stackexchange.com/a/8398/757 a sort of dance step — a simple move to be mastered as part of more complicated coreography of precise motions to convey a message, which is interpreted by others who know the correspondance of the formal system to other systems of thinking and imagining, sometimes consisting of physical reality or a caricature of it.

If you are not confident in your ability to make simple motions, e.g. to make simple speech acts, then no linguistic argument will convince you that language has any correspondance to reality; and the same is true of formal logic. What formal logic allows us to do is to check whether an argument has any steps which we don't have very much confidence in. That is, if we are sufficiently skeptical, the best we can do is say that we cannot find obvious flaws in the reasoning; the complementary case being when we can find obvious flaws, as in an invalid derivation. Of course, it is possible to make mistakes when identifying a step of reasoning as invalid, but at least it provides us with the opportunity to try to demonstrate it's falsehood by attempting to imagine a refutation of the statement being asserted by focusing on the consequences of the mis-step. Then we may try to bring our resources to bear, if we are worried that we have reasoned poorly, to ask whether the statement to be proved or the imagined refutation seem more coherent with our models.

Of course, as respects captial-T Truth, one might say that any claim to have access to absolute truth represents an act of hubris: that the world is necessarily so simple as to be completely comprehended by a mind handily contained within a cubic foot of space. To anyone familiar with the phenomena of turbulence and quantum mechanics, or the mathematical construction of fractals or strange attractors, or indeed the Halting problem and the P vs. NP problem — in short, the mathematical discoveries or problems of the 20th century — the idea that absolute capital-T Truth is something which is easily accessible even from premisses of analytical philosophy is laughable, unless the statement is so vague as to communicate almost nothing of the world's complexity, or so elaborate that it exists only as a script which was deliberately and pains-takingly recorded; the knowledge consisting more in the ability to decipher and recite the record as a sort of ritual for the purpose of undertaking some act in the world of which the record somehow represents an incomplete but possibly helpful sketch. Formal logic is a school of such ritual performance, which describes a particularly reliable way to formulate and perform such rituals. 

Logic is not a guarantor of truth, but merely (!) a very powerful tool for precise argumentation, and one which has a very good record of reliability, even if many people find it a difficult tool to wield carefully. As with any tool, it is only as reliable as the person who uses it. But somehow, as with the tools of art and of construction, we find that we can often recognise when someone has used it skilfully, and aspire to ideals of not only precise but elegant and artful wielding of this tool — which after all is a form of language.

The role of formal logic is, in short, a form of exercise in which to try to reason carefully, and to learn what careful reasoning looks like. But it cannot teach one to reason, nor guarantee good reasoning, without having some basic skill already.
[Sorry this is wall of text-y but the question is really hard and outside my area]

One of the most pressing philosophical problems at the end of the 19th century was to explain how to reconcile the passivity of the senses with the activity of the mind. If our knowledge is going to be about the world, then somehow the world is going to have to ``push back'' and we are going to have to receive information from it. However, at the same time our minds clearly organize and shape that experience in terms of concepts to make it meaningful. 

Here's an analogy to help explain the problem. Suppose you are wearing red glasses, so everything looks red to you. You are having a certain set of sensory experiences, but those experiences are being conditioned by the colored glass. The concepts that our minds actively create are like these colored lenses. We have concepts in our minds like time, identity, change, object, etc. That condition all our experiences. Think about what you really experience. You don't see meaningless fields of color, you see the book on the shelf. You don't hear pure frequencies, you hear the car going by in the street. That is to say that everything you experience is interpreted, and the concepts your mind creates are part of that interpretation. 

Now here's the problem: If you want to ask whether everything is really red or not, all you have to do take the glasses off and look.  However you can't "take off" your conceptual lenses to see if the set of concepts you are using accurately organize the sensory information you have received or not. Ask yourself: Does time really exist? You could say, well, look, I see things changing around me all the time. Of course you do, your mind is using the "time" concept and applying it to sensation--the question is whether your mind is doing it right or not? Is there something objective in reality itself that your concept of time corresponds to? That question looks really deep and hard.

At the very beginning of the 19th century, Kant tried to answer questions like these with the transcendental turn. Kant's idea was that his predecessors had been thinking about this question in the wrong way. Kant argues that it is not possible for us to have experience at all without time: the mind's activity and the senses' passivity are simultaneous. Hence, just by describing how the concept of time in our minds work, we discover everything there is about the world that could ever be empirically discovered through the senses too! The objective validity of our concept of time, in other words, can be demonstrated by the fact that it would not be possible for us to have the kind of experience we do at all without time. Notice that it is very important for Kant's view that the concept of time is something universal, so every rational subject would have to have the exact same conception of time for his solution to work. Kant thought this kind of maneuver--investigating the conditions of the possibility of experience--would solve a whole range of problems like this about the nature of space, time, selfhood, and other stuff.

By the end of the 19th century, a number of huge problems had arisen. Here's a famous one from mathematics. Kant argues that our concept of space is euclidean--and that we know that this conception of space is objectively valid because there isn't any other way that it is possible to think of space that would allow us to have the kind of experiences we do. But Gauss and Riemann and host of others had shown that it was certainly conceptually possible to make non-euclidean geometries and by the time of Einstein, it appears that the geometry of actual space-time because an empirical rather than conceptual question. Further, there were a number of philosophers, most notably Hegel, who took issue with Kant's idea that every rational mind must have the exact same set of concepts. These philosophers pointed to the importance of history and culture--concepts seem to change over time and mutate in different ways in different cultures.

Husserl, the founder of phenomenology, is attempting to respond to issues like this. Like Kant, Husserl thinks we need a transcendental project--we must investigate what makes it possible for us to have the kind of experiences we do. However,  Husserl thinks that one important kind of experience we have is when the things we think we know turn out to be different than we expected. We have the experience of being brought up short, having our expectations dashed, or fulfilled and so forth. What this shows us is that the world pushes back even harder than Kant thought. It isn't that our mind is "making up" features of reality that everything most conform to--rather it is that the objects in the world are themselves already have some kind of structure or unity or cohesion and these objective meaningful features of the things are disclosed to us in our experience by means of the interpretations we can give them. So, our minds are active--they create interpretations of our experience that construe such information in meaningful ways, but there is already something meaningful in the object itself which can provide confirmation or disconfirmation of that interpretation. Further, the process is dynamic: new aspects of familiar objects get disclosed to me through new experiences all the time. Investigating how these meaning-revealing experiences work is the project of transcendental phenomenology. 

There are other kinds of phenomenology too. Some phenomenologists are interested in investigating things like how I get the sense I have of my body in space. In that sense, phenomenology is something more like a set of methods or research questions about how some particular kinds of experiences work. One could think those methods are valuable while thinking that Husserl's particular transcendental answer to the very deep philosophical problem I've outline above didn't work. Such a person would be a non-transcendental phenomenologist. 
The statement that "no access to the noumena is possible" might not be a fair interpretation of Kant. It would be true to say that we cannot understand the noumena through the categories of the understanding and we cannot experience it with the forms of sensibility. At the same time, you are right to assert that for Kant freedom only applies to the noumenal.

The relationship between this and ethics is first considered out in the Third Antinomy but hinted at by Refutation of Idealism. In these texts, it is basically that room is left for freedom in the transcecndental (as Kant uses the term). Again, note that Kant has not said that this realm is wholly inaccessible. It is a domain of reason (remember the title is Critique of Pure Reason). But Kant does not spell out reason's access except insofar as reason has freedom.

Chronologically, Kant's next work to consider it is the Groundwork -- especially section III which gives a rather different account than the third antinomy for how ethics is possible. There, Kant needs to prove the existence of a being that is rational and has a free will. Because only such a being is capable of the ethics described in the groundwork. Most contemporary Kantians don't depend on this framework and instead make their own proofs. Korsgaard, for instance, maintains that we engage in acts of rationality and thus commit ourselves to morality which follows from reason. (I will leave this merely as a remark as to  how she tries to ground it). The problem of the determined phenomenal realm is in the background here but not a central feature.

Next, we have the Critique of Pure Practical Reason that gives a different argument for why we have moral freedom that addresses again the problem of a determined phenomenal realm. I think this one is better liked than the Groundwork version. But I don't honestly remember how.

The Metaphysics of Morals follows, and it briefly reconsiders this in the introduction to the combined volumes and in the introduction the Doctrine of Virtue. In there, it affirms the distinction again but argues that we are free and noumenal as rational creatures using the existence of reason and its applicability to both domains in different ways as an argument for morality.

In all honesty, the best treatment, however, occurs in the Religion with the Bounds of Reason Alone. While some people thing this is an appease the censors book, I think Kant genuinely believes what he's writing. And the topic he's considering is whether the will's prior decisions can make morality impossible or more difficult. Here, he considers the choice to be moral that has to precede all other choices (under the description of conversion) and the need for an exemplar who has made the moral choice (presumably a reference to Christ). We also see here an account of moral law where the moral law is only "given by God" but truly given by the subject's own reason -- projectable into the idea of God as a type of crutch.

The noumenal's ability to act as cause in the phenomenological is one that is inaccessible because the categories of the understanding cannot understand it and the forms of sensibility cannot experience its actions -- only its effects. Consequently, the reality of its activity must be an article of faith for rational beings (that and the correspondence thesis that Kant repeats in several places which maintains that even though the world is unjust, there is a God who exists who will even out justice in the next life).
Rex Kerr answers your question well to the extent that you ask about the desires, perceptions, and knowledge of individual inquirers or scientists. We may be able to will ourselves to perceive things in a certain way out of sheer force of desire, up to a point. What point that is exactly becomes an empirical psychology question. I suspect that for some people, experiencing psychosis, little desire is necessary to adjust their sense of reality such that it doesn't conform with perceptions, while for others it may take considerable will or unconscious desire.

However, that is all to discuss the individual, which is the wrong unit of analysis for discussing natural science. Philosopher Helen Longino, for instance, has argued persuasively that an individual person cannot do science in isolation, that science is a fundamentally social process. Individuals can have knowledge they acquire on their own. I see that I am typing now. I know that I am typing. By "know" I mean that I am defeasibly very confident, but not that I am objective. That knowledge is not yet scientific, and we should understand that knowledge as neither certain nor objective. 

Your scientist would therefore be wrong to say that "only the hard sciences produce true knowledge," but right to say that scientific methods produce better-justified knowledge than pre-scientific knowledge, because only science, by definition, can lend objectivity to knowledge. Science simply is the process through which beliefs are tested and criticized in ways that justify our treating the few beliefs that pass our tests as more objective. 

How? Knowledge-generating methods and procedures are scientific precisely if and because they neutralize the desires of individuals or groups to believe one thing or another. An individual's perceiving and believing independently do not have those features. When methods and procedures involving different, independent assumptions converge on the same results, we describe those results as more "robust" or more "objective."

All of this is consistent with the idea that yes, our desires can influence — though I'm not sure I would agree they can "determine" — our beliefs. But no amount of desire per se can render our beliefs scientific or objective. We should only understand our beliefs as hewing   closer to reality than other beliefs do when our beliefs have been produced by desire-neutralizing processes rather than by desire itself.
This is not a specific (argumentative) fallacy. It is a humorous conflation between the http://en.wikipedia.org/wiki/Ordinal_number ordinal and the http://en.wikipedia.org/wiki/Cardinal_number cardinal use of numbers, e.g. "the sixth finger" vs. "five fingers" in this case.

As an aside: There was an interesting experiment with children (age 4, I think) that shows how humans have an early understanding of cardinality. (I don't remember the source.) It goes like this: the subject is shown ten cookies in a row. The subject is asked how many cookies there are. The subject proceeds to count them and answers "ten". A cookie mid-row is taken away and the question is repeated. Now, the interesting result is that a certain percentage of children count the cookies by their cardinal order, note that the "six(th)" is gone, but that the "ten(th)" is still there and conclude that there are still "ten" cookies in front of them.

  an insight that I was the first to articulate: that there are no moral
  fact


twilight of the idols.

of course the question is one about "ideas" - did Nietzsche learn [even, if his primary impulse is] from Stirner without referencing him.

I would hazard no, on the grounds that if the influence was small there's no reason not to mention it, yet there's no need to explain Nietzsche's work with appeal to major plagiarism, because anyone can be an amoralist.

Unless you are talking about a specific part of Nietzsche's corpus?
A proper reductio ad absurdum argument relies upon the fact that if a premise is true, an absurd conclusion would unavoidably follow.  The word "unavoidably" is key; if any step is not logically forced by the previous step, the entire argument falls apart.

In the scenario at hand, the premise (that there is an illegitimate bias against "rich" defendants) could be true without the "absurd" statement (that no factors other than a defendant's wealth are even considered) being true.  Consequently, the absurd statement does not follow from the premise, and the premise is in no way invalidated by the absurd statement.  Indeed, the argument is so poor as to suggest the person making it might not be debating in good faith.
That the person who holds the right also gets to pass the right down to his children as a piece of property. This is how, for instance, coats of arms and peerages in the british system work. (Although it is only the oldest legitimate son that can inherit such rights, not all of the children). 
Simply use SEP; see the entries on http://plato.stanford.edu/entries/intuitionism/ Intuitionism in the Philosophy of Mathematics and http://plato.stanford.edu/entries/mathematics-constructive/ Constructive Mathematics.

Of course, if you want some book references, following @Paul Ross suggestion, I will add :


  Errett Bishop, Foundations of constructive analysis (1967)
  
  Errett Bishop & Douglas Bridges Constructive Analysis (1985)
  
  Michael Beeson, Foundations of constructive mathematics (1985).


All of them deal with the "mathematical side" and not with the philosophical.

About this one, see :


  Michael Dummett, Elements of Intuitionism (2nd ed, 2000).

As you know, the two terms mean something different, as spatio-temporal relations aren't in themselves causal relations. Being spatio-temporally isolated simply means not standing in spatio-temporal relations like “before,” “10 minutes after,” “beside,” “10 meters below.” Being causally-isolated just means not having any causal relations, such that nothing that happens in A affects B, and nothing that happens in B affects A.

So the question is, can things — and let's not talk about possible worlds for a moment since possible worlds are defined in terms of these relations — be spatio-temporally isolated without being causally isolated and vice-versa? 

In the first case, some people imagine God as living in a spatio-temporally isolated realm, but as knowing things that happen in our space-time (i.e. having beliefs caused by events in another space-time). That offers an example of causal but not spatio-temporal relations. The events are spatio-temporally isolated, but not causally isolated. Remember I'm not trying to offer a physically-possible example, only illustrating the difference between the concepts. 

Meanwhile, in the second case, imagine two things popping in and out of existence for only a second in the same space-time, and so standing in spatio-temporal relations. But imagine that they do not have common origins, and that they are further than a light-second from one another, so that no information traveling at the speed of light from one to the other could reach the other. I would say the two things are causally isolated, but not spatio-temporally isolated.

Remember that nothing turns on these being terribly plausible scenarios. (It may well be, for instance, that causation in our actual universe always involves spatio-temporal connection.) Indeed, the possible worlds that the concepts are used to define may themselves be a little strange! What matters is just that the concepts — these two kinds of relations — are distinct.
There's quite a few questions in there, but I'm interested in the topic as well. I share your general frustration. I will be teaching a "critical thinking" course this upcoming semester, and the number of qualifying textbooks is limited. They tend either to bore me to tears or rapidly jump in complexity.

First, I think at least in the initial units, it would be helpful to provide a full answer key. For later units, it may be acceptable to leave at least some questions as "exercises for the readers."

Second, the inclusion of fallacies seems to be wholly or at least generally absent from texts that consider formal logic. I think for students that take it seriously, they will recognize things as fallacious on their own. At the same time, I do cover some fallacies myself. The problem is that fallacies tend to involve judgments calls -- is something a slippery slope or a legitimate consequence of a chain rule? Is it an equivocation or are the two really the same? Was that a biconditional and valid or a conditional and thus affirming the consequent? Moreover, I've always run into taxonomy problems regaring some fallacies (genetic or ad hominem?)

Third, inductive logic also tends to turn out to be a question of individual method. There's Mill's methods and a crap ton of other ways to do it.

Fourth, I think Venn diagrams work for some but not all students. I don't mind teaching them, but I do question their value -- at least the AEIO subset that's normally taught. But I think they do help for students overall.

Fifth, I don't use the index.

Sixth, I think the biographies would be only minimally important. I would be more interested in them if they brought up thinkers who faced and solved problems -- e.g. Austin and Searle and the limits of logical positivism, the barber problem, Wittgenstein's disappointment with logic, Lewis's bullet-biting williningness to accept an infinite number of worlds as all real.

I' m interested in flipped classroom as well. My one worry is that students will be rocking their cell phone while the computer goes through the lecture... and then not sufficiently prepared for class.
The concept of "hegemony" is usually associated with Gramsci (especially his http://www.marxists.org/archive/gramsci/prison_notebooks/ Prison Notebooks) and "interpellation" with Althusser (https://www.marxists.org/reference/archive/althusser/1970/ideology.htm Ideology and Ideological State Apparatuses). The latter was influenced by the former. Both concepts are motivated by the same question: Why is it that the proletariat does not revolt as Marx predicted?

Hegemony could perhaps be conceived as a state of affairs: the success of the dominant class in making their view of the world (ideology) accepted and internalized by others as their own.

Interpellation, on the other hand, is a process of such internalization (subjectivation). Althusser writes that


  ideology ‘acts’ or ‘functions’ in such a way
  that it ‘recruits’ subjects among the individuals (it recruits them
  all), or ‘transforms’ the individuals into subjects (it transforms
  them all) by that very precise operation which I have called
  interpellation or hailing, and which can be imagined along the lines
  of the most commonplace everyday police (or other) hailing: ‘Hey, you
  there!' 
  
  Assuming that the theoretical scene I have imagined takes place in the
  street, the hailed individual will turn round. By this mere
  one-hundred-and-eighty-degree physical conversion, he becomes a
  subject. Why? Because he has recognized that the hail was ‘really’
  addressed to him, and that ‘it was really him who was hailed’ (and not
  someone else).


https://faculty.washington.edu/mlg/courses/definitions/hegemony.html A useful exposition of Gramsci's hegemony. http://www.longwood.edu/staff/mcgeecw/notesoninterpellation.htm A useful exposition of Althusser's interpellation.
One large part of the reason is the influence of Plato and his followers on world religions.  Plato's philosophy all centered around an abstract entity that he sometimes called the "https://en.wikipedia.org/wiki/Theory_of_Forms Form of the Good." This entity combined all possible real perfections into itself --it was the most beautiful, most wise, most good thing that could possibly exist, and all other things in the universe were increasingly imperfect copies of it.

Later, Plato's Roman followers, the https://en.wikipedia.org/wiki/Neoplatonism Neo-Platonists, placed an explicitly religious interpretation on what Plato had typically described in more abstract, less personified terms.  This, in turn, influenced https://en.wikipedia.org/wiki/Augustine_of_Hippo St. Augustine, the great African theologian who formulated much of what became foundational Christian orthodoxy.  He had previously been exposed to the Neo-Platonists as an educated Roman citizen, and when he converted, he identified God as revealed through Christ with the Neo-Platonic "One."

These philosophies similarly had an influence on other world religions, https://en.wikipedia.org/wiki/Platonism_in_Islamic_Philosophy including Islam.  Since https://en.wikipedia.org/wiki/List_of_religious_populations over half of the global population adheres to either Christianity or Islam, that in itself is enough to answer your question.
What you want to look at is the social psychology of group decision making. The pioneer in the field is Irving Janis, a psychologist at yale. Groupthink is poor decision making that results from individuals self-censoring because of social pressures because of high cohesion among the group. Everybody thinks the same, i'll be branded as an outsider if I voice my opinion that this decision is really bad, so I don't speak up and we make a bad decision. 

Interestingly, too low a degree of cohesion among the individuals also leads to very similar effects. People who are all different just don't trust each other and so they self-censor for fear of starting huge, unproductive arguments about points of fundamental disagreement. 

Look at the wikipedia page on groupthink for more info.
Generally speaking, no (in either school), especially when the God is question is some kind of being. As a Westerner its very difficult to not see the Tao through a Western lens especially when translators translate it as God in an attempt to make it more accessible. Generally speaking, it is translated as "way" not because the translators are being overly literal, but because "way" is a really good word for what it describes.

I think it's probably easiest if we go with the English word "way" as a guide to the meaning of Tao. Not because it is exactly correct, but because it's close enough for our purposes.

Is God a "way" in any reasonable sense. Not really. The Christian religion might be called this (in fact it is: the way of Christ). But the Christian God Himself is not usually thought of in this manner (Let's assume http://biblehub.com/john/14-6.htm John 14:6 means something more like "I can show you the way").

http://plato.stanford.edu/entries/daoism/#Dao SEP says no also, I've highlighted the most important bit - the quote is from http://plato.stanford.edu/entries/daoism/#Dao a long article which is probably worth reading if you are interested in the topic:


  Dao [...] was the center of Chinese philosophical discussion. It
  occupies the position at the center of thought that in Western
  philosophy is filled by terms like ‘being’ or ‘truth’. The centrality
  tempts interpreters to identify dao with the central concepts of the
  Western philosophical agenda, but that is to lose the important
  difference between the two traditions. Metaphysics and epistemology
  dominated early Western philosophy while ethics, politics and
  philosophy of education/psychology dominated Chinese thought. Although
  it's insightful to say humans live in dao as fish do in water, the
  insight is lost if we simply treat dao as being or some pantheistic
  spiritual realm. Dao remains essentially a concept of guidance, a
  prescriptive or normative term. In the late Classical period, dao
  paired with devirtuosity to form the Chinese term for ‘ethics’
  “dao-de.” Dao is the pivot of Chinese philosophy—but it still
  translates as ‘way’, not ‘being’.

In some respects, you could say that Sartre is "borrowing from Kant." It will greatly depend on what you mean by borrowing. Iphigenie's comments are highlighting the differences, and those are definitely worth pointing out but a type of "rationalist" heritage is worth bringing up.

What I would say is the common thread is an emphasis on "autonomy" and a belief that human beings possess a type of unrestricted autonomy in reference to their choices. Neither thinker is ultimately naive enough to say that we always have this, but both theories have been accused of separating us from bodily concerns under the belief that we can make choices regardless of circumstances. In the simplest terms, both have a very high belief in our autonomy and that we have a free rational will.

At the same time, there are some crucial differences about how our rationality works for both thinkers. A core feature of Kant's account of morality and his account of rationality is that they have universality. In moral theory, this means that the moral rules apply to everyone insofar as they are humans at all. (Kant's particular method of how he gets there for morality is both highly contested and largely believed to have failed). But the key is that for Kant, reason works the same in every person and will logically lead them to the same conclusions. This is evident if you consider both the phenomenological / noumenal split and the categories of the understanding (the transcendental unity of apperception). This has led to the accusation that Kant's philosophy is a "German sausage machine" because whatever comes in gets pumped out the same. Thus, the CI is the same for all subjects who are rational. In a sense rationality predominates autonomy. (There's a lot more complexity if we are start looking at imperfect duties...)

For Sartre, our autonomy is our defining feature. In his view, we do seem to have a type of practical rationality, but the questions of what we will make our choices based are on largely left up to our autonomy to decide. Thus, in Existentialism is a Humanism, Sartre works from the case of the young man who must decide whether to serve France, his mother, or the church. For Sartre, we will never have enough evidence to decide the most important questions rationally (i.e., there's no sausage machine -- there's rats, pigs, whales, and chickens and you've got to decide what they are there for).

To sum up, both share a belief in autonomy and some idea of rationality, but for Sartre both are ultimately species of autonomy. For Kant, autonomy is about a will ordered under reason. In a sense, they are both inheritors of Descartes and the outcome of the Meditations where we have faculties of will and reason -- and one can outrun the other and go wrong. For Descartes and Kant, will is the source of error. For Sartre, false belief in "reason" is. 
"Normal" determinism — or at least, the way that people normally approach the notion of determinism — in the face of apparently random events is the position that the randomness is due to uncontrolled variables in the influences on the apparently random system, which you are not taking into account. A good example would be the brownian motion of grains of pollen: it's random motion is due not so much to an inherent randomness of the motion of the pollen, as unaccounted-for-impacts on the pollen by molecules. (Notwithstanding the fact that the motion of those molecules is ultimately quantum-mechanical, of course.)

"Super-determinism" is the position that the apparently random behaviour of quantum mechanical systems, following the Born rule, is due to the fact that our own choices of experiments to perform are finely tuned in correlation with the systems we measure, to give rise to these statistics. Not only is our behaviour determined, but it is determined in such a way as to limit what we can see, and specifically to fool us into seeing random behaviour according to a stable statistical rule when the behaviour is in fact perfectly predictable in principle.

So super-determinism is indeed a variety of determinism: but it turns our usual assumptions about apparent randomness on its head — not only is our behaviour determined, but it is determined precisely in such a way as to prevent us from seeing that the world is deterministic.
Often, the universe is considered to be everything by definition. Physicists would use this kind of definition but make it weaker by speaking of the observable universe, i.e. the part who's existence we are sure about.

A)            Universe: Everything there is
B) Observable universe: Everything that can be known about (right now)


If the first case, there is nothing that exists outside the universe and there would be nothing you could do about it. You could never get "outside" of it, because it always contains you, no matter where you are in (or not in, for that matter) space-time.

It sounds more like you are talking about the observable universe, which may or may not have nothing outside of it. It's not generally considered practical to get outside of the observable universe, and scientist often use "universe" instead of "observable universe" because they are trained to avoid speculating on things that are thought to be unknowable.

This is important, because there are now two meanings of nothing, so that when I say "there is nothing beyond the universe" it can mean

1) There is no X such that X is outside the universe (from A)
2) There could be something outside the universe, but it is inconsequential (from B)


This makes the language quite tricky, generally "nothing that is P" refers "there is no X such that X is P", nothing is not a thing. Yet, if we are talking about the observable universe, the nothingness outside the universe might actually refer to something. Leading to a very strange usage of the word 'nothing' as "things which we don't know about". This is a source of confusion.

If there is actual nothingness (1) then you are asking about the impossible. If there is "epistemological nothingness" (2) then the best we can say is "who knows!" (though the https://en.wikipedia.org/wiki/Cosmological_principle cosmological principle would suggest that it would be very much the same as here)


  Would you cease to exist or could you actually exist in nothingness?


In actual nothingness (1), you would cease to exist (though its better to say that you can't go there), in "epistemological nothingness" (2) you can go there, but we can only guess as to what it is like.


  But if you assume that there is nothing beyond our universe


Then you are restricting the answer to actual nothingness (1).
We begin by recalling the basic definitions needed to settle the questions:


  Definitions.
  
  R is reflexive       =def   ∀w : wRw;
  R is symmetric    =def   ∀w, v : (wRv → vRw);
  R is transitive      =def   ∀w, v, u : (wRv ∧ vRu) → wRu.


Now we identify the relations in questions (1–5), ignoring the other details:


  Question 1. R(x,y) ≡ BiologicalFatherOf(x, y).


You're right about R being irreflexive and asymmetric, because no person is a biological father of himself and no person is a biological father of his father. But R is also intransitive, because the biological father of your biological father is not your biological father!


  Question 2. R(x, y) ≡ [x ∈ (a..y)], where a is fixed and (x..y) is the straight line from x to y inclusive.


Is R reflexive, i.e., is R(x,x) true? R(x,x) is true iff x ∈ (a..x), i.e., iff x is on the straight line from a to x inclusive (Sorry for the unorthodox notation; I hope its use is justified here). Because of the inclusiveness, x is indeed on that line, so R is reflexive. 

To check for symmetry, assume R(x,y) and ask is R(y,x) true? R(x,y) implies that x ∈ (a..y), i.e., x is on the straight line from a to y. R(y,x) says that y ∈ (a..x), i.e., that y is on the straight line from a to x. R is not symmetric, because the line from a to y might be longer from the line from a to x.

To check for transitivity, assume R(x,y) and R(y,z) and ask is R(x,z) true? R(x,y) means that x is on the straight line between a and y, and R(y,z) means that y is on the straight line from a to z, so the line from a to z is an extension of the line from a to y. It's given that x is between a and y, and since the line from a to z extends the line from a to y, x must also be between a and z! So R is transitive.
† Thanks to https://philosophy.stackexchange.com/users/4316/lucas Lucas for directing me toward the right interpretation of the relation.


  Question 3. R(x, y) ≡ (x → y).


You're right about reflexivity and transitivity, but wrong about symmetry. R is reflexive because every statement x materially implies itself. R can be seen to be transitive by two applications of modus ponens or detachment. R is certainly not symmetric, otherwise material implication collapses to equivalence. 


  Question 4. R(x, y) ≡ Consistent(x, y).


R is reflexive, because any statement is consistent with itself (I'm not sure about contradictions; should we exclude them or say that two contradictions are somehow consistent?). R is symmetric, because if x is consistent with y, then y is consistent with x. R is not transitive, because while x may be consistent with y, x may be inconsistent with some z consistent with y. That is because for x and y to be consistent, (x ∧ y) has to be satisfiable, which may be true for different reasons for (x and y) and (y and z), so (x and z) might still turn out to be unsatisfiable.


  Question 5. R(x, y) ≡ (x != y).


R is irreflexive, because every x is indeed identical to itself. R is symmetric because if x isn't identical to y, then y is also not identical to x. Lastly, R is not transitive, because while (x and y) and (y and z) might be distinct, it doesn't imply that (x and z) are distinct, i.e., (x = z) is possible.
Interesting question! You used the word 'model' when describing the turnstile, so I'll start with these:


  Syntactic consequence Γ ⊢ φ says: sentence φ is provable from the set of assumptions Γ.
  
  Semantic consequence Γ |= φ says: sentence φ is true in all models of Γ.


Models are a semantical notion, so the use of 'model' needs to be avoided in the characterization of syntactic consequence. Now that we're clearer about the definitions of the two types of consequence, I hope you can see that it's not at all obvious that the notions of provability and truth coincide. Significant effort goes into proving the equivalence between a proof system and a semantics for many logics. 

Take propositional logic, for example. It has a proof system, the so-called propositional calculus, and a semantics, the so-called truth-tables. The propositional calculus captures the notion of syntactic consequence, truth-tables the notion of semantic consequence. A routine exercise in introductory logic courses is to show that the propositional calculus, in some presentation, is sound with respect to the truth-tables, i.e. that:


  Soundness. If [Γ ⊢ φ] then [Γ |= φ].


Although the proof is easy, it still needs to be shown; otherwise we'd have to take it on faith that our axioms (if we have any) are true and that our rules of inference are truth-preserving. Similarly for the converse direction, which is called completeness:


  Completeness. If [Γ |= φ] then [Γ ⊢ φ].


This one is usually much harder to prove, and is important because we want the proof system to capture or prove all the truths our semantics generates. Propositional logic enjoys both properties, but there are logics for which such proofs either have not yet been or cannot be devised.

  I read this article about intuition (gut feeling?) on wikipedia, and I
  simply can't get my head over it. Why is intuition considered as
  "acquiring knowledge without interference or the use of reason".


Intuition is what we know subconsciously, at the back of our minds

Consciously we use what we can see, hear, taste, touch, smell, but intuition requires higher level of consciousness, i.e. 6th sense.


  Without knowing about some kind of subject you wouldn't have "gut
  feeling" in a first place.


But perhaps, you do know the answer. The Universe around us is very complex, and our minds are fantastic machines that can take this all in. However, we can only process so much consciously. 


  Another question comes in my mind: Why rational thinking can not be
  referenced as long term intuition?


When someone is trying to solve a problem, they say they will "meditate on this", because meditation allows a person to go to a higher level of consciousness, where they can perceive and understand things they cannot otherwise do with "rational thinking", i.e. seeing hearing, tasting, touching, or smelling.


  Ex: I am finishing high school and I am deciding what to do next: go
  to work, go to collage/uni, do nothing. 
  
  Doesn't my decision come from intuition in a first place? (My decision
  can be "changed" via rational thinking but again what triggered
  "thinking about changing my decision"? (intuition?)).


Of course, your decision can be "changed" by rational thinking, but how will you feel if you are going against your intuition? 

If your intuition tells you to go to college/university, but your rational thinking tells you to go to work (perhaps because of your current financial situation), will you feel happy, or will you get a sick feeling in your stomach. Perhaps your intuition is telling you that going for higher education is a permanent solution for any financial troubles because you will learn the skills you need for a decent-paying job.
This isn't an answer - more a suggestion as to how it might begin to be resolved.

The question of the compatibility of free-will & determinism as it is debated in contemporary philosophy is not how it it would be seen in Early Antiquity, but Bobiez argues that it does become a question  in Late http://en.wikipedia.org/wiki/Free_will_in_antiquity#Susanne_Bobzien Antiquity

I'd suggest, that this compatibility question becomes acute when considered in materialist philosophy - like that of Epicurus & Democritus, or contemporary Physicalism; where freedom has to be manufactured out of matter & void.

According to the http://en.wikipedia.org/wiki/Stoicism Stoic Philosophy:


  The universe is a material, reasoning substance, known as God or Nature, which the Stoics divided into two classes, the active and the passive. The passive substance is matter, which "lies sluggish, a substance ready for any use, but sure to remain unemployed if no one sets it in motion."The active substance, which can be called Fate, or Universal Reason (Logos), is an intelligent aether or primordial fire, which acts on the passive matter:


One might suggest, that if anything has freedom, it is God/Nature (as the Stoics concieved it); and we - humans - partaking in God/Nature, also partake in freedom, more limited than that of God/Natura, and more than matter. In contemporary terms, this position might be called http://www.iep.utm.edu/panpsych/ Panpsychism

This should be taken as speculation, but Bobiez in her book http://www.oxfordscholarship.com/view/10.1093/0199247676.001.0001/acprof-9780199247677 Determinism & Freedom in Stoic Philosophy discusses this question in much more depth - but note it is a scholarly work.
It appears that Cicero's main contribution to philosophy was in political philosophy. The extensive account of his idea was only found in the nineteenth century.


  His big idea, which he tirelessly publicized, was that of a mixed or balanced constitution. He favored not monarchy nor oligarchy nor democracy, but a combination of all three. His model was Rome itself, but improved. Its executive had quasi-royal powers. It was restrained partly by the widespread use of vetoes and partly by a Senate, dominated by great political families. Politicians were elected to office by the People. [My emphasis.]


From http://www.goodreads.com/book/show/84593.Cicero Anthony Everitt's Cicero.

However, looking at http://en.wikipedia.org/wiki/Mixed_government Wikipedia's 'Mixed government' entry, this doesn't appear to be much of a novel idea at all. :)
Modern philosophy of language actually says a fair bit about this. (I've seen this example, and ones like it, in a number of philosophy articles. I'll give some references at the bottom.)

First, I'll argue that Lincoln is right. Then I'll say some stuff about the use/mention distinction, which is a central concept in the philosophy of language, and is key to seeing why Lincoln is right.



Imagine if everybody used the word "leg" (as in, the string of letters) to refer to what we call tails as well as what we call legs. That is, in this hypothetical scenario, "leg" means what we mean by "leg or tail".

Because this word means something different in this situation, it turns out that people speak a very slightly different language than English. Let's call their language English*. We can give give easy instructions on how to translate between English and English*: "leg" in English* means the same as "leg or tail" in English (and everything else means the same in English and English*).

Now, suppose we ask the question: In such a situation, how many legs does a dog have? What language are we speaking when we ask it? If we're speaking English, then the answer is "4" -- in the hypothetical scenario, dogs still have 4 legs (imagine it, if you like, there are lots of people going around pointing at dogs' tails saying "that's a leg", but the dogs still only have 4 legs).

If we're speaking English*, then the answer is 5, since, in English*, the sentence "dogs have 5 legs" is true. (Since, by our translation rule, it translates into the English sentence "dogs have 5 legs-or-tails".

But we are surely speaking English when we ask the question. Lincoln certainly was. In fact, in general, when evaluating counterfactuals, we're still speaking our language, rather than whatever language is around in the counterfactual. Imagine that we ask "if the English language had never existed (and everybody spoke French) how many legs would a dog have?". If we were supposed to evaluate the question in the language of the counterfactual situation, we would only be able to return a blank look, but we can answer "four". Similarly, we might want to answer counterfactual questions in which there are no people or languages.

(As an aside, the same goes with different times, as well as different counterfactual scenarios. So, we might ask whether whales ever used to be fish. The answer is no. People used to use the word "fish" to refer to whales, but that doesn't mean that whales are fish.)



There is a question in the vicinity of Lincoln's, which does have the answer "five". Compare the two following statements: 


  
  If the word "leg" applied to dogs' tails, then dogs would have had five legs.
  If the word "leg" applied to dogs' tails, then "dogs have five legs" would have been true.
  


(1) is false, for the reasons that I've just said. It uses the word "leg", and we know that the word (in English) does not refer to tails. The second mentions the sentence, and asks whether it's true.



Use and mention

I've been using lots of quote marks in what I've just written, and I've been careful about where I've used them. This is because I want to be very careful to distinguish between where I've used a word, and where I've mentioned the word. Using a word means just that. If I say "John is tall", then I'm using the word "John" to say something about John. But if I say " "John" is four letters long", I'm talking about the word "John" (since John himself is obviously not four letters long). This is called mentioning the word "John" It is common in philosophy to use quotation marks to pick out a mention of a word, rather than a use.

(The http://en.wikipedia.org/wiki/Use%E2%80%93mention_distinction Wikipedia article on the use/mention distinction is fairly good, apart from bizarrely citing the Strunk and White, who should never be consulted for style or grammar advice.)

What's this got to do with the question? Well, when we're using the word "leg", we're using it in our context, to mean leg. And as we use the word "leg", it does not refer to tails. To get at the thrust of what things are like in the hypothetical community, we need to mention the word "leg", to say that, for example, in the community it refers to tails, or that in the community, the sentence "dogs have 5 legs" is true. Notice that the antecedent of Lincoln's counterfactual is mentioning "leg" (despite it not being made clear with quotation marks).



References to philosophy

I promised some references for where I'd seen this recently. Here are a couple (not exhaustive, by all means)


Eli Hirsch uses this example a lot when discussing a view he calls "quantifier variance". He want to say that we could have used the word "exist" so that the sentence "Tables do not exist" is true. Nonetheless, he claims, we do not use the word in that way, and the sentence "tables exist" in in fact true, that is, tables exist.

Unfortunately, I can't find anything by him on this which isn't behind a paywall. On the offchance that you have access (maybe you or somebody you know has internet access from a university), here are some papers:


http://philpapers.org/rec/HIROA Ontological arguments : interpretive charity and quantifier variance
http://philpapers.org/rec/ELIQVA Quatifier variance and realism
https://ndpr.nd.edu/news/24764-quantifier-variance-and-realism-essays-in-metaontology/ A (non-paywalled) review of a book of the same name

Issues related to this have been raised as objections to a form of deflationism about truth. Deflationists say that all there is to truth is something called the T-schema. This says:



  "S" is true if and only if S


where S is some sentence. For example:


  "Snow is white" is true if and only if snow is white


But there's a bit of a problem, since, as the Lincoln example shows, these come apart where we consider counterfactual situations in which the meanings of words change. Had we used "leg" to refer to dogs' tails, then "dogs have five legs" would have been true, but dogs would not have had five legs.
Shane's answer is great overall on what to read, but reading your title and question body again... you asked what to skip.

Skip his Biology in its entirety. There's quite a few texts in there. Mostly interesting only on an anecdotal level (nearly all the primary texts here http://plato.stanford.edu/entries/aristotle-biology/ http://plato.stanford.edu/entries/aristotle-biology/). I'm not saying that it's completely worthless -- just that it will only matter if you want to study a particular subfield in history of philosophy of science.

All of some sections of the Politics can be skipped. Particularly, the lengthy discussions of each political system in the Greek world (BK 2 sections 8-12). Some of them are worthwhile so consult a contemporary commentary that should give you the highlights instead of trudging through the descriptions. Also if you will read both Nicomachean Ethics and Politics, you can skip the second half of NE Book 8.
So there are problems with peer-review, but it's not quite as bad as you are making it out to be here. 

Talking about the process of how a submission becomes published will help explain. 

First, the author submits an article to a journal for consideration. At this stage, the article is prepared for blind review, so there is no identifying information in the manuscript. 

Second, the editor of the journal will decide whether the submission is worth being refereed or not. If not, then the paper is "desk rejected". Many journals get several hundred submissions a year, and there simply aren't enough people to adequately referee them all. So the editor has to make some call about which papers are worth spending the valuable resources necessary to bring the article up to publication quality on.

If editor thinks the article maybe has a shot of getting published, he or she will send the article to referees for comment. Usually the paper goes to between one and three referees. 

Different journals can be ranked in terms of who knows whom in this process.

A single blind journal will be one where the referees don't know the authors of the papers they are refereeing. 

A double blind journal will be one where neither the referees nor the authors know each others identities. 

A triple blind journal will be one in which neither the referees, nor the authors, nor even the editors know the identities of the authors and referees. (These kind of journals require editorial assistants who handle the emails and so forth to preserve the integrity of the process)

Now even triple blind journals are susceptible to failures of the review process. It can just so happen that you get asked to review a friend's paper, or a paper you happen to have heard at a conference. Ideally, a referee in such a position should recuse themselves, but my sense is that that doesn't happen often, just because it's often really difficult to find qualified referees who are willing to volunteer their time, so recusing oneself might be equivalent to getting the paper automatically rejected for lack of qualified referees. 

There are problems with actual implementation to be sure, but overall I think the process at triple-blind reviewed journals is sound.
One simple example of a philosopher who would have disagreed with the "existence precedes essence bit" is http://en.wikipedia.org/wiki/Theory_of_Forms Plato:


  Plato's theory of Forms or theory of Ideas asserts that non-material abstract (but substantial) forms (or ideas), and not the material world of change known to us through sensation, possess the highest and most fundamental kind of reality.


He was obviously not contemporary to the modern Existentialists (so not "Anti-Existentialist" in that sense), but his works offer one possible opposite arguments from the Existentialists.
I think this is a challenging question, but one that can be thought through in a detailed way. The conclusion I'm going to defend is that a universal grammar that looks anything like what Chomskyans expect will be analytic a priori knowledge -- assuming those terms are indeed well-defined. I'll do my best to select fairly robust definitions of those terms, but keep in mind that anyone who rejects the existence of a priori knowledge, or who rejects the analytic-synthetic distinction, will reject my conclusion as meaningless or ill-formed.

I'll also discuss the lingering possibility that knowledge of a universal grammar might indeed be synthetic a priori knowledge, and what one would have to demonstrate to persuade me of that claim. 

Space does not permit a full development of the argument I want to make, so take what I'm offering here only as a rough sketch -- in two parts. I'll begin by talking about aprioricity; then I'll talk about analyticity.

Knowledge of Universal Grammar is A Priori

First, I want to defend the position that if anything is a priori knowledge, then any well-formed universal grammar is a priori knowledge -- regardless of whether it is "innate." The argument is very simple and goes like this:


If a priori knowledge exists at all, then any knowledge that we can mathematically formalize is a priori knowledge.
A "well-formed universal grammar" is a syntactic structure that we can mathematically formalize.


The desired conclusion immediately follows. Recall that "a priori" knowledge is not necessarily innate knowledge -- it's simply knowledge that can be verified as true without having to turn to experience. (That might always count as "innate" depending on what your definition of "innate" is; but let's not get into that!)

Now, premise one seems indispensable if we're using these terms in ways that are even close to standard. Premise two is defensible because the whole point of Chomskyan grammars is that they can be formalized; for example, transformational grammars can be formalized as https://en.wikipedia.org/wiki/Transformational_grammar#Formal_definition tree automata. So if the Chomskyan program is on the right track, then the particular universal grammar inside the heads of all humans is mathematically formalizable, and is therefore a priori knowledge. 

Now, what if this grammar isn't really universal? What if different people have different grammars in their heads? I don't think that would change anything. If we have multiple differing grammars inside our heads, they all should still count as a priori knowledge if they are mathematically formalizable. But if there are no mathematically formalizable grammars in our heads, then the Chomskyan program is on the wrong track, and the question stops being coherent. (We would still have a priori knowledge of things like context-free grammars, transformational grammars, pushdown automata, and tree automata! They just wouldn't have any particular relation to the grammars of natural human language.) 

Knowledge of Universal Grammar is Analytic

The difficult part of this question is whether our knowledge of a well-formed universal grammar would be synthetic or analytic. Here again, we have to accept that the distinction exists; otherwise the question is incoherent. But what might the distinction mean in this case? In particular, we need a precise understanding of the term "analytic." Then we need to understand what it takes for a priori knowledge to be synthetic. This last problem is very difficult, and I think the best approach is to look at what might make mathematical knowledge synthetic rather than analytic from a post-Fregean point of view.

So I'll begin by turning to Frege's account of analyticity, which is usefully summarized by the http://plato.stanford.edu/entries/analytic-synthetic/#Fre SEP. In short, Frege tries to clarify the notion of "containment" that Kant uses to define analyticity. According to Kant, an analytic statement is one that states a fact already contained in the definitions of the terms it uses. So the statement "all bachelors are unmarried" is analytic, but the statement "all bachelors are sad" is synthetic. Frege attempted to refine this definition by linking it to the idea of formal or logical equivalence. If, by a process of purely formal substitution, one can derive a statement from a set of given prior terms, then that statement is analytic. 

Now, Frege's hope was that he could show that all arithmetical knowledge was analytic. But there's a convincing argument that he failed. This argument has to do with the problem of the actual existence of mathematical entities. Frege's system http://plato.stanford.edu/entries/frege-theorem/#6.2 explicitly commits itself to the existence of mathematical entities, but the justification for that commitment must be synthetic! 

Why should we believe that? Because for any given formalization of arithmetic, there exist diophantine equations that do not have solutions, but that http://plato.stanford.edu/entries/goedel-incompleteness/#HilTenProMRDThe cannot be proven unsolvable within that formalization. Since diophantine equations are really quite elementary components of mathematics, we would like a commitment to the existence of mathematical entities to include a commitment to the existence of diophantine equations. And if we are committed to the existence of those equations, then we would like there to be a fact of the matter whether or not any given diophantine equation is solvable. But if we depend only on analytic knowledge of mathematics -- if we rely only on formalization -- then we have to accept that in some cases, there is not a fact of the matter whether a particular diophantine equation is solvable. The conclusion that there is a fact of the matter is an inescapably synthetic judgment -- it posits the existence of Something outside of the formal system of definitions and substitutions that describes it. But because that Something is strictly mathematical in nature, it seems unreasonable to describe our knowledge of it as a posteriori -- unless you reject the idea of a priori knowledge altogether.

If you don't want to confront this problem, then you don't have to commit yourself to the existence of mathematical entities, but you then give up some kinds of certainty. If you don't want to make that sacrifice, then you have good reason to accept the claim that at least some mathematical knowledge is synthetic a priori knowledge. 

So to sum up, it seems we need to say yes to at least three questions to make a convincing claim that some knowledge of X is synthetic a priori knowledge.


Is there a truth about X that the formal definition of X doesn't already "contain"? 
Do we feel a strong motivation to accept that truth rather than remaining agnostic? 
Is that truth indeed a priori?


Applying these three questions to a hypothetical Chomskyan universal grammar, I think the answer is probably no in all three cases. Now this is where my argument breaks down a bit, because of course there is no established universal grammar yet. It may turn out that linguists discover the actual universal grammar, and find that 1, 2, and 3 are all true of it. But I see no particular reason to accept that conclusion yet! 

Furthermore, there as been at least some speculation that universal grammar is itself the very http://plato.stanford.edu/entries/analytic-synthetic/#ChoStrLin paradigm of analyticity. In this account, it is precisely the structure of the universal grammar that gives us our understanding of analytic truth. In that case, it would seem strange that our knowledge of universal grammar is itself synthetic. On the other hand, there doesn't seem to be a strong reason to assume that it is not. Perhaps the best route is to remain agnostic on the matter. But if I had to place a bet, I'd bet that our knowledge of universal grammar, such as it is, is analytic.
In De Interpretatione 1a1, Aristotle defines and describes homonymy in the following way:


  When things have only a name in common and the definition of being which corresponds to the name is different, they are called homonymous. [E.g.,] both a man and a picture are animals. These have only a name in common and the definition of being which corresponds to the name is different; for if one is to say what being an animal is for each of them, one will give two distinct definitions.


Let's apply this to Kenny's example. One thing a doctor, a scalpel, and a cancer have in common is the name 'medical': a doctor is a medical person, a scalpel a medical instrument, and a cancer a medical problem. The question is whether the 'definition of being' which corresponds to 'medical' is the same for all three. To answer, let's ask: what does it mean for each of  those things to be medical?:


A doctor is medical in the sense that she is a professional who practices medicine.
A scalpel is medical in the sense that it is ordinarily used during medical operations.
A cancer is medical in the sense that it is a condition that requires medical attention.


For those things, a different definition of what makes the thing medical is used, so they're said to be homonymous. Contrast that with an example Aristotle gives of synonymous things (1a6):


A man is an animal in the sense that [insert: your definition of what makes something an animal].
An ox is an animal in the sense that [insert: your definition of what makes something an animal].


For these things, the same definition of what makes the thing an animal is used, so they're said to be synonymous. These definitions have certain arbitrariness to them, but the bigger problem here is that:


Aristotle assumes that there is such a definition of being; 
Aristotle assumes that that definition of being is unique.


I have tried to guess how Aristotle might have justified the claim that medical man, medical instrument, and medical problem are homonymous. But the explanation I've given rests on Aristotle's assumption that "the definition of being" denotes a unique object, an assumption that you and I might not share. For example, we might, as the OP has, propose a definition of 'medical' in such a broad way that it can act as a definition of being medical for all three things; and so on. There are lots of other avenues open.

                                                                    Reference

Ackrill, J.L. (1963) Aristotle's Categories and De Interpretatione, Clarendon, Oxford.
Note: I'm answering the question in the body of the question, not the question that comprises the title of this page.

Once you accept memetic evolution, I'd say yes, with the caveat that your language for expressing it over anthropomorphises (sic?) the meme. The idea that any genes or memes have a kind of will that drives them to replicate is foreign to Dawkins' thought; it's much more mechanical than that.  Memes replicate with modification under selective pressure, with the resulting effect that they behave as though they are "trying" to survive.

The emphasis on eliminating competitors in your question glosses over the idea that memes exist in an environment, both physical and mental, and depending on the characteristics of that environment different features of the memes will be beneficial, thus it is not necessarily the case that a religious meme will ultimately turn vicious.
The word "game" makes a good metaphor for the interaction between people in a society where there is gain and lose and where the interactions are not happening chaotically but in more or less systematic ways and according to social norms some of which are clear to articulate about while others are implicit. But I think that the use of the word "game" became widely used after the publication of the popular book "Games People Play: The Psychology of Human Relationships" in 1964 by the psychiatrist Eric Berne which became bestseller and of which millions of copies were sold since its publication.
Spinoza's treatment of cosmology and theology is unique in the philosophical tradition. It is certainly true that God plays an essential role throughout Spinoza's thought. He always appears, however, in the very strange form signaled by Spinoza's recurrent phrase, "God, or nature." 

For Spinoza, only what is capable of independent being and cognition counts as  a substance, and only the entirety of nature in its interconnections is independent in this way. He equates this infinite substance with God - all extension is the extension of God, thus the equation signaled by the phrase, “God, or nature.”

There are definitely great differences between Deleuze's thought and Spinoza's, but the affinity which is a continual source of inspiration for Deleuze is what the latter sees as a profound immanence in Spinoza's thought. God is not separate from this world and there is no separate realm to speak of.

Nonetheless, I think Deleuze plays a bit fast and loose with the history of philosophy. This one aspect of Spinoza’s thought is what he refers to when he speaks of Spinoza and Nietzsche as precursors to his philosophy of radical immanence. Of course, there are enormous differences between those two philosophers and between each of them and Deleuze. Deleuze is not making a micrological analysis of either - at least where this comparison is concerned. He is interested only in this one aspect (which is certainly a far-reaching one).

You raise an interesting point by suggesting that infinite modes could represent a kind of transcendence. It would not be the sort of transcendence which Deleuze is separating himself from here, however. Many things, according to Spinoza, are beyond the capacities of a finite creature like the individual human. Nonetheless, nothing is beyond God, and his reality is the same reality as that which contains all finite creatures (whether we know of them or not) - his substance is the same infinite substance we all are part of. There are many interesting differences one could find between Spinoza and Deleuze, but his focus is narrow when he declares himself an inheritor of Spinozistic thought.
Why do not start with an history of philosophy ? For example Anthony Kenny, http://rads.stackoverflow.com/amzn/click/0199656495 A New History of Western Philosophy.

A brief "classic" can be : Bertand Russell, http://rads.stackoverflow.com/amzn/click/1604595132 The Problems of Philosophy

Online, you can find http://plato.stanford.edu/contents.html Stanford Encyclopedia of Philosophy : from Abelard to Zhuangzi. All entries have bibliography.
It isn't necessarily invalid to accept infinite regresses. Rejecting them was a classical and medieval requirement for two reasons:


An infinite regress defies the chain of causation it is meant to explain. In other words, if you define causation as A --> B, then for any B, you need an A. An infinite regress would mean never arriving at the A at some point but claiming that what we're talking about is still causation.
Medieval and ancient thought rejected the possibility of an actual infinite. A infinite regress requires an actual infinite. I'm sure shane could give a more thorough answer because this is closer to his speciality, but I'll just [cite wikipediahttp://en.wikipedia.org/wiki/Actual_infinity 1] to show you the list of authorities on that.


But many modern views believe actual infinities are possible, solving problem 2, and many believe causality is in the mind -- semi-solving problem 1. In medieval logic, arriving at an actual infinite is the same as arriving at a contradiction -- a sign that something has gone wrong.
I found http://books.google.com/books?id=AvX1FeO76gYC&pg=PA179&lpg=PA179&dq=Peter%20van%20Inwagen%20moral%20judgements&source=bl&ots=rVlkLlgwu6&sig=UPWV3DXHJ5pGSxCSjVM_dN63tTc&hl=en&sa=X&ei=2_CRU8LGMqnnsATLoILwBA&ved=0CD0Q6AEwAw#v=onepage&q=Peter%20van%20Inwagen&f=false one writer (page 183) who seems to describe the Hard Determinist point-of-view in a way that allows for some response to criminal acts:


  Can we say of an [ethically disabled] indvidual - Robert Harris, for example -  that he ought not have killed the two young men? Certainly. Could we say that he was morally wrong to commit such murders? Of course. Even though he could not have done otherwise, what he did was horrifically wrong... It makes perfect sense to recognize that Harris is severely morally disabled, and that given who he is at this mature stage of life, he could not have resisted committing the murders.. Robert Harris is not a tornado, but a person with rational powers... who makes choices (though not super "ultimate" choices") and who might be capable of reform.


So, a couple points I take away from this:


Hard Determinists believe you don't ignore criminal acts at least because the person can be changed in the future
To say that someone had no ultimate choice in the matter does not mean that the thing that was done was morally ok.
It is ok to even go so far as make judgements about whether an individual is capable of moral reasoning.


I suppose that a hard determinist just thinks that all of these choice are deterministically made.

What I could not find any references for though, is how hard determinists reason about things like legislation. I would imagine that legislation is a decision much the way to steal or commit murder is, and it is a deterministic decision, meaning it is based on the inputs of the situation, and you don't have any ultimate choice in the matter of how to punish people for their bad choices.
The Kantian definition of talent in the context of imperfect duties is that these are abilities that can help others. The reason for this is that the justification for why we must develop our talents follows from a human limitation and the Categorical Imperative.

Specifically, as human beings, 

(1) we need help at different points in our lives

and

The Categorical Imperative means that we need maxims that can be universal.

But this means that we somehow need the Categorical Imperative to include requiring rational creatures to provide us with aid. So we universalize that and it applies back upon ourselves. Thus, the talents that matter are those that can help people.

From this, however, it does not follow that juggling is excluded. Because we have wide latitude in selecting our talents that we develop. And there are many different forms of assistance we may need throughout our lives. What seems like it would be excluded is an ability that is improved which could never help others or an improvement in level in ability that one could not conceive of helping others. So then maybe playing video games is not a talent under this definition. But again, we are not required to spend every waking moment improving our talents.
To really grasp what is going in this section, we need to step back and position ourselves in the Phenomenology. We are now in the domain of "self-consciousness" as a mode of certainty which Hegel explains differs from other modes of certainty. His critique of other modes is that "what is true for consciousness is something other than itself" (166). He explains that for the other modes of certainty (sense-certainty, the concrete thing of perception, and for the Understanding, a Force") prove to be ways objects exist for something other than themselves.

What Hegel is here doing is making the Kantian move (thus my highlighting of differences in terms). His point is largely that certainty is a function of mind not of that which is outside of it. At this point, Hegel can unify object and Notion (Begriff) as the for-itself and in-itself of the same thing.

Thus paragraph 167, Hegel declares "we have therefore entered the native realm of truth" (i.e. the place where truth happens -- acts of consciousness). Thus, in 167, he considers the depth of saying I am I which appears empty but turns out to be quite meaningful insofar as it involves a dialectical and reflective separation between the notion and the object and the application of object-notion to the self.

But paragraph 168 shows us what happens to objects when self-consciousness makes certainty about thinking: "the object ... has ... returned into itself" under the idea of a living thing. Hegel distinguishes the mind and the body that has the mind: "the former is the unity for which the infinite unity of the difference is; the latter, however, is only the unity itself, so that it is not at the same for itself" -- in that dense gibberish-like fragment, when Hegel says "for which difference is" he means in contemporary vocabulary that it's that mind predicates. Moreover, when self-consciousness is "desire" it defines its object only as a negativity (i.e. food that I eat -- instead of what it really is). tl;dr: Consciousness then becomes the software running on the dumb hardware of the living thing.

Now to 169, life occurs in things that have essential forms. In this respect, he's an Aristotelian through and through. What's interesting about the essence is that not only does it supersede the distinctions it also has its own independence and has endurance (think Anthony Kenny's definition of the form as the self-regulating principle). But things that are merely different instances of the same essence (where essence is both quasi-Aristotelian essence and mental construct for describing) is that the objects are only determinated by consciousness itself.

I don't know if that makes it any clearer... but basically living things pose an interesting problem for self-consciousness since it has moved the basis of certainty to the mind which encounters objects. Now, we need to understand what sort of object a living thing is.
Socrates' personality was in some ways closely connected to his philosophical outlook. He was remarkable for the absolute command he maintained over his emotions and his apparent indifference to physical hardships. Corresponding to these personal qualities was his commitment to the doctrine that reason, properly cultivated, can and ought to be the all-controlling factor in human life. Thus he has no fear of death, he says in Plato's Apology, because he has no knowledge of what comes after it, and he holds that, if anyone does fear death, his fear can be based only on a pretense of knowledge. The assumption underlying this claim is that, once one has given sufficient thought to some matter, one's emotions will follow suit. Fear will be dispelled by intellectual clarity. Similarly, according to Socrates, if one believes, upon reflection, that one should act in a particular way, then, necessarily, one's feelings about the act in question will accommodate themselves to one's belief—one will desire to act in that way. (Thus, Socrates denies the possibility of what has been called “weakness of will”—knowingly acting in a way one believes to be wrong.) It follows that, once one knows what virtue is, it is impossible not to act virtuously. Anyone who fails to act virtuously does so because he incorrectly identifies virtue with something it is not. This is what is meant by the thesis, attributed to Socrates by Aristotle, that virtue is a form of knowledge.

Socrates' conception of virtue as a form of knowledge explains why he takes it to be of the greatest importance to seek answers to questions such as “What is courage?” and “What is piety?” If we could just discover the answers to these questions, we would have all we need to live our lives well. The fact that Socrates achieved a complete rational control of his emotions no doubt encouraged him to suppose that his own case was indicative of what human beings at their best can achieve.

So Socrates' view on free will, believing that the unexamined life is not worth living, was the wisdom and will for self-control, which for him required reflection or a conscience, in other words, for socrates free will is impossible without self-control, for people without self control arent capable of free will because being slaves to their passions they lack the free-will required for self-control. His view in the republic, (in the dialogue with Thrasymachus) is in conflict with the libertarian view, where people who are "slaves" to their passions have the right to self-determination, regardless of what their idea of the best life is, and the reason for his disagreement with libertarian free will in the republic is that justice requires reflection, and that the tyrant is a slave to his passions, does not reflect on his actions and believes he has the right to self-determination.

i also find the stoic view (which they borrowed from socrates') on emotional self-control interesting, namely, that all emotion emerges from incorrect judgement and that the person with reason properly cultivated is able to control their emotions because they posses the wisdom to properly put the source of emotional conflict into the correct perspective or context, and therefore able to make the correct decision. 
First, it might be useful to recall that Hume claimed that all propositions can be classified into two categories: 1) relations of ideas and 2) matters of fact. The truth of relations of ideas is known a priori, without the aid of experience. Logical or mathematical propositions are such relations of ideas and we can be sure of their truth because denying them would involve a contradiction. As for matters of fact, their truth depends on how the world is and thus can only be justified a posteriori, i.e. with experience. That X causes Y or that the colour of Napoleon's horse is white are propositions whose truth depends on experience of the world. This distinction is often called 'Hume's Fork' and it mirrors to some extent the necessary/contingent, analytic/synthetic, a priori/a posteriori divide. 

To come back more specifically to your question, I think Hume would say that the necessary connection between a cause and an effect is a matter of fact, but the 'necessary connection' (this term is perhaps misleading) between premisses and a conclusion in a deduction is a relation of ideas. The following proposition, 'Were the premisses of a valid deductive argument be true, the conclusion would necessarily follow.', is true in virtue of the meaning we ascribe to the words involved like 'valid, 'deductive' or 'argument'. Basically, one is only spelling out the meaning of the proposition and what this meaning logically entails.

So is it the case that "the rules of the deductive game" necessarily apply? Here I might be deviating from Hume, but the short answer is no. It is relative to a language and there are many types of logics, http://plato.stanford.edu/entries/logic-paraconsistent/ paraconsistent logic, http://plato.stanford.edu/entries/logic-fuzzy/ fuzzy logic, http://plato.stanford.edu/entries/logic-relevance/ relevance logic, http://plato.stanford.edu/entries/logic-free/ free logic, http://plato.stanford.edu/entries/logic-modal/ modal logic, etc. But in a language where 'deduction' means what it commonly means, yes, the rules necessarily apply. One cannot deny that the conclusion of a valid deductive argument necessarily holds provided the premisses are true. That would contradict one's own concept of deduction. But it doesn't mean that necessarily 'deduction' ought to mean that, if that is what you asked.

Finally, concerning Kant, one central idea of the Critique of Pure Reason is that some a priori concepts, the categories of understanding, necessarily apply to all the objects of human knowledge. They structure all our thoughts and experience. One such category is of 'Causality and Dependence' and contains the idea of the necessary connection between a cause and its effect. Also, Kant didn't buy Hume's Fork. The Critique's main motivation was to show that synthetic a priori judgments were possible, i.e. that it is possible to know a priori some propositions about the world. 
Normal arguments regarding maximising expected utility, presuppose that the distribution of conditions is independent of your strategy.

The counterintuitive (and many would say: counterfactual) element of Newcomb's paradox is that the distribution is said to depend on your strategy. You can understand the game easily enough for two strategies:


Suppose the predictor actually has the described power, and you both believe it does and trust that it will provide the $1M if you intend to take the contents of only the one box. Then, if only for selfish reasons, you'd be a fool to plan to take the second box. And after the reveal, it doesn't matter that you could then grab the second box as well: by hypothesis, you are in that circumstance because of a prediction, assumed accurate, that you won't choose to.
If the predictor actually has the described power, but you either don't believe it does or don't trust it to provide the $1M, you will be receptive to taking both boxes. The predictor, knowing this (by hypothesis) and also knowing whether you would choose to take the second box given the opportunity, will leave the opaque box empty if so. It would in effect be producing a self-fulfilling prophecy, but only because it knows enough about your intentions to do so, and because it has for some reason resolved only to give you $1M under specific circumstances.


Your strategy, in the game, would obviously depend on whether you think such a predictor is possible, and honest. If you don't, you should take both boxes; if you do believe in the predictor, you shouldn't.

If you believe in the predictor but get an empty box, that's tough: you were wrong either about it's ability to predict (if you go away empty-handed) or its intent to act in good faith (if you intended to take only one box but take both after re-evaluating your relationship with the predictor). However, the premise of the puzzle disallows this contingency. You may not believe that the game can be realised in fact, but the premise of the question is that the predictor is both perfect at prediction and honest. And in this case, any doubt of the player is a matter only of not knowing, or accepting, that premise.

If you accept the premise of the question, it's obvious how you ought to act. The only question, then, is whether you accept the premise of the question! If you don't, then it's not that Newcomb's paradox is unsolvable: it's that you refuse to regard it as worthy of serious consideration. And that's bound up with issues of philosophical naturalism (computational complexity in particular), and psychology.
In short, Kant's answer is that 'causality' isn't, contra Hume, merely constant perceived conjunction. If this is the case, then the problem of induction applies and it is not possible to infer that there is a necessary connection between a cause and its effect. Instead, Kant argues that causality is an a priori concept of the faculty of understanding. Because the concept of causality a priori mediates our experience of the world it isn't a purely subjective matter, as Hume claimed. The categories of understanding, among which 'Causality and Dependence', a priori structure our experience of the world and thus license the idea of necessary connection.

That said, it should be noted Kant doesn't deny that there are causal laws which lack the necessary character of 'pure' causal laws.

Since you mentioned the SEP, you might want to have a look at the entry on http://plato.stanford.edu/entries/kant-hume-causality/ Kant and Hume on Causality. It discusses the  problem you want to address in much more detail.
From the recent book by Jan von Plato, http://rads.stackoverflow.com/amzn/click/110761077X Elements of Logical Reasoning (Cambridge UP, 2013), pag 11:


  The two sentences if A, then B and B if A seem to express the same thing. Natural language seems to have a host of ways of expressing a conditional sentence that is written A→B in the logical notation. Consider the following list :
  
  From A, B follows; A is a sufficient condition for B; A entails B; A implies B; B provided thet A; B is a necessary condition for A; A only if B.
  
  The last two require some thought. The equivalence of A and B, A↔B in logical notation, can be read as A if and only if B, also A is a necessary and sufficient condition for B. Sufficiency of a condition as well as the 'if' direction being clear, the remaining direction is the opposite one. So A only if B means A→B and so does B is a necessary condition for A.
  
  It sound a bit strange to say that B is a necessary condition for A means A→B. When one thinks of conditions as in A→B, usually A would be a cause of B in some sense or other, and causes must precede their effects. A necessary condition is instead something that necessary follows, therefore not a condition in the causal sense.


In conclusion :


  what is the relationship between "if A then B" and "A only if B"? 


They have the same meaning.
I will answer in what seems like either a serious jest or dialectical irony: by using a better definition of rationality.

Yes, a certain level of thinking would get you stuck unable to pick between two equally desirable outcomes and thus winding up worse than either. But this seems to be a thoroughly impoverished definition of rationality. You demonstrate that clearly in your own objection -- this rationality seems unable to incorporate the negative consequences of not choosing. This if there is any source of randomness that can help the ass pick, it should use this to decide the meaningless choice.

Now, you can keep the thought experiment alive by eliminating any source of randomness to help the ass. But then it seems like a robust form of rationality in such a world would devise a rule that handles these situations: "given two equally arbitrary options and the necessity of picking one or the other, go left" [or some such rule]. (This seems to me to be a feature of how we understand the conditional with a false antecedent -- we need to pick something if we want to keep our logic bivalent).
I cannot answer for all ethical theories, but for Kant, the answer is most definitely yes.

Specifically in the Metaphysical Principles of Virtue or Doctrine of Virtue (Both are names for the Tugendlehre), Kant identifies both suicide and lying as wrong not because of anything they do directly to others but as failings in one's moral duty to oneself.

Working from memory (though I spent a few pages on in my dissertation), the basic argument for suicide being a wrong is that the self is a rational creature and it is the duty of every rational creature to always consider rationality to be of worth and not price (non-relative value).  To kill yourself is to act against the rationality in yourself and thus immoral for Kant. The suicide case is followed by casuistical questions that look at whether certain acts constitute a violation of this duty. Here, he mentions borderline cases like knowingly sacrificing yourself in a war or killing yourself because you have "hydrophilia" (= rabies).

For the second example, Kant's argument that lying is a failure in duty to oneself is a bit more interesting and ingenious. It follows along similar lines but explains that lying is an insult to the sort of being you. It's the reduction of rationality which depends on the truth to contingency for the sake of convenience. Again, this is followed casuistical questions about what constitutes "lying" or not. For Kant, idle banter at a party is not lying even if it is not per se true.



I am not familiar enough to know a passage in any utilitarian or consequentialist works on this point, but my suspicion is that the answer here would also be yes unless the thing to be maximized is "autonomy." If it is autonomy understood as pure expressions of freedom, then no such wrong is possible. But if it is suffering, then there's no reason to imagine that you are not committing a wrong against yourself when you act in such a way that increases your suffering.



If we take Aristotle's Nicomachean Ethics to be the origin of virtue ethics (a claim that involves a certain sort of historical anachronism), then there's good reason to think that many wrongs are wrongs ultimately against the self for virtue theorists. I'll explain a little bit about. Aristotle's theory is built on the function argument (Book 1 section 7) which argues that a thing is best when it is fulfilling its function. Moreover, when it fulfill this function then it experiences eudaimonia (not to be confused with say the fun of a drug high -- seek book 2) and exhibits arete (excellence) in its actions.

The primary way in which something is wrong on a pure virtue theory approach is that it undermines the self's commitment to excellence. There's nothing in the nature of the self that is best fulfilled by being a lying scoundrel or by committing actions which will help to make oneself into that. Similarly with your bestiality example, human sexuality is not most fulfilled by having sex with animals. 

I'll stick with lying however to show the point. Developing a skill for lying will incorporate lying into your character, but that's not what we're meant for. As you lie more, your ideas of what is pleasurable for you to do will warp towards lying, and this will move you away from eudaimonia.
Well, Zeno and Chrysippus argued that everything is fated, as follows. “When a dog is tied to a cart, if it wants to follow it is pulled and follows, making its spontaneous act coincide with necessity, but if it does not want to follow it will be compelled in any case. So it is with men too: even if they do not want to, they will be compelled in any case to follow what is destined”.
Diodorus Cronus also formulated an enigmatic argument (known as the Master Argument) as follows.  It is clear, he says, that the following three propositions cannot all be true.
1. Everything true about the past is now necessary. (I.e. you can’t do anything about the past, it’s done).

(2) The impossible does not follow from the possible. 

(3) There is something that is possible, and yet neither is nor will be true. (i.e. there are some possibilities that will never be realized, no matter how long you wait)

Diodorus accepted 1 and 2, and so rejected 3: whatever is possible either is true or is going to be true, he thought. So you can’t do anything about the future. The argument is entirely unclear, probably because key parts of it have been lost.

  I have studied Marx in a lot of subjects in the school, such as History, Sociology, Economy and Political Sciences. The bad side of this is that each professor told me different things about Marx.


There are many Marxisms - philosophical, cultural, political & economical. Its important to see that Marxs own writings are part of what is now called http://en.wikipedia.org/wiki/Political_economy political economy; for example his labour theory of value is an extension of Adam Smiths theory; and as a young man he was part of that group called the http://en.wikipedia.org/wiki/Young_Hegelians Young or Left Hegelians  that was critical of the Prussian state and of Religion; its important to realise that as a thinker he drew on many strands of intellectual thought and because he was a point of reference for many other thinkers - some of them far from his own - he left his mark on many others.


  Was he a defendor of capitalism? 


When Marx was writing the system that is called Capitalism was prevelant in a small number of North European nation states, predominantly England; though he traced it back to the commercial city states of Northern Italy; this was one of the reasons he emigrated to England - to study its effects and causes at first hand. 

Capitalism should be distinguished from the petty capitalisms of the classical civilisations of Islam & Rome; the immediate precursors of Capitalism. Its also worth noting that contra the physical & biological sciences that his science isn't attempting to uncover the laws of motion for all economies for all time  - it is not a universal theory as Newtons theory of Gravitation was a universal theory - but that it was a historically & socially constituted description & critique; he wrote that a new economic & political order would demand a new analysis.

As an astute observer of the Capitalism regime he predicted that it would cover the globe - ie what is now known as Globalisation (in at least some senses). He also admired the energy of the bourgeois (as opposed to the feudal order) which he considered would transform the relations of production throughout the globe; part of this must be at least predicated on the global extent of the colonial empire which would ease the introduction of these new methods. 


  [was he] just criticizing the distribution of the income?


In the latter half of Capital (volume 1) he describes his anger at the inequity of Early Capitalism; so, yes; there is a moral imperative there; but this moral anger was shared by a wide spectrum of people in 19C England/Europe - for example Chartism;but its not simply about distribution of income; 


  and set a new political-economic system (communism)?


Marx was a marginal figure in the political scene in Europe - "https://www.marxists.org/glossary/orgs/f/i.htm he had been exiled from Germany, thrown out of Belgium and expelled from France" when he joined the First International - The International Workingmans Association; it was through this organisation that his ideas became visible.

Here Marx became a political activist and he aligned himself with the political current that became Communism.


  Was the socialism installed in the Soviet Union by Lenin what Marx would like?


Its difficult to judge from Marxs own writing as he died well before the Russian Revolution. One suspects he would have celebrated the revolution but been dismayed by its trajectory - particularly during the Stalinist era.


  Is right to say that Marx wasn't a communist?


Yes & No; as a political activist he was - he & Engels cowrote The Communist Manifesto after all; As a thinker and philosopher - if one is to take his theory as granted, and name the political & economic order that supersedes Capitalism as Communism then he could not be - its impossible to belong to a movement or order that is not in existence; what one can say is that he aligned himself with forces that he believed in bringing a new order about.
To say that human agency itself is an illusion is a vey strong statement, Bretanos notion of intentionality and Husserls phenomenology take a point of view that opposes this by looking at the world from the direct view of consciousness; Heidegger,too, probably fits along this line too as he considers Being in Time.

Structuralism has two roots in modern philosophy, the more well-known has roots, as you recalled, in Saussures structural linguistics; the other root is in Bourbaki, the structuralism of modern mathematics whose modern avatar is category theory; notably only the first has had an impact on Philosophy through Saussures structuralism being taken up by Levi-Strauss in his Anthropology; Bourbakis structuralism has had a wide impact on mathematics but is struggling to make its voice heard elsewhere; even in such  a close and neighbourly discipline such as Physics. Mathematics has had a wide impact on the flavour of philosophy of the analytic kind - through the foundational study of mathematics and logic - which has developed in Wittgensteins analytics philosophy of language (predominantly of the propositional kind - which is why it slips past poets and prose sylists).

http://en.wikipedia.org/wiki/Structural_linguistics Structuralism in linguistics avoids all questions of semantics that is meaning in favour of a purely structural view of language; that is the parts of language and how they inter-relate; that is:


  The foundation of structural linguistics is a "sign," which in turn has two components: a "signified" is an idea or concept, while the "signifier" is a means of expressing the signified. The "sign" is thus the combined association of signifier and signified. 


This amplifies and analyses the older idea of a word 'dog' (the sign or signifier) and the dog itself (the signified); but notably now a picture of a dog is also signifier; and similar things can be said for the visual grammar and iconography of advertising, cinema and architecture.


  Signs can be defined only by being placed in contrast with other signs, which forms the basis of what later became the paradigmatic dimension of semiotic organization (i.e., collections of terms/entities that stand in opposition). This idea contrasted drastically with the idea that signs can be examined in isolation from a language and stressed Saussure's point that linguistics must treat language synchronically.


Here two things are being said, that the sign 'dog' is understood as different from the sign 'cat'; and that to understand the sign 'dog' one must also understand the entire language; this, at first, appears odd - do we not understand the sign 'chien' as the french word for the sign 'dog'? And this without understanding the entire French Language? We do, of course; but one must understand that for humans that to know one language, is in some sense to know them all; for they all have structural similarities (this is Chomskys thesis).

They add:


  Saussure set out to model language in purely linguistic terms, free of psychology, sociology, or anthropology. That is, Saussure was trying precisely not to say what goes on in your or my mind when we understand a word or make up a sentence. [...] Saussure was trying to de-psychologize linguistics


This doesn't mean that linguistics can be depsychologised; but that we ask what can we know about language if we are prohibited from utilising our knowledge of sociology and psychology; in this sense it has some commonality with Skinners Behaviouralism; and the object-orientation of Category Theory.

Levi-strauss applied this platonic theory to Anthropology; to understanding the structures of myth without understanding what these myths signified to the clan or tribe.  Thus its myths are signs, and made up of further signs.

addendum

One has to be deeply read in either linguistics or anthropology, I suspect, for the structural approach to begin to make sense; I can't speak for structuralism in the afore-mentioned subject, but certainly its true that structuralism in mathematics, which I do know something about, only begins to make sense when one has completed an undergraduate course - at least for a typical student - there are of course atypical ones, which tends to happen more with mathematics because of its subject matter than the humanities.

  If the universe were deterministic (determinism, understood as the ability to accurately foresee all properties of universe at arbitrary time (or "time-space")), would it mean that God cannot exist (since it would not be able to change the state of the universe at a given time)?


No. http://www.simulation-argument.com The Simulation Argument appears to trivially demonstrate that a deterministic universe presents zero problem for deity, or for less-than-deity. For our reality could easily be a simulation (e.g. we could be in The Matrix), run by beings outside the simulation. Such a simulation could be a http://en.wikipedia.org/wiki/Eternalism_(philosophy_of_time) block universe. Given such a universe, a 'change' to it would appear to force a re-simulation from scratch, which would mean that the previous, unchanged version simply ceases to exist.
An obvious example of an ethical system that measures things by "goodness" and not just good or bad is utilitarianism. In Utilitarianism, it is understood that all actions have costs and benefits and it is ethical to choose the thing that maximizes overall difference.

In many other traditions have an the notion of prudence, and define it as a practical application of the rules of absolute right and wrong you refer to. http://www.newadvent.org/cathen/12517b.htm Christian philosophers continue to view it in this light, although the philosophical underpinnings go back to http://en.wikipedia.org/wiki/Prudence#Prudence_in_Rhetoric Cicero and even Aristotle.

Then to answer your question, it is not only reasonable to expect an ethical system for help in making decisions, but is probably more common than not, since cost/benefit tradeoffs or prudence make their way into many ethical systems.
I don't know that any well-known philosophers have addressed this, but game theorists have.  This question seems closely related to the http://plus.maths.org/content/mathematical-mysteries-survival-nicest iterated prisoner's dilemma.  In some cases, an eye for an eye is the optimal strategy; in others, an eye for an eye with random forgiveness proves optimal, both to the individual and to the system as a whole.  It all depends on what strategy your opponents are using.

I suppose that whether this kind of optimality translates into a prescriptive philosophy depends on whether you think morality ultimately derives from game theory.  I happen to think it does.
"Margarine is better than nothing." Here, "nothing" is referring to the absence of something.

"Nothing is better than butter." Here, "nothing" is a placeholder for anything at all.

Thus, the meaning of the word "nothing" is different in the two sentences and you have equivocation.

If you maintained the meaning of "nothing" from start to finish
(so that "Nothing" means 'absence of something' as defined in the first sentence above),
then "Nothing is better than butter" would be equivalent to "Butter is worse than nothing":


  
  Margarine is better than nothing.  (It is better to have margarine than to have nothing.)
  Butter is worse than nothing. (Having butter is worse than having nothing.)
  Therefore, Margarine is better than butter.
  


Here, the meaning of nothing is consistent.
There seem to be two versions of the fallacy. The first says: φ is possible, therefore φ will be true at some point in the future. The second: φ is probable, therefore φ will be  true at some point in the future:


  Variant 1. An appeal to possibility: Poss(φ) ⊢ F(φ);
  
  Variant 2. An appeal probability: Prob(φ) ⊢ F(φ).


Depending on your account of possibility and probability, these will have different explications. I will sketch a way of explicating (1), leaving you with http://yalcin.cc/resources/yalcin.2010.probabilityoperators.pdf Yalcin 2010 to work out how to explicate (2).

What we need is a modal language with both alethic (e.g. Poss) and temporal (e.g. F) operators. I propose to use a temporal language and define the needed alethic modality in it instead of taking it as an undefined symbol. As usual, we start with the definition of the language:


  Definition 3. (Language) Given a propositional letter 'p', the well-formed formulas of Priorean temporal language are generated by the following grammar:
  
                                           φ   :=   p   |   φ′   |   ¬φ   |   (φ ∧ φ)   |   G(φ)   |   H(φ).


We read G(φ) as it "henceforth φ" and H(φ) as "hitherto φ"; the rest of the operators are familiar. For everyday research purposes you would then define the semantics of this language on what are called flows of time and prove things about the logic. Here we're concerned with defining things only, so let's define the operators that we need in order to express (1) and (2):


  Definition 4. (Future Temporal Possibility) To say that "φ will happen" is to say that "it's not the case that: henceforth ¬φ". This is the motivation behind the definitions: 
  
                                                                  F(φ)    =df   ¬G¬(φ),
  
                                                                  P(φ)    =df   ¬H¬(φ).


Now we define the alethic possibility operator Poss using this language.


  Definition 5. (Alethic Possibility) To say that "φ is possible" is to say that "either φ is true or φ was true or φ will be true". This is the motivation behind the definition: 
  
                                                          Poss(φ)    =df   P(φ) ∨ φ ∨ F(φ).


This says nothing more than that if φ is possible, then there is at least some point in time (either now, in the past, or in the future) at which φ holds. To explicate Variant (2), this operator has to be strengthened. The explication of Variant (1) is then the following:


  Variant 1. (Explication) P(φ) ∨ φ ∨ F(φ) ⊢ F(φ).


The very form of it suggests its counterexample: take any proposition p that has happened in the past and will never happen again (e.g. "Julius Caesar is being stabbed"). That means that P(p) is true. Therefore P(p) ∨ p ∨ F(p) is true. But it's not the case that Caesar will be stabbed again, so F(p) is false.

                                                                   References

van Benthem, J. (2010) http://rads.stackoverflow.com/amzn/click/157586598X Modal Logic for Open Minds, Stanford, CSLI Lecture Notes #199.
Holliday, W.H. (2012) http://philosophy.berkeley.edu/people/page/123 Modal Reasoning, Lecture Course (Spring), UC Berkeley.
Yalcin, S. (2010) http://yalcin.cc/resources/yalcin.2010.probabilityoperators.pdf "Probability Operators".
Nietzsche - of course. TBH I can't think of anyone else, it was a simply theistic time ha!

You could I suppose look into zen Buddhism - the answer there would be complex, and perhaps not to your taste, but there is the argument / assertion that morality is a dualistic way of thinking. Of coure they don't condone [nor accept - there is still a http://en.wikipedia.org/wiki/Vinaya vinaya in Japanese Buddhism] immorality, but there is the famous answer of Bodhidharma ['official' founder of zen] to an Emperor who asks about the http://en.wikipedia.org/wiki/Merit_%28Buddhism%29 merit of all his good deeds


  No merit whatsoever.


HTH a little.
Let U be the union of T. Any derivation U ⊢ A uses a finite number of assumptions from U. Since the set T of theories is linearly ordered by inclusion, there is a theory T' ∈ T containing all these assumptions, so that T' ⊢ A. Since T' is a theory, A ≠ ⊥. Also since T' is a theory, A ∈ T', which gives A ∈ U. Thus U is a consistent and closed under derivations. Thus U is a theory.

EDIT: Above I assumed that a theory is consistent, which the question did not require. Allowing inconsistent theories, the proof still works (with the obvious changes).
My Sociology professor, Stijn Oosterlynck (Antwerp University, Belgium) , has answered me in Dutch.

This is the original answer:


  Bourdieu gebruikt een combinatie van cultureel en economisch kapitaal
  om sociale klasse te definiëren. Essentieel is dat een sociale klasse
  niet kan gedefinieerd worden op basis van socio-economische posities,
  maar tot stand komt in de culturele (consumptie) praktijk van mensen.


And this is how Google Translate renders it:


  Bourdieu uses a combination of cultural and economic capital to define
  Social class It is essential that a social class can not be defined on
  the basis of socio-economic positions, but is created in the cultural
  (consumption) practice of people.


So what have I learned:
Bourdieu didn't shy away from using the word class.

Additionally: Bourdieu noted that classes were fractured because people carry different individual capitals => class is fractured because of the different capital-compositions. E.g. businessmen focus on economic capital and violinists focus on cultural capital, but both might be part of the same class.
Surplus value is a philosophical or at least critically scientific 'thing', it is in no way the same as monetary profit. Surplus value is a measure of exploitation in terms of value, i.e. the more surplus value I make from my workers, the more exchange value I create for myself. 

Sometimes I do so without making a profit, as in your example. This means that the analysis of value defines something that is logically independent of price. Marx tries to show that the nature of surplus value means that capitalism must encounter periodic "crises." 

One could object that it's only price that drives capitalism, and so his proof of economic crisis is not essential to capitalism. This would be bad for Marx.
For me, in direct response to the title:


  All life comes into its own as free and equal in dignity, rights and consideration. Such life as is endowed with reason and conscience also must observe this truth in transactions with any other form of life.


As an individual that also places value on non-human life, the restriction to human beings seems relatively arbitrary.  Moreover, the usage of brotherhood comes off as a bit chauvinistic.  All equal in dignity, we're just also going to ignore the existence of women and non-binary transgender identifying individuals in the next sentence.  Starting with these two targets, I worked to modify the statement.

My personal adaptation would shift from usage of human beings to life.  Fortunately, for extension purposes, life isn't defined exceptionally well right now, but definitely includes humans.  Unfortunately, that opens up what should be a relatively straightforward statement to a certain degree of discussion.  Oh well.  That's why there's a whole stack exchange to discuss this issue.

Likewise, I append consideration to dignity and rights.  This has the purpose, in human systems, of also mandating treatment in excess of the minimum required, and in non-human systems, of acting towards other life in accordance with its specific conditions and needs.  That is to say, when I take consideration of other humans, I give of my time and resources to others.  When I take consideration of other life, I choose vegan dietary options such as do not harm others and respect eco-systems even at non-zero financial cost.

Moreover, I can conceive of both Homo sapiens that may or may not be captured by the term "human beings" that lack reason or conscience and, for those reasons, should not be held to the same standards as other human beings.  Likewise, with the extension beyond human rights, restricting reason and conscience to humans in particular becomes meaningless.  For that reason, I developed a special class characterized exclusively by capacity for reason and conscience, and charged it with the implementation of my statement (as no other life would be capable of reading, understanding, and acting on it).

I'm left with something that isn't really a Universal Declaration of Human Rights, but, in my opinion, largely subsumes the Declaration, and also address broader and more difficulty issues with its provision for just treatment of non-human life.

==================================================================================

As it stands today, I highly doubt the declaration would be applied to any non-human life, even that with reason and conscience.  Historically, xenophobia always supersedes tolerance, especially in first contact.  Without specific and intentional provision for rights of non-human life, I would expect no rights to be afforded.  However, human is an open concept.  As the Declaration refrained from usage of scientific terminology,  currently we are working with (thanks Google!) the following definition:


  a human being, especially a person as distinguished from an animal or
  (in science fiction) an alien.


Now, that's pretty imprecise.  Humans are animals, and there's only a differentiation from aliens in science fiction.  You'd probably lose the debate, but it is possible to argue that the "human" term could include any form of life with reason and conscience (in fact, you could even argue so on basis on the Declaration).  If we encountered non-human sentient life tomorrow, I would argue for its protection on this basis.

==================================================================================

Lost human tribe?  I'm more optimistic about this.  People love things like themselves, and we'd all at least be within the same Genus (right, we're in the same Genus at least?).  Especially as human and Homo sound somewhat similar, I'm sure many would be fine calling them humans.  I hope that's reasonable.

In terms of actual ethics, well, you see what I think about respect in my generalization.  I believe we would absolutely be bound to treat them (as anything else) with the utmost respect.  In accordance with the Declaration, I believe we would as well.  However, these are not ironclad truths descending directly from the wording of the declaration, so your mileage may vary.

==================================================================================

I think if we formulate the question as "Oh I can treat x in any way I want with no moral implications, right?" we have a fairly straightforward philosophical answer.  The Declaration is a subset of this answer when x is taken to be consensus reality's definition of humans.  That reduces this to a question of consensus reality, which starts to drift into theoretical sociology, so I'm fairly comfortable taking the question this far and no further.
Craig loves this argument. Its proper title is the Kalam Cosmological Argument and it is formally phrased thus:


Everything that has a beginning of its existence has a cause of its existence.
The universe has a beginning of its existence.

Therefore:

The universe has a cause of its existence.

Craig and apologists like him then add two more steps.

If the universe has a cause of its existence then that cause is God.

Therefore:

God exists.


The first three steps of the argument have a number of flaws when examined for logical inconsistencies. 

Firstly, the argument hinges on a sloppy generalization that "Everything that begins to exist has a cause" This is an unsupported assertion. It has been demonstrated in laboratory conditions that some events (on the quantum scale) do not have a cause or if they do, we have no understanding of them and to call them God would be fallacious. One must question whether it is appropriate or even possible to apply our every-day, inductively derived understanding of causality to extreme conditions such as the beginning of the universe. The philosopher Hume argued that the only way to know if a principle holds in conditions very different from those in which it was derived is to have direct experience of it happening.

Secondly, the original formulation of the argument simply proves the universe had an extant cause. Craig and his ilk add additional steps with no logical basis to get to their god of choice. You can go on YouTube and see Hamza Andreas Tzortzis, a well known Islamic apologist, use the same argument to prove his god is the creator of the universe. Whilst this doesn't refute the argument itself it does cast some doubt on William Lane Craigs use of it especially given that Craig himself admits that he doesn't believe in God because of this argument but because of personal experience and the revelation of scripture.

Thirdly, A close examination of of the premises reveals a number of logical fallacies:

Special Pleading: The argument attempts to avoid the question of gods origins with the words "Everything That Begins To Exist" without justifying why god should be exempt from the laws of causality that are then invoked to argue that everything else that exists must have been created by god. 

Equivocation Fallacy: The KCA posits that the universe was created Ex Nihilo (out of nothing). This is not how everything we see around us came into being. The world around us is created Ex Materia (out of matter) in a logical chain of events involving a causal agent, some acted upon 'stuff' and a resulting event. In other words, every example we have of creation (except the afore-mentioned quantum events) is one of matter being reconfigured into different matter, not popping into existence fully formed. The universe is the only example of something truly "beginning to exist" from a previous state of nothingness, leaving no inductive support for the premise that "whatever begins to exist (Ex Nihilo) has a cause". 

Taking account of this the argument should be reformulated thus:


Everything that begins to exist Ex Materia has a cause.
The universe began to exist Ex Nihilo
Therefore the universe has a cause.


The argument is obviously invalid and can be discarded

Composition Fallacy Taken from Dan Barkers article 'Cosmological Kalamity'


  The first premise refers to every "thing," and the second premise treats the "universe as if it were a member of the set of "things." But since a set should not be considered a member of itself, the cosmological argument is comparing apples and oranges.


We describe the the way physical objects behave within the universe by relying on induction and the laws of physics, neither of which can apply in the absence of a universe. It is a fallacy of composition to assert that the individual elements of a thing possess the attributes of a thing. A computer is good at calculations. this does not mean that every component of a computer is good at calculations. Your power supply cannot add up your bank balance.

Finally, even if we accept all its premises, the KCA does not allow for the possibility of another cause for the universe such as a natural process or a non-divine intelligence.
Given all this one must conclude that the KCA is not a sound or valid argument for the existence of god.

Sources:
www.reasonablefaith.org
www.wikipedia.org
wiki.ironchariots.org
infidels.org

For another deconstruction of WLCs use of Kalam I recommend the YouTube channel Theoretical Bullshit. TBS has an entire playlist devoted to Craig and has managed to reformulate Kalam to disprove the existence of God.
The recognition notion is inherently Hegelian in its origin. Mostly googling "Isaiah Berlin Hegel recognition" but filtering the results a little bit, I would recommend reviewing the following if you want to see how the idea has worked out in relation to Berlin himself:

(1) http://plato.stanford.edu/entries/berlin/ SEP Entry on Isaiah Berlin  

(2) http://books.google.co.jp/books?id=qO3tLxWOGncC&pg=PA71&lpg=PA71&dq=isaiah%20berlin%20hegel%20recognition&source=bl&ots=TDQ5keeP-q&sig=74Qwa3jxJUqq0rrRCBBsRFtREBA&hl=en&sa=X&ei=g_3tU_j4D9Lh8AWn6YCYCw&ved=0CCsQ6AEwAzgK#v=onepage&q=isaiah%20berlin%20hegel%20recognition&f=false Isaiah Berlin: Liberty, Pluarlism, and Liberalism esp. on pages 70-72

(3) Isaiah Berlin and the Politics of Freedom: ‘Two Concepts of Liberty’ 50 ... - the chapter on "Social Selves" should be on topic [if it isn't then something is amiss]

The work Axel Honneth also seems to be centrally on a politics of recognition as it relates to Isaiah Berlin. See http://faculty.fordham.edu/jeflynn/Flynn_Review_Honneth.pdf http://faculty.fordham.edu/jeflynn/Flynn_Review_Honneth.pdf .



If you want to understand the basis more generally, I would recommend studying Hegel specifically the much-misunderstood master-slave dialectic and its resoultion.
Here are a few other things to checkout, mostly not at all modern:


http://classics.mit.edu/Aristotle/rhetoric.html Aristotle's Rhetoric is one obvious example on the subject itself.
Other works of Cicero, while perhaps not addressing oration in the content, are themselves considered useful examples of oration. See http://en.wikipedia.org/wiki/Pro_Archia_Poeta Pro Archia Poeta as an example. The Wikipedia article discusses (and I've seen other similar discussions in introductions to book versions that concur) how the speech is structured.
Augustine was trained as a rhetorician before his conversion, so addresses rhetoric and oratory in some of his works. I'm not sure of any work that addresses rhetoric at length itself, but he discusses his education in Rhetoric in The Confessions and in all his works follows similar patterns based on his earlier training. He studied Cicero extensively and states explicitly that Cicero was an influence on him, so any of his writings are going to have a rhetorical style similar to Cicero's.
The speeches in Thucydides might also be interesting. He doesn't write anything theoretical about rhetoric, but he says himself that the speeches are largely what the speakers should have said, and so in that sense are an applied guide to oration.
A list of more http://en.wikipedia.org/wiki/Rhetoric#Notable_modern_theorists modern theorists of rhetoric, Wikipedia has a list. I can't say I've read any of them though.



  Chaim Perelman was a philosopher of law, who studied, taught, and lived most of his life in Brussels. He was among the most important argumentation theorists of the 20th century. His chief work is the Traité de l'argumentation - la nouvelle rhétorique (1958), with Lucie Olbrechts-Tyteca, which was translated into English as The New Rhetoric: A Treatise on Argumentation, by John Wilkinson and Purcell Weaver (1969). Perelman and Olbrechts-Tyteca move rhetoric from the periphery to the center of argumentation theory. Among their most influential concepts are "dissociation," "the universal audience," "quasi-logical argument," and "presence."
  
  Kenneth Burke was a rhetorical theorist, philosopher, and poet. Many of his works are central to modern rhetorical theory: A Rhetoric of Motives (1950), A Grammar of Motives (1945), Language as Symbolic Action (1966), and Counterstatement (1931). Among his influential concepts are "identification," "consubstantiality," and the "dramatistic pentad." He described rhetoric as "the use of language as a symbolic means of inducing cooperation in beings that by nature respond to symbols." In relation to Aristotle's theory, Aristotle was more interested in constructing rhetoric, while Burke was interested in "debunking" it.
  
  Edwin Black was a rhetorical critic best known for his book Rhetorical Criticism: A Study in Method (1965) in which he criticized the dominant "neo-Aristotelian" tradition in American rhetorical criticism as having little in common with Aristotle "besides some recurrent topics of discussion and a vaguely derivative view of rhetorical discourse." Furthermore, he contended, because rhetorical scholars had been focusing primarily on Aristotelian logical forms they often overlooked important, alternative types of discourse. He also published several highly influential essays including: "Secrecy and Disclosure as Rhetorical Forms.", "The Second Persona," and "A Note on Theory and Practice in Rhetorical Criticism."
  
  Marshall McLuhan was a media theorist whose theories and whose choice of objects of study are important to the study of rhetoric. McLuhan's famous dictum "the medium is the message" highlights the significance of the medium itself. No other scholar of the history and theory of rhetoric was as widely publicized in the 20th century as McLuhan.
  
  I.A. Richards was a literary critic and rhetorician. His The Philosophy of Rhetoric is an important text in modern rhetorical theory. In this work, he defined rhetoric as "a study of misunderstandings and its remedies," and introduced the influential concepts tenor and vehicle to describe the components of a metaphor—the main idea and the concept to which it is compared.
  The Groupe µ. This interdisciplinary team has contributed to the renovation of the elocutio in the context of poetics and modern linguistics, significantly with Rhétorique générale (1970; translated into English as A General Rhetoric, by Paul B. Burrell et Edgar M. Slotkin, Johns Hopkins University Press, 1981) and Rhétorique de la poésie (1977).
  
  Stephen Toulmin was a philosopher whose models of argumentation have had great influence on modern rhetorical theory. His Uses of Argument is an important text in modern rhetorical theory and argumentation theory.
  
  Richard E. Vatz is a rhetorician responsible for the salience-agenda/meaning-spin conceptualization of rhetoric, later revised (2014) to an "agenda-spin" model, a conceptualization which emphasizes persuader responsibility for the agenda and spin he/she creates. His theory is notable for its agent-focused perspective, articulated in The Only Authentic Book of Persuasion (Kendall Hunt), derived from the Summer, 1973 Philosophy and Rhetoric article, "The Myth of the Rhetorical Situation."
  
  Richard M. Weaver was a rhetorical and cultural critic well known for his contributions to the new conservatism. He focused on the ethical implications or rhetoric and his ideas can be seen in "Language is Sermonic" and "The Ethics of Rhetoric." According to Weaver there are four types of argument, and through the argument a person habitually uses the critic can see the rhetorician's worldview. Those who prefer the argument from genus or definition are idealists. Those who argue from similitude see the connectedness between things and are used by poets and religious individuals. The argument from consequence sees a cause and effect relationship. Finally the argument from circumstance considers the particulars of a situation and is an argument preferred by liberals.

It sounds like you're referring to the "Law of Cause and Effect," which tells us that every material effect has a prior cause.  I counter that your question is an example of special pleading, suggesting that everything requires a cause, except for this super special uncaused cause which started everything.

Either every "cause requires a cause" or "not every cause requires a cause."  Either all causes were caused by a prior event, meaning the uni-multi-ultraverse model you propose is perpetual, or not every cause requires a prior cause which means there is no need for a special snowflake "initial cause" needing to "choose" to start things off.

Anyway, modern science (and the Law of Cause and Effect) only offer models for how reality operates in our present universe.  As such, it does not (necessarily) apply before our universe existed, and may not have even applied during the initial moments after the big bang.  

Our scientific models of the universe do not speak to how things worked before the big bang, and currently the only thing we know about things before planck time are that things certainly did NOT operate according to the same rules (http://hyperphysics.phy-astr.gsu.edu/hbase/astro/planck.html http://hyperphysics.phy-astr.gsu.edu/hbase/astro/planck.html).
This is a pretty broad question.  I'm just going to do a brief overview for that reason.

Say you're at Diagon Alley and your tummy is making the rumbles that only Bertie Bott's Every Flavored Beans can satisfy.  Since you're a wizard (in this example) you can throw on your invisibility cloak and take some without paying, or you can plunk down some hard earned cashmoney.

Well, chances are however you make your cashmoney, you'd rather do less of that, and eat more beans, so all things considered, you'd certainly prefer not to pay.  However, you may choose to pay anyway.

What was that?

Choose?

Oh, so there is a choice.

Granted, every choice is informed by past action.  There's no denying that.  However, whenever evaluating input to determine output, we must always make a choice.  And this choices affect what additional inputs we receive and so on.

Well, at some point, we hadn't really received much input yet.  Then the worst thing happened and we were born, and we immediately gained agency and were able to affect our surroundings, even if only in the slightest from the beginning.

So to me, our responsibility for our actions is seated with not just an individual actions, but the path through life we have chosen for ourselves and who we have decided, either intentional or unintentionally, to be.

So in that extent, we are fully responsible for our actions, as we have more control over them than anyone and even, to some extent, chose our culture and environment.  Certainly, other people can influence us, and change our mental state, but in the end everything is our own internal choice.

==================================================================================

Wait a minute.  Turing Hypothesis.  Everything computable in nature is computable by a Turing Machine, which means you're computable by a Turing Machine, and Turing Machines are deterministic.  That means all your choices could reasonably be determined at any time given sufficient information about the present state and computing power (in practice, the uncertainty principle prevents this but can have a divine agent build the machine for purposes of philosophy).  So while you are making choices, they're really determined by all the bits and bytes or tapes and symbols or dendrites and axons and you're just along for the ride.

==================================================================================

Well, you get to decide whether determinism and free will are compatible or not as there doesn't seem to be any great degree of consensus on that issue.  I hold that all individuals are completely responsible for their actions because they are the only agents that pass the final decision on their own actions so all responsibility rests with them.  To me, it doesn't matter whether this decision is deterministic or not.

Good luck.
I generally take characters on shows to be a different instance of the same person, that is, the name doesn't matter, but in the context of the show the actor is that same actor but in the context of the parallel universe developed for the show.

Let's use object orientated because that is freakishly easy notation for this problem.

(Consensus Reality).(Wil Wheaton) portrays (The Big Bang Theory).(Wil Wheaton).

So if someone asked me what character Wil Wheaton plays in the The Big Bang Theory, I would say "He plays Wil Wheaton" which is the verbal representation of the statement above in OO notation because context is reasonably clear from the discussion.

For example, my name is Calvin.  Moreover, the protagonist of my perception of reality is Calvin.  So I have two Calvins.

(Consensus Reality).Calvin and (Calvin's Perception).Calvin.

In Consensus Reality, Calvin is portrayed by the same Calvin as in Calvin's Perception, so I would say that the credits of Consensus Reality could list Calvin as played by himself.

However, there are certain differences.  For example, (Calvin's Perception).Calvin was not born, but just slowly emerged into consciousness over time (due to the nature of memory).  However, this difference can be reconciled by viewing these different Calvins as different instances of the same Calvin across multiple abstractions of reality.

Or at least, that makes sense to me.
It seems to me that the quote from Rilke is quite consonant with a Platonic understanding of Beauty.  If we recall, Plato believed that our earthly existence is a pale imitation of a deeper Reality. In the quote Rilke is picturing a direct encounter with creatures more Real than he is, the Beautiful angels.  

His terror stems from the conviction that his own lesser reality will melt away and vanish as as result of the encounter, as the shadow is destroyed by the light.  His larger claim is that our perception of beauty is intimately tied together with the terror of an encounter with the Real, a terror tempered only by our understanding that the Beautiful has no intent to destroy us.

This conception of beauty is probably closer to the Kantian or the Aristotelian "Sublime" than the Kantian or the Aristotelian "Beauty" --it would seem that Rilke views Beauty only as a safer, less immediately dangerous variant of the Sublime.
There seem to be several questions here, I'll address the first and second:  

I'm not a Deleuze scholar but his claim seems fairly clear from the quote.  In the Greek system, according to D, when people commit crimes, the blame is shifted to the gods.  In Christian belief, on the other hand, people are responsible for their own sins, but Jesus takes the punishment for those upon Himself, although blameless.  

D is indeed drawing parallels between the systems, but he nevertheless does consider this itself to be a psychologically significant shift.  To provide a simplified gloss of his claims: In the Greek system, you bear the punishment, which is the consequence of your crime, but you don't bear the guilt.  In the Christian system, you bear the guilt, which is the consequence of your sin, but not the punishment.  The crime is something that you do, an event that happens.  Sin is something that comes from within you, an intrinsic flaw in your nature.

I won't venture to evaluate whether he is correctly evaluating the Greeks, the Christians or Nietzsche, but I do think this at least represents a reasonable distillation of the provided quotes.
Lewis Carroll's puzzle first appeared in the April 1895 issue of Mind. It directly influenced the formulation of the first primitive proposition of Whitehead & Russell's Principia Mathematica.

This puzzle exposes the difference between implication and inference: an implication only tells you what follows your premise, but does not tell you whether your premise is true; an inference tells you what you can infer from a true proposition.

The reader of the second kind needs a hypothetical to enable her or him to infer (not just imply) Z from A and B. The hypothetical is Modus Ponens. Regression happens because Modus Ponens is presented in a wrong form:


  IF P and (IF P Then Q) Then Q


It uses If-Then in the place of "therefore," thus both P and (If P Then Q) are presented in a hypothetical form. Regardless P or (IF P Then Q) is true or not, the implication (the outer IF-THEN statement) is always true, e.g. "if pigs fly then I am pope" is always true. Since an implication asserts neither the premise nor the conclusion, an endless regression will never reach Q's assertion.

The correct form of Modus Ponens should be like this:

If P Then Q
P
Therefore Q


Notice when "THEREFORE" replaces the outer IF-THEN, Q will not be asserted unless both P and (IF P Then Q) are really true. "THEREFORE" should be used only for inferences made from true proposition to true proposition.

In Whitehead & Russell's Principia Mathematica, Modus Ponens is presented in the form of ✳1.1 and ✳ 1.11. Both are primitive propositions, i.e. undemonstrated propositions.

✳1.1.  Anything implied by true elementary proposition is true. Pp.

✳1.11. When ϕx can be asserted, where x is a real variable, and  ϕ(x) implies Ψ(x) can be asserted, where x is a real variable, then Ψ(x) can be asserted, where x is a real variable.

Notice the absence of hypothesis.
The question seems to be worried in a somewhat inflammatory way, so I'm going to answer it in somewhat less inflammatory terms. Also, while it sounds like philosophy of religion because of the figures you picked, this is primarily just a matter of logic. Let's divide the question into different cases.

Question 1: Would two people making opposite truth claims necessarily be a contradiction?

The answer to this question is yes. 

If Person A and Person B take the positions P and not P regarding the exact same claim  then at least one of them is wrong per the law of non-contradiction. (I will leave living outside the laws of non-contradiction as an exercise for the reader). 

So if A says that person C ate a banana for breakfast on July 12, 2014 and person B refers to the same Person C and says they did not eat a banana for breakfast on July 12, 2014 then at least one of them is wrong.

**Claims:**
A: P
B: not P.
--> P and not P (= contradiction)


Question 2: Would two people claiming another person told them something where the two are told different things necessarily be a contradiction?

The answer to this question is not necessarily. The reason is simple. Let's say Person A tells you that Person C told them they ate a banana for breakfast on July 12. Let's say Person B tells us that Person C told them they did not eat a banana for breakfast on July 12. This is not a contradiction because what they are saying is not the same thing. A is reporting what they C told A. B is reporting what C told B. 

**Claims:**
P: banana breakfast
A: Q [ C told me P]
B: R [ C told me not P]
--> Q and R 


Now, we need some means of unpacking Q and R to figure out whether this is (a) a contradiction, (b) a misunderstanding, or (c) that C is a liar.

In the banana case, we must conclude at a minimum, that either A, B, or C lied at least once. Because if we took all testimony as factive we would have: P and not P. So either C's utterance to A or A's recounting or C's utterance to B or B's recounting is false. But this or is not exclusive, everyone could be lying.

If Q and R turn out to be non-contradictory claims, we could still have but do not necessarily have lying going on. Say Q and R are about different years.

Question 3: if two people receive orders from the same person to do different things is that somehow contradictory?

Here, we need to refer to case 2, but we're left even further from the likelihood of a contradiction. Why? Because claim Q is now A says C told me [A] to do X and R is now B says C told me [B] to do Y.

A or B or C could still be lying, but now there's no logical set that makes the contradictory if all of them are telling the truth. 

To make a contradiction, we would need to show that the content of X and Y are contradictory in a rather strong sense. Ex. that is not contradictory: A says that C told him to sweep the floor. B says that C told her to ignore the floor. Clearly not contradictory.  Ex. that might be contradictory: A says that C said to exterminate people with glasses. B says that C says to send people with glasses to safety. C might be pretty twisted but is not necessarily being contradictory.

The following relevant type seems to belong here:


  Case 3 Terms
  
  A: C told me to tell M that Q.
  
  B: D told me to tell N that R.


To show them contradictory there's a lot of leg work that would need to happen to show that Q and R are inconsistent a way strong enough to warrant that being contrary (so "plant in spring" and "harvest in fall" types of differences won't come into play). That M and N are relevantly similar groups to be being asked to behave in contradictory ways. That C and D are sufficiently identical entities, and that A and B are not the parties causing the transmission error.

Question 4: Mohammed and Jesus

I am not that familiar with Islam, so I can't directly address every detail of how Muslims understand this working out. But from what I gather Muslims read the statements of Jesus to have different meaning such that if they were to contradict Islam Jesus never said them. Thus, Jesus's claims to divinity are rejected by Muslims. So  So if Jesus is B, then the claim is that B never said those things. 

In other words, look at our case 3 terms, let's say the claims in Islam involve A, C, M, Q and those in Christianity B, D, N, R. They accept an identity between C and D counting Jesus as a prophet. They accept some differences between M and N. In cases where R would contradict Q, they reject that B ever said that.

For Christians, I generally take it that the identity of C with D is questioned. So it's kind of irrelevant what C told A to tell M, because the claims are not accepted as truly from God.

tl;dr

The sort of contradiction you claim never happens because the groups resolve around those claims in differing ways.

The claims at are not simply contradictory as in P and not P. But rather involving A says that C said to A to tell to M message Q. Sure, they can't both be true, but that would only be a problem for someone who has already accepted the truth of A's claims about being spoken to by C to tell to M message Q and B's claims about being spoken to by D to tell to N message R. But there's no requirement in either religion to accept the entire set of claims made in the other religion. 
Hint : Type corresponds to concept. Token corresponds to instance or example.

Thus, species is a type while human is a token.

Try to form a proposition about species that uses two different tokens.
Chomsky defended his notion of a universal grammar in the human subject on two grounds; first that linguistic analysis tends to show structural affinities across widely separated languages;  secondly that children learnt language from a minute number of fragmentary sentences (think of the massive case training by typical neural networks for natural language learning.

This theory of an inate potentia of language in a subject attacked the then prevalent theory by Skinner, which was an aspect of his behaviouralist paradigm (he denied the subject in the human subject), and determined language acquisition purely environmentally.

In Platos Meno, Socrates expounds on his theory of http://en.wikipedia.org/wiki/Anamnesis_(philosophy) anamnesis:


  He suggests that the soul is immortal, and repeatedly incarnated; knowledge is actually in the soul from eternity (86b), but each time the soul is incarnated its knowledge is forgotten in the trauma of birth. What one perceives to be learning, then, is actually the recovery of what one has forgotten. 


This is illustrated by:


  Socrates asking a slave boy questions about geometry. At first the boy gives the wrong answer; when this is pointed out to him, he is puzzled, but by asking questions Socrates is able to help him to reach the true answer. This is intended to show that, as the boy wasn't told the answer, he could only have reached the truth by recollecting what he had already known but forgotten.


Using Aristotles terminology - in this picture we already know language in potentia (or dunamis) but only becomes language in actualite (or energia) when expressed in the world, and by the world (the world as  a midwife).

Finally thinking of grammar as a kind of formal logic; the same is likely for logic; and then the same for critical thinking.
The Platonic realm exists in the Platonic sense because it has been clearly conceived of as Platonic object, itself.  "The realm of ideas" is just the idea of the collection of all ideas, which one automatically has if one has ideas and then expresses ideas about the nature of ideas.  The question is whether the way that idea exists qualifies as existence.

The question is akin to asking whether the word 'definition' has a definition.  Of course it does.  But if you did not already know what a definition was, how could that one define anything?

Similarly this all 'exists' if our definition of existing is as naive as the notion of defining has to be to someone who would write a definition of 'definition' as the first entry in a lexicon.  But criticism at that level of naivete is just bullying, not thought.

We have to work into that definition from the outside, and we have no choice but to start from a naive idea of definition, or of idea.  To force later problematic results back onto the original consideration is just circular.  We have ideas, whether we want to or not.  So 'how do we gain access to ideas' is not a real question, unless it is about the process of realization, rather than about access.

For me, the argument for 'not cutting' this concept out of our thought is that this mode of thought is inescapable.  It is the one we fall into with the habits of childhood, which is how most of us approach most problems we meet fresh.  We need more sophisticated ways of reigning in childish impulses, but we should not lose them, as they are the basis of our thinking, and always will be.
Think of "Knight" true and "Knave" as false. Then expand by considering that what each person says is a type of conditional. i.e., if Albert is a knight than what he says is true. If he's a knave, then it's false.

This will give you the following translations:

1. A -> (B & ~C)
2. B -> ((A & B) v (A & C) v (B & C))
3. C -> (A & B)


For (a), we begin by adding 

4. | C  Assumption that C is  knight [i.e., not a knave]
5. | A & B MP 4,3 
6. | A &E 5
7. | B & ~C MP 1,6
8. | ~C  &E7
9. | C & ~C = Contradiction
10 ~C Contradiction Elimination 4-9


For (b), we are trying to prove (A &B) v (~A & ~B). This one is a little tougher to crack, because we want a disjunction as a conclusion. We can get this if we can prove either half or if we can prove something else that is incoherent and turn into the two halves. Here it is quite helpful to know that Carla is a knave, because that means we can use that in conjunction with 2.
I don't think this is an answer, but its a long series of comments. TLDR; there are many more considerations to the problem of evil than you seem to address.

You've missed a key element of Leibniz's theodicy, and in a way that seems to grossly distort his thought. God creates the best of all possible worlds, yes, but this is not to say that there is some existing catalogue of possible worlds from which God chose the best one. Such an account doesn't really obviate the problem of evil; it simply denies that God is omnipotent (since he---apparently---couldn't create world without evil). Leibniz's actual view rely on a certain form of teleology: the best possible world is a world that contains suffering because (for whatever reason) it allows for a more full expression of good than would be possible in a world in which there is no suffering (thus, for example, his Discourse on Metaphysics §3). This comes quite close to what you outline as the first interpretation of Augustine's view, and is actually quite a classical argument traceable back to at least Plato and---possibly, depending on how one understands him---Heraclitus.

Incidentally, Augustinian theodicy (whether or not this qualifies as the original Christian theodicy---and I'd hesitate to assert that!) certainly depends on freedom of the will. For freedom of the will is what allows man to withdraw from God and so to create the possibility of evil. Whatever you may think of the notion of evil as the privation of good, it seems irresponsible to dismiss this view out of hand, for it ties back directly to the heart of the question: is the existence of evil (which very few deny) contrary to the existence of God? If evil is created by some means that God (for whatever reason) places beyond his control, can he be blamed for it? I don't mean to rhetorically suggest that the answer to this question is "no"; it cannot be denied, however, that it is a question that deserves consideration---for if God is blameless in the existence of evil, then no amount of evil would seem to contradict the existence of God.

Scholastic Christian thought has tended to argue that one can regard God as not being "good" in our sense without thereby asserting that God is evil, immoral, or does anything other than what is good. God's goodness is taken to be not a different goodness from our own, but more perfect, and so occasionally manifesting itself in forms that seem to us evil. God can appear to be immoral, according to human standards, but this is due to our finite inability to grasp the infinite goodness at work. This is why Aquinas and other's speak of humans as participating in the goodness of God, albeit to greater and lesser degrees of perfection; no one can attain the goodness of God, but one can approximate it. In this sense, morality isn't strictly redefined, since the same good is there for God as for humans, it is just that God is fully able to realise this good, while human beings are not.

There may be something you find unpalatable in such answers, but surely that is not sufficient to reject an argument?

Another way, perhaps with some similarities and overlap, can be found, for example, in the Bereshith Rabbah:


  R. Simon said: When the Holy One, blessed be He, came to create Adam, the ministering angels formed themselves into groups and parties, some of them saying, 'Let him be created' whilst others urged, 'Let him not be created' Thus it is written, Love and Truth fought together. Righteousness and Peace combated each other (Ps. LXXXV, 11): Love said, 'Let him be created, because he will dispense acts of love'; Truth said, 'Let him not be created, because he is compounded of falsehood'; Righteousness said, 'Let him be created, because he will perform righteous deeds ; Peace said, 'Let him not be created, because he is full of strife' What did the Lord do? He took Truth and cast it to the ground. Said the ministering angels before the Holy One, blessed be He, 'Sovereign of the Universe! Why dost Thou despise Thy seal? Let Truth arise from the earth!' Hence it is written, Let truth spring up from the earth (ib. 12).
  
  All our Rabbis say the following in the name of R. Hanina, while R. Phinehas and R. Hilkiah say it in the name of R. Simon: Me'od (E.V. 'very') is identical with Adam as it is written And God saw everything that He had made, and, behold, it was good---me'od (Gen. I, 31), i.e. and behold Adam was good. R. Huna the Elder of Sepphoris, said : While the ministering angels were arguing with each other and disputing with each other, the Holy One, blessed be He, created him. Said He to them: 'What can ye avail? Man has already been made!'
  
  Bereshith VIII.5


There are many ways of interpreting this text, and a great many voices at work in it. And yet, the underlying conviction through it all is that God acts according to what he sees as right, not because he has his own version of right different from another version of right, but because he can see all the various sides that created creatures cannot.

Again a similar reading can be offered of God's famous response to Job from Job 38:

Then the Lord answered Job out of the whirlwind:

“Who is this that darkens counsel by words without knowledge?
Gird up your loins like a man,
    I will question you, and you shall declare to me.
“Where were you when I laid the foundation of the earth?
    Tell me, if you have understanding.
Who determined its measurements—surely you know!
    Or who stretched the line upon it?
On what were its bases sunk,
    or who laid its cornerstone
when the morning stars sang together
    and all the heavenly beings shouted for joy?
“Or who shut in the sea with doors
    when it burst out from the womb?—
when I made the clouds its garment,
    and thick darkness its swaddling band,
and prescribed bounds for it,
    and set bars and doors,
and said, ‘Thus far shall you come, and no farther,
    and here shall your proud waves be stopped’?
“Have you commanded the morning since your days began,
    and caused the dawn to know its place,
so that it might take hold of the skirts of the earth,
    and the wicked be shaken out of it?
It is changed like clay under the seal,
    and it is dyed like a garment.
Light is withheld from the wicked,
    and their uplifted arm is broken.
“Have you entered into the springs of the sea,
    or walked in the recesses of the deep?
Have the gates of death been revealed to you,
    or have you seen the gates of deep darkness?
Have you comprehended the expanse of the earth?
    Declare, if you know all this.
“Where is the way to the dwelling of light,
    and where is the place of darkness,
that you may take it to its territory
    and that you may discern the paths to its home?
Surely you know, for you were born then,
    and the number of your days is great!
“Have you entered the storehouses of the snow,
    or have you seen the storehouses of the hail,
which I have reserved for the time of trouble,
    for the day of battle and war?
What is the way to the place where the light is distributed,
    or where the east wind is scattered upon the earth?
“Who has cut a channel for the torrents of rain,
    and a way for the thunderbolt,
to bring rain on a land where no one lives,
    on the desert, which is empty of human life,
to satisfy the waste and desolate land,
    and to make the ground put forth grass?
“Has the rain a father,
    or who has begotten the drops of dew?
From whose womb did the ice come forth,
    and who has given birth to the hoarfrost of heaven?
The waters become hard like stone,
    and the face of the deep is frozen.
“Can you bind the chains of the Pleiades,
    or loose the cords of Orion?
Can you lead forth the Mazzaroth in their season,
    or can you guide the Bear with its children?
Do you know the ordinances of the heavens?
    Can you establish their rule on the earth?
“Can you lift up your voice to the clouds,
    so that a flood of waters may cover you?
Can you send forth lightnings, so that they may go
    and say to you, ‘Here we are’?
Who has put wisdom in the inward parts,
    or given understanding to the mind?
Who has the wisdom to number the clouds?
    Or who can tilt the waterskins of the heavens,
when the dust runs into a mass
    and the clods cling together?
“Can you hunt the prey for the lion,
    or satisfy the appetite of the young lions,
when they crouch in their dens,
    or lie in wait in their covert?
Who provides for the raven its prey,
    when its young ones cry to God,
    and wander about for lack of food?


These latter two, of course, rely heavily on the inscrutable will of God, which you may not find a palatable answer. It is, nevertheless, an answer that some people have found sufficient.

More formally the problem of evil could be formulated thus (unapologetically stolen from http://plato.stanford.edu/entries/evil/ The Stanford Encyclopedia of Philosophy):


If God exists, then God is omnipotent, omniscient, and morally perfect.
If God is omnipotent, then God has the power to eliminate all evil.
If God is omniscient, then God knows when evil exists.
If God is morally perfect, then God has the desire to eliminate all evil.
Evil exists.
If evil exists and God exists, then either God doesn't have the power to eliminate all evil, or doesn't know when evil exists, or doesn't have the desire to eliminate all evil.
Therefore, God doesn't exist


It has therefore been assumed that one can resolve this problem not merely by claiming either that god is not morally perfect or not omnipotent, but that God may not be omniscient. For it would seem that if any of those three qualities is denied, the proof given above fails, and all three have been denied by various people endorsing various different doctrines.

To get at the broader question: is there a satisfactory answer to the problem of evil? For myself, I'm inclined to invoke Protagoras: "Concerning the gods, I have no means of knowing whether they exist or not, nor of what sort they may be, because of the obscurity of the subject, and the brevity of human life."
Geirsson and Losonsky, in http://chrome-extension://ecnphlgnajanjnkcmbpancdjoidceilk/content/web/viewer.html?file=http%3A%2F%2Fwww.public.iastate.edu%2F~geirsson%2Fpdf%2FPlantinga%2520and%2520the%2520Problem%2520of%2520Evil%2C%2520World%2520Congress.pdf Plantinga and the Problem of Evil (from your "P.S." statement) fail at least two ways in attempting to address Plantinga's argument:


Counter-Factuals (CFs) are possible actions.  But all possible actions are not guaranteed to be actualizable actions.
They miss a piece of Plantinga's argument which they even quote: ".. he will take at least one wrong action"


For those who don't wish to read all of Plantinga's argument and the response from Geirsson and Losonsky, the particular passage I refer to here is regarding an example from Plantinga in which a person with free will, Curley, is presented with an opportunity to accept a bribe, and he accepts.  This is considered a moral failing (evil in the world) by Plantinga, but you could substitute any other moral failing or free will action that you believe brings evil into the world.



Point 1: Counter-Factual Actualization

Regarding possible worlds and CF actualization: both your question and Geirsson and Losonsky are assuming that all CFs are actualizable.  In other words, there is an assumption in the argument against Plantinga that there is at least one possible world where all CF possibilities could actually occur.

Consider Plantinga's example of Curley and whether or not he will accept the bribe: Plantinga is stating that a weakly actualized world in which Curley is presented with the same opportunity to accept the bribe will result in Curley always accepting the bribe.  That is the free will choice that he makes, as a morally free agent.  He calculates the moral situation and chooses wrong.  Presented with the same circumstances and the same ability to freely choose between good and evil in this particular situation, he will always choose evil and accept the bribe.  Free will doesn't mean we can willy-nilly choose a random action from among those that are available.  It simply makes us the agent that does the choosing between the right and the wrong way without compulsion to choose one or the other by circumstance or God forcing our hand.  It doesn't mean that given the same circumstances in another possible world that we would choose differently! If we did, that would make us a different person - a different moral actor.

While there is a possible CF action where Curley does not accept the bribe, Plantinga's argument relies on the fact that Curley, given the same circumstance, will always accept the bribe - his will/nature does not and won't change unless his free will is destroyed through strong actualization. 

Edit: Plantinga's word for this is "Essence". Curley's Essence leads him to make the free will choice of always accepting the bribe in that circumstance. "Essence" is distinguished from "Person" as explained here: http://christianapologeticsalliance.com/2013/08/22/alvin-plantingas-free-will-defense/ Alvin Plantinga's Free Will Defense

Therefore, while there is a possible CF action, there is not a realizable CF action. The only way of obtaining a possible world where Curley does not accept the bribe, according to Plantinga's argument, is for God to strongly actualize a world with the circumstance's changed in a way which removes Curley's freedom of action to the point that God has, in reality, removed Curley's free moral choice, his free will.  God must either not allow him to choose by removing the circumstance so there is no choice, or God must directly force him to choose differently.

The long and the short of it is, that according to Plantinga's argument, there is no possible world where Curley both has free moral agency, and does not take the bribe, due to Curley's nature.  Now, there are plenty of people other then Curley, who put in the same circumstance, will not take the bribe.  So there are possible worlds where we can find a person with free will who will not take the bribe - I will address this in the second point, but for the first point, we are only dealing with Curley, and his free will choice, given Plantinga's example, is that with the circumstances placed before him, his free will choice is to take the bribe.  No CFs exist that can be actualized in another possible world for Curley, in particular, where he does not take the bribe, without God changing the circumstances in a way that does violence to his free will choice.

In order to find a possible world where Curley does not take the bribe, you must remove his free moral agency - you must change his nature, his will, so that he no longer desires the same outcome from the situation.  Such a possible world does not exist while keeping his free will intact.

The only other option is for God to not create Curley. For than, see point 2.



Point 2: ".. he will take at least one wrong action"

The second point is that Plantinga doesn't require for a free will agent to take the bribe in the given scenario in order for them to be Transworld Depraved (TD).  While we know that Curley is TD because he does (and always will) accept that bribe given the same circumstance, but that doesn't mean that all moral agents must also accept this same bribe to be TD. After all, if every moral agent only accepted the bribe, then it would be easy to argue that free will didn't truly exist.

But Plantinga doesn't require that every moral agent accept the bribe, given the same circumstances.  Plantinga only requires that any given moral agent must take at least one wrong action to be TD (quoted from the end of his example).

God could choose to actualize a world without Curley, because God knows that Curley will bring evil into the world by accepting the bribe. He can certainly find a possible world with free moral agents other than Curley who will not accept the bribe. The key, though is that if these other actors fail morally in any other choice, then they also will be TD. To pull this off and create a world with both free will and no evil, he needs to find a world with moral actors that won't choose any wrong action. Plantinga's argument only requires that any given free will moral actor fail on one possible moral choice for them to be TD.

So, let's take Mary, who chooses the good and does not accept the bribe.  That only shows that it is possible that she is not TD.  It does not prove that she is not TD.  We must put every other possible situation in front of her, and if she fails morally at one of them, then she has taken (or would take) at least one wrong action, and is TD.  Plantinga's argument only requires the possibility that all moral actors are TD.  To defeat his argument, it would have to be proven that this is not possible - that there must be a possible world where there are free moral agents will not undertake a single wrong moral action.

I actually believe that Plantinga's defense would stand up even if it can just be shown that a single moral actor would always choose wrong; but it is a stronger argument if it remains a possibility that all moral actors must be TD.



Bonus Point: Time Segmentation?  What the...

The remaining thrust of Geirsson and Losonsky's argument against Plantinga's defense relates to actualizing segment's of time.  While other's appear to have accepted this at its face and addressed this directly (see http://chrome-extension://ecnphlgnajanjnkcmbpancdjoidceilk/content/web/viewer.html?file=https%3A%2F%2Fpeople.ucsc.edu%2F~otte%2Farticles%2Fotte.twd.pdf Transworld Depravity and Unobtainable Worlds by Richard Otte), I believe time segmentation and trying to build a perfect good world is quite irrelevant.  Can we build a world without evil by creating Adam and then ending the world before he sins?  Sure, but that destroys the point completely.  If the point is to defend the God of the Bible (or an all-powerful, all-knowing, always good God who creates man to have a relationship with God, if you prefer), then attempting this time segmentation by cutting the timeline short does violence to God's purpose with respect to creation - to create free moral beings that are truly capable of love and relationship with him. If that is the ultimate good that required free will moral actors to be created, then it should also be a part of the equation.

I understand that in the end the time-segmentation argument is an attempt to string together all the time segments in which only good occurs into a possible world where there is no evil done - but again, that cannot be achieved because it relies on the assumption that all CFs are actualizable for a given moral agent with free will.  This argument explodes because it forces a person to be different then they choose to be in order to have a possible world where they choose differently.  It is just a disguised form of strong actualization - trying to do piecemeal what Plantinga's base argument disallows in its definition of strong actualization.
For starters, I would look at the idea of http://en.wikipedia.org/wiki/Historic_recurrence historical recurrance. As the wikipedia article notes


  Nevertheless, while it is often remarked that "History repeats itself," in cycles of less than cosmological duration this cannot be strictly true.


While not strictly true, there are several examples of philosophers and historians who have made an argument noting the similarity of two situations (first two paraphrased from the article):


Macchievelli noticed "when states have arrived at their greatest perfection, they soon begin to decline."
Thucydides wrote about the Peloponnesian War, "not as an essay which is to win the applause of the moment, but as a possession for all time," because he believed that much about the human condition was stable (i.e., not a random walk)
There is a quote from the Bible: "That which has been is that which will be, And that which has been done is that which will be done. So there is nothing new under the sun." (Ecclesiastes 1:9) which scholars estimate was written between http://en.wikipedia.org/wiki/Ecclesiastes#Composition 450 and 180 BCE.


It seems then that the idea of being in very similar stations (even if not the exact same one) is a common philosophical belief.
Maybe an example will help you: redness is such that necessarily, anything that is red is also colourful. So redness contains colourfulness.
Necessarily means that you cannot conceive of something having the first without also having the second.
I think that the above line of reasoning is very intuitive and attractive. Sticking with the theme of geography, I can only imagine how many words are in the everyday lexicon of a cartographer that you or I would errantly replace with "mountain" or "forest". This example, like the mathematician or the farmer, points to the development of language to describe increasingly technical and specific aspects of the environment as more and more time and energy is spent in that environment.

There is also, of course, a reflection of cultural values in that evermore specific language. We see that often- For English speakers, "cousin" can refer to any number of different relatives. For Mandarin speakers, there are specific terms for the older female cousins on your father's side, as opposed to the younger, male cousins on your mother's side, as opposed to older, male... you get the point. http://kwanfamily.info/culture/familytitles_table.php/ Chinese Familial Titles. That specificity is reflective of specific cultural norms, to some degree. Here though, another language, for example, English, does not lack that specificity, as evidenced by the fact that accurate translations for each of those familial terms, however cumbersome, do exist.

The question, then, is whether or not there are words that describe "snow" in some capacity which cannot be translated. If there are, then the native Inuit language actually has more words for "snow" than another language, say, English does. But, if those great many words describe snow in various capacities, and all of those can be translated, (I.E. Snow (noun), snow (verb), snowdrift/snowbank, wet snow/dry snow, falling snow/fallen snow, heavy snow/medium snow/light snow, etc.)there isn't really an abundance of terms in one language as opposed to the other. One language may consolidate elements of the many phenomena into a like category (snow) but specific terms for any given phenomena can then be created in that language. 

Alternatively, there are words that cannot be translated to English in any understandable way. As philosophy students, we are all familiar with Aufheben, Noumenon and any other number of complex terms which must be borrowed from their native languages and used as such http://matadornetwork.com/abroad/20-awesomely-untranslatable-words-from-around-the-world/ Words that cannot be Translated. If a significant amount of the Inuit words for snow in any given capacity meet this criteria, then we could more comfortable state there is an abundance of terms in one language compared to the other.

Ultimately, a more informed understanding of the Native Inuit language will be necessary to answer this question.
That's the golden question! And, by the course of things, without solution. The answer pressuposes some philosophical background which is practically based on opinion. A good approach to the schools are http://plato.stanford.edu/entries/philosophy-mathematics/ http://plato.stanford.edu/entries/philosophy-mathematics/. I would also recommend the preface to the second edition of https://archive.org/details/principlesofmath005807mbp https://archive.org/details/principlesofmath005807mbp. In choosing a school of thought, don't forget to consider that every theory by it's essence is fallacious; for example, the theory of concatenation has logical circularities by it's own nature, because we use concatenation to approach the theory (a word in english language is a concatenation, and we need some english words to explain the fundamental concepts which can define concatenation). The same thing happens with mathematics. When mathematicians try to define the number 2 they're already using this concept, because the "idea" of two is already present in concepts such as dyadic relations, or english particles with two letters. So, you should focus on the theory that has more practical use and concision. Take intuitionism for example, although it has some very interesting points of view, it couldn't even build up classical analysis, so it isn't very usefull. Russell's logicism, although accepts the notion of universals such as relations and classes, derived all mathematics using only the logic of relations, so it's worth to pay attention to it. Be carefull with what people say about logicism, they tend to be exaggerated, he defined mathematics as logic and logic as mathematics, so his ideas didn't please mathematicians who liked to think of logic as some separated philosophical branch without very much use.

Have a nice day.
Sisela Bok has a few books that try to give non-technical overview of just these concerns about when a general principle of ethics becomes impossible to hold prescriptively, and where the contradictions lead.

One is on lying one is on secrecy and one is on the use of violence as entertainment.  She goes over in detail how general rules break down and how different people have looked at case-wise ethical concerns.

I find them tedious, and only ever got to the middle of the second one.  But her footnotes might point you at someone you find more interesting.
In addition to Russell's and Wittgenstein's analytic philosophy some of the most major influences on modern philosophy, which may perhaps be called breakthroughs, are: 

1) Kant's transcendental method and critique of metaphysics that ended speculations about "intelligible" entities, and our supposed ability to perceive them directly. Transcendental arguments from structure of knowledge to faculties of mind became a frequent part of reasoning in philosophy and cognitive sciences.  

2) Husserl's phenomenology that built on the idea that there is no qualitative gap between sensory perception of material objects and intuition of ideas. Rather they are idealized extremes of the same ability we possess. This positively complemented Kant's critique to a degree. 

3) Existensialism, which goes back to Kirkegaard and Nietzsche, who pointed out that philosophy should draw on life experience as a whole, and that is far broader than rational thought dominating most of the classical philosophy.

4) Hegel's dialectic, a still controversial insight that not just the knowledge itself, but also its relationship to reality, evolve in ways which make traditional static ontologies and epistemologies inadequate. The evolution process is supposed to be universal, and is often likened to a spiral of triads. The original assertion is first "negated", and then "negated" again into a refinement of the original, but at a higher level. No static "final truths" (still retained by Kant, Husserl and existensialists) are available because even the correspondence to reality is itself subject to the dialectic. Hegel's ideas became more famous outside of philosophy due to Marx, who transplanted them into history and politics, where they fed into his theory of social change.

Other influential contributions are structuralism, and Heidegger's hermeneutics, but they are not at the same level as the ones above. Heidegger, for example, creatively combines phenomenology and existensialism to recover some of the lost metaphysics by mitigating the separation between the subject and the object. Structuralism came from developments in linguistics (Saussure) and anthropology (Levi-Strauss) that are similar to earlier mathematization of natural sciences. But the idea that philosophy and science can properly access only relational structures, if that, rather than the essences behind them, goes back to Kant.
you write: 


  He sees a black hat on the man in front of him: His should be able to
  conclude that his hat is white because there is a hat of each color,
  so if the one in front of him is black, his must be white


That is wrong; assuming the first (to answer) prisoner gave the correct answer, the second prisoner can only conclude there can't be two white hats, and since he said he didn't know what color was the hat he was wearing, it implies the prisoner in front was in fact wearing a black hat. 

That is how the prisoner in front knew what color was the hat he was wearing.
I think Dawkins is a little sloppy in explanation here, but his counter-argument, once understood, is devastating.

Firstly, he notes in passing that these arguments assume that there must be a "first cause". This is not readily apparent. We could live in a universe that has existed forever, or a universe that exists within some greater structure which creates and destroys universes in accord with some eternal equilibrium.

Secondly, he attacks the lack of explanation (the "entirely unwarranted assumption") as to why God should somehow be immune from requiring a cause. Implied in this is that if we postulate a first cause, there should be some attempt to address why it itself does not need to be caused by anything.

Thirdly, he attacks the arbitrary assignment of qualities to this "first cause" (such as omniscience, goodness, etc). He seems to attack the "dubious luxury" of having a terminator a little more strongly than is warranted, but as he proceeds it becomes apparent that he's skipping right into the presumption of an intelligent entity, which more than deserves the ridicule. And of course, even if we did assume that some intelligent entity was the "first cause" we would not be able to infer anything of their motives from the simple act of starting everything.

His attack is not so much based on the lack of evidence for the arguments as on the failure of the argumenter to even perceive that evidence is necessary.
You will need to strike a balance. 

If you can't enjoy today, or tomorrow, or they day after that, or the day after that, ... you can't enjoy anything. 

You should think about foreseeable long term consequences of your actions, so that your actions today don't negatively affect your happiness tomorrow. But there are many things that you can't foresee - it's rather pointless to worry about them. And there are things that you can foresee but not change - it's also rather pointless to worry about those things. 

And if you try planning a very long time ahead, be aware that circumstances change. You might do X today so that you get Y in ten years time, knowing that having Y in ten years time will make you happy - and in ten years time, you don't actually care about Y anymore! On the other hand, there might be future things that you don't care about today, but that you care very much about when the future arrives. 

So a short summary: Be happy today. Don't do stupid things by ignoring the future. Don't do stupid things by overthinking the future. Don't let worry about the future make you unhappy today. 
In order to show that the conclusion is not a logical consequence of the premises, we have to find a counter-example, i.e. a "world" were the premsies are ture and the conclusion is not.

After having checked that the two premises are satisfied in the "world" depicted, we can conlude that ¬∃xTet(x) it is not true, simply because there are two tetrahedra.
Explanation of the Mnemonic

Brody, Boruch A. "http://go.galegroup.com/ps/i.do?id=GALE%7CCX3446801188&v=2.1&u=uarizona_main&it=r&p=GVRL&sw=w&asid=038582f15f268e2b9ebdb165daf9d33a Logical Terms, Glossary of." Encyclopedia of Philosophy. Ed. Donald M. Borchert. 2nd ed. Vol. 5. Detroit: Macmillan Reference USA, 2006. 533-560. Gale Virtual Reference Library. Web. 19 May 2016.:


  mnemonic terms
  
  The names that the medieval logicians introduced for the valid syllogisms. One such term is "Barbara." The key for these mnemonics is as follows: The three vowels respectively indicate the three constituent propositions of the syllogism as A, E, I, or O. For first-figure syllogisms the initial consonants are arbitrarily the first four consonants; for the other figures the initial consonants indicate to which of the first-figure syllogisms the syllogism in question may be reduced. Other consonants occurring in second-, third-, and fourth-figure mnemonics indicate the operation that must be performed on the proposition indicated by the preceding vowel in order to reduce the syllogism to a first-figure syllogism. The key for this is as follows: "s" indicates simple conversion, "p" indicates conversion per accidens, "m" indicates metathesis (interchanging of the premises), "k" indicates obversion, and "c" indicates convertio syllogism (that is, the syllogism is to be reduced indirectly). In mnemonic terms the only meaningless letters are "r," "t," "l," "n," and noninitial "b" and "d." More elaborate mnemonics have been devised for syllogisms in which two or more of the premises exhibit modality. See entry "http://go.galegroup.com/ps/i.do?id=GALE%7CCX3446801182&v=2.1&u=uarizona_main&it=r&p=GVRL&sw=w&asid=5327b27f12b49923b785c958133fcb14 Logic, Traditional."
  
  Mnemonic Terms
Name        Figure      Major   Minor   Conclusion
                        premise premise
Barbara     first       A       A       A
Baroco      second      A       O       O
Bocardo     third       O       A       O
Bramantip   fourth      A       A       I
Camenes     fourth      A       E       E
Camestres   second      A       E       E
Celarent    first       E       A       E
Cesare      second      E       A       E
Darapti     third       A       A       I
Darii       first       A       I       I
Datisi      third       A       I       I
Dimaris     fourth      I       A       I
Disamis     third       I       A       I
Felapton    third       E       A       O
Ferio       first       E       I       O
Ferison     third       E       I       O
Fesapo      fourth      E       A       O
Festino     second      E       I       O
Fresison    fourth      E       I       O


Reduction

So, what are the different types of reduction mentioned above?


simple conversion
conversion per accidens
metathesis (interchanging the premises)
obversion
convertio syllogism (indirect conversion)



  reduction of syllogisms
  
  The process whereby syllogisms in imperfect figures are expressed in the first figure. Reduction is direct when the original conclusion follows from premises in the first figure derived by conversion, obversion, etc., from premises in an imperfect figure. Reduction is indirect when a new syllogism is formed which establishes the validity of the original conclusion by showing the illegitimacy of its contradictory. See entry "http://go.galegroup.com/ps/i.do?id=GALE%7CCX3446801182&v=2.1&u=uarizona_main&it=r&p=GVRL&sw=w&asid=5327b27f12b49923b785c958133fcb14 Logic, Traditional."





  conversion
  
  In traditional logic, a type of immediate inference in which from a given proposition another proposition is inferred that has as its subject the predicate of the original proposition and as its predicate the subject of the original proposition (the quality of the proposition being retained). The process of conversion yields an equivalent proposition only when the original proposition is an E- or I-proposition; when it is an A-proposition traditional logicians allowed for conversion per accidens (or by limitation)—that is, conversion plus a change in the quantity of the proposition from universal to particular. Thus, the E-proposition "No men are immortal" yields "No immortals are men," but the A-proposition "All men are mortal" can be converted only by limitation, yielding "Some mortals are men." The process of conversion yields no equivalent proposition if the original proposition is an O-proposition. See entry "http://go.galegroup.com/ps/i.do?id=GALE%7CCX3446801182&v=2.1&u=uarizona_main&it=r&p=GVRL&sw=w&asid=5327b27f12b49923b785c958133fcb14 Logic, Traditional."





  obversion
  
  In traditional logic, a type of immediate inference in which from a given proposition another proposition is inferred whose subject is the same as the original subject, whose predicate is the contradictory of the original predicate, and whose quality is affirmative if the original proposition's quality was negative and vice versa. Obversion of a proposition yields an equivalent proposition when applied to all four types (A, E, I, and O) of propositions that traditional logicians considered. See entry "http://go.galegroup.com/ps/i.do?id=GALE%7CCX3446801182&v=2.1&u=uarizona_main&it=r&p=GVRL&sw=w&asid=5327b27f12b49923b785c958133fcb14 Logic, Traditional."

"In fieri" (in becoming) was a phrase frequently used by the scholastic philosophers. E.g. http://www.logicmuseum.com/wiki/Authors/Thomas_Aquinas/metaphysics/liber5#lib5l1n13 here. 

"He [Aristotle] says that all of the foregoing senses have something in common inasmuch as that is said to be a principle which comes first (1) either with reference to a thing’s being (as the first part of a thing is said to be a principle) or (2) with reference to its coming to be [in fieri] (as the first mover is said to be a principle) or with reference to the knowing of it".
A proposition is analytic if true or false in virtue of its meaning only. The contradiction of an analytic truth is nonsense. Example: red is a colour. Bachelors are unmarried.

It is synthetic if true or false in virtue of the world. The contradiction of a synthetic truth is meaningful (albeit false). Example: human blood is red. John is a bachelor.

It is known a priori if you don't need experience to know its truth value (example: math and conceptual analysis), a posteriori otherwise (scientific truth, facts).

Intuitively, analytic and a priori seem to go together, and synthetic and a posteriori as well. You don't need experience if the meaning only is at stake, otherwise you do need input from the world. Kant however assumed that some mathematical and metaphysical statements are synthetic a priori, a priori because they are known by intuition only, yet synthetic because their contradiction is not absurd. Example: the axioms of euclidean geometry. One can formulate consistent non-euclidean geometries, but Euclid's axioms are true in virtue of physical space and known a-priori (because according to Kant, space is a condition of experience).

This assumption was challenged afterwards (notably, euclidean geometry is not the geometry of physical space, so math axioms might be pure linguistic conventions). 

Finally Quine challenged the analytic synthetic distinction on the ground that one cannot distinguish clearly the linguistic and factual components of a sentence. Quine believed there is no such thing as a-priori meaning.

A third important, related dichotomy is necessity / contingency. Traditionnaly, empiricists conflate analycity and necessity but Kripke challenged this (he assumes some metaphysical necessities are synthetic, such as gold's atomic number).

I've never heard of analytic a posteriori, although Kripke gave examples of analytic contingency, such as the choice of a conventional measurement unit.
"I would like to begin with an almost narcissistic reflection. Why do I resort so often to examples from popular culture? The simple answer is in order to avoid a kind of jargon, and to achieve the greatest possible clarity, not only for my readers but also for myself. That is to say, the idiot for whom I endeavor to formulate a theoretical point as clearly as possible is ultimately myself: I am not patronizing my readers. An example from popular culture has for me the same fundamental role as the Lacanian procedure of the passe - the passage of analysand into the analyst; the same role as the two mediators, the two passeurs. I think it's not an accident that the Lacanian popular quarterly in France, as you probably know, is called L'Âne - the Donkey. The idea is that in a way you must accept a total externalization: you must renounce even the last bit of any kind of initiated closed circuit of knowledge. And precisely this is for me the role of my reference to popular culture. In this full acceptance of the externalization in an imbecilic medium, in this radical refusal of any initiated secrecy, this is how I, at least, understand the Lacanian ethics of finding a proper worth.

I think that the way I refer to popular culture, this necessity that I feel that we must go through this radical, if you want, imbecilic, external medium, is a version of what Lacan, in his last phase at least, referred to as the 'subjective destitution' that is involved in the position of the analyst, of the analyst as occupying the place of the objet petit a. This position, I think, is far more radical and paradoxical than it may appear." -zizek
In the interest of being conservative, let us assume this is not an original part of the source of the book.

It is not integral to the story, and does not expound on itself, so it is probably an editorial improvement.  The best guess, to my mind, is that this is a suggestion by the 'J' editor of the texts (q.v. http://en.wikipedia.org/wiki/Jahwist http://en.wikipedia.org/wiki/Jahwist).

This editor favors the use of the name Yhwh as a name, preferred over references to God via a title or descriptor, or the two other proper names El and Elohim.  He/they/that is the  most likely shaping force to give a basis for the meaning of his favorite name, since it makes the other names seem more arbitrary.

People disagree about when the 'J' editing process took place.  Estimates range from 950 BC to the 5th century BC.  But I think that the latest proposed dates still rule out influence from Parmenides, it seems unlikely any new and foreign idea would have affected scribal decisions that quickly.

It is also dubious how deep the thinking here was meant to be.  It may just be reconciling old God names with monotheism.  In particular the name of some original "El" god named "Yah", a warrior counterpart of Baal, and who may also be the "Lah" in "Allah" may have gotten reshaped into Yahweh.  The epithet "Lord of Hosts" may be a tieback to the old name, so the tradition could have its war-god and eat him too.  And it may be emphasized here only as part of the theme of 'Man as Adam as Earth', for God to be what was before Earth, rather than considered in a more deeply philosophical sense.

(Of course modern Christians and Jews, centuries later, do now consider it in that more philosophical sense.  'Ein Sof Aur' and all that.  But we have lot of philosophy between then and now.)
For 1a, you are able to go from ∀xFx to Fc, where c is an arbitrary constant. Then anything you can prove about c can be generalized by a universal quantifier, since c was arbitrary.

I think the most helpful rule for this 1b would be Df∃ and Df∀.
They just say that:
∀xFx <-> ~∃x(~Fx)
∃xFx <-> ~∀x(~Fx)

For the second problem, existential quantifiers insure a certain amount of something. If I say ∃x∃y, there are at least two things. Likewise, existential quantifiers can tell you when there is no more of something ~∃x. The trick is in the variables you use.

EDIT: Thanks jobermark, I did slip up there.
Hmm . .

If I' understand it correctly, you're saying that if we believe we are free, then we experience freedom, thus effectively we are free

One thing that could undermine this would be if a machine was created which could use the deterministic nature of reality to predict our futures. 

(as an aside.. It would also have to predict itself, and know about its affect on you if you were to ask it a question - and know that you were going to ask it. Blimey just realised I might ask a philosophy question about that lol)

But my point is .. if something was able to tell you that in 15 minutes a bird will poo on your car, and lo and behold it became true, or any arbitrary future event (given the world is deterministic) then would you still believe you're free ? 

So does our perception of free will rely on there being nothing currently being able to predict it for us ?

If that's the case then feee will is just a current perception of reality, a bit like us thinking the world was flat.

If such a machine were to be bult, our perception may change.

So "Am I any less free because someone might be able to determine my choices before I make them?" : I think you wouldn't BE any more or less free, but you might FEEL less free.

This assumes that reality is 100% deterministic and our soul/conciousness/etc is also included in that.
It could be ethical if the withholding of information could reasonably do more harm to the individual than the sharing of information.

Rumor is a powerful force, especially in the internet era.  Without any facts to draw on, it often invents its own facts.  This can be more damaging than the unveiling of actual factual evidence during the proceedings.

Consider the recent trial of Darren Wilson, the police officer who shot Michael Brown.  The verdict was innocent, so it fits your argument as a case where it would be unethical to release information.  Nearly 5000 pages of documents were released.  Because they were released, nobody can question what the Jury did or did not have to work from when making a decision.  Anybody can freely decide to themselves whether the jury arrived at a just answer.

Nobody can undo the past, so of course we have to rely on imagination.  Can you imagine how the populace would respond if the verdict was "innocent, but we won't tell you why.  You have to trust us?"
First, one should distinguish determinate and determined.
Being determinate means having a truth value. Being determined means being deducible from present or past states and the laws of nature.
Determinism (the latter) does not follow from logic, only determinateness does.
The difference is important because the fact that something will occur does not mean strictly speaking that it will occur as a matter of physical necessity. A determinate future does not imply fatalism (or at least this is a contentious issue).

Second, it is possible to resist the view that all future events are determinate as a matter of logic. 
Your intuition is right that we cannot learn something about the world by pure a priori reasoning. 
This intuition can be implemented here by noting that determinateness of propositions is a linguistic principle (that all sentence have a truth value). The ontological counterpart would be: all objects have determinate properties.
While the linguistic principle can be accepted a priori, its ontological counterpart can only be known by experience.

Let us take an example from quantum mechanics: an electron can have no determinate position. Then it is true that all sentences of the form "this electron has such position" are determinate. Actually, they are all false.
The linguistic principle is true, yet the ontological principle fails.
One possible interpretation would be that in this case, our language is not adapted to reality (the appropriate language would be a language that would attribute a wave-function to the electron).
Perhaps a proper language would restore determinacy in the case of electrons. However then determinacy is language-dependent: it does not mean much if our language is not adapted to the world; you'll end up with a bunch of false, but really uninformative sentences.

The lesson is this: a logical or linguistic principle can teach us nothing about the world, because further, we need to assume that there is a certain correspondence between language and reality, which does not go without saying.

Finally there are other avenues for the one who wished to deny that future events are determinate.
One can for example deny the principle of logical bivalence and add a new logical constant: indeterminate. One can also assume that truth is intrinsically tensed ('it will be true' cannot be translated into a tenseless, atemporal statement such as 'it is (atemporally) true at time t'), or that only the present (and maybe the past) exists.
As has been https://philosophy.stackexchange.com/questions/19722/whats-the-term-for-winning-an-argument-using-the-elegance-of-manipulation?noredirect=1#comment45286_19722 pointed out in the comments, the closest correct answer to this question that I'm aware of is "sophistry".

That is, there is no term to my knowledge that is specifically about winning an argument using elegant/deceptive manipulation, but the act itself is known as sophistry. The people who do this are known as https://en.wikipedia.org/wiki/Sophist sophists.

Being called a sophist wasn't always meant in a negative way, and indeed the original terms referred to people who were simply well-spoken. The word actually comes from Greek σόφισμα, sophisma, from σοφίζω, sophizo "I am wise"https://en.wikipedia.org/wiki/Sophism [2], but this changed over time.


  Owing largely to the influence of Plato and Aristotle, philosophy came
  to be regarded as distinct from sophistry, the latter being regarded
  as specious and rhetorical, a practical discipline. Thus, by the time
  of the Roman Empire, a sophist was simply a teacher of rhetoric and a
  popular public speaker.
  https://en.wikipedia.org/wiki/Sophism https://en.wikipedia.org/wiki/Sophism

I'd strongly suggest moving this to the Math.SE forum, https://math.stackexchange.com/questions/834140/is-the-exclusion-of-uncountable-additivity-a-drawback-of-lebesgue-measure see this post, but seeing as how you are keeping it here, I'll offer some thoughts:

Oppy is discussing what properties a measure should possess, from a foundational perspective. Note that a measure is defined on a measurable space, which consists of a set, a sigma-field on that set, and a set-function that obeys the http://mathworld.wolfram.com/Measure.html measure axioms:


The measure of the empty set is 0
If set A is a subset of set B, the measure of set B should be at least as large as the measure of set A
The measure of the (finite or countable) union of mutually disjoint sets is the sum (finite or countable) of the measure of each such set.


Note that (3) is an assumption, and one that Oppy justifies by appeal to a very basic mathematical property that we take for granted...the limit of infinite sums. I have seen other authors (e.g., Robert Ash) also take pains to justify the need for countable additivity by appealing to the richness of the mathematics allowed by assuming/requiring countable additivity, not on any physical grounds. 

In fact, there are set functions that are finitely additive (all partial sums exist) but that don't converge to the value of the set function at the limit itself (think jump discontinuity) when a countable sum is taken. 

Specifically for your question, Oppy was addressing Zeno's paradox about distance. The distance to be traveled is being divided into an infinite sequence of intervals, each half as long as the previous one. Now, under the axioms of measure, we'd expect that no matter how we divide up the distance to be covered, as long as we specify a countable set of divisions, the sum of the length of the divisions should give the total length (i.e., a meter is a meter, no matter what scale we measure it in or how we break it up).

Thus, if we reject countable additivity, then we can have measures (e.g., length) with counterintuitive properties, such as the total distance covered by the runner being dependent on the way we break up and add the partial distances. By requiring countable additivity, we are forcing a common-sense definition of length (and measure in general) and excluding definitions that lead to weird behavior.

There are several interesting counterexamples that show what can happen if we try to work with non-measurable sets (http://en.wikipedia.org/wiki/Banach%E2%80%93Tarski_paradox Banach-Tarsky paradox, http://en.wikipedia.org/wiki/Vitali_set Vitali Sets) or if you try to work with set functions that are only http://www.ams.org/journals/tran/1952-072-01/S0002-9947-1952-0045194-X/S0002-9947-1952-0045194-X.pdf finitely additive 
(Thanks to virmaior for pointing out the text.)

There's a paragraph on this in Existentialism is a Humanism:


  First they tax us with anarchy; then they say, “You cannot judge
  others, for there is no reason for preferring one purpose to another”;
  finally, they may say, “Everything being merely voluntary in this
  choice of yours, you give away with one hand what you pretend to gain
  with the other.” These three are not very serious objections. As to
  the first, to say that it does not matter what you choose is not
  correct. In one sense choice is possible, but what is not possible
  is not to choose. I can always choose, but I must know that if I do
  not choose, that is still a choice. This, although it may appear
  merely formal, is of great importance as a limit to fantasy and
  caprice. For, when I confront a real situation – for example, that I
  am a sexual being, able to have relations with a being of the other
  sex and able to have children – I am obliged to choose my attitude to
  it, and in every respect I bear the responsibility of the choice
  which, in committing myself, also commits the whole of humanity. Even
  if my choice is determined by no a priori value whatever, it can have
  nothing to do with caprice: and if anyone thinks that this is only
  Gide’s theory of the acte gratuit over again, he has failed to see the
  enormous difference between this theory and that of Gide. Gide does
  not know what a situation is, his “act” is one of pure caprice. In our
  view, on the contrary, man finds himself in an organised situation in
  which he is himself involved: his choice involves mankind in its
  entirety, and he cannot avoid choosing. Either he must remain
  single, or he must marry without having children, or he must marry and
  have children. In any case, and whichever he may choose, it is
  impossible for him, in respect of this situation, not to take complete
  responsibility. Doubtless he chooses without reference to any
  pre-established value, but it is unjust to tax him with caprice.
  Rather let us say that the moral choice is comparable to the
  construction of a work of art.


(My emphasis.)
Here is an article (in french--abstract in english) from Bitbol on Destouches: https://www.google.fr/url?q=http://michel.bitbol.pagesperso-orange.fr/destouches_long.pdf&sa=U&ei=wSuhVLHtDsLTaLKEgoAK&ved=0CA0QFjAB&sig2=Fxqr_4Nfxsr2mZsz5_WkWw&usg=AFQjCNGdtnDyYkjrAlaqidWozObZtVdZFA https://www.google.fr/url?q=http://michel.bitbol.pagesperso-orange.fr/destouches_long.pdf&sa=U&ei=wSuhVLHtDsLTaLKEgoAK&ved=0CA0QFjAB&sig2=Fxqr_4Nfxsr2mZsz5_WkWw&usg=AFQjCNGdtnDyYkjrAlaqidWozObZtVdZFA

The most notorious result on contextuality in QM is Kochen-Specker theorem.
See this entry: http://plato.stanford.edu/entries/kochen-specker/ http://plato.stanford.edu/entries/kochen-specker/
The theorem says roughly that one cannot assign non-contextual, definite values to all observables of a system in pain of contradiction.
Some interpretations solve the problem by selecting a priviledged observable (generally the position as in bohmian mechanics and GRW), other by assuming the contextuality of measurement results (Everett-like interpretations).

Concerning the link between contextuality and wave-like behaviour, I don't know Destouches' contribution on the subject. The closest I can think of is this article which explains intuitively why QM can be seen as a generalization of a probability theory (with complex numbers as probabilities) and how this is related to some fundamental aspects of QM
http://www.scottaaronson.com/democritus/lec9.html http://www.scottaaronson.com/democritus/lec9.html
A complex number can be represented as a positive coefficient and a phase. If you impose continuity constraints over space-time, you get something pretty much like a wave (sorry this is not a rigorous proof).
Put most simply, Kant falls back on the Augustinian notion that determinism and free will are both real, because time is an illusion.

For Kant, time and space are forms of human intuition, and other beings are not necessarily bound by them.  Our notion of causation is tied to time, but in a lot of ways, traditional religion expresses divine or angelic causation as tied to intention alone.  To use Aristotle roughly, final cause is ultimately more real than efficient cause, and efficient cause may exist only for animals.

If a use helps -- this idea helps to nail down some aspects of how, for instance, maxims must be universalizable.  Intention is allowed as a real parameter, but time should only be a contingency.  A categorical decision that involves a time limit cannot really be truly categorical, because causation is the category and causation is not necessarily temporal succession under natural law -- that is just how it looks to us.
The language you're using seems like it is quasi-Aristotelian. 

In Aristotle's Nicomachean Ethics, Aristotle speaks of virtues as the mean between two extremes. In that context, he calls the ideal position "the Golden mean." For this model, he suggests courage which is http://classics.mit.edu/Aristotle/nicomachaen.3.iii.html somewhere between brashness and cowardice (EN 3.7). And for the person who knows their own character, they need to consciously overcompensate to approach that mean.

But the model is not the idea that there's a healthy middle between everything. As Aristotle makes clear, some things do not admit a mean or at least it's not something where we have clear poles. Aristotle speaks of http://classics.mit.edu/Aristotle/nicomachaen.4.iv.html these as "without a name" for one of the two extremes.

There is no mean between justice and injustice on the Aristotelian picture because justice picks out the name of the mean between we might say mercifulness and legalism (though Aristotle might not like that placement). 

Injustice where it occurs is always unjust and wrong, so it's not part of a middle ground.
I think one answer is that people are fearful. Others having liberty (to do something others don't like), freedom (to protest what others respect), equality (mixed cultures when others prefer conformity), and justice (which sometimes lets the guilty go free) may make many fearful, for example from the parentheticals I provided.

I happen to agree with Benjamin Franklin: "Those Who Sacrifice Liberty For Security Deserve Neither", but lots of people are very willing to do this out of fear. It's a big problem, in my view, and drives lots of unfortunate political behavior.
Short answer: Oui. In Nihil Unbound Ray Brassier makes a case for the absolute validity, realism, and positive nihilism of the scientific project itself. 

In its negations and development of the oft-maligned "view from nowhere" the scientific view steadily reduces our phenomenological picture of "man-in-the-world" into a smaller and smaller pointless blip within space, time, and evolution. Brassier focuses in particular on the capacity of science to conceive of and validate "truths" beyond the existence of science, meaning, or consciousness itself, such as the big bang or the extinction of the sun in 4.5 billion years. This is, he argues, a true escape from a subject-oriented ontology.

For Brassier this is the only undeniable value and true being of the eroding "human," to rid itself of the pitiful, clinging illusion of "man" and "self." At the same time, Brassier does retain a synthesizing form of the "rational subject" in his scientific naturalism and "transcendental realism." And there are others--Lyotard or Zen Buddhists, for example--who undertake an unsentimental, atoms-and-void post-humanism.    
Short Answer: No.

Long Answer:

Think of a convincing argument.  It would start from unobjectionable premises and then through unobjectionable chains of inferences proceed inexorably to an unobjectionable conclusion.  Such a systematic treatment is so formalized, it could be checked (or even generated) by a machine.

In short, a rigorous argument that convinces all would be tantamount to a mathematical proof.

Now examine the structures of proofs.  You either proceed from premises that all accept, or you make your proof hypothetical (i.e.: if these conditions hold, then such a conclusion must necessarily follow as shown by these steps).  

Such proofs work because they demonstrate what "is". 

Yet morality is about what "ought" to be. Can you even agree on an "ought"?  What would your (unobjectionable) premises be?

This isn't to say there aren't arguments for morality or that these arguments may not convince some people.  This is to say that such arguments would not have the force of a mathematical proof.

Now if you're willing to accept a weaker argument that proceeds on the hypothetical (assuming X holds, then Y must follow) then you could provide an argument that all would agree would hold in a world in which the premises are true, but this doesn't mean they'd agree they hold in our world.
You are correct.  The book is sloppy with its wordings

Your passages 1 and 3 are important, and (almost) correct


Every chaotic system is based on nonlinear equations
There are systems based on nonlinear equations which are not chaotic


From these, we can infer that there are chaotic systems are a proper subset of systems defined by nonlinear equations.  Weather is explained as being nonlinear, but that's as far as you can go.

However there are a few fun issues:


Not all chaotic systems are based on nonlinear equations;  most are.  Infinitely dimensional linear systems can be chaotic.  However, the book is right that, within the realm of finite dimensional systems, if you're linear, you're not chaotic
Weather is not nonlinear because of the reasons they say.  Weather is nonlinear because the models we have for it are non-linear differential equations.  The effects of changes in windspeed are an effect of the nonlinearity, not a cause of it.


For completeness, here are the "characteristics of Chaotic systems" from http://en.wikipedia.org/wiki/Chaos_theory Wikipedia, which openly states that they are not fully agreed upon, but these are pretty good starting points:


It must be sensitive to initial conditions;
It must be topologically mixing; and
It must have dense periodic orbits.


The actual reason weather is considered chaotic is that it demonstrates all three of these characteristics.
According to my understanding, it is noy "historically correct" to say that Pythagoreans discovered the irrational numbers.

Archaic Greek mathematics shared the (implicit) assumption that, given two magnitudes, e.g. two segments of lenght a and b respectively, it is always possible to find a segment of "unit lenght" u such that "it measures" both, i.e. such that [using modern algebraic formulae which are totally foreign to Greek math] :


  a=n×u and b=m×u, for suitable n,m.


From the above assumption, it follows that :


  a/b = n×u / m×u = n/m.


The assumption amounts to saying that the ratio between two magnitudes is always a ratio between integers (i.e. in modern terms: a rational number).

But note that for Greek math the only numbers are the natural ones and they must be distinguished from magnitudes : a segment, a square, ... which are "measured by" numbers expressing the ratio between the measured magnitude and the relevant "unit" magnitude.

For ancient Greeks there are no rational numbers; but only magnitudes measurable with multiples of a suitable unit one.

The discovery of the existence of irrational magnitudes, through the proof that the case where b is the side of the square and a its diagonal is not expressible as a ratio between (natural) numbers, leads Greek mathematics to the withdrawal of the above (implicit) assumption, that we may call : "commensurability assumption" and to the axiomatization of geometry, i.e. the systematic effort to explicitly lists all the needed assumptions.

In conclusion, in ancient Greek mathematics there were no "irrational" numbers, nor "inifinte" ones.
He doesn't say that from not being able to settle all disputes follows that one can settle many disputes. He merely notes that it allows for that.

His point is that ¬∀d∈D[S(d)] is weaker than ¬∃d∈D[S(d)], since the first allows for ∃d∈D[S(d)] (although this does not necessarily follow), while the second doesn't. (I use D for the set of all disputes, S(d) for 'it is possible to settle d').
I found some references to these commentaries in https://books.google.be/books?id=9B-DBAAAQBAJ&pg=PA52&lpg=PA52&dq=zizek+mimetic+theory+ren%C3%A9+girard&source=bl&ots=4B5ZTidkyL&sig=ybJTzReielPd1XZIPGPf7TiTeP0&hl=en&sa=X&ei=WbvUVPiELYKyUfexgkg&ved=0CFYQ6AEwCQ#v=onepage&q=zizek%20mimetic%20theory%20ren%C3%A9%20girard&f=false Monica Germana(ed.) e.a., Apocalyptic Discourse in Contemporary Culture: Post-Millennial Perspectives on the End of the World, p. 52, 2014.

Žižek indeed talks about mimicry in "Slavoj Žižek & Boris Gunjevic, God in Pain: Inversion of Acopaclypse, New York: Seven Stories Press, p. 124-126, 2012"; where in these passages, the mimicry seems related to the feminine.

In the same book (http://www.google.be/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0CB8QFjAA&url=http%3A%2F%2Fm.friendfeed-media.com%2F07ae58439969f69c25f7f9dce96c3d10ae7fa7ca&ei=QzrVVPTPApDVaqD1gZAK&usg=AFQjCNGKTqxrnEgVwtfOqPPFFxyULH7CYw&sig2=9jJxXRKWDxJWnmujZugLaw click here to download) on pages 63-64: René Girard and scapegoating are mentioned.

More assumed comments/allusions of Žižek on René Girard can be found in the source linked to above.
This is an interesting question, but I think it mostly boils down to two definition problems occurring in tandem. 

First, we need to be clear about http://plato.stanford.edu/entries/quotation/#2.2 use-mention:


  Despite its ubiquitous appeal, it is controversial exactly how to draw the distinction. The initial thought is easy enough... 


The SEP article then supplies an example and maintains that the baseline is something is used when it denotes a thing or person in the world and mentioned when it signifies the word.



It's going to be hard to apply that definition to spelling a word since spelling a word (restricting this to languages that use an alphabet or syllabary) involves letters as they relate to words.

To put it another way "Sammy" is spelled "s" "a" "m" "m" "y" seems to 

mention "Sammy"
but use "s" "a" "m" "m" "y" insofar as the very use of the letters is to spell words.

but you could also argue that it merely mentions both if you see the names of the letters as distinct words from their use in spelling things.

This account assumes that by "spell" you mean to "spell out" as into consciously engage in the act of spelling a word. If you are unconsciously spelling words (not thinking about the letters but merely producing the word), then it's not clear there's any room for a use-mention distinction. I say this because I don't know how you would be mentioning anything in that case, since you are using the letters to make words which are also being used in their use rather than being mentioned.
There's a couple different things going on in your expanded question. Let's take it sentence by sentence.


  Indeed, the thinking activity of a reflective person presupposes such a 'reflective person'. 


Perhaps but this has little to do with the argument Descartes actually makes in Meditation 2


  What I observe is that there are certain attributes or characteristics in words, words like 'think', 'articulate', 'summarize', 'deduce' are mainly applied to human-beings.


Yet Descartes' argument does not hinge on an observation about how we use language. Instead, it's a substantial claim about the activities he finds the "I" engages in upon reflection. 


  If 'think'(subjectively) is privileged to human beings, then 'thinking' along will prove the existence of someone, if not 'I'. If these words are not only applicable to human, that some animals also possess such capabilities, there is also one distinction of human beings from animals, that is the power of subjective initiation and the 'awareness of such initiation'(self-consciousness). 


This bit is curious because his argument in Meditation 2 specifically denies that what he has proven exists is a human being as understood in the metaphysics of his time.


  When someone uttered 'I', he is already using both of the attributes, that it is impossible for us not to think but simultaneously initiatively utter 'I', hence it is sufficient as proof of the existence of 'I', and thus 'think' is surplus or as a further elaboration for 'I'.


His argument is slightly different than what you're saying here. He is just concluding there's some locus of thinking (and several similar activities). It works precisely insofar as there must be something (on his view) for this thinking to be coherently happening (within the guarantee of a God to block the evil demon).


  It seems to me that both 'there is thinking activity, therefore someone'(if thinking is privileged to human beings, and uttering such sentence is a think activity) or 'I, I am'(with the recognition, self-awareness of 'I' and such recognition entails thinking activity in the broadest sense) are both sufficient to prove existence of at least something, and the latter is sufficient to prove the existence of 'I'.


It greatly depends on the sort of 'I' you are trying to prove exists. Descartes is specifically trying to prove a res mensa (thinking thing) exists rather a res extensa. That there are things would prove only the latter. That some thing engages in thinking would prove the former. (You can make an argument from the notion of I -- this is what Hegel does much later, but this is not what Descartes says he is doing)


  Maybe let me condense my query a bit. It is that 'I think, therefore I am' seems a bit tautological, that when he says 'I', it is simultaneously implied the cognitive activity of thinking which is necessary for I to recognize myself and to utter 'I'. Also, surely, both 'I' is identical and we are ascribing different activities or states which has the same subject 'I' relied on, and this sounds a bit tautological to me.


Descartes disagrees adamantly with your "surely" ( dangerous word in philosophy). Moreover, it's not a tautology because 'I' by itself doesn't prove anything. Specifically, this is because he has banished all sorts of evidence except his mental activity.


  So when I read the critic by Bertrand Russell, I promptly agree. 'If the cogito does not presuppose a substantial self, what then is the epistemic basis for injecting the “I” into the “I think”? Some critics have complained that, in referring to the “I”, Descartes begs the question by presupposing what he means to establish in the “I exist.”(1945, 567) 


There are lots of critiques of Descartes. The logical positivist one requires us to backport concerns somewhat foreign to Descartes -- specifically the indexical problems of the "I" that they ran into in trying to translate everything in natural language into logic.

It's not clear that this critique is right either. Why? Simply put, the introspective datum is that there's a self doing some thinking. There's some complexity here, but we could consider what Descartes offers a type of transcendental argument rather than question-begging. 

To put it another way, if I read 1.6 x 10 ^ -19 eV and then infer there's an electron, is that question begging? Descartes begins with his datum of introspection -- that there's thinking going on and infers that cetera demonis there must be something that holds those thoughts.

A better version of the objection Russell raises would be to argue introspecting at all is question-begging.


  Russell argues that accordingly, “there is pain” and “I am in pain” have different contents, and Descartes is entitled only to the former'


Yes but then apply the transcendental argument Descartes is (possibly making):


There is a pain
pain = ... [some definition of pain]
There must be a pain-bearer / pain-experiencer


But actually at Med 2, Descartes has bracketed out the experience of pain (it won't be back until around Meditation 5).
The implicitness that Brandom talks about is implicitness (embeddedness) in bare practice. His idea is that the more basic knowledge is just how to do something. The more advanced knowledge is how to symbolically express what we do. When we achieve that advanced knowledge, what was first implicit in practice, in bare activity, become explicit in that it can be talked about, and reasoned about.

For example, a person may be reasonable, logical, without having any acquaintance with logic. This is the level of bare practice. If that person later learns logic, she will learn how to express in the logical vocabulary what was formerly implicit in her bare actions. The knowledge of logic, in turn, will provide her with additional tools to check for logical validity, when her spontaneous (implicit) logical inclinations might falter.
Nachiketa being a good obedient son, was only following his father's orders. In Katha I. i. 5. Nachiketa says "Among many I am the first;..." this sentence implies that a good son or disciple anticipates his fathers wishes, he does not have to wait to be told to do something before acting.

In the Indian philosophical tradition, once a man says something or gives his word, it is considered a great sin to go back on it or take it back. Although his father had spoken in anger, it didn't matter.

There are other examples of similar circumstances.

When Arjuna brought his wife back with his brothers he called to his mother to come out and see what they had brought home today. Without looking out, their mother (thinking they had brought home some food) called out to share it equally among themselves. To keep it so that their mother would not have to go back on her word, all the brothers married the same woman.

When Rama was supposed to be crowned King, one of his father's minor wives reminded his father of a promise he had made to her and demanded as payment of the promisse that he make her son King. Rama, so that his father would not have to go back on his word, declined the crown and was sent into exile.

The moral of all these is threefold; 1) don't go back on your word 2) always be very careful what you say, and 3) be an obedient son/daughter/disciple no matter how bad the circumstances appear to do otherwise.

In all three instances, Nachiketa, Arjuna, and Rama, it was an opening to great teachings and epics.
Hegel described himself in the case of dialectic (as in many others) as standing on the shoulders of Kant. Kant's http://en.wikipedia.org/wiki/Kant%27s_antinomies antinomies of reason were examples of dialectic, which Hegel took to a much greater scale.


  In modern times it was, more than any other, Kant who resuscitated the name of Dialectic, and restored it to its post of honour. He did it, as we have seen, by working out the Antinomies of the reason. The problem of these Antinomies is no mere subjective piece of work oscillating between one set of grounds and another; it really serves to show that every abstract proposition of understanding, taken precisely as it is given, naturally veers round to its opposite. (Shorter Logic § 81)


Hegel took Plato (not Parmenides) to be the ancient inventor of dialectic. Plato in turn is described as following on Socrates, who is said to be the inventor of "subjective" dialectic, a method or technique. Plato is deemed the father of "objective" dialectic, as an inherent aspect of philosophy.


  Among the ancients Plato is termed the inventor of Dialectic; and his right to the name rests on the fact that the Platonic philosophy first gave the free scientific, and thus at the same time the objective, form to Dialectic. Socrates, as we should expect from the general character of his philosophizing, has the dialectical element in a predominantly subjective shape, that of Irony. (ibid.)


Hegel mentions Plato's Parmenides as an example of Platonic dialectic.


  If, for instance, the Sophists claimed to be teachers, Socrates by a series of questions forced the Sophist Protagoras to confess that all learning is only recollection. In his more strictly scientific dialogues, Plato employs the dialectical method to show the finitude of all hard and fast terms of understanding. Thus in the Parmenides he deduces the many from the one. In this grand style did Plato treat Dialectic. (ibid.)

I don't think this is in essence any different from various ontological arguments; I don't think it bears much relation to Plantinga's Evolutionary Argument Against Naturalism.  (Plantinga does have a version of an ontological argument.)

http://en.wikipedia.org/wiki/Ontological_argument#Alvin_Plantinga Plantinga's ontological argument, and your argument, manifest a confusion about the difference between what one can imagine (or state) and what is real.  That is, you start by granting that our minds can outline states of affairs that are not real, model worlds if you will; and then you insist that because some quality or property or proposition is true in the model world, it has some bearing on the real world.  It need not!  We can formally state all sorts of things that have no bearing on the real world at all, and in at least some sense we can imagine them.

There is no real avenue for improvement because it is exactly this (invalid) jump that forms the crux of the argument.  In fact, pretty much every premise of yours is highly doubtful in the sense you mean it once this jump is ruled out.  "All conceptions of reality are derived from the natural world" may be true causally, but only in the sense that all YouTube videos are "derived" from nonlinear properties of electrons in doped silicon.  It's not the kind of derivation you need to conclude anything about the real world given our models of it.  To show that strong kind of derivation you would need to undertake an extensive empirical study, and would probably come up empty.

Likewise, conceptions of reality need not, prima facie, be a coherence of meaningful experiences (though to call it a "conception of reality" we would expect to find some coherence and meaning even if fragmented).  It seems doubtful that people believe that God shares no properties with the natural world if you allow that things like "love" and "justice" can be statements about very complex processes in the natural world.  People extrapolate all the time, and P5 basically says, "No extrapolation, that's cheating!"; also, advanced pure mathematics is almost entirely about stuff that is meaningful in contexts absurdly disjoint from properties of the natural world.

(For what it's worth, Plantinga makes a very different kind of mistake with the EAAN, which is to confuse a possible world that he can imagine with the actual world and its correlation structure; in cases where correlations are unreliable or biased, we do in fact have unreliable perceptions, e.g. passage of time when one has a fever, all sorts of impressions about our internal state, etc..  The EAAN is a good argument that not any natural world could be comprehensible to evolved organisms, but it is a horrible argument that our natural world doesn't reward comprehension with fitness.)

So--sorry!--this sort of tactic doesn't generally lead anywhere (hasn't ever yet, at least), even if it can be transiently interesting along the way.
Any chance you're talking about The Road to Serfdom by Friedrich Hayek?

I haven't read the above book in ages, but I did stumble across the following on an amazon review of a closely related book named Individualism and Economic Order, which is a collection of several essays:


  After dealing with the absurd notion of full information, Hayek turns
  to three issues. First, Socialists once aimed at overcoming the
  results of markets. Now they accept the results of market competition
  as a standard to aim at. Second, an omniscient and omnipresent
  dictator would also require omnipotence to plan an economy using their
  omniscience. Even if they had omniscience, the central planners would
  still have to work through an imperfect bureaucracy. So the notion of
  omnipotence is absurd. We must look at the actual bureaucratic
  problems that planners will face. Third, Perhaps, in a world of
  unchanging data Socialist planners could arrive at efficient prices
  for the means of production through trial and error. But, with
  changing data, the plans of the authority will never match the
  decisions of the 'man on the spot'. Hayek discusses incentive problems
  and knowledge problems at length, and also mentions the potential for
  abuse by concentrating power into the hands a few. This is the subject
  of his book "The Road to Serfdom".


Given Hayek's economic views, it wouldn't be too surprising to come across an essay which supports the free market over planned economies. 
I can't refer to philosophers, but I have personally built a system like this to explore the consequences of such thinking.  When I put it to some of my religious friends, they smiled, and politely said, "That's a neat model, but that isn't how my God is defined."

So yes, there is such a mathematical theoretical definition of God.  However, one cannot assume that such a definition matches the definition used by others.

Consider, as a "proof by analogy," the http://www.merriam-webster.com/dictionary/finish definition of "finish" from Meriam Webster, of which I will only reproduce definition 2 and 3 of the transitive form of the verb:


  transitive verb
  
  2 a :  to bring to completion or issue : hope to finish their new home before winter b :  to provide with a finish;
  especially :  to put a final coat or surface on finish a table with varnish
  
  3 a :  to defeat or ruin utterly and finally the scandal finished his career  b :  to bring about the death of


Needless to say, providing a mathematical definition for one of these forms of "to finish" does not help if you are conversing with someone who uses it in the other sense.

Even if you can show that behaviorally your model is identical to their, defining God within a religion is usually treated as an ontological issue, not a epistemology issue, so they generally will not accept any argument built from it through mere logical progression (which is usually the purpose of such a model).
I can't speak for the philosophical content as such; but merely as a native speaker of English with an amateur interest in philosophy. 

I would suggest that you wouldn't lose much by dropping the 'per se'; here it seems to be acting as a stylistic marker; there is also the hint of a suggestion that it means this sentence, in itself; and without the surrounding context. 

However, considering:


  An attitude colouring the subject of enunciation 


appears to be a rephrasing in more technical terms what he had written in 
standard English earlier:


  an attitude of ambivalence towards the meaningful content of the sentence uttered


To utter, is to enunciate; the utterer, is a speaker, ie a subject; and thus the subject of enunciation; also I'd read colouring as ambivalence; especially when one considers the platitude 'not everything is black and white', meaning that ambivalence is not 'black and white' but 'coloured'.

Given all this, it seems that the 'per se' is indicating the sentence without the qualifier; for example, using the sentence:


  I can't help but think all ethical problems are black and white


The sentence 'per se' is the 'literal' meaning; pointing, or so I think, to the sentence fragment which is without the qualifier 'but' (plus other words that are part of it's construction, to wit the preceding words, and the word think).


  all ethical problems are black and white


Finally, this links up with what I wrote earlier; that it loses the 'surrounding context'; that is, in this case, it loses the ambivalence suggested by 'but'.

Note: I can't help but notice that the example I've chosen is a counter-example to Finks thesis - here but is acting as emphasis. 
The difference is a subtle one. Nietzsche believed that there was no objective reality, believing it to be conditional and contingent. This view is called perspectivism. Popper on the other hand, believed that while it may be impossible to obtain objective reality, one could still construct theories and until they were falsified, there is no reason to abandon them. This is called empirical falsification, and revolutionized science. Nowadays, scientists in many fields follow Popper and try to find an example supporting the null hypothesis (the opposite of what they believe) in their experiments, because one counterexample disproves a hypothesis. Until a theory is falsified, it will not be abandoned. 
Division of labour is inevitable; but judgement has to be exercised as to what extent. 

Making a bow and arrow and then going hunting is very different from sitting in an assembly line and screwing in one arrow head onto its shaft, hour after hour. 

A similar but different observation was made by Simone Weil about workers who were made to do dangerous work - she observed that the work could be safer and more humane, that training could be given. 

The question here is the efficiency of the total machinery of production versus the quality of life, or human flourishing (eudaimonia). 
The status of http://en.wikipedia.org/wiki/Newcomb%27s_paradox Newcomb's scenario is a matter of controversy. However, it does seem that either (1) free will is illusory, or that (2) Newcomb's scenario is itself paradoxical.

Newcomb's scenario involves a "predictor" i.e. a kind of "prophet" who is (nearly) infallible in his predictions. If this ingredient is even coherent, if a "predictor" is even a possibility, it implies that the future is determined in advance. For the predictor could not tell the future, unless there was a (pre-determined) future to be told.
The existence of 'strange attractors' undermines the physical assumptions behind eternal return.  The math does not work: previous centuries have just not understood how complex prediction really is.

The standard cheezy example is that as you zoom in on a point on the boundary of the Mandelbrot set, the image really can be proved to continually produce motifs not present in earlier images.

The fact it might look the same on many occasions does not mean it is repeating, because it can be moving through the same state in a different evolutionary direction.  Even if there is infinite time, there are also infinitely many derivatives of any function, so infinite subtlety in its variation, and constant capacity to escape repetition.

A simpler example that even the Pythagoreans knew about, is that digit expansions of pi do not repeat, so a circular object rolling infinitely around a square whose side is an even multiple of its radius will, in fact, not ever fall into a perfect, repeating pattern.  The position on the rim where it starts down the next side will always be a tiny bit different from what it was on every previous occasion.

If something that simple and clean never repeats, why would anything as complex as a universe?

The classical answer here is that the difference is always shrinking and at some point the difference is small enough not to matter.  But from parts of math like bifurcation theory, we see tiny differences can have huge effects over long periods, if they somehow eventually affect a point where the system is very touchy.  

Previous generations of mathematicians did not really take that to heart.  There is strong human bias to presume convergent behavior.  But given computers, we can see by observation that repeating systems of any high complexity almost always have points where some of the derivatives grow very, very large, so a very small difference can make a big bump.  This was the ultimate death knell of high-powered analog computers, and the reason everything is digital now.

From an entirely different direction, the level of determinacy presumed simply is not consistent with our observations of the world.  We really do observe quantum indeterminacy.  So if you have any faith in modern science, this is just not realistic or likely.
One position in the philosophy of maths is Structuralism (as has been pointed out in the comments). According to Structuralism, mathematics is not about numbers, sets, functions, etc., but about structures. It identifies common mathematical objects with places and relations in structures. 



Some time ago, people thought that numbers are really sets. For example, 0 is the null set, 1 is the set of the null set, 2 is the set of the set of the null set, and so on.

But this way of identifying numbers with sets is just one way to do it. Here is another. 0 is the null set, 1 is the powerset of 0, 2 is the powerset of 1, and so on. (which gives us the following sequence: {}; {{}}; {{}, {{}}};...

(This is a very short and probably bad summary of Benacerrafs 'What Numbers Could Not Be' (1965))

This insight motivates the Structuralist's position, that any sequence of stuff will do.



But what are these structures? According to some, they are abstract objects in their own right. Here we have the problem of supplying a satisfying epistemology of abstracta. According to others, they are concrete. Here we have the problem that mathematics is thought to be non-contingent, while what is concrete, and how much concrete stuff there is, is contingent. And according to a third position, they are merely logically possible, which again dodges some problems and runs into others (do we know that there are possible structures? etc)



Literature: 
The relevant SEP link is http://plato.stanford.edu/entries/philosophy-mathematics/#StrNom here

Resnik (1981) - Mathematics as a Science of Patterns

Shapiro (1997) - Philosophy of Mathematics - Structure and Ontology

Hellman (1989) - Mathematics Without Numbers - Towards a Modal-Structural Interpretation
No. This is an old-fashioned, fancy way of saying


  A man has as much property as he tills, plants, improves, cultivates, and can use the product of land.


Or, freer, interpreting: 


  A man owns the land he tills, plants, improves, cultivates, and can use the product of.

Well, there is an ancient and unsettled debate between libertarians who believe free will is incompatible with a deterministic (or random) universe, and http://plato.stanford.edu/entries/compatibilism/ compatibilists who believe the libertarian notion of free will is incoherent, and propose a definition of free will which is compatible with a deterministic (or random) universe.

You can read about this debate here: http://plato.stanford.edu/entries/freewill/ http://plato.stanford.edu/entries/freewill/

I also recommend a good book called http://rads.stackoverflow.com/amzn/click/019514970X "A Contemporary Introduction to Free Will" by Robert Kane.

I would just like to note that while I don't believe the universe is deterministic (why should it), randomness does not help, since random behavior is not any better than deterministic behavior when it comes to free will or responsibility.
The phrasing for this that I use is striving to find a win-win situation in all interactions.

You have a purpose in mind: you want to buy food.  They also have purposes and interests; you generally don't know exactly what they are.  You have many possible ways to buy food.  Some of those may coincide with their purposes and interests, and some will not.  This quote is directing you towards looking for which ways are beneficial to both parties, not just looking for the easiest way to satisfy your own needs.  The suggested minimal solution is to find a way to buy the food which respects their dignity.  I would argue this search for win-wins should go beyond simply respecting dignity, but it's certainly a start.
OK, but everything with mass also exists only alongside 'its field', the gravitational field its mass creates. So it seems many particles come with fields. Is there an objection to the electric field that does not apply to the gravitational one?

Further as I understand it, the strong force is also a field, and a separate one. So a better question, then, is why this one of the three (or more) fields is absent for specific particles.  Rather than considering it special, it seems to me that we should assume everything comes with all of he fields, but that a neutron happens to be an electron and a proton overlaid, canceling out this particular one of the fields.  And this is the only field which we happen to be in the position of seeing both the positive and negative versions of.  (Since we are not allowed to get near antimatter.)

From this perspective, (which I think is close to Maxwell's approach to electricity), then, there is a consistent model where spatial forces are prior to particles.  In that model, particles are not really objects, but, instead, inflow/outflow points for the fluids that make up the lines of force for the fields, the same way lines of current make up a laminar flow between a source and a sink in a conformal field. 

Particles then have mass (or not) because one of the fields they 'source' or 'drain' is gravity.  The have the ability to localize because they source or drain the field for the strong nuclear force, and they have charge because they source or drain some electromagnetic 'substance'.

  An argument is valid if and only if the truth of its premises entails the truth of its conclusion and each step, sub-argument, or logical operation in the argument is valid. – http://en.wikipedia.org/wiki/Validity#Validity_of_arguments Wikipedia


This definition only talks about concrete arguments1 with true premises. It basically does not tell you anything of concrete arguments with false premises. From this follows that the definition does not forbid a valid argument (with false premises) to have a false conclusion.

Validity of arguments is best checked with abstraction. Consider for example2:


  P → Q.
  P.
  ∴ Q.


This argument is valid; it follows from the http://en.wikipedia.org/wiki/Modus_ponens Modus Ponens. If the premises are true, we know for sure that the conclusion is true (this is the definition of validity of an argument; see above). 

However, now consider:


  If it's raining, I eat the cat.
  It's raining.
  ∴ I eat the cat.


This argument is valid since it has the same form as the abstract argument above. However, as it turns out, it's not raining (the second premise is false). Moreover, I am not eating a cat at this moment. Hence, the conclusion is false while the argument is valid3.

Validity is often confused with http://en.wikipedia.org/wiki/Soundness soundness:


  An argument is sound if and only if
  
  
  The argument is valid.
  All of its premises are true.
  


At this point, please rethink your answer to the textbook question. When you've made your mind up, hover your mouse here:


   Your argument is not a valid argument. The conclusion does not logically follow from the premises. For example, if grass is not green and water is not wet, then this does not tells us anything about whether it's raining or not. However, if you also have as premises that grass is green and water is wet, then, yes.


1: By concrete argument I mean an argument with concrete premises, i.e. without variables. So some 'P' can only be part of a concrete argument if we know what is meant by 'P'. I will use abstract argument for an argument with variables.
2: The symbol ∴ means 'therefore' and is used to indicate the conclusion.
3: Whether or not the first premise is true is out of the scope of this answer.
The reason there isn't a huge amount of philosophical criticism is that the answer is simple and well-understood: if your premises are false, your conclusions may be also even if your reasoning is valid.

But there is a rather famous exposition by John Stuart Mill (http://plato.stanford.edu/entries/economics/#3.1 summarized here) about the epistemological validity of economics in the face of not quite getting your assumptions right.  The basic argument as I understand it is that if you get your premises essentially right, your conclusions will be approximately right, and that's good enough to tell whether you're on the right track.

This sounds lovely, and was very popular for a while, but as it came under criticism, a new idea from Milton Friedman (yes, the famous economist) gained hold, which is that you should see how accurate specific predictions are not worry too much about false assumptions.  Also sounds lovely, but it's basically a dodge (we're wrong; who cares?) and inadequate because you want not just to get little easy-to-measure predictions right, but also make sure your whole economy doesn't tank (i.e. you want some assurance of whether big rare events are being made more or less likely).

The SEP article covers various modern responses.  In particular, approaches http://plato.stanford.edu/entries/economics/#4.1 inspired by Popper's approach to the scientific method (including the slightly more forgiving formulation by Lakatos) seem to indicate that economics is no science and should be treated with skepticism.  It's not at all clear to me that this is wrong even if it is not acceptable to economists.

Because, as I began, the fundamental problem is pretty simple: the premises are false, and sometimes badly so, and it's just not that tricky of a philosophical issue when you're in that situation.
Basically with a proof system, you're seeking a rule-based process that will allow you to evaluate as valid ALL and ONLY the admissible arguments that actually are valid.


A SOUND system never characterizes any invalid argument as valid (but may throw out some of the good apples along with the bad).  If your system is SOUND you can absolutely rely on any argument that makes it through the process, but you might miss some good ones.
A COMPLETE system never fails to characterize a valid argument as valid (but may incorrectly endorse some invalid arguments). If your system is COMPLETE, you aren't missing anything, but you can't rely on what you have.


The standard proof tree system is SOUND and COMPLETE.  Any open branch of the tree represents an interpretation where all the premises are in fact mutually consistent, and taken together, all the open branches cover every such interpretation.  However, if you swap out that one rule, you can reach situations where some things can appear inconsistent that aren't.

What makes it tricky is that the correct way to evaluate an argument with proof trees is to see if the premises are compatible with the NEGATION of the conclusion.  If so (and there are open branches on the finished tree), the argument is INVALID, if not (and all branches close), it is VALID.  This is a little counterintuitive because you are checking the opposite of what you actually want to show (in fact, it took me quite a while to think through it myself while crafting this answer).

In the particular case of swapping out this rule (Change #1), you introduce times when some branches will close that shouldn't close.  This will make some invalid arguments incorrectly seem valid.  This makes the system no longer SOUND.  However, you don't introduce any times when any branches stay open that should close, so every valid argument still seems valid, and thus the system is still COMPLETE.
In terms of Bayesian hypothesis testing, Occam's razor is incorporated in the prior probabilities of the hypotheses.  Often one can interpret differences in the prior probabilities as being "entropic".  E.g. imagine two models: H1: 0<=x<0.2, H2: 0.2, based on some parameter 0<=x<1.  If we take the maximum entropy (constant) distribution as the prior distribution for x, then the a priori bias towards H2 is due to the fact that there are "more states", i.e. higher entropy, for that model.  This straightforward use of Bayesian hypothesis testing does not have the feature of balancing energetic against entropic considerations; or equivalently there isn't the analog of (variable) temperature.

There is research on the statistical mechanics of Bayeisan networks, e.g. variational approaches for estimating the free energy in physical systems can be applied as approximate propagation algorithms (Yeddida is a relevant author).  In the end, the thermodynamics is all done at kT=1, so that energy <=> log-likelihood.

When you get to machine learning problems, you can start to see things that look like temperatures in the models; and thus you get more interesting analogies.  I've seen papers (don't have reference handy) where during the initial phases of learning Bayesian networks, they used (effectively) a high temperature to prevent over fitting the conditional relationships while the structure was still uncertain, and then lowered the "temperature" until kT=1, and they were finding the maximum likelihood model for the data. 

There is what I consider a related application in http://webdocs.cs.ualberta.ca/~sutton/book/the-book.html reinforcement learning where a temperature-like parameter can be used to go between exploration (entropy driven) and exploitation (energy driven).

In terms of the kind of hypothesis testing alluded to in the OP, I haven't seen research that has real thermodynamics (absence of evidence and all...), and I don't see what feature of those kinds of problems map onto the idea of a temperature.  However, in various places in machine learning I have seen what look like relevant ideas; this is due to the fact that that these types of problems need to balance model fit (energy analog) against generalization (entropy analog).  None of them exactly match the criteria set in the question, but hopefully provide some indications of where related ideas have popped up.
(Edit: this answer is now split into two parts, thanks to a lengthy discussion with Rex Kerr.  I made my original answer on a very specific reading of the scientific method.  He had a very different reading, which came to a different but very related outcome.  I've tried to capture that in the first part.  The second part is my original answer, for those who wish to use the stricter reading)

There are at least two extremes as to how one can define the scientific method.  One is a process, one is more of a set of principles and a goal.  The process is well defined as:


Observe something interesting
Formulate a hypothesis that you think would model this interesting thing better than existing model.
Run a series of independent tests of the hypothesis.
Statistically demonstrate that the original model (often called the null-hypothesis) predicts the outcomes of the tests to be highly unlikely.
Reject the null hypothesis (assuming the data backs your claim)
Demonstrate that your new model does a better job of predicting the statistical results.


This is what I was taught the scientific method was in high school.  If that is the version you are after, skip ahead to the second part, which explicitly targets that reading.

However, there is another more fluid reading which also exists.  The statistical requirement is relaxed, because it can cause trouble.  However, there is a focus on both the elimination of hypotheses through testing and the preference towards hypotheses which are testable.  This reading of the scientific method is a very general direction, so the alternatives are equally general.

Science is a very deductive learning approach.  It depends upon one writing a hypothesis in highly objective terms and then testing it.  There are many situations where deductive learning does not work.  Procedural learning is often viewed as an alternative approach.  Consider the case of an athlete.  They collect large amounts of information from scientific approaches, but the final bit that takes them from a "good athlete" to a "great athlete" is all "feel."  There may be no written hypotheses.  There may be no statistical testing.  Yet, the mind absolutely learns in this way.  Thus, procedural learning like this would be a valid alternative method.  In fact, many Chinese martial arts focus almost entirely on procedural learning because it is so hard to learn deductively.

Which reading of the scientific method you want to use is up to you.  What follows is written entirely from the perspective of a strict statistically valid approach to the scientific method.  Much of what has made science great is its ability to build upon previous hypotheses.  While statistical rigor is a nicety for rejecting hypotheses, it becomes essential for building hypothesis which can support others.



Finding an alternative to the scientific method depends on you deciding what you want out of a method.  You will never find a better tool than the scientific method at it's game.  However, if that game is not what you really want it to be, there are alternatives.

The most visible example of this I have seen is western medicine compared to Traditional Chinese Medicine.  They developed very different approaches, and yet both appear to yield results.  TCM actually does work on line along your questioning: it is not fundamentally built off of rejecting hypothesis.

Let's look at the scientific method, and see if we can make some headway.  There are two major features of the scientific method which stand out as "interesting" for this line of thinking:


The scientific method is highly steeped in the language of statistics.
The scientific method seeks objective theories.
The scientific method tests theories.


These are traditionally seen as strengths.  However, they can also be seen as weaknesses (like all good superheros, their strength is their weakness.. that's what makes them interesting).

The scientific method is completely and utterly useless without statistics.  This means any singular event is completely beyond its reasoning.  It cannot provide answers to topics such as "the purpose of your life" because there is only 1 you, and N=1 means there is no statistics.

Related to this, the scientific method strives to be objective.  It always tries to remove the observer from the picture.  This is very valuable, because it ensures that your discoveries are applicable to others.  However, it also proves to be tricky in many situations.  Social studies in particular have great difficulties with the scientific method because it is so very difficult to make good tests that keep the observer out of the loop.  As an example, TCM claims that acupuncture works.  Those who have tried it, claim it works with uncanny success.  However, science has had fits trying to find any effect of acupuncture beyond the infamous cop-out "the placebo effect."  The issue is that it is almost impossible to develop an effective control to measure against because the acupuncture practitioner knows if they are doing it right or not.  Whether you believe acupuncture works or not depends heavily on whether you accept results which lack a solid control to ensure objectivity.

Finally, science tests its theories.  This sounds absurd, because it seems so obvious that you should test them.  However, a theory is not accepted at all until it is tested.  The result is that anyone with a theory must expend the resources to do the testing before science will do anything with it.  Other approaches get away with a different style: you use a theory once you have it, and you test it when you get an opportunity to do so.  The tests can also be dangerous.  (Edit: I had a reference to the LHC and potential to create black holes here, but it was too contentious.  Instead, it has been replaced with a hypothetical example)  Consider a hypothetical particle physics experiment.  The scientist is rather confident that their theory is correct.  They begin experimenting, after calculating that they would like 100 samples to do statistics on.  Generally speaking, they are finding their theory holds out for test after test.  However, on tests which disagree with their hypothesis (which happens in the scientific method due to noise), the observer notices a burst of energy from the test apparatus.  That burst becomes stronger and more dangerous with every data point that disagrees with their hypothesis.  At some point, the scientist decides to cut the experiment short, because they are uncomfortable putting their life at risk to finish the test.  By the strictest reading of the scientific method, that data cannot be analyzed because it is tainted with the scientist's choice to cut the tests off early.  This might induce biases because the scientist is more likely to cut them off faster if the results look good for their theory.  Other methodologies are capable of using this data (including the intuition of that scientist, who will not try the exact same experiment again).

Seeing that the strengths and weaknesses of science are so confounded, it is up to each individual to decide if those are ideal for them.  There are many others, none so visibly different from the scientific method than that of TCM.  As described to me in a lecture, the difference is in the approach towards healing the human body:


Western medicine tears the body apart into components, develops hypotheses about these components, then builds them up.  At each step, it develops testable hypotheses, and tests them.  From there, it finds things which may provide results, and tests those.
TCM starts with the body as a whole, finds things that cause good results, then develops testable theories about why the results occurred.


The end result is that much of TCM is doctor-centric.  A doctor finds out what works well for them, and suggests it to others.  The focus is less on rejecting bad hypotheses, and more on finding new good hypotheses.  TCM relies more on natural attrition to weed out the hypothesis, rather than actively trying to disprove them.

Can I claim one is better than the other?  I'm not sure if I can.  However, I do feel comfortable claiming that they are different, and that a remarkably large number of individuals consider one better than the other in both directions.  It's simply another way to approach things.
Well here's one reason: Noise.  The mathematical God is unselective as regards the reality it creates, and generates vast, indefinitely extensible hierarchies that are filled with collections within collections, some of whom are enormously complex and specific and others of whom are simple, unitary or all-encompassing.

Although the mathematical God conceives of the universe in totality in ways we might view as beautiful, that's not the full story of each of the various (also infinite) objects within that totality, and the mathematical God doesn't filter its creation to only contain those elements that are simple and binary.  Arguably, that's what makes applied Maths so useful to us.
It is difficult to establish strict rules in matters of style, but I think that in general it is more readable to state the conclusion of an argument before the premises. Because, from the point of view of the reader, it provides a context. Without knowing what is the goal, the desired conclusion, at least in part, the reader would be in the dark as to what the premises are for, as to what the author is getting at. The "standard form" is fit for a more formal and unequivocal, even if less readable, presentation of an argument.
It seems to me that what you are getting is one specific definition, and not general differentiations.  So far we have a lot of Popper, but this covers only one scientific method.

I trust a workman to judge his trade.  So to me, what differentiates science, must apply equally to everything that the great scientists of any era recognized as science in their own day.

That includes Alchemy (pursued by Newton) and Platonic cosmology as concretized by Ptolemy (with which Tycho Brahe tried desperately to find a Copernican compromise), even Marx and Freud (which many people at the time of their origin considered scientific, even if they disagreed with them.)  Continuing to believe in such things once they are superseded by better explanations is counter-scientific, but in their day, these were science by the standards of those who should know.

So Popper doesn't cut it.  His is a theory of why science works, not a definition of science, and he is only partly correct.  There is not just one scientific method, there are many.  And while falsification with calculated risk may provably be the most statistically sound approach overall, it does not explain what a lot of major names in science actually did with their time, or why they were productive.  Here are some variations:


Many modern physicists spend most of their time determining which sets of hypotheses can be harmonized with one another and which cannot.  Experiments in important areas have become large undertakings that need to be somewhat rationed.  Where does that fit into Popper?  Is it all wasted time? Their mathematics is not falsifiable, only the theories which are being compared and contrasted by it are.  And we cannot seem to produce an experiment that would test them.  The big experiment at CERN might have, but it came out with a number that does not actually remove any of them.
What Darwin did was science, and he did not follow Popper's criterion.  He worked entirely inductively from a huge mass of data in almost everything he did.  Until we had genetics, his work remained unfalsifiable.
Biologists have always drawn conclusions from amassed data and woven them into large, complex systems, relying on the weight and completeness of the system to validate their assumptions are not bad.  The entire Linnean system on which our current taxonomies are built with no experiments.  Linnaeus was an Aristotelian, and did not really value experimentation.  This, although a very useful tool, is too general to be overall falsifiable.
Chemistry has at its root the periodic table, first roughed out by Mendeleev, who did it without reference to original experimentation.  He obsessively categorized and recategorized the physical chemistry of the time until the sets of things in related categories had the fewest differences.  Until we discovered orbitals, this was not falsifiable.


All of these are scientific methods.  Some are better than others, and some only work well for people with a particular temperament, but they have produced real science that we value.

To me, the things that these systems do have in common seem to be these:


Data matters.  We can see Aristotle's 'physics' as physics, but the refusal to accept contradictory observation, and just drop his biases, keeps him from being a physicist.
Challenges are to be recognized and met.  Some may see reality more easily or find precision with less effort, but reality is reality and consistent failure to agree on observations, even those of the commoner or oddball, is to be taken seriously and diagnosed.  (Galileo's Salviati owed both Sagredo and Simplicio answers.)
Nature is presumed consistent. The rules are not random, so when things differ there should be a diagnosis.  That does not mean that something like Brownian motion or quantum indeterminacy is forbidden.  But it has a meta-layer at some level where the randomness leads to observable consistency, and the randomness itself explains that consistency.
Parsimony and elegance accompany truth.  The simplest explanation for a phenomenon gets the first crack at acceptance.  Clutter in your theory is a sign you are failing.
Different sciences harmonize.  We seek a single, overall truth.  So there is no split between disciplines that allows chemistry not to apply to biology, or physics not to apply to psychology, as there is are splits that allow, for instance, religion not to apply to philology, or anthropology not to apply to math.

Understanding capitalism requires understanding a constellation of concepts that reinforce each other. I'll try to make some headway here.

A helpful way to think about capital is as the aggregate of all non-labour inputs to production. Some would include land as a factor of production as well, and some others would consider human capital to be a form of capital (typically when explaining why capital in aggregate does not run up against the problem of diminishing marginal returns.)

The defining characteristic of capitalism is that capital is privately owned. As you can see, it is compatible with a great diversity of political systems (ranging from the illiberal democracies of Singapore, to the authoritarianism of China, to the democracies in the West). Because capital is privately owned, it is typically invested in such a way as to maximise profit. This isn't necessarily the case, and some people might invest their private wealth in non-profit organisations. But the dominant paradigm is typically acquisition for private gain. 

The term became popular in its modern usage sometime in the middle of the 19th century, possibly slightly earlier. Marx was probably not the originator, but he was definitely contemporaneous with others who did. Potentially Proudhon and socialists of other stripes. Since then the left has kept this usage alive, together with the oft-mentioned 'bourgeois mode of production' - which is essentially synonymous.



For Capitalism

The capitalist is likely to speak of capitalism being conducive to human freedom (freedom to buy and sell, enter into contracts), and to the generation of wealth and prosperity for mankind. He is likely to speak of its efficiency with respect to classical economics - the invisible hand through the price mechanism equilibrates supply and demand, so that the market clears (everyone is satisfied). And possibly, that capitalism encourages thrift and industry - which are virtues (although, this is susceptible to the immediate retort that we are conditioned to think of these as virtues, because they are useful within capitalism, not because they have any timeless worth).



Anti-capitalisms (two main types, with many sub-types)

1. A Normative Critique

The main line here is that capitalism is unjust and causes us to detract from the good life. There is substantial trove of academic debate on whether Marx himself thought capitalism was unjust. (c.f. Norman Geras, "The Controversy about Marx and Justice).

The most common type of this critique is - capitalism leads to inequality in resources. Some people may regard this as intrinsically negative, which is up for debate. But this inequality typically translates into unequal political influence - which we see in the form of corporate lobbyists and other distortions to the democratic process. 

Some other normative critiques (nowhere near exhaustive):

Capitalism is exploitative - maximising profit involves underpaying workers and denying them the fair share of the revenues.

Capitalism is coercive - while people may seem to voluntarily enter into labour contracts, the reality is that they have very little other option. Back in the day when peasants had some land - they could get by on subsistence farming. The modern-day proletarian has no such option. Notice that it is not an issue of whether the proletarian (working-class man) is better off or not, it is an issue of whether he is free to choose or not. 

Capitalism is alienating - it prevents us from working in the right sort of way, that which actualises our potential. We are stuck doing pointless jobs - like waiting fast food tables, when simple etiquette would do without it, or shuffling papers within an engorged bureaucracy, telemarketing, or roadsweeping, when machines can do it so much better. Because what maximises profit doesn't necessarily coincide with what develops our potential, there is a problem. Capitalism also alienates us from our fellow man - we see each other as potential consumers, or labour, which prevents us from relating in a dignity-preserving way.

2. An Efficiency Critique

Capitalism is inefficient, and squanders our natural resources. In the Marxian lingo you would hear about capitalism being 'a fetter on the productive forces' at some point in future (1859 Preface to a Critique of Political Economy). The idea is that the productive forces (labour, machinery, natural resources...) have a tendency to develop, and the relations of production we choose have a bearing on how effectively the productive forces can develop. Capitalism has unleashed great productivity, but those who subscribe to a Marxian view of history are pessimistic about whether it will always be conducive to the development of the productive forces. 

From the Greens (environmentalists) you might hear about how capitalism takes a myopic view and systematically disregards environmental externalities. When selfish interests dominate government policy-making on the environment, there is wanton environmental degradation in the service of profit. This is often brought across in ethical terms - but considerations of natural resource scarcity lead me to consider it an efficiency-based critique, at least in part.

Hope this helps!
Thomist philosophy held that essence preceded existence, apart from God whose essence was existence; and this in line with a conception of God as the necessary being; whereas humans and all else are contingent.

Mans essence being his soul; one can say that being in the world existence draws out his essence; in a similar way that in Platos a Dialogue The Theatatus; Socrates draws out what in essence was already there.

An old tradition stated that through  introspection one can discover the hidden divine realm; consider for example in the Islamic tradition Al-Hallajs utterance Ana al-Haq (I am the truth - truth being a name of God - for which he was executed) which has parallels in the Christian and Indian traditions. 

But after the death-of-god theology of Nietzsche; this realm evaporated so as Haydon explains that when Sartre looked within and 'pushing aside memory, knowledge and sensation' he found nothing; and he turned this into the philosophical concept of Nothingness.

Sartres innovation is to turn turn the two terms around so that existence precedes essence; one exists first and it is through existing in the world and it's commitments that's ones essence is formed. 

Thus all there is is the material and the empirical; and when one pushes this aside, one does not find God as 'hidden treasure' or a 'lamp in a niche'; or as for Kant the 'moral law' but nothing, the void - a blankness.

This induces nausea and vertigo. 

We have only the pure thingness of things rather than being imbued with something more than they are; there is no  presence, just absence - or one could say the presence of absence.

The non-rational is not the lack of thinking or of thought as such; but should be seen as a term placed in opposition to the Enlightments project of rationalism; hence the reactions of Romanticism and Existentialisms.

As Haydon points out there is a kind of a parallel in the traditions of the East; possibly in particular the Tao, whose opening lines echo that of Sartres philosophical opus Being & Nothingness. 
I assume you mean the metaphysical status of propositions.  The propositional calculus doesn't give much insight into determining what a proposition is--after all, it takes propositions for granted and attempts to develop a formal analysis of them.  Similarly, mathematics won't tell you what a set is, but simply stipulate set axioms that are intended to model what we already understand a set to be.

However, the question has been approached pretty famously by Frege, Russell, and many others--you may be interested to see the debates on the topic.  While there isn't unanimity on the answer to the question, I would claim that the "intended proposition" of a simple sentence is the set of all equivalent thoughts which the speaker attempts to communicate; the "public proposition" actually expressed by a simple sentence is the set of equivalent thoughts that a linguistic community tends to agree are expressed by the sentence.

To give just two important other notions of what propositions are:  For Frege, they are abstract objects that refers to their truth-conditions.  For modal realist David Lewis, propositions are sets of possible worlds.  
You are right. The correct answer would be:


  This argument is valid. However, for this argument to be sound it is also necessary that its premises are true. Therefore, this argument is sound iff the two premises are true.


NB: see Mozibur Ullah's comment on the question for a way to argue that this argument is invalid (in which case it would directly be unsound); however, in that case I would say the examiner is a little bit pathetic.

I don't know your examiner, but is it possible that this was a trick question?

An argument is sound when it's valid and its premises are true. Therefore, to determine soundness you need to determine validity and truth. To determine validity, you need to answer the question: "would it be possible that the conclusion is false while all premises are true?" If so, then the argument is invalid. If not, the argument is valid. Determining truth... well, let's just say that's more complicated!

If your examiner insists that you can determine the soundness of that argument, you could show him the definitions of soundness and validity, preferably from your book, but if they are not there, http://www.iep.utm.edu/val-snd/ from the IEP would be sufficient:


  A deductive argument is said to be valid if and only if it takes a form that makes it impossible for the premises to be true and the conclusion nevertheless to be false. Otherwise, a deductive argument is said to be invalid.
  
  A deductive argument is sound if and only if it is both valid, and all of its premises are actually true. Otherwise, a deductive argument is unsound.

"Pathos" is appeal to emotions, a passionate appeal, as opposed to ethos and logos that appeal to character and reason respectively. Moral pathos is appeal to emotions about morality. What unites Nietzche, Kierkegaard, Pascal, St. Augustine, etc., is that they are both moralizers, whether advancing a version of  morality or denouncing it, and very passionate writers, employing various rhetorical means (vivid examples, poetic sentences, etc.) to ignite readers' passions while making their (im)moral case. 

On a side note the expression is a macaronic mixture, "moral" is Latin, and "pathos" is Greek.
There are animals other than fish.  

You want "no interpretation", "no X does Y" is easiest to address by contradiction.  So let us imagine an interpretation as a counterexample.

We only need one counterexample, to contradict "no interpretation".

It has to be one with animals.  So let's choose the simplest easy interpretation with animals: one animal -- me.  So the conclusion is false.

But fish are animals, too, and I am not a fish.  So we have ruled out fish entirely.

Then both premises can be true.  The nonexistent, necessarily swimming fish still don't swim.
I don't think there is any deeper intuition there.  It is just a matter of linguistic convenience.

But if it helps, the word is part of a set of words in English, including 'lest', 'else' and 'except', that are generally related to exceptions in rules or intentions. (I only start with the least common one first because it is the one most closely related historically.)

"I dare not wear wool lest it rain", meaning I want to, but will contradict my own wish for a good reason.  I wear wool by choice, unless it is going to rain.

"You must choose a meat option, or else you should mark may 'vegetarian' if you do not eat meat.", meaning there is a general rule, but sometimes there is an allowed variation.  Choose a meat, unless you are vegetarian.

Or, of course, "It is illegal for adults to ride a bicycle on the sidewalk except when accompanying minors under the age of 13."  Meaning again that there is a rule, but also an exception.  (Obviously the source of the word 'exception'.)  Bike in the street, unless protecting children.

I hope that helps.

(But if it does, that means this question did not belong here, but instead belonged on English Language and Usage SE instead.  Ask questions of logic here, unless they are really about Engish and not logic...)
In the ancient theorisation of the body politic, social and economic there was a four-fold distinction between priests/philosophers, warriors/kings, merchants/artisans and labourers/slaves (Platos Republic and the Rig Veda).

Marx collapses these into two in the modern era: Labour vs Capital

Arendt is making a similar distinction but theorising it differently - don't capitalists 'work'?

She distinguishes Labour from Work:

Labour is connected to neccessity and the entirely conditioned will; to being a means - ie to tools, to unconstructive and property-less work (for them); to slaves and to animals; it is connected too to inaction; to the lack of speech; thus vita laborans.

Work is connected to freedom and the unconditioned will - free-will; to being an end; to constructive property and being property-owners and to citizens; to being human; to be human is to act. Thus vita activa.

So whilst, Marx as a theorist of the economic order theorised a duality: Labour vs Capital; Arendt distinguishes between Labour vs Work. 

Her main observation is that in the ancient polis labour was small-scale and restricted to the house-hold ie the private realm and did not dominate the public order which was the realm for politics: for the free discourse of citizens; for her this labour has escaped the private realm and entered the public sphere.

To answer your final question: work being aligned being aligned with what is human in us has the higher dignity.
If the claim is 'If my religion is true there will be criticism. There is criticism, therefore my religion is true', then it is a case of http://rationalwiki.org/wiki/Affirming_the_consequent affirming the consequent. 

Affirming the consequent is saying 'If claim A is true then result B is true. As result B is true, then A is true'. This is a fallacy as it assumes that A must be the only  cause of B. In the example above, the religious person assumes that the only possible reason criticism can exist is that his/her religion is true, ignoring other possible causes such as good thinking.

It took me a while to identify the central fallacy, as affirming the consequent in the case that the consequent is criticism spawns many other fallacies. Making criticism of your claim proof of your claim means dismissing criticism on the grounds that your claim is true, which is simultaneously special pleading and circular reasoning. 

I am not quite sure if there is a specific name for when the consequent is criticism from just anybody. If it is cricism from the establishment particularly, then it is the Galileo gambit (I do not have enough reputation yet to post more than 2 links, but you can just search for the fallacies on the website I've linked to above). Of course, the Galileo gambit is very often accompanied by the Shill gambit, which is when you accuse any random critic of working for a corrupt establishment/conspiracy. While the Galileo+Shill gambit is often just called pig-headedness, I propose that we should start calling it the California kale gambit after this poem: http://freethoughtblogs.com/cuttlefish/2015/02/17/how-i-know-im-right/ http://freethoughtblogs.com/cuttlefish/2015/02/17/how-i-know-im-right/
The terminology seems to me to have been borrowed from a version of http://en.wikipedia.org/wiki/Correspondence_theory_of_truth the correspondence theory of truth (roughly, the version of Wittgenstein's Tractatus). According to this version, a statement is made true by something real, a fact, or
is made false by the absence of an appropriate fact. So, if a statement is neither true nor false, it implies that there are no candidate real entities, facts, in the corresponding realm, such that the truth of the statement can be decided by the existence or absence of such a fact. Therefore such a condition has been called anti realism.

The more specific relation to verification-transcendent statements may be an outcome of the actual kind of 'anti realism' that was investigated by the philosopher who coined this term, http://en.wikipedia.org/wiki/Michael_Dummett Michael Dummett. The status of verification-transcendent statements is an old issue surrounding empiricism. Dummett's definition made possible discussing this issue on a general "semantic" level, with no specific ontological commitments.
I see this as two questions:  


Is religion a legitimate part of the history of science?    
Is religion legitimate ONLY as a part of the history of science?


I would say the answer to the first question is a clear "yes." Not only can we view, historically, religious beliefs and rituals as precursors to early scientific beliefs and practices, we can also note that many historical figures, from the ancient Egyptian priests to Descartes, have made scientific advances that have grown out of their religious beliefs.

For the second question, the answer clearly depends on your own religious beliefs.  The most general, neutral evidence for religion having its own, ongoing legitimacy, aside from any historical scientific benefits, is exactly as you mentioned --that many smart, educated people continue as believers.
The short answer is "no". Your main question is whether (2) follows from (1);


  (1) P → Q [ P is a sufficient condition for Q ],
  
  (2) Q → P [ P is a necessary condition for Q ].


The reason the entailment from (1) to (2) doesn't hold is that it's possible that Q follow from some proposition R that is not equivalent to P. The only instance where the entailment is realized is one where all necessary conditions for Q are logically equivalent to P.

A note on your examples. It's true that you must drive to be a good driver: GD → D. And it's also true, since it's a hidden tautology, that you must drive well to be a good driver (and vice versa): GD ↔ DW. But since not all drivers are good drivers, the entailment doesn't hold.
Sartre did use the expression "existence precedes essence" as a motto, but his implied critical target was not Aristotle's general essence theory. It was, rather, the specific idea of human nature. Sartre's expression was meant to express the existentialist stand, that a human being's way in life is not chosen for him in advance, by his own nature or origin. That one has to choose one's way, and that one is free to do so.


  What do we mean by saying that existence precedes essence? We mean that man first of all exists, encounters himself, surges up in the world – and defines himself afterwards. If man as the existentialist sees him is not definable, it is because to begin with he is nothing. He will not be anything until later, and then he will be what he makes of himself. Thus, there is no human nature, because there is no God to have a conception of it. Man simply is. (Existentialism is Humanism)


The order of Descartes's Cogito
(I think, I exist) was epistemological, and Sartre did not challenge it as such. What Sartre did challenge, was Descartes's Cogito-related metaphysical conclusion that the I was a thinking substance.


  The I that appears on the horizon of the 'I think' is not given as a producer of conscious spontaneity. Consciousness is produced over against it and moves towards it, comes to meet it. This is all that can be said. (The Transcendence of the Ego)


Descartes did not challenge Aristotle's category theory, i.e. the division of all entities into substances, essential properties (attributes) and accidental properties (modes). But he strayed from Aristotle's metaphysics in many other ways. For example, concerning which entities were the substances.

Sartre is usually thought to be following in Heidegger's footsteps, not the other way around. Heidegger 
held a principle similar to "existence precedes essence", but he resisted Sartre's interpretation that existentialism was therefore  "humanist" i.e. human-individual-centered.
I keep pushing the intuitionistic view of mathematics, in which the subject of mathematics is our accumulated, shared intuition.  If mathematics arises from our notion of space, that is prior to language, and to culture.  If our notion of accumulating area is inborn, and becomes mathematics when we notice it and express it in language, then whether mathematics controls our thinking depends on which side of the fence of language you are talking about.

From that point of view, we have a shared intuition of area, and we have, separately, formalized ways that try to keep that intuition free and unaffected by individual experience so that it can be shared.  The former clearly controls thought, the latter helps this happen more easily, but probably contributes little control of its own.

At the same time, there are other aspects of language that I feel strongly shape our thinking.  I just gave an example here https://philosophy.stackexchange.com/a/23625/9166 https://philosophy.stackexchange.com/a/23625/9166, and plenty more examples fill Wittgenstein and other language-focussed philosophers.

There is experimental evidence that even these are a selection from among a basic range of intuitions that are promoted or suppressed selectively by exposure.  This is part of the Chomsky theory of generative-transformational grammars.  There is a trans-linguistic "deep structure" representation.

So to some degree, the elements of grammar that I feel deeply shape our thinking are still in the same area as mathematics.  But we choose which aspects of deep structure are most accessible, and which ones will be used together differently in childhood by exposing ourselves to different languages which veil the underlying meaning in transformations and representations.
The following books can most be read by beginners, and most are meant for beginners. I don't cover every topic, because I don't have time to compile such a list:

History of philosophy: 
-Ancient Philosophy: A Contemporary Introduction (Routledge Contemporary Introductions to Philosophy) by Christopher Shields.
(Shields has also edited a book on ancient philosophy which is much more advanced, and not as good, get this instead.)

-Philosophical Analysis in the Twentieth Century, Volume 1: The Dawn of Analysis by Soames.
-Philosophical Analysis in the Twentieth Century, Volume 2: The Age of Meaning by Soames.

(These books by Soames on the history of analytic philosophy are not always historically accurate, but they are still very useful and Soames writes clearly. Perhaps not for a total beginner.)

-On individual philosophers see for example http://www.routledge.com/books/series/SE0831/ The Routledge Philosophers series, some of these are more advanced.

-On some modern philosophers, you might see for example the Key Contemporary Thinkers Series, from Polity/Wiley.

Philosophy of language: 
-Philosophy of Language (Fundamentals of Philosophy), by Alexander Miller.
-An Introduction to the Philosophy of Language (Cambridge Introductions to Philosophy) by Michael Morris is also readable - though Lycan's Philosophy of Language is probably better.

Philosophy of science:
-Theory and Reality: An Introduction to the Philosophy of Science (Science and Its Conceptual Foundations series) by Peter Godfrey-Smith.
-The Blackwell Guide to the Philosophy of Science (Blackwell Philosophy Guides, Vol. 7) ed. by  P. Machamer & M. Silberstein. 

(The first is a popularizing introduction, the second is a little more advanced.)

Logic: 
-Logic, Language, and Meaning, Volume 1: Introduction to Logic by Gamut.

Additional useful books:

-Philosophy and Ordinary Language: The Bent and Genius of our Tongue (Routledge Studies in Twentieth Century Philosophy) by Oswald Hanfling. 

(This book by Oswald Hanfling is pretty amazing, and will change the way you approach philosophical problems, and make you realize why language is so important for philosophy. You don't have to agree with it, but it's a very useful book on philosophical methodology from the ordinary language philosophy perspective.)

-The Cambridge Dictionary of Philosophy 
by Robert Audi. Useful to have.

On Wittgenstein, because you need to read about his philosophy before you die:

-A Wittgenstein Dictionary by Hans-Johann Glock. Doesn't include the new Wittgenstein interpretations, but is still very handy.

-Wittgenstein (Arguments of the Philosophers) by Robert J. Fogelin. Get the 2nd edition.

Other good book series:

http://www.routledge.com/books/series/NPOP/ New Problems of Philosophy
http://www.mqup.ca/browse-books-pages-46.php?filters=a%3A1%3A%7Bi%3A13%3Bs%3A4%3A%223722%22%3B%7D Central Problems of Philosophy
http://www.routledge.com/books/series/SE0276/page_1/ Problems of Philosophy
http://www.routledge.com/books/series/SE0129/ Routledge Philosophy GuideBooks
http://www.routledge.com/books/series/PHILCOMP/ Routledge Philosophy Companions
http://www.cambridge.org/cl/academic/subjects/philosophy/series/cambridge-companions-philosophy Cambridge Companions to Philosophy
http://www.wiley.com/WileyCDA/Section/id-405214.html Blackwell Companions to Philosophy Series

Regarding your comment on the big names. Philosophy does not have "normal science" and "paradigms", so you can't escape the big names approach in most introductory level textbooks. And after all, philosophy is about ideas, concepts, arguments, words, definitions, interpretations, theories, questions etc. and these don't exist in a vacuum but are what humans produce. Often philosophers are not even trying to invent theories, instead their goal might be to analyze theories. 
You can go back to Frege.  There are two kinds of meaning to any proposition, sense (Sinn) and interpretability (Beweis).  Something only has sense if the interpretability can find a reference (Bedeutung).  This is kind of like the propositional logic vs model theory approach to validity.  An argument can be valid in construction, but if the system lacks a model that instantiates its arguments it still does not mean anything.

So we can think a lot of things that have interpretability but lack sense.  It is questionable whether something that lacks interpretability is a genuine thought, or a mere instance of symbol manipulation.  The Tractatus is coming down in the latter camp.  Since propositions that cannot be instantiated are not really thoughts, their expression is not really language.  They cannot contradict anything because they cannot get leverage on meaning.

The latter sentiment does not seem logically connected to the earlier ones.  In my interpretation, he is making a functional interpretation of Plato's position behind anamnesis, that truly important thoughts cannot be stated, but must be conveyed by manipulating one's interlocutor into a position where the meaning will be recognized (as, in Plato's theory, all important thoughts are already in the mind).  (This is arrogating the contents of his work to the status of 'truly important thoughts', which is a bit excessive, to my mind.)

One can make interpretable arguments that basically lack sense, if the referent is simply not available to the listener.  But you can still lead someone to that a sensible thought by means of the nonsense.  (You can grow the accessible models by intension, not just construction.)
Marx was a theorist of Capitalism which he considered the dominant form of economic activity on this era; to be distinguished from earlier ones - such as the mercantile city states and feudalism; or much earlier systems of barter say; as Rosa Luxembourg explained he was focused on formulating the economic laws of motion of Capitalism; and this needs to be distinguished from his work as a critic of capitalism which in a way many people were in mitigating the brutalities of a new system of economic production that hadn't been domesticated yet: the latter part of the first volume of Das Kapital displays his dismay to the 'bare life' (vita laborans or vita zoe) that some working men were reduced to - this part of the book is a kind of study in what today might be called social anthropology.

As Marx was after a scientific explanation of economics he couldn't allow his personal sympathies distort his thinking on the subject; the force of gravity operates no matter how I may feel about plane crashes. 

Communism in one way of thinking is the economic order that comes after Capitalism; in another way of thinking its a specific political programme to force this change; and in another it describes regimes that were named as such as a bloc against the West during the long Cold War. 
I think 'non-sequitur' is a vast overstatement, and this is a mere 'over-generalization'.  And not even very far 'over': the statement cannot generalize absolutely, but it does generalize pretty well.

In a strong sense the homogeneity assumption is itself an application of the Copernican Principle.  It is the assumption that we do not happen to inhabit a place where space is especially 'nice', in the sense of having the "Goldilocks" quantity of matter: that we don't live somewhere too special.

So this is just a disagreement as to what flavor of 'general' is most objective, and either side relies upon a strong injection of the 'Copernican' ideal, but in different forms.

Unwinding your objection to the Big Bang theory -- the weakest point is that it assumes that time is uniform in a very strong sense.  It gets into big trouble if you follow the history of expansion back to when space would have to move objects apart faster than the speed of light in order to expand quickly enough.  So, you can toss out the uniformity of time, but then the rationale behind continuously extrapolationing time back across trillions of years gets a little questionable.  Why shouldn't time have changed again and again?

The notion of the field particles arising out of the Higgs boson early in the history of the universe "when the rules were different" is the same sort of thing, it puts the irregularities away from us, so we feel like that place is special, not ours.  Why assume the rules got decided at a given energy level and then stuck there forever?  Why should they not slowly adapt across time?  (And if we don't get to be special, why does anyone else? Harumph, <pout/>.)

We end up with the notion that time and other basic forces can be significantly different, but in general they are just like we see them where we live.  In the same way the homogeneity of density is Copernican, so is this notion of time and fields.  It is about the familiar being general so that we don't imagine we are special again.

I don't see the disconnection needed to make this a non-sequitur.  The Copernican Principle is properly applied here, and if anything, too healthy.  (From a Nietzsche angle, in rejecting the deductions of our slave-morality religion: that we are all equally special and masters are evil cheaters; we have taken up an even more slave-morality position on specialness: that we are not worthy -- we do not deserve it, but someone must.)

The principle is internally inconsistent as a metaphysical principle: not all notions of 'general' can be equally objective, because we are someplace, and that place really will have some idiosyncratic properties.  And picking and choosing which ones are most objective, just to favor the chosen explanations of our own physics, would violate the principle itself.  Our place would be special in that it allowed us to truly see what was and was not special about it from experimental data.

But that does not undermine its usability as a component of theories.  It just requires compromise between different applications of the principle to be chosen by each theory.  We just have to guess what is and is not special about home until we get a good sense of life abroad.

---- Separate second answer:

There is also a compromise to be struck between the Copernican principle and the (Weak) Anthropic one.  It is not impossible that things work out the way they are because we are here to observe them.  A lot of biologists think we are in the "Goldilocks zone" of energy balance, and life is much less likely to arise at any other point on the spectrum of energy balance because small polar molecules in liquid form are scarce.  And we do not accuse them of being anti-Copernican, we let this idea guide where we are spending public money looking for planets with life.

We could also be in the "Goldilocks zone" of matter distribution, where observers are unlikely to survive elsewhere.  The odds of just one hole goes down, but the theory of massive variations in distribution itself could still make sense.
I think this is a solid question, and one that might be difficult to fit into the format of an SE answer. Thus, I'll try to provide a brief sketch of what I take the longer answer to be.

First, I want to suggest that one needs to be very careful in how one uses "rational"/"reason" and "understanding"/"knowing" when speaking about Kant. In the paragraph where you write about "In both instances", you state "showing that both cannot be rationally proven", but I think this is slightly infelicitious. Kant thinks both causality and the existence of God cannot be known -- but not because they are not related to reason. Instead, it is that understanding / i.e. knowing / is the application of the categories to a thing that has been placed under the manifold of sensibility. 

Thus, it makes no sense for causality to be knowable, because causality is one of the conditions of knowledge. (as in the Sophie's World account of red glasses).

Similarly, God does not fit under these categories either for Kant. Kant rejects the possibility of knowing God in this way through one of his antinomies.



With that distinction in hand, we can turn to the quotation you provide, note the last phrase "directed to moral interests only". It has been argued by several thinkers that the Critique of Pure Reason is a propaedeutic to Kant's moral philosophy, and this is one of the passages that supports that interpretation.

Thus, to see how God and causality differ, we might turn to Kant's moral philosophy, which on a very crude sketch makes causality in the world the antithesis of rational autonomy. This rational autonomy in turn depends on the existence of God. First, God serves as a final judge meting out proportional happiness to the goodness of agents at the end of time (this is called the proportionality thesis). In the Critique of Practical Reason, Kant calls "God a postulate of practical reason" (See 5:122-134). Also see Religion from around page 96.

To put it another way, God and causality belong to two distinct realms that the Kantian moral self finds itself in. In the one realm, the self's actions are determined (causally) by what has preceded the self. In the other realm, the self uses freedom (rational freedom) to determine the course of its actions in a way that is imperceptible when that self is viewed as an object (rendered through the categories of others or even the self) but which is intimately tied to the existence of God.
You're kind of begging the question, assuming that the meaning of life depends on purposes and that all purposes already have been fulfilled.

Indeed, in such a scenario there would be no meaning to life according to that definition. If you would still like to have a meaning of life, you could:


Use another definition of "meaning of life"
Argue that that situation in which all purposes have been fulfilled is merely hypothetical.

You might look at philosopher Margaret Schabas's 2006 book http://press.uchicago.edu/ucp/books/book/chicago/N/bo3637382.html The Natural Origins of Economics, about the emergence of the very idea of “economy.” Schabas is a historically-oriented philosopher who writes clearly for a broad audience.

For an overview of the range of issues about economics discussed by philosophers, and references to their publications, The Stanford Encyclopedia of Philosophy has http://plato.stanford.edu/entries/economics/ an article on Philosophy of Economics. The SEP is currently perhaps the best free, open, net-accessible, high-quality starting point for learning about nearly any area of philosophy.
I will lift a key quote from Marx, as included on https://en.wikipedia.org/wiki/Commodity_fetishism Wikipedia:


  As against this, the commodity-form, and the value-relation of the products of labour within which it appears, have absolutely no connection with the physical nature of the commodity and the material relations arising out of this. It is nothing but the definite social relation between men themselves which assumes here, for them, the fantastic form of a relation between things. In order, therefore, to find an analogy we must take flight into the misty realm of religion. There the products of the human brain appear as autonomous figures endowed with a life of their own, which enter into relations both with each other and with the human race. So it is in the world of commodities with the products of men's hands. I call this the fetishism which attaches itself to the products of labour as soon as they are produced as commodities, and is therefore inseparable from the production of commodities. 


Marx is writing a critique of political economy here, so he is primarily concerned with the theory of value, not "things" in general. Fetishism in general (as opposed to the fetishism of commodities in particular) is an ancient way of thinking, not something new, and Marx clearly recognizes that. Similarly, Marx never suggests that greed and avarice were invented by capitalism. It is a mistake in my opinion (although a common one) to generalize or extrapolate too much from Marx's ideas into the realms of culture, psychology, etc.  

When we "take an origin of the industrial revolution back to the John Key's flying shuttle" we focus on the material forces of production, rather than the social relations of property and production. That precisely misses Marx's point here. For him, technological improvement is the result rather than the origin of modern capital. What, then is its origin? It's the seperation of direct producers from the means of production, which Marx discusses in the chapter on "so-called primitive accumulation". Land became a commodity, peasants were dispossesed of their livlihood. They now had to purchase commodities in order to survive. This was a pre-condition, already taking place in England before what we think of as the Industrial Revolution. The very essence of commodity fetishism is to forget that the unique "freedom" afforded by commodity exchange is premised on the underlying relations of coercion and exploitation. 

Forms of commodity exchange have existed for thousands of years if not longer. But before modern capitalism, there has never been a society in which commodity exchange was the central principle of social reproduction. Venice was an exceptional and early case of city-state ruled by a powerful merchant elite, with a high level of autonomy from the church and the aristocracy. In that sense, it was a society characterized by commodity exchange. In some sense, you could certainly extend Marx's concept of commodity fetishism to that context. But today, the fetishism of commodities is much more pervasive and deeply-rooted then in any previous human society. Marx sees the Industrial Revolution as the turning point because it was then that labor-power in general was commodified to such an extent that capitalism became a "mode of production" in its own right, fully independent of feudalism. 
I think the question you're asking has two features.

One part is merely historical. What is now called "science" or perhaps "natural science" is what was once called "natural philosophy." You can see the remnant of this in the title of the academic degree "Doctor of Philosophy." Philosophy was one of four classical doctorates at one point in the European system (the four being: law, medicine, theology, philosophy). Philosophy is the most expansive of those in its objects of study. In a sense, disciplines separate out from philosophy as the amount of specialized knowledge required to perform them goes up to the point where it is no longer possible to study them as a part of philosophy. Stated in the opposite direction, philosophy keeps only those questions and subject matters which do not resolve out into other methods of inquiry.

The second issue in your question is that you seem to be assuming a certain definition of what "science" means and what it accomplishes. This question to some extent remains a part of philosophy. To put it another way, it's clearly "science" to do the experiment; something is still happening that is science in the interpreting the physical experiment and improving our understanding of the theory, and it's not always clear we can say what that means within the realm of science itself.

Also understanding what specifically the science is doing remains a question for philosophy (are were overthrowing old theories? are we improving and refining the same theory? What is the "scientific method"? Is there one? Are there many? Are they a family of methods? Are they (merely) dogma?
Obviously this is not a reduction to infinite regress, it is a "slippery slope" fallacy.

Theoretically the proponent of the original argument would fully accept eating an animal that had lived out a full life in relative natural comfort, but sees that animals are not farmed that way, and considers the way they are farmed to involve torture of some sort.  Killing them too early, keeping them too constrained, etc.

There are people who go that far with plants, for instance the Jain.  Since the plants entire goal in life seems to be to grow up and spread seeds, thwarting that may constitute 'torture' of a plant.  But they will still eat what falls naturally from a plant if it does not prevent the plant from reproducing.  (They will eat the fruit, as long as they seeds get fertilized, and they will consume the vegetation of annual species, but they will not harvest it alive.)

There is no one who has a notion of what it means to torture bacteria.  So there is no parallelism here.
What the professor would like to have happen is the following:


  Let's suppose you can achieve infinite value with action A, with p(A) = 0.7.
  Let's suppose you can achieve infinite value with action B, with p(B) = 0.4.
  Now, if this infinite value were finite N, we could compare A & B:


  0.7*N + 0.3*(small stuff) > 0.4*N + 0.6*(small stuff)
       because we can ignore the small stuff if N is really big and
       0.7*N > 0.4*N



  So, let's just pick sufficiently big N and do it this way.


This, at first glance, seems like it might be a way to deal with infinity.  (The explicit step of plugging in probabilities and ignoring the small stuff is what was missing in saying that it gives the right answer for certain vs. 1/6th-certain obtainment of infinite value.)  If, for instance, the only possible infinite good is being "saved" by a (single, known) effectively omnipotent monotheistic god, it seems to work out okay.

But let's think about this a little bit more.  How could you accrue infinite value, anyway?  One obvious choice would be everlasting finite value: something has goodness G per unit time, and you can make it happen forever (and apply no temporal discounting).  Awesome!  Then, picking N is equivalent to picking some point sufficiently far in the future and only counting the first however many millennia: N = G*T for some really big T.

However, what if you can accrue goodness not at rate G but at rate 2*G if you take the riskier 0.4-chance method?  Then the two accounts diverge:


  Fixed value N method:


0.7*N > 0.4*N



  Fixed time T method:


0.7*G*T < 0.4*2*G*T = 0.8*G*T


Oops.  So it doesn't even work in really simple cases like this, where finite actions now lead to infinite ongoing outcomes.

More generally, if you have two competing infinite goods,  you are unable to decide between them, because if you pick separate N and N' for the two things, it is no longer true that one will always beat the other: who beats whom will depend on your choice.

As if this weren't bad enough, the consequences of treating infinity this way are rather shocking:  as soon as you can imagine an infinite good that is not completely, absolutely impossible, you are forced to abandon all else in pursuit of it, including consideration of other people.  So, for instance, if you need to massacre and torture an entire civilization in order to save one person for eternity (something which you imagine has infinite value where all else is finite), then it is "rational" and just to do it.

So I don't think you can argue anything that comes out of this is "rational"; the analytic framework doesn't adequately capture the issues that might be at play.

(But you should understand the "make N really big" idea and why it fails mathematically despite looking initially promising.)
My answer to the question as stated is: None. Nobody commits a fallacy at any point in the dialogue, as far as I can see. This is utterly unsurprising--a pair of professional philosophers committing a logical fallacy in a published paper would be like a professional basketball player missing a wide open, no-pressure layup. It can happen, but it's really rare. 

That doesn't mean that the Lewis' positions are correct, It just means that the premises they give in support of their conclusion do in fact support the conclusion. Whether those premises are actually true is the important thing, and that is not a matter of logic. 

There are no generally effective ways of proving which premises are actually true.      
Reagarding Tarski's original motivation, we can see the new English translation of Tarski's 1936 paper :


Alfred Tarski, http://www.tandfonline.com/doi/abs/10.1080/0144534021000036683#.VZ4dGPntmko On the Concept of Following Logically (1936) :



  Even relatively recently it seemed to many logicians that they had managed, with the help of a relatively simple conceptual apparatus, to capture almost precisely the everyday content of the concept of following, or rather to define a new concept which with respect to its denotation would coincide with the everyday concept.
  
  Thanks to the development of mathematical logic, we have learned during recent
  decades to present mathematical sciences in the form of formalized deductive
  theories. In these theories, as is well known, the proof of each theorem
  reduces to single or multiple application of a few simple rules of inference - such as the rule of substitution or detachment - rules which instruct us to which operations of a purely structural character (i.e. operations involving exclusively the external structure of the sentences) one has to subject axioms of the theory or previously proven theorems in order that the sentences obtained as a result of those operations may also be acknowledged as proven. Logicians began to suppose that those few rules of inference completely exhaust the content of the concept of following: whenever a sentence follows from others, it can be obtained from them - by a more or less complicated route - with the help of the operations specified in these rules.
  
  Nevertheless, today we are already aware that the scepticism was here not at all out of place and that the position sketched above cannot be maintained. Already a few years ago, I gave an example - by the way a quite elementary one - of a deductive theory which exhibits the following peculiarity : [example follows of https://math.stackexchange.com/questions/821777/understanding-%cf%89-consistent-and-%cf%89-incomplete-theory ω-incomplete theory].
  
  [...]
  
  The supposition suggests itself that on the route sketched above - supplementing the rules of inference used in the construction of deductive theories with further rules of a structural character - we would succeed finally in capturing the `essential’ content of the concept of following, which has by no means been exhausted by the rules used until now. Relying on the http://plato.stanford.edu/entries/goedel-incompleteness/ investigations of K.Gödel, one can demonstrate that this supposition is mistaken: if we abstract from certain theories with a very elementary structure, then always - no matter how we enrich the stock of rules of inference - we shall be able to construct sentences which follow in the everyday sense from the theorems of the deductive theory under consideration, but which cannot be proven in this theory on the basis of the accepted rules. In order to obtain the proper concept of following, essentially close to the everyday concept, one must resort in its definition to other methods altogether and use a quite distinct conceptual apparatus.

Basically the schemes are the guides to forming empirical concepts, according to the Critique of Pure Reason. The schemes are not merely coordinated with the categories, they are the empirical contents of the categories. The categories, themselves a-priori concepts, are the possible types of empirical concepts: substance concepts, causation concepts, etc. The schemes are modes of temporal pattern matching within the sensory manifold (not all sensory input is spatial, but it is always temporal). For example: if something always found to endure through changes, it would be a prima facie substance. If events of type A are always found to be followed by events of type B, this is a prima facie case of causation. And so on for the rest of the categories.


  Now this representation of a general procedure of the imagination to present its image to a conception, I call the schema of this conception. In truth, it is . . . but schemata, which lie at the foundation of our . . . sensuous conceptions . . . The conception of a dog indicates a rule, according to which my imagination can delineate the figure of a four-footed animal in general, without being limited to any particular individual form . . . time is contained in every empirical representation of the manifold. Thus an application of the category to phenomena becomes possible, by means of the . . . determination of time, which, as the schema of the conceptions of the understanding, mediates the subsumption of the latter under the former.
  (Critique of Pure Reason, "Of the Schematism of the Pure Conceptions of the Understanding.")


As to the objection, that this "collapses Kant's impenetrable wall between appearances and things in themselves", well, it doesn't seem to me to do so over and above Kant's picture of mere sensation. The sensory manifold is located in time and space, which are, according to Kant, a priori (and therefore, subjective) forms. The specific ways in which the sensory manifold is distributed in space and time are however a posteriori, and therefore prima facie correspond to something in the things-in-themselves. Kant apparently thought that you could not really get any further than that, so that the things-in-themselves still remain unknowable. It may be of interest to note that Schopenhauer, in his version of Kantianism, indeed held that empirical concepts can teach us a great deal about the thing-in-itself.
The Vedas say that the Om (pronounced AUM, and better represented as AUM) is the sound (vibration) that was first projected out of Brahman. It is from this initial vibration that the entire universe is created. As it is the manifestation of Brahman in the universe it is equated with Brahman. It is referred to as such throughout many many places in the Vedas. As it is equated with Brahman, both literally and figuratively, prayers are always started by first pronouncing AUM. Some examples are first the Prasna Upanishad fifth chapter. A few verses from this chapter:


  
  He replied: O Satyakama, the syllable AUM is the Supreme Brahman [Nirguna Brahman] and also the other Brahman [Saguna Brahman]. Therefore he who knows it attains, with its support, the one or the other.
  Again, he who meditates on the Highest Person [Saguna Brahman] through this syllable AUM consisting of three letters, becomes united with the effulgent sun. As a snake is freed from its skin, even so he is freed from sin.
  ...And also through the syllable AUM he realizes that which is tranquil, free from decay, death, and fear, and which is the Highest.
  


and the Mandukya Upanishad (I.) says:


  Harih AUM! AUM, the word, is all this [i.e. the whole universe]. A clear explanation of it is as follows: All that is past, present, and future is, indeed, AUM. And whatever else there is, beyond the three-fold division of time--that also is truly AUM.


other examples include Katha Upanishad (I. ii. 15) "It is AUM"; Katha Upanishad (I. ii. 17) "This AUM is the best support"; Taittiriya Upanishad (I. viii. 1) "AUM this word is Brahman."

Swami Nikhilananda says (The Upanishads, V2, pp 223-224):


  The ultimate identity of AUM is thus explained: The phenomenal world consists of ideas or mental states. Ideas depend upon words fpr their expression. The utterance of the word AUM (A,U,M) gives the clue to the pronunciation of all words or sounds uttered by human beings. The various parts of the vocal organ that are used in the utterance of all sounds are also used in the pronunciation of AUM. Therefore AUM is the matrix of all sounds, which in their diversified forms give rise to the words used in language. The sound A, coming from the throat when the mouth opens to utter any word, is the beginning of all sounds. The sound M is the final sound when the lips are closed. And the sound U is the rolling forward of the impulse which has been created in  the throat and which ends with the closing of the lips. Thus when AUM is uttered, all the various  parts of the vocal organ needed for uttering words are used. Therefore AUM is said to include all sounds. The substratum of all sound is AUM, and the substratum of phenomena is Brahman. The sounds signifying the phenomena are non-different from the phenomena, since both are illusory. When the illusion disappears. there remains only the substratum, which is one and admits no difference. Therefore it is said that Brahman is AUM.   

Synchronicity or mysticism is hardly mentioned in respectable philosophy.  A recent mention in psychology (quoted below) throws some light, and Stanislav Grof writes interestingly about it.  Synchronicity and mysticism seem to be a better subject fit for psychology than analytical philosophy.  It's such a different paradigm, akin to speculating that reality is plastic on a fundamental level.  The impenetrability of the Ding an such (thing-in-itself) would disappear, but experience of synchronicity merely suggests that it might be permeable.

Stanley Schneider's essay 'The Mystical and Spiritual in the Large Group' can be read online here:- 

http://books.google.com/books?id=Wa3IX8s-XakC&pg=PA73#PPA78,M1 http://books.google.com/books?id=Wa3IX8s-XakC&pg=PA73#PPA78,M1 


  Mystical influences were 'in the air.' 
      In 1933, Freud stated an opinion that brought his public  coolness towards the occult closer to his private interest and  desire for
  further understanding: 

"No doubt you would like me to hold fast to a moderate 
 theism and show myself relentless in my rejection of 
 everything occult.  But I am incapable of currying favour 
 and I must urge you to have kindlier thoughts on the 
 objective possibility of thought-transference and at the 
 same time of telepathy as well."  (Freud 1933, 
 New Introductory Lectures, p. 85)


Given that in your quote Hitchens himself says that this koan is only "attempted" and is a "brief parody," it seems unlikely that Hitchens spent long pondering his own sentence.

Given that this occurs in the context of thought, reflection here likely means contemplation of an idea. The joke comes in, of course, that contemplation requires thought, which requires a mind, which the irritating sign indicates should be left at the door.

I am not an expert in either Hitchens or Eastern thought, but I would mention that my own religious tradition finds the idea of abandoning one's mind at the door every bit as irritating as Hitchens finds it. As anyone who has read Augustine or Aquinas (for only two examples), reason is an important element to at least some religious traditions.
First, arguments from your opponents stated motivation are obviously flawed.  He is using an inappropriate notion of cause, and therefore of solution:

Follow the argument down to its logical closure: It is likely given the number of minor infraction for which, via this argument, would get you wounded or killed, that basically no one would want to live in such a world.  The level of stress and fear would simply be too high.  Following the proposed pattern, if no want wanted things this way, we would all just kill ourselves.  Problem solved?  No.  This points up the fact that eliminating a problem is not solving it.

Where does the distinction arise?  Fairly early: If I decide to solve a mechanical problem in my car by disposing of the car, I am not solving the problem.  The problem is that I do not have a functioning car, and after disposing of the car, I still do not have a functioning car.  We need a definition of 'solved' that makes sense, and that involves discerning the functional failure of the system and addressing it.



But thwarting one argument against something does very little toward showing it is actually false.

There might still be some other way in which violence might be applied to every problem.  To really undermine the idea that violence solves every problem, you need an important example where violence never really helps.  (If it helped at all, it might still be the lynchpin of the application, the thing that tips the balance, breaks the final impasse, and therefore really solves the problem.)

Getting correct information from other people is such an example.  Nor is it a trivial example.  Much of the functional failure in our society is about ineffective communication.  And much of that failure to communicate is based in fear.

For instance, leaders arrange to control the knowledge of their acts so that they will not be held accountable, and the decisions they make as a result create opportunities for corruption and political inefficiency.  Producers make sure that others do not know how to truly evaluate the quality of their products so that consequences of lower quality seem accidental and are not traced back to them.  This prevents honest competition and makes markets inefficient, as well.  So failure to communicate truthfully is a major problem for any political system.

This fear works in a way that is not amenable to solution by creating additional fear.  Since most violence short of murder does raise the level of fear, you are caught in a place where violence cannot help you.  (And, obviously, killing someone permanently prevents getting any further information out of them.)

To see how adding fear does not help, look at torture.  We know from studies of torture that additional fear or pain motivates one to give information, but it primarily motivates lying.  If someone will give you truthful information under duress, they would generally have given it to you without the use of violence.

This is disputed at great length, and lied about in Congress and in fiction, but the data are clear.  No matter how you abuse or threaten someone, with direct pain, psychological force, threats to loved ones, etc., the primary effect is to garner false information, mostly false confessions or false implications of the guilt of innocent people.

Other uses of violence to get reliable information suffer the same intrinsic failure -- it is far too easy to lie; lying preserves the speaker's worth just as much as, and often more than, telling the truth; and lying makes one feel like one has some control, some ability to thwart the person harming you and get a minimal revenge.  So, knowing that adding fear primarily creates lies, instead of more truthful communication, in what way can violence solve the huge number of problems traceable to this single cause?

Since we cannot get better information from others by violence, if violence is to solve our information-related problems, it would have to be by preventing there being information we must acquire from others.  We can only have privileged access to all information through some form of totalitarian surveillance.

But again, the data are clear.  We have studied police states and surveillance in cults.  To the degree that actual violence is a part of surveillance, it creates fear of the consequences of misunderstandings.  Even if you are innocent, you can look guilty and get punished.  People act on this fear, causing subterfuge, sabotage and rampant basic dishonesty to undercut the effectiveness of the surveillance.

The logical reaction is to increase the consequences of lying, but enforcing those consequences would require knowing who is lying, which involves getting information that is already being withheld effectively.  So there is no actual point of application that will make it a better risk for everyone to tell the truth.

So, the problem remains unsolved, and it is hard to imagine better applications of violence that have not been ruled out by what we already know about how people naturally react to being controlled with violence.  (We know a lot.  We have been doing it for a long time.)

You can escape this by defining down violence to more subtle forms.  For example cults can achieve very complete control of truth, and surveillance through authority, guilt, and fanaticism, as long as the enforcement is not seen as violence.  Once it is, members naturally collude in resisting it.

But that is just cheating.  Social coercion and more subtle means of control simply are not violence.  So even in the most bloody-minded, psychopathic picture of the world, violence fails us in addressing one important range of problems.

(Obviously, I don't personally accept this psychopathic, war-of-all-upon-all worldview.  But it is part of the general argument for violence, so it is a better frame for an argument toward contradiction.)



But the opposite extreme argument, that violence is unnecessary and can be done away with, which is what you presumably want help defending, is also flawed:

If you don't have organized violence, given that agreement is never total and destruction is always an option you cannot take away from people, you will have disorganized violence.  And it may be preferable to go that direction, but then that is not a society where violence is unnecessary, it is one where it is tolerated and shaped, so that it might be contained.

And I am offended that your impossible goal is so strong a thread in our ethical tradition.  To me, it betrays a deep, patriarchal Statism based on basic internal contradictions that any clear-eyed ethical thinker should see through.

That entire inclination in Western thought hits me as simply classist/sexist dismissal of the working-class/male role outright.  Marcuse aside, we cannot universally adopt the middle-class/female privilege of choosing to put aside aggression and presuming someone else will coordinate protection.

By shifting the duty to protect us up to some idealized proxy Father in the Sky or the Statehouse, we have not eliminated the violence involved, or even reduced it.  We have simply concentrated it, and we either encourage specialization in violence, which encourages abuse, or we force a greater duty upon the unwilling.
The idea of the proof is simple: assume we have a prediction device which answers "yes or no" questions, then show that there is a Boolean function of the state of the universe that the prediction device cannot predict.

What is this function?  It is the negation of the answer given by the prediction device!  This is considered a function of the state of the universe because the prediction device exists within the universe.  Stripped of all its complex notation and jargon, the proof is a restatement of a logic puzzle: if there is a computer that gives "yes or no" answers and knows everything, what question can you ask that it will not be able to answer?

"Will your answer to this question be 'no'?"

Does this really refute determinism?

Wolpert's model of a prediction device is defined as a pair C of functions (X,Y) with domain the possible wordlines (in philosophy jargon, nomologically possible worlds) u of the Universe U, where X is the 'setup function' (with no codomain defined in the paper) and Y is the 'answer functon' with codomain {0,1}.  The setup function X maps to initial states of the prediction device--X(u) is the initial state of the prediction device in the worldline u of the Universe, including its input.

Then the proof simply shows that the device C = (X,Y) cannot predict the function ~Y: whenever Y(u)=1, ~Y(u)=0, and obversely.

Note that there is no dependence of the answer function on the setup function.  For distinct answer functions Y, Y', prediction devices with identical setups C=(X,Y) and C'=(X,Y') give different answers.  To prove non-determinism, Wolpert has assumed non-determinism!

This has the strange consequence that if we built a machine C = (X,Y), and found that there were a function of the universe ~Y that our machine could not predict, there would be a machine C' = (X,~Y), physically indistinguishable in its initial state from C in all possible worlds (since the setup function is the same) which predicted the "unpredictable" function ~Y perfectly! 

To remove this circularity, could we use this argument as a reductio, i.e., assume determinism, so that any machines with distinct answer functions Y, Y' must have distinct setup functions, and then derive a contradiction from the assumption that some machine predicts the negation of its answer function?  No: the argument becomes completely trivial--of course the machine (X,Y) doesn't predict the function ~Y, because our assumption of determinism implies that for each u, the initial state X(u) determines the output Y(u).

In other words, if Y is not determined by X, then although it is trivial that a machine with answer function Y cannot predict the function ~Y, we can at least claim that "No matter how the device is set up, there is a function of the state of the universe it cannot predict"--as Wolpert says in the paper, even if the device is given the correct answer in its input, it cannot predict the output of the function correctly.  This sounds impressive, until we realize that this is because we've already assumed non-determinism.

But if we assume that the initial state of the device determines its output, then the proof result reduces to "If a machine is set up to output some values, then the values it is set up to output are not equal to the negation of these values."  

We have either circularity or triviality.

The door to determinism remains open.
After your comments I assume the last line claims "Exists x Likes(x,carl)". 

To prove the claim, take x = carl. 

If in line 2 you take x = carl and y = max, then line 1 with Likes(x,y) implies Likes (x,x), i.e. Likes (carl, carl), q.e.d.

Do you agree?
The experience of the current moment being different from the memory of the previous moment is a discrete phenomenon.  Our memory is instantaneous and qualitatively isolated from any other remembered moment.  Memory is not continuous, it is itemized.  Each event we attend to has the feeling of two-oneness, of becoming an event.

But if we back away from our concrete memory and concentrate on the possible memories we might have had, we find that we might have had memories between any two we actually have.  Consciousness is continuous, even if perception is not.

To put this in less vague frame, look at how it plays out in actual phenomenal experience near the limit of our processing resolution.

In "Consciousness, Explained", Daniel Dennett describes the experiment where a red light on one side of our peripheral vision and a green light on the other, when flashed too close together for them to be processed separately, get perceived as a single moving object that changes color.

We perceive the single event of there being a ribbon of light across our visual field which is red on one end and green on the other.  But in retrospect we can identify the point where our brain assigns the (illusory) change in color because we naturally force continuity on our discrete sequential experience.  So time is experience as continuous, but the experiences are discrete, and mapped onto the continuum artificially.  

Since the interpolated continuity is at a different level of processing, and not made up of the actual discrete events, but interpolated from them, one cannot connect them in a way that makes the continuum a collection of points.  We are prevented from undoing the illusion, because it is necessary to our narrative arc.  From an extreme position, if we want to be intuitively motivated, we should respect this difficulty as natural to our psychology and not pretend we can remove it.
We allow the wealthy to displace the homeless from unoccupied buildings whether or not they have a better use for them and whether or not the displaced people might be expected to die as a result.

Presumably that means that most of us hold moralities that allow this to happen.

If nothing else, our organs are our most closely held piece of personal property, and it is never inappropriately earned.  They are naturally given in utero, and all maintenance and growth are the work of one's own body.  So in any morality that allows for properly acquired wealth to be unequal enough to cause starvation, and for stolen wealth to be reacquired by the holder, it would be within your right to reacquire the organ.

Such moral systems tend to be hard to ground theoretically or to state clearly.  

I do think Kant, or some more naturalistic version of "limited interchangeability" imposes a more limited right to private property, and an obligation to make some attempt to support those in desperate circumstances.  And that you can derive advice here directly from Kant.


We can consider that the person taking another's property is always addressing them as a means, and not an end-in-themselves.
You can rule out the notion that one may steal to stay alive, because one can never really know the consequences of one's theft, and it might simply cause another's death to take place in your stead.  It is better if the reallocation of goods takes place in a way that is effected more indirectly, so that it cannot be used too easily as a weapon.
But it is difficult to uphold revenge or recovery in Kant, because we see how it leads directly to endless revenge when two sides disagree on the value of the things taken or retaken.  In this case, the value of the organ is seriously different for both sides, but still quite high -- we all have two because they tend to wear out, so if I let mine be taken, I might die younger.
At the same time, a complete right to retain property, that regularly results in death, is itself a weapon, aimed at the destruction of the 'surplus population', and treating those who do not fit well into society as means and not ends.  Witnessing suffering degrades future moral capacity unless one responds to the empathic pull that is the sentimental reflection of duty.  (This is harder to base directly on theory, but it just seems obvious.  And it is a lemma Kant derives in making his argument for limiting one's consumption of animal products to what can be produced without cruelty.)
When communities have themselves set up mechanisms that attempt to prevent the poor allocation of goods from resulting in death, it is best that everyone be equally subject to them.  So, since in this case there is a vast system for voluntarily donating and recovering organs, theft of them should be discouraged, as it will degrade that system.


From that I would propose that I should be prevented from taking back the organ, but that I should be placed on whatever recipient list the individual stealing it would have occupied.  I do have some right to recover the stolen goods, but not to kill in the process, and there is a way for this to happen.

Since I think you should be prevented from threatening the holder's life, whatever his relationship to the threat, your follow-up question doesn't come into play.

How recompensation for the organ itself should be managed is a really difficult call.  If the person who needs the kidney bought it on the black market, for instance he has substantial money, and that could be used.  But if the sufferer is really basically impoverished by his illness, he has a debt that he will not be able to pay.
Zeno is known not only for Achilles and the Tortoise. He is said to have written a book, but the book hasn't survived (or hasn't been discovered). We know about https://en.wikipedia.org/wiki/Zeno%27s_paradoxes nine of his paradoxes from Aristotle's Physics. Among them the Dichotomy, the Arrow, the Stadium.

The Arrow argues that when an arrow is shot, at each moment it occupies some place. Therefore, at each moment the arrow is at rest in that place. Therefore, the arrow does not move. For nothing can move and rest at the same time.

The Arrow is, then, an argument against the reality of movement. It pictures every moment as independent of the others.

The Achilles paradox, on the other hand, is not merely against the actuality of movement. Even if we accept that each moment is independent of the others, we still face the Achilles problem: Achilles cannot pass the tortoise, but we see that he does. Therefore what we see is an illusion. And what do we, in general, see? The Achilles seems to be an argument against the reality of time, not merely in the sense of change and movement, but more generally as a static manifold, as a plurality. We are supposed to conclude that time, as we know it, does not exist, not only in the sense of movement and change, but in the sense of a genuine manifold, of a genuine plurality.
It was Galileo who first seriously suggested we remove the distinction created by Aristotle between two realms with distinctly different physics.

In "... The Two Chief World Systems ...", he introduces the notion of the inertial frame of reference, as experienced on a boat, as the normal compromise between the stationary and the moving, and suggests reasoning about the heavens as large moving objects more like boats, and less in an idealized a priori way.

Newton had already a century or so of other thinkers inspired by Galileo before he proposed a single unifying law in a mathematical form that would explain both equally well.  This included Kepler, who solved the primary problem Galileo's astronomy introduced -- that circular orbits do not capture most of the subtleties of planetary motion, but elliptical ones do.

Newton has to have been moved by the quadratic nature of Kepler's astronomical geometry, and Galileo's knowledge that gravity on earth was quadratic.  (The rule is captured in the book in terms of Fibonacci numbers, but that breaks down straight into squares.)  So our tendency to think this was just single act of genius and not an integration of scientific details, is kind of overstated.  In fact, if Hooke is not lying, both of them computed the same position of a comet based on Kepler, by fitting it to a conic section, before Newton's work was published.

In the text, Galileo does not seem to employ the principle of sufficient reason per se, but he relies strongly on the idea that needless variation, especially when it must be extreme, is an indication of a poor argument.  For instance, if the stars move on the spheres, some spheres spin at different rates than others to achieve the apparently consistent motion of the skies on Earth, the farthest spheres must turn quite quickly, whereas if the Earth spins, then stars at all different distances from us just move at some fairly consistent speed.

(He also continually points out that Aristotle himself would not put up with the level of authority assigned by everyone to Aristotle himself.  So he may have wanted to avoid dependency on other a priori notions in Aristotle on the modern side of his argument.)

Whitehead in "Science and the Modern World" seems to think that from Thales on, almost everyone presumed that physical laws were uniform throughout the universe.  He thinks that this notion of trustworthy uniformity is somewhat characteristic of the West, reflected in Greek drama and Roman Law, and is a sort of shared para-religious impulse behind the nature of our science. 

That makes Plato's and Aristotle's notion of two separate realms kind of an aberration, that was eventually ironed out.
Yes, the original http://plato.stanford.edu/entries/democritus/#2 atomic theory, usually attributed to Leucippus and Democritus, was formed in part as a response to Parmenides' arguments against the reality of movement, and to the related paradoxes of Zeno's. The Democratic atom possesses some of the properties of the Parmenidian One: It is neither created, nor destroyed. It also never changes, intrinsically, but only in relations to other atoms. One could say that while Parmenides rejected the reality of relations altogether, Democritus made them the basis of contingency and movement, keeping intrinsic properties fixed.
To the extent that eternal and indestructible indivisibles (atoms) express conservation of matter we should credit it back to Leucippus and Democritus rather than Lucretius, he was simply poetizing Epicurus. However, a global conservation law does not have to be tied to counting, and by implication to a finite number. The "sum" that "remains undiminished" may just as well be interpreted as the sum (union) of atoms as elements of being, after all atomists were among the few in antiquity to admit actual infinity, to claim contra Aristotle and Euclid that magnitudes do split into indivisibles, and even to https://www.academia.edu/3051043/Epicurus_and_the_mathematicians_of_Cyzicus reject Euclidean geometry because it was inconsistent with existence of the smallest length. Together with postulation that each atom retains individual identity for all eternity this is a clear expression of a global conservation law. Lucretius then derives his local law from the global one: decrease of atoms in one object is exactly equal to increase in another. Or as we would say today, change of matter in any volume is equal to the flux across its boundary.

Parmenides, Plato and Aristotle meant ex nihilo nihil est in a somewhat broader sense, I believe. Not applied (just) literally, but more broadly and abstractly as a causality principle: every move needs a mover, every effect needs a cause. And of course Aristotle's causes are more than just material and effective. As for appreciation of the atomists' natural philosophic conservation law in antiquity the conditions were not right. It finds its proper context in dynamics, indeed mathematical fluid dynamics, and not only was ancient physics far removed from that, but atomists cut themselves off from even mathematical statics and kinematics by rejecting Euclidean geometry.
It is true that Hobbes held that sovereignity without absolute power is not a sovereignity in the true sense of the word. However, this is marginal. Hobbes was not much concerned with formal problems, like the sense of sovereignity or infinite regresses. He was more concerned with the concrete prospects of war and violence. His substantial argument was that without an arbitrator with decisive power, violence and treachery are imminent everywhere, and life becomes insufferable.


  The only way to erect such a Common Power, as may be able to defend them from the invasion of Forraigners, and the injuries of one another, and thereby to secure them in such sort, as that by their owne industrie, and by the fruites of the Earth, they may nourish themselves and live contentedly; is, to conferre all their power and strength upon one Man, or upon one Assembly of men, that may reduce all their Wills, by plurality of voices, unto one Will. (Leviathan, "The Generation Of A Common-wealth")


The divine right of kings when it is accepted by the people is indeed a powerful factor of stability, in Hobbes' sense. However, although Hobbes defended absolute sovereignity, he  decidedly did not recognize the divine right of kings. He argued that such a status existed only in the special circumstances of the biblical Jewish nation. There was no basis, Hobbes argued, for a similar status among Christians. Religious ministers ought to have no say in political matters. This is supposedly reflected also in Christ's own instruction to his followers to submit themselves to whoever is the prevailing ruler, even an infidel.


  Another Argument, that the Ministers of Christ in this present world have no right of Commanding, may be drawn from the lawfull Authority which Christ hath left to all Princes, as well Christians, as Infidels. (Leviathan, "From The Authority Christ Hath Left To Civill Princes")

I'll suggest this approach, using Natura Deduction (see : Ian Chiswell & Wilfrid Hodges, https://books.google.it/books?id=JeUDUWYD5eQC&printsec=frontcover Mathematical Logic (2007)) :

1) ∀x∀y((S(x,a)∧ S(a,y))→S(x,y)) --- premise

2) ∀x¬S(x,x) --- premise

3) ¬S(x,x) --- from 2) by ∀-elimination

4) S(x,a) --- assumed [a]

5) S(a,x) --- assumed [b]

6) S(x,a) ∧ S(a,x) --- from 4) and 5) by ∧-introduction

7) S(x,a)∧ S(a,x) → S(x,x) --- from 1) by ∀-elimination twice

8) S(x,x) --- from 6) and 7) by →-elimination (modus ponens)

9) contradiction with 3) and 8) and thus by RAA (reductio ad absurdum) applied with 5) :

10) ¬S(x,a) --- discharging [b]

11) S(a,x) → ¬S(x,a) --- from 4) and 10) by →-introduction, discharging [a]

Now, the ausiliary assumptions [a] and [b] have been discharged, and we are left with the premises 1) and 2) where x is not free; thus, we can apply ∀-introduction, concluding with :


  ∀x(S(x,a) → ¬S(a,x)).

I think the confusion comes from schematic identification of logicism with realism, intuitionism with conceptualism, and formalism with nominalism, referencing positions in the old debate on the nature of universals. This is mostly right, but not quite: Hilbert is a nominalist about mathematical objects, but he is a conceptualist (Kantian) about mathematical symbols and their manipulation. "The subject matter of mathematics is... the concrete symbols themselves, whose structure is immediately clear and recognizable". The difference with intuitionists like Brouwer is that they were conceptualists about mathematical objects, not just symbols. 

In fact, this was Hilbert's original innovation. He considered (idealized) mathematical symbols as objects of a priori perception in a way similar to Kant's view of arithmetic as a priori synthesis in time (hence their agreement against Frege, to whom arithmetic was analytic), and geometry as a priori synthesis in space. But Hilbert extends this to formulas of algebra, formal logic, etc., by merging both space and time into a joint medium of syntheses. These are the "logical concrete objects that are intuitively present as immediate experience prior to all thought", "a condition for the use of logical inferences and the performance of logical operations". A condition of the possibility of certain knowledge, also very Kantian. But Hilbert's extension of Kant gives much more: we can have synthetic a priori knowledge of logical consequences of all our axiomatic theories. Indeed, their proofs are analogous to Euclidean constructions in geometry, they are a priori syntheses of imagination, but based on symbols rather than figures. 

This Kantian, in spirit, view of symbolic manipulation explains the key goal of Hilbert's programme: establishing completeness and consistency of mathematics by finitary means. While there is no restriction on the nature of objects that we choose our symbols to represent, there is a restriction on what we can do with those symbols. Only constructions of finite length, although potentially unbounded, are accessible to our Kantian faculties. But should we manage to reduce all our proofs to such constructions we will get the holy Grail: a synthetic a priori certitude for all of mathematics. Alas, this optimistic hope was proved unattainable by Gödel.

See https://books.google.com/books?id=gUeTAgAAQBAJ&pg=PA67&lpg=PA67&dq=hilbert+nominalism&source=bl&ots=YuODVOA5vR&sig=YM2OGV6a9qHMN4Vl6QRiD05dV2M&hl=en&sa=X&ved=0CDgQ6AEwBGoVChMI84WIsJ_6xwIVhBuSCh306g29#v=onepage&q=hilbert%20nominalism&f=false Brown's Philosophy of Mathematics for more details.
It depends very much on how deeply you wish to delve into the works of a particular philosopher.  Many general concepts translate well, and you can learn a lot using only translated works in your native tongue.  However, the devil is in the details.  Many of the best philosophers pushed the boundaries of their language, and when one does so, it becomes remarkably hard to effectively capture the intent of the philosopher when undergoing translation.

I can give two examples.  The first is an incredibly common case.  Everyone who has interacted with Christianity in English knows "Thou shalt not kill."  However, that is not necessarily the most ideal translation.  The phrase in its native Hebrew is "לא ירצח".  The word translated as "kill" is the verb "רצח".  Most modern scholars believe that word is more effectively translated as "murder," not "kill," indicating an "unlawful killing," but with other meanings such as "to break, to dash into pieces."  Needless to say, it gets complicated when one discusses "unlawful killings" in a document often referred to as "the law."  For the majority of applications, the translation as "Thou shalt not kill" is sufficient.  However, when discussing the ethical implications of warfare with respect to Biblical law, it is essential to know the difference.

The other example is a favorite of mine  is found in Sun Tzu's Art of War (disclaimer: this was my own study as a layman who really doesn't know enough Chinese to do such interpretation. Of course, I think my child is perfect in every way, just like every parent!).  This book is often recommended to business professionals to explore parallels between the business world and war.  In the first chapter, as translated by Thomas Cleary, we find:


  Therefore measure in terms of five things, use these assessments to make comparisons, and thus find out what the conditions are. The five things are the way, the weather, the terrain, the leadership, and discipline. 


He then goes to talk about each of them.  This is a fine translation, and captures a great deal of the intent.  However, more meaning is found in the original phrasing of the second sentence (I provide a Pinyin pronunciation and gloss here, from (https://eastasiastudent.net/china/classical/sunzi-bingfa-shiji/ source).  The source also has the original words, as written by Sun Tzu.  Stack Exchange's text format doesn't allow Chinese characters, so I had to omit them here):


  Yī yuē dào, èr yuē tiān, sān yuē dì, sì yuē jiāng, wǔ yuē fǎ. 
  [one] [say] [Way], [two] [say] [Heaven], [three] [say] [Earth], [four] [say] [General], [five] [say] [Method]


Just from the gloss, we can see minor differences.  For one, "weather and terrain" have been glossed as "Heaven and Earth."  This is where we can dig into the the cultural implications of Sun Tzu's actual words.  "Dào" is a fundamental Chinese concept that you can spend a lifetime exploring and never fully understand it, but it can be described as the way everything flows (somewhat analogous to our concept of the universe).  "Tiān" and "dì" are literally Heaven (or Sky) and Earth, so the gloss captures them well.  In The Daoist cosmology, oft represented by three horizontal lines on top of each other, heaven is above (the top line), the earth is below (the bottom line), and man is in between (the center line).  The next two characters are complicated.  "Jiāng" is great fun,  often thought of as a symbol for "meat" and "hand," referring to nourishment.  It can be translated literally as General, in the military sense, but the word is also oft translated as "will," or even "future" ("will" being an essential human trait for putting food on the table every day).  "Fǎ" is another complicated word with many translations.  It has  been translated as "law," "discipline," as well as many others (including the glosses' translation as "Method" with a capital M).

If one looks at it from this perspective, one has the way everything moves, heaven, earth, and the will and discipline of man in between.  While the translation by Cleary may direct one to look at a set of things.  The study into the original words suggests an alternate mindset Sun Tzu might have been inspiring: pay attention to Everything, categorized in the traditional Chinese manner of The Dao, Heaven, Earth, and ways of Men.  Sun Tzu recommends a general never forget to perceive anything, never omit any detail presented before him.

I spent many hours on this sentence, trying to explore its meaning in its original language.  I readily admit that I probably still got it wrong (shameless plea: any who speak Chinese, please correct any inadequacies in my work!).  However, I find it an excellent example of what you can get from a translation versus what you can get with an in depth study in the native tongue.
You may want to refine your question in terms of "human dignity" as distinct from "human rights." While it is often invoked, I am not sure that "human dignity" is well-defined or anything more than a vague appeal.

In Kant's deontic ethics there has always been a tension between the categorical imperative to act in accord with "universal maxims" and the treatment of each individual as an "end in him/herself." The latter might be called "human dignity" as an essential and incomparable value. But even if we leave "dignity" vague in this way, we can still have big problems with "human," as in cases of abortion, euthanasia, artificial intelligence, or bioethics. 

In utilitarian systems, such as Hobbes, Bentham, Singer, or Buddhism, the "human right" is defined negatively as the reduction of misery or suffering, which can then be extended as far as "all sentient beings" with the capacity to suffer. But here generally individual "dignity" is contravened by some "summum bonum" or the avoidance, as in Hobbes, of the "summum malum." 

In Marxism, utilitarian "human rights" are looked upon with suspicion, since they are rooted in, reducible to, and idealizations of the right to own property. This "right" then functions to degrade real human "dignity" in the capacity to be free, social, and creative beings. Real dignity or "self-worth' becomes completely indexed to property.

My inadequate answer, then, would be that most ethical systems make some appeal to "human dignity" in the sense of some immeasurable, in-exchangeable worth by which human beings are naturally "recognized" and cared about. But the system becomes "ethical" only as it begins to define, restrict, and rationalize this overly broad starting point into rules of action and reciprocity. 

If some absolute "dignity" (etymology: "privilege, honor, worth") accrues to human individuals or families, say, then the purest ethics of "human dignity" would be the bloody world of the Iliad or the Medieval lord where each subject struggles for recognition of his honor and his unique "human" willingness to die for it.                  
One of the fundamental principles of quantum mechanics is the principle of superposition. Its most simple application reads: If two paths exist to move from state A to state B, then the transition function (psi-function) develops to the final state as the sum of the two separate transition functions.

The double split experiment has two different paths from A to B. Hence there are two transition functions which have to be considered. The experiment can be executed with individual photons, one photon after the other is sent through the double split. If the experiment performs undisturbed then both transitions functions of a photon are coherent and interfere. In the experimental setting the double split is substituted by a beam splitter which produces a left and a right beam.

For the theoretical proposal, the experimental setting and the interpretation of the result of the delayed-choice quantum eraser see


Brian Greene: The Fabric of the Cosmos. 2004. p. 101ff
Aharonov, Yakir; Zubairy, Suhail: Time and the Quantum: Erasing the Past and Impacting the Future. Science, Vol. 307, 2005, p. 875-879


Scully and Drühl in 1982 propose a means to tag photons differently after leaving the beam splitter. Tagging adds to each transition function a different which-path information. As expected, this tagging destroys the coherence. The result does not show any interference. 

Secondly, they propose a quantum eraser which removes the tagging just before the final detection of the photon. As expected, the two transition functions with erased which-path information interfere. 

As a third step, Scully and Drühl propose a delayed-choice quantum eraser. Behind the beam splitter each photon is down-converted to a pair of entangled photons of half frequency. One photon of the pair is named the signal photon, the other the idler photon. The idler photon is tagged with which-path information. 

Now, the transition functions of the signal photons are treated as before. But the idler photons, each carrying the which-path information of it and its signal partner, are either observed separately and their which-path information is read off. Or they match and loose the which-path information. 

The astonishing result of the experiment emerges when separating the paths of the signal photons from the paths of the idler photons by a far distance, e.g. 10 light years. Assume that today the signal photons terminate their path. One observes non-interference of the signal photons, because their which-path information still exists, namely contained in the transition function of their idler partners. 

10 year laters also the idler photons terminate their much longer path. They are detected either after matching or they are detected in separation. Now one can single out those signal photons whose idler partners have matched and thereby erased their which-path information. The subset of the corresponding signal photons provides an interference pattern.

Greene draws the following conclusion:


  Again, let me emphasize that the future measurements do not change anything at all about things that took place in your experiment today; the future measurements do not in any way change the data you collected today.


Hence the answer to your original question is: The delayed-choice quantum eraser is no refutation of the principle of causality. The future event does not change the past event.

Green continues:


  But the future measurements do influence the kinds of details you can invoke when you describe what happened today. Before you have the results of the idler photon measurements, you really can’t say anything at all about the which-path history of any given signal photon. However, once you have the results, you conclude that signal photons whose idler partner were successfully used to ascertain which-path information can be described as having – years later – traveled either left or right. You also conclude that signal photons whose idler partners had their which-path information erased cannot be described as having – years earlier – definitely gone one way or the other […]. We thus see that the future helps to shape the story you tell of the past.  

Bootstrapping generally means the evolvement of things without the need of an additional external influence or input by a simple...let's say "algorithm".

An aristotalian deduction (as most philosophy, I think) usually starts by a normal fact analyzing its conditions by "thinking it right", that is following the rules of logic most prominently established (rather: written down) by himself. By this, you get step by step a deeper insight of what it means to be/do this and that.

I think the author called it specifically Aristotelian because he is thought to be the first who did this in such a systematic manner for almost everything that occured in his life.
The quote is from the preface, chapter 6, of On the Genealogy of Morality: A Polemic. When Nietzsche characterizes moral as Tartuffism he means bigotry, alluding to the leading character from Moliere's play with the same title.

Missing the point is a defect in an argument in which an assertion is made, or even a conclusion reached, which may be cogent, but it is irrelevant to the proposition that is being discussed. An example might be:


Alice: People should not be allowed to keep dangerous animals in their homes because of the risk that one escapes and injures somebody.

Bob: But zoos have lots of dangerous animals and they never injure anybody. 

Bob is clearly missing the point, which is about whether dangerous animals should be allowed in homes. Zoos are run by competent professionals. 

I guess this is what you mean by arguer doesn't know how to argue. 


Begging the question is a fallacy in which there is no better reason to believe the premises than you already have for believing the conclusion, or if you like, that there is no flow of evidence from the premises to the conclusion. 


Alice: Coke is the best drink in the world. Therefore Coke is better than Pepsi. 

This argument is valid, but it begs the question, because one would not believe that Coke is the best drink in the world except by first comparing it with all the other drinks, including Pepsi, and finding that it was better. 

I guess that this is what you mean by shaky premise. 


Suppressed evidence, also commonly called cherry picking, occurs when someone argues for a proposition by only looking at positive evidence and ignoring negatives. 


Alice: Economist X is really good because he correctly predicted the stock market crashes in 2002 and 2008.

Bob: Yes, but he's been predicting stock market crashes every year for the last 20 years, so he's bound to be right sometimes.

Here, Alice is cherry picking the successful predictions and ignoring the failed ones. 

I guess this is what you mean by ignoring stronger evidence. 


False cause, or questionable cause, occurs when one reasons from an effect to a cause, but the identified cause is incorrect or doubtful. Reasoning from effects to probable causes is a kind of abductive reasoning and is extremely common. There is nothing intrinsically wrong about reasoning in this way, but it becomes questionable if there are many possible causes and no reason has been offered as to why the other possibilities are ruled out. It may also be questionable if there are many contributory causes rather than just one, or if the cause has been confused with the effect. 


Alice: Bob was watching the football game earlier and now he's upset. His team must have lost.

This is a questionable cause. Maybe this is why Bob is upset, but there are many other possibilities. 

I guess this is what you mean by imagined connection between premise and conclusion, though this is not the best description. The connection may be plausible but far from certain. 
In your first proposal (∃x[F(x, h) ∧ ∀x∃y(D(y) ∧ O(x, y))]), you're assuming Harry has at least one friend, which may not be the case. If he has no friends, the statement is true (see https://en.wikipedia.org/wiki/Vacuous_truth vacuous truth). Also, you're using x both as bounded by ∃ and as bounded by ∀, while the latter is inside the first. This is never allowed.

In your second proposal (∀x∀y[F(x, h) ∧ D(y) ∧ O(x, y)]), you're saying that everyone is a friend of Harry, that everyone is a dog and that everyone owns everyone!

Here are some hints to get you started (since this looks like homework I won't give you a complete solution):


"All of Harry's friends are dog owners" can be rewritten as "For all people it holds that if they are Harry's friend, then they are a dog owner"
"X is a dog owner" can be rewritten as "There is an Y such that Y is a dog and X owns Y"




Your third suggestion (∀x[F(x, h) → ∀y(O(x, y) ∧ D(y))]) is almost correct. However, this reads as "For all x holds that if they are friends with Harry, then for all y it holds that x owns y and y is a dog" -- in other words, Harry is a dog as well (and x)!
The "meaning" of the logical connective are defined by the rules of inference governing them.

For conjunction ("and") we have :


  (φ∧ψ) ⊢ φ and (φ∧ψ) ⊢ ψ;


for disjunction ("or") we have :


  φ ⊢ (φ∨ψ) and ψ ⊢ (φ∨ψ).


The first couple of rules formalize the fact that :


  "Asserting a conjunctive proposition is equivalent to asserting each of its component propositions separately."


But for "or", we have no rule like :


  (φ∨ψ) ⊢ φ.


This correspond to :


  "In disjunctive (or alternative) propositions, no one of the components is asserted."


In other words, the assertion of a disjunction does not license us to assert its disjuncts separately.

If we know that an "alternative" between two possibilities holds, not necessarily we are able to know which between the two holds.
Science is completely possible in a world with an active God.  This can be proven by analogy.  Consider a role-playing game such as "Dungeons and Dragons."  Most of the action of the game takes place in a highly structured and consistent manner, according to the rolls of dice, and a complex system of statistics.  However, the "Dungeon Master" (an additional participant in the game, who moderates rather than plays) has wide latitude to create and discard game scenarios, tweak the statistics, and even ignore the results that the dice dictate.

From the viewpoint of a character within the game, the statistics are the science on which his world is founded, the actions of the Dungeon Master that contradict those statistics are the miracles.  Both can certainly coexist, in fact it is a necessity for an entertaining game.  However, the players tend to strongly prefer that departures from the statistical expectation be kept to an absolute minimum, in order not to endanger the realism (and sense of consequential import) of the game.

An accurate knowledge of the science of the game is valuable to a character or a player of the game to the same extent which that science is not customarily suspended.
Break it up into two parts:


  But freedom is simply the fact that this choice is always unconditioned


I think this quote can be understood in light of something that Robert Barron (who I believe quotes someone else, but I forget whom) often says: one view of freedom is that it is hovering between the "Yes" and the "No." He contrasts this with a traditional Christian view of freedom, where freedom is freedom to do something particular.

Sartre seems to be disputing this - freedom to Sartre is the ability to make any choice one wishes without being externally compelled or influenced.


  We shall never apprehend ourselves except as a choice in the making


Again, Robert Barron has a http://www.wordonfire.org/resources/article/the-adventures-of-classical-morality/461/ post about this where he sums it up as "existence (unfettered freedom) precedes essence (who or what a person becomes)". In other words, we first exist as something, and through the choices we make are core is defined. This is again in contrast to religious views, for example, about humans being made in God's image (and so our essence precedes our existence).
It would be to argue against meanings as mental or objective entities. Grice and Strawson rely on meaning as something propositional statement "inherently" has, Quine's position, like late Wittgenstein's, is to replace reified meanings with linguistic roles in social use when interpreting language. In Word and Object, that came out about a decade after the Two Dogmas, he argued that even if "inherent" meanings existed they wouldn't make much of a difference, because due to indeterminacy of translation we wouldn't be able to communicate them. "Critics have said that the thesis is a consequence of my behaviorism. Some have said that it is a reductio ad absurdum of my behaviorism. I disagree with this second point, but I agree with the first. I hold further that the behaviorist approach is mandatory. In psychology one may or may not be a behaviorist, but in linguistics one has no choice". One has no choice because children learn language from overt social practice, and grow up into as much an authority on meanings as anybody else.

Grice and Strawson resurrect the analytic/synthetic distinction based on synonymy treated as a black box. Quine, they argue, makes a Socratic assumption that something not describable in simpler terms without circularity has no place in discourse. But it should be rejected, clearly some terms must be admitted as basic, and why not synonymy? It can be reliably recognized and taught to novices, so the fact that it can not be characterized without circular reference to analyticity should not be grounds for dismissing it, perhaps it latches on to something "intuitively". However, Quine was asking for a description of analyticity-in-a-language, where language is varied, so the description has to explain analyticity as such, not just give an assurance that we will be able to tell when it comes to it. He did not contest that groups of sentences can be recognizably prescribed as analytic in particular languages. And it is unclear if reduction to synonymy can do the job even in the sense of Grice and Strawson, because recognition of synonymy may not be "reliable" or "teachable" beyond particular languages with familiar usage.
Nietzsche here isn't sceptical about cause and effect, but is simply pointing out the naïveté of the mechanistic philosophy which supposes that this is all there is. 

Today, we would say he is against reductionism; when we reduce all phenomena to purely mechanical phenomena. Instead, sometimes - yes and sometimes - no:

When I pick a stone and throw it low across the surface of a lake and so skimming it; it is right to model it using mechanical notions - as a particle of matter - so here, yes; but when I speak to a man and then send him on his way, it is generally wrong to think him modelled purely as a particle of matter ignoring all that is animate in him - so here, no; now, this might seem obvious in this description - but it isn't so easily obvious when one looks at the contemporary situation when physicalism reinterprets, refashions and blows new wind and motion into the old mechanistic philosophy. 

In this polemical quote, he is against reducing free-will by the 'enlightened' thought which reduces phenomena to a mere mechanics of thought; or in the field of human endeavour or history to see a mere mechanics of historical or social forces - a useful comparison here is the scientific materialism of Marx or the postivist sociology of Comte. In this way, he is against a reductive enlightment that turns thinking into mere formulae and cant.

His polemics is against importing the deterministic notions of cause and effect from Newtonian (or earlier, Epicurean) Physics which apply to inanimate matter in the small (atoms) and in the large (cosmological - stars and galaxies) to matter animated by mind - ie us. 

In his final paragraph, when he mentions the 'in-itself'; I assume this is the thing-in-itself, the ding-an-sich; and here is merely repeating what Kant supposed of it, or demonstrated: that nothing specific can be said of it, and in particular we cannot talk about it causality there.
There has been a fair bit of discussion of this statement from Wittgenstein. Kripke in Naming and Necessity famously disagrees entirely and offers "the standard metre in Paris is 1 metre long" as an example of an aprioi contingent statement. A priori because we don't have to measure it to know it is 1 metre long, but contingent because that particular rod could have had a different length from the one it actually has. 

I'm not an expert on Wittgenstein so I wouldn't presume to interpret him, but he may be making the point that to say (1) the standard metre is one metre long; is quite a different kind of statement from saying (2) a piece of wood in my hand is one metre long. (2) ultimately means that the piece of wood is the same length as the standard metre, while (1) cannot simply mean that the standard metre is the same length as itself, because that is vacuous. Rather, (1) is part of a language game of measuring and has a special status in that game.

As to what the father should say to his son, I don't see any problem with the father giving the answer: it is one metre long - that is how the metre is defined. 

(Incidentally, although the metre was defined that way at the time Wittgenstein and Kripke were writing, it isn't any longer; it is now defined in terms of the speed of light.)
See http://plato.stanford.edu/entries/spinoza-attributes/ Spinoza's Theory of Attributes and http://plato.stanford.edu/entries/spinoza-modal/ Spinoza's Modal Metaphysics.


  Spinoza defines the term “attribute” thus: “By attribute I understand what the intellect perceives of substance as constituting its essence” (Ethics, 1D4). This definition is reminiscent of Descartes' notion of attributes as it appears in the Principle of Philosophy insofar as attributes are related to the essence (or essences) of substance.
  
  Another claim that has to be taken into account in an analysis of Spinoza's view on attributes is that God is his attributes: 
  
  [Ethics, 1P4:] “Therefore, there is nothing outside the intellect through which a number of things can be distinguished from one another except substance, or what is the same (by 1D4), their attributes, and their affections” (italics added), [1P19:] “God is eternal, or all God's attributes are eternal,” [1P20Cor.:] “It follows second, that God, or all of God's attributes, are immutable.” Some might consider 1P29Schol to be making an identity claim as well: “But by Natura Naturata I understand whatever follows from the necessity of God's nature, or from any of God's attributes…” Spinoza in these places seems to be claiming that there is an identification of the substance with its attributes. 


Thus, if attributes constitute the essence, and if God his is attribute, then we can conclude that :

(i) God is his essence

(ii) God's essence exists, because it is God itself.
This is called the http://plato.stanford.edu/entries/future-contingents/ problem of future contingents, and the conclusion is called http://plato.stanford.edu/entries/fatalism/#1 logical fatalism. Already Aristotle struggled with it in the famous example of tomorrow's sea battle. By the law of excluded middle the sea battle will happen, or it won't happen. Whichever the case one of them is true, and by the nature of truth if it is true tomorrow then it is already true today. What will happen will happen, so it appears predetermined "by logic alone".

Although most agree that something is wrong here, there is controversy as to what exactly is wrong. Intuitively, there is no determinate "what" in "what will happen, will happen" before it happens, but to encode this intuition into logic is tricky. There is some controversy even on what Aristotle's own solution is, but it is usually assumed that he rejects bivalence for future contingents. In other words, they are neither true nor false until they happen (or not). This is one of those cases where the classical logic is not adequate to formalizing our reasoning, and systems of temporal (time-dependent) logic were created to do it.
The word "morality" is used in several distinct ways in philosophical literature. One feature of this is time period of authorship. The English word "morality" is a cognate of the Latin word https://en.wiktionary.org/wiki/moral#Etymology moralis which Cicero used to translate the Greek ethikos. Thus, on a certain level, the pair should have the same meaning. Sometimes, this does occur.

There are other cognate terms as well, mores and ethos refer to the practices of a particular culture or people.

In Hegel, the terms Moralität and Sittlichkeit refer to the goal of a universal morality (potentially identified with Kant) and the values that grow out of a particular people. Moralität commits the sin of being unmediated insofar as it creates an ought outside of the domain of Spirit. (http://www.blackwellreference.com/subscriber/uid=/tocnode?id=g9780631175339_chunk_g978063117533917_ss1-6 see here). For Hegel, the key image is Antigone -- with the challenge of the requirements of the state as set against the Sitten of the family. For Hegel, the solution is a morality  that is also ethics.

Contemporary philosophers do not necessarily follow Hegel. In much contemporary work, "moral philosophy" is an equivalent to "ethics" which is understood to be the discipline in which we study questions of action and right or wrong (sometimes called "axiology" but this is a word I see little written in actual philosophy papers).

Whence "morality"? Morality also seems to take on a popular meaning as the morality of society. Thus, the link to Christian in some uses. But in all honesty, I think this is kind of boogeyman usage, where we need a whipping boy to distinguish genuinely thought through moral philosophy from common practice. 

An implicit claim in the use of the word "morality" is linked to the Hegelian usage above in that the term "morality" often implies a universal viewpoint whereas "ethics" does not carry this implication.

For instance, Roger Ames would write Confucian Role Ethics rather than Confucian Role Morality.

Similarly, we call it professional ethics rather than professional morality.

But we have the text Prospects for a Common Morality.

Thus, I would say in contemporary philosophy that "ethics" is generally a safer word choice than "morality."



While the above is broadly based on my experience with the literature, here are a few references to help with respect to Kant and Hegel on these terms:

Jon Stewart Kierkegaard's Relation to Hegel Reconsidered (Cambridge University Press, 2003), p. 311. He cites Alfred Elsigan "Zum Begriff der Moralität in Hegels Rechtsphilosophie," Wiener Jahrbuch für Philosophie 1972, p. 88 and Hegel's own *Philosophy of Right.
This is a good, somewhat complex question, and you may get as many different answers as there are Marxists.

First, though Marx had a background in German Idealism, through which he analyzed British political-economy, it is a bit hard to come grips with his "materialism." He tends to place the material base of production prior to the "intellectual" superstructure, but he does obviously accept "conditioned" mental agency in history. The "theoria-praxis" divide gets entangled under the convenient term "dialectics." In any case, yes, the material transformation of history will presumably bring about a new social-mental framework, a new human setting for the first time liberated from necessary class antagonisms and all their cultural, psychological ramifications.

But the question of historical cause and effect is cloudier. I believe Marx saw the transformation of history in almost steam-age, thermodynamic terms, a mass pressuring of outcomes. Remember that Marx was basically an analyst of capitalism and modernity, he really did not specify any political program or revolutionary practice. After the Second International, Lenin and others lost faith in the spontaneous "revolution from below," and saw the "Vanguard Party" as providing the necessary intelligent agency to guide any revolution.

You are right, Marx did see capitalism as a necessary prelude to socialism, and doubted Marxism could work in an agricultural society like Russia. Capitalism, by brutal means, does accomplish "commodity" farming, the uprooting of farm labor, and the utter dependence of each member of society upon a vast, complex division of labor. This in turn broke the ancient Malthusian constraints of population and "nature." Through complex manufacturing, humans could for the first time accumulate wealth by reorganizing unattached people, the proletariate.... without more land! That is the crucial leap. There was no necessity to grow a society by seizing the land of another society. Enlightened, scientific human capacities pass beyond the bloody, zero-sum game of history.

Socialization of production meant socialization of the state. Because of this division and rationalization of labor, this utter dependence on cooperation, it was only rational that human beings would begin to seek their own well-being in complex cooperation and common interest, at last eliminating the final remnants of divisive exploitation in the form of the capitalist class...the class who may or may not choose to work, but who, in their purest form, are simply "legal owners," shareholders whose legal share of social output will only grow whether or not they work. Since this underlying antagonism and alienation suffuse modern culture, the "revolution" will surely entail a new intellectual outlook, epoch, or secularized Geist.

Again, the question is the intellect as historically causal. Not even the most adamant "vanguardist" would argue that you can carry out a top-down revolution without the necessary historical conditions, which must include a high development of commodity production and some level of awareness, willingness, and confidence on the part of the proletariate. Yet mind is also the catalyst of material change. Like a Hegelian subject, the proletariate can only become its true, rational self precisely by passing through the material conditions of revolution, and only afterwards knowing "intellectually" what it has become.

The complex dialectic of "theoria-praxis" or "base-superstructure" in Marxism is not unlike a social version of the old "mind-body" problems that philosophy can never fully resolve.             
We are confronted with two possibilities here: Either free will, or God. But why? Well, let's see what omnipotence implies for free actions.

If our will is free, it is free in every concious action of a rational being (I take rationality to be important from "scholastic subtleties"). 

Either God is omnipotent, then he is able to intervene in our actions, too. Or our actions are free (our own sphere of freedom), then God would not be able to intervene, as in any other case the freedom would be his freedom to let us do what we want, but not ours. That is why "Maybe God just doesn't wish to exercise his powers" will not be able to perserve our freedom. 


  Freedom in a meaningful notion means freedom from every external determination, either by God or nature.


An all-powerful God will take away all the meaning of freedom, because only he would be free in the full sense in letting us make our choices. And that surely brings a philosopher of the absurd to state that the notion of an omnipotent God is absurd, because it is metaphysical "knowledge" that will not make any difference in our practice.

That said, Camus himself surely adds a moral dimension by saying "God the all-powerful is responsible for all evil". That leads to the old problem that scholastic tradition takes God to be good and omnipotent by definition. Both is meant to lie in the notion of God. But this is another paradox, as you correctly stated.
Here is a formalization in quantifier calculus with identity:

Premise: GetJob(Jones) ∧ ∀x(GetJob(x) → x = Jones) ∧ HasCoins(Jones) 

Conclusion: ∀x(GetJob(x) → HasCoins(x))

By https://en.wikipedia.org/wiki/Universal_instantiation universal instantiation assume GetJob(a), by the second conjunct in the premise a=Jones, by the last conjunct and substitutivity of identity HasCoins(a). Since a was arbitrary the conclusion follows by https://en.wikipedia.org/wiki/Universal_generalization universal generalization.
Definitions

One has to define "omniscient" (knowing all things) and "omnipotent" (being all powerful) properly, otherwise one runs into trouble without even considering your question.

Let's deal with "omnipotent" first.

Omnipotence 1

If by "omnipotent" you literally mean "being able to do everything", then consider the following fact:


  It is impossible to create an uncreated object.


This is at least one thing that no being, not even God, can do. You may then object that this is irrelevant, but at least you will have to admit that it just makes absolutely no sense to talk about "omnipotent beings" that can do everything because there isn't one.

Omnipotence 2

If you restrict "omnipotence" to "being able to do every possible thing", then you still need to define or axiomatize "possible". One way is via consistency, where we define something to be possible if and only if it can be true without being inconsistent with what are already true. (If you know first-order logic, in a first-order theory possible sentences are simply those whose negation is not provable. But my definition here is not restricted to a particular logic.) If we define "omnipotence" this way, then there is still the following fact:


  It is impossible for anything to make it so that nothing ever existed. (English does not have the capability of conveying this accurately, but by "ever" I do not intend any connotation of time but simply actuality.)


This needs some thought, but is undeniable, because even if anything could make everything disappear, he cannot change the fact that something did once exist. Again, I intend this to be not restricted to time-based existence. This has the following implication for any God:


  It is impossible for God to make it so that nothing ever existed.


This does not contradict omnipotence of such a God, if we use the restricted definition of omnipotence. But it already tells us one logically irrefutable way in which God is necessarily restricted. However, consider the following:


  Is it possible for God to make it so that he/she/it is not omnipotent?


If you say "no", then you would be saying that God is forced to be omnipotent. If you say "yes", then you would be saying that God can choose to become not omnipotent, in which case there can be free will.

Omnipotence and free will

Thus the necessary conclusion from the above reasoning is that the standard argument that omnipotence is incompatible with free will is invalid if the above definition of omnipotence is used. If another definition for omnipotence is used, what would it be? Under most alternative definitions, it's no longer important whether God (if he exists) is omnipotent. So far almost all writings on God's omnipotence do not precisely specify what they mean anyway, so their arguments are not well founded.

Free will

I'll use the definition that "free will" means "ability to choose the future". This of course depends on your definition of "future", but it suffices for our argument later. This is also a very weak kind of free will, but it avoids the problem of defining what choices are involved. This also depends on exactly what "choice" means, which cannot really be defined. I'll just say let's use our intuitive meaning for now.

Omniscience 1

If by "omniscience" you mean "knowing the truth value of everything", then of course any omniscient being will know the future of everything. This applies even in the case that you assume that there is one world for every possibility. In any case, existence of an omniscient being implies non-existence of free will in the sense that we cannot choose the future if it is already something that is known by this being. You cannot say that we can make choices that can change this knowledge because by definition an omniscient being knows the final result of all choices.

Also, a being that is once omniscient cannot choose to become not omniscient, because while omniscient he already knows everything including when he is not omniscient, unless he also can make himself forget what he knew before. But indeed an omnipotent being can become not omniscient and make himself forget what he knew before, so even if there is a God and there is free will we cannot conclude that this God was never omniscient!

Omniscience 2

Another possible definition of "omniscient" is "being able to determine the truth value of any thing". This is strictly weaker than the above definition of "omniscient", for the same reason that mathematical induction does not imply the existence of an infinite collection. An omniscient being of this kind can still be compatible with free will for choices which he does not attempt to determine until they are made. Again, I intend no time connotation here but English forces my grammar. But most people do not even think of such kind of omniscience, not to say believe that their God (if any) is of this sort.

Omniscience 3

Some who believe in the existence of a God simply believe that God is omniscient about people in a weaker sense of "knowing what people would do given their choice of virtues". In other words, people have the free will to choose virtues that they desire, but based on those choices their lives are essentially determined. One variant of this is found in the Jewish psalm:


  A man's heart devises his way, but YHWH directs his steps.


Different people interpret its meaning differently, but it is consistent with belief in a limited form of free will with a limited form of omniscience.

Reason for creation?


  Question: Why would an omniscient God create anything if he already knows what is going to happen? Knowing how it will turn out to be, one does not need to create anything, since creating it is a waste of effort.


Firstly, "waste of effort" may mean two different things to a human and to a God. Even more so, if a God really exists, who created the world and living creatures, and humans can appreciate the (natural) world for its beauty and not just for any material benefit, so also it is reasonable to expect a powerful creator to also be able to enjoy creating and his creation even if he knows how it will turn out.

Secondly, the reasons for doing things usually are much more important than just to find out how things will turn out. We eat food not so that we can find out how they taste, but because we need food. On a higher level, we institute laws and live by them not to find out anything, but because we want to preserve peace and order (social stability). And we want to find out how the natural world works not for curiosity alone, but often also so that we can learn from it to be able to do things better, including feeding ourselves and those around us, and maintaining peace and order.

Thirdly, by the previously mentioned considerations, it is not necessary that belief in a God entails believing in omnipotence or omniscience in the usual sense that people talk about. If for example we have limited omniscience and limited free will in the specific form mentioned above, it is reasonable for God to want to create the creation in order to allow people's choices to be played out, because then choices made would have real consequences that (usually) coincide with the intentions, because the laws governing the world are not chaotic but predictable. So far from predictability being useless, it is in fact extremely meaningful because it gives our choices meaning. Of course, in this view not everything is predictable, such as our choices and those of others.
Every formal question presupposes a https://en.wikipedia.org/wiki/Domain_of_discourse domain of discourse from which valid answers can be drawn.  Whether or not it is made explicit, a question like this appears to be seeking a mathematical answer.  Giving a color-based answer violates the implied domain of discourse, and suggests that the person answering has either accidentally or deliberately misinterpreted the question.

Of course, there are situations where "https://en.wikipedia.org/wiki/Thinking_outside_the_box outside the box" thinking is required, or desirable.  In such a case the implied domain of discourse is the "box" and ignoring it is "thinking outside of it."

Formal questions, however, restrict the realm of possible answers by necessity.  In a formal system, every recognized condition must be well-defined within that system.  That cannot be guaranteed without a restricted domain.
It reflects the difference between two types of knowledge, knowledge by acquaintance and knowledge by description. "We shall say that we have acquaintance with anything of which we are directly aware, without the intermediary of any process of inference or any knowledge of truths". Russell's notion of acquaintance is extremely narrow, he reduces it to indexicals "I", "this", "here" and possibly "now". Only these can define explicitly. 

Everything else is known only by description, which is some so-and-so, and to know it is to know that it is so-and-so and that so-and-so exists. For a definite description this so-and-so also has to be unique. Russell even counts proper names as implicit descriptions. Definitions of descriptions are contextual, Russell does not directly define their meaning, but rather defines the meaning of sentences containing them:"This is the principle of the theory of denoting I wish to advocate: that denoting phrases never have any meaning in themselves, but that every proposition in whose verbal expression they occur has a meaning". For example "the present king of France" is rephrased in sentences as "there is an x, x is now a king of France, and if y is also now a king of France then y is x". Although "the present king of France" sounds like an object, in the rephrasing it is essentially dissolved into predicates, which is why Russell sometimes calls descriptions incomplete symbols.

See http://plato.stanford.edu/entries/knowledge-acquaindescrip/ Knowledge by Acquaintance vs. Description and https://faculty.washington.edu/smcohen/453/RussellDisplay.pdf Russell On Denoting.
This is quite a broad question, of course. To give you one interpretation:

The concept of will to power is mainly to designate the 'essence' of life, rather than a physics concept. It is an adaptation of Schopenhauer's 'will to life'. According to Nietzsche, life wants to expand, grow, overpower, multiply. He differentiates between a strong will to power and a weak will to power. The strong will affirms life, the weak will is the will to power turned against life itself, for example by preferring an other, ideal world or by ascetic practices. Due to the spread of christianity, the weak will to power has become prevalent. Now that science has discovered the imagined other world is false, this weak will to power is no longer legimatized. This is nihilism. (See for example the famous 'Lenzer Heide'-fragment, German: http://www.nietzschesource.org/#eKGWB/NF-1886,5[71] http://www.nietzschesource.org/#eKGWB/NF-1886,5[71])

The Übermensch is a new purpose to fill this void, but it is to promote the strong rather than weak will to power. Here the eternal recurrence comes in. Although Nietzsche also considers this a cosmological concept, he primarily uses it as a 'ethical' touchstone. How do you know if you will to power is strong? If you affirm the idea that your life may occur again in the exactly the same way for all enternity, than you affirm life as it is, including its suffering. If you don't affirm it, your will to power is not strong enough.


  What, if some day or night a demon were to steal after you into your
  loneliest loneliness and say to you: 'This life as you now live it and
  have lived it, you will have to live once more and innumerable times
  more' ... Would you not throw yourself down and gnash your teeth and
  curse the demon who spoke thus? Or have you once experienced a
  tremendous moment when you would have answered him: 'You are a god and
  never have I heard anything more divine.' (The Gay Science 341)

The first statement is right.

For the second one, while it is right your explanation why truth table method does not give us an algorithm for predicate logic, from this fact does not follow that some other algorithm cannot exist.

The existence of an algorithm for predicate logic is ruled out by a https://en.wikipedia.org/wiki/Entscheidungsproblem theorem of https://en.wikipedia.org/wiki/Alonzo_Church Alonzo Church.
Essay II of Genealogy of Morals is entitled “Guilt, Bad Conscience, and Related Matters”.

Nietzsche identifies “the contractual relationship between creditor and debtor” as the sociological source and origin of issues like injury, guilt, and punishment (section 4).

Section 20 states that “the consciousness of being in debt to the gods” increases in direct proportionaly to the influence in society of the god concept. Hence one would conjecture that the decline of the importance of the god concept in society also diminuishes the strength of the consciousness of guilt.   

According to section 21 any assessment of guilt and duty from a moral point of view has to consider the human conscience. Nietzsche states that contrary to expectations the dominance of these concepts did not diminuish even for humans who no longer believe in god. The terms guilt and duty are no longer part of a contractual relation to god but move into the human conscience and become moral terms. 

The sentence 


  the aim now is to preclude pessimistically, once and for all, the prospect of a final discharge....


says: With the decline of the religious worldview a final discharge by god is no longer possible, which aggravates the human situation. 

The bad conscience attacks the creditor but – according to Nietzsche – also the debtor. 

But also to me it remains unclear who is considered the debtor after the decline of the god concept. Hence I have to join you last question.  
I agree with commenters that question as it stands is unlikely to elicit good answers. Given the lack of context and the wildly spluttering, multi-limbed brain of Zizek, who knows?

I will offer one modest, reasonable reply. To many Marxist theorists, such as Luxemburg and Karatami, Capital accumulation always requires a noncapitalist environment, relatively unexploited resources and populations external to the system. I believe this is correct.

The most obvious examples are 19th-century imperialism and the modern "liberation" movements that drew minorities, women, "youth vanguards," etc.,  into labor and consumption systems. This noncapitalist environment, or The Frontier, can be anything, from a rainforest to public institutions, from the family home to a war zone. And it can be continually recreated, by sheer destruction of Capital if need be.

So from the perspective of Capital, eventual penetration of the billion-plus labor force and consumption capacities of the supposedly communist countries was essential, perhaps inevitable. Why was it reciprocal? 

First, no Marxist would describe the Soviet Union or China as communist. With the collapse of the Second International and the failure global revolution, Russia and later China were still-born as deformed, state-capitalist systems regressing into international competition with the liberal capitalist nation states.

Since the states failed dramatically to "wither away" they remained precariously "on top" with all the modern state problems of stabilizing and appeasing mass populations increasingly alienated from "the revolution." They could not help but observe that "consumerism" proved to be an unsurpassable tool of regulation, political diversion, and popular quiescence. What else were they to do?

Marxism proper is, like Christianity, a "universalist" ideology and "utopian" aspiration. When the social structure remains locked into "state" structures policies are determined of necessity by the other, antagonistic states, not by some aspirational ideology. As "states" organizing "capital," the "different objectives" you cite are entirely superficial.

For the real answer, you'll have to ask Zizek, in whom a thousand answers bloom.           
Wikipedia, which is the source of the quote, in another article also https://en.wikipedia.org/wiki/Philosophical_aspects_of_the_abortion_debate#The_bodily_rights_argument lists the typical objections, with references, which arguably point out moral distinctions.

The responsibility objection: kidnapping makes the violinist scenario analogous only to abortion after rape, in most cases the intercourse was voluntarily, so the woman herself caused the baby to need her body. 

The stranger objection: embryo is the woman's child, unlike the violinist. 

Let die objection: abortion kills the embryo while unplugging the violinist only lets him die, so abortion is premeditated murder, but with unplugging death is a foreseeable but unintended consequence.

http://catdir.loc.gov/catdir/samples/cam033/2002022282.pdf Boonin argued more recently (Thomson's paper is from 1971) that the above distinctions are either morally irrelevant, or do not apply to abortion in their moral aspect. Here is a critique of that http://connection.ebscohost.com/c/book-reviews/20379899/defending-abortion-philosophically-review-david-boonins-defense-abortion due to Beckwith.
Underdetermination of theory by evidence, explored in great detail by Quine, means that from finitely many observations and measurements, that we are able to make by any point in time, even combined with perfect methodology, we are unable to determine a unique theory consistent with them. In other words, even if there were such a thing as the correct theory of nature we lack physical capabilities to find out what it is for sure, distinct theories may well be empirically equivalent. This is over and above the interpretational indeterminacy, where theories are "mathematically" equivalent despite postulating existence of different kinds of entities. For instance, Copenhagen and Bohmian interpretations of quantum mechanics are interpretationally distinct, but mathematically equivalent. They, or rather their natural extensions, may become inequivalent if in the future certain new types of measurements beyond quantum mechanics will become possible. These presumed extensions are only empirically equivalent for the time being.

As for compatibility with realism, it depends on the type of realism in question. It is generally agreed that indeterminacy rules out the most naive form of realism, which simply projects current theoretical entities onto objective reality. More sophisticated forms of realism impose restrictions on "realistic" theories in addition to their simple agreement with the observations (such as simplicity, theoretical unity), and/or restrict the scope of what is claimed to be objectively real. 

Structural realism for instance concedes that "essences" of objects do not enter our experience, and only relations among them are reflected in our theories. In this view interpretational indeterminacy is baked into the cake, as long as there is a transformation connecting two theories that preserves their relational structure, they equally reflect as much of reality as we are entitled to. This can be tightened up by insisting that theories not be considered in isolation but in a holistic system that exhibits internal coherence. A sophisticated realist then admits that even big pieces of successful theories may be discarded (like ether and phlogiston were), but optimistically hopes that as science progresses larger and larger portions of it will match the objective reality.

See http://plato.stanford.edu/entries/quine/#UndTheEviIndTra SEP article on underdetermination of theory by evidence, and http://courses.washington.edu/phil560/Worrall.pdf Worall's defense of structural realism.
The topic you've raised is broad. Except for the two approaches you mention towards the social sciences - interpretation (advocated by anti-naturalists) and (nomological) explanation (advocated by naturalists), there is the pluralist stance combining the two, and there is the approach known as 'critical social science'.  

The pluralists contend that social scientists can pursue both naturalist and anti-naturalist research programs. According to their view social scientists can on the one hand attempt at explaining some social phenomenon by 'social laws' parallel to laws of nature (thus - naturalist approach), and at the same time - they can also attempt at interpreting the meaning of the laws by an appeal to Hermeneutics (thus - anti-naturalist approach).    

Traditionally, the dispute among varied philosophers over the methodology of social sciences has indeed involved the question of the possible degree of objectivity of the social sciences. 

Few of the many sources on the topic, some of which touch upon economics:

F. A. Hayek, "The Theory of Complex Phenomena", in Studies in Philosophy Politics and Economics, Chicago Press, 1967, pp.22-24

Carl G Hempel, "The Function of General Laws in History", in Journal of Philosophy volume 39, 1942, pp. 35-48

Max Weber, "'Objectivity' in Social Science and Social Policy", in The Methodology of the Social Sciences by Max Weber, 1949

Milton Friedman, "The Methodology of Positive Economics" in Essays in Positive Economics Chicago Press, 1953, pp.3-23 
I suppose what you might be looking for is the idea of the noumenal world, in which pure force of will might exist as a soul or identity of some sort, which somehow links to the real world and can influence it somehow in order to grant will to an individual. Given that such a universe is ultimately unknowable to our limited senses, it can never be discovered by science and could hide behind the pretense of a probabilistic or non-deterministic universe.

Ultimately it comes down to the semantics and concept of 'free' and 'will' being more than just the sum of deterministic or non-deterministic experiences, necessitating something supernatural and beyond the bounds of physics and science in order to remove it from the constraints involved. The alternative is to dismiss the concept altogether for being absurd or untestable and instead question those semantics; an illusion of "free will" may just arise from the ability to be aware of alternate possibilities and the factors involved in a decision rather than some kind of unbridled volition that transcends the laws of physics.
There are several notions of intuitionistic continuum, the closest ones to Aristotle's are Brouwer's "fluid continuum", and especially late Weyl’s version of it since On the New Foundational Crisis of Mathematics (1921). We have to keep in mind, however, that Brouwer and Weyl received their view through a major intermediary, Kant. Although Aristotle’s and Kant’s descriptions of motion and continuum are sometimes indistinguishable phenomenologically, what was objective reality to Aristotle was only a phenomenal form of perception to Kant. But all of them did share the most basic premise: continuum is given as a whole, points and parts are imposed on it.

Weyl makes suggestions as to mathematical realization of his fluid continuum and Brouwer built a full blown theory of his somewhat "less" fluid one, but remarks pessimistically that “the inapplicability of the simple laws of classical logic eventually results in an almost unbearable awkwardness”, the closer we get to the intuitive continuum the less palatable it becomes mathematically. Predicative continuum of early Weyl, developed by Feferman and applied to physics by Field, is even less fluid, but was shown to be sufficient for all of classical physics at least. In his time Aristotle could afford to be optimistic, for one finds the same conception of “fluid magnitude” in his Physics, as in Euclid’s Elements. In our time intuitionism could only build chain of continua mediating between philosophical insight and mathematical physics.

Weyl concludes that there is a divide between mathematical theorizing and philosophical insight into our experience, of time and motion in particular, which seems to echo Aristotle’s “response to the question” vs. “response to the actual facts of the matter”. But he goes further suggesting that it can not be bridged, which implies that Zeno’s challenge must get different answers on different grounds:”if phenomenal insight is referred to as knowledge, then the theoretical one is based on belief... But where is that transcendent world carried by belief, at which its symbols are directed? I do not find it, unless I completely fuse mathematics with physics and assume that the mathematical concepts of number, function, etc. (or Hilbert’s symbols), generally partake in the theoretical construction of reality in the same way as the concepts of energy, gravitation, electron, etc.”

Tieszen gives a nice review of Weyl’s fluid continuum in http://philmat.oxfordjournals.org/content/8/3/274.abstract Philosophical Background of Weyl's Mathematical Constructivism, also his with co-authors https://dspace.library.uu.nl/bitstream/handle/1874/26962/preprint211.pdf?sequence=1./268322146_The_philosophical_background_of_Weyls_mathematical_constructivism Brouwer and Weyl: The Phenomenology and Mathematics of the Intuitive Continuum compares it to Brouwer’s. 



P.S. In On the New Foundational Crisis of Mathematics (1921) Weyl wrote: “an ensemble of individual points is, so to speak, picked out from the fluid paste of the continuum. The continuum is broken up into isolated elements, and the flowing-into-each-other of its parts is replaced by certain conceptual relations between these elements, based on the “larger-smaller” relationship. This is why I speak of an atomistic conception of the continuum”. Weyl speaks here of points “picked out” arithmetically, as in the classical conception or his earlier constructivist one. 

To approach fluid continuum we need to commit Brouwer’s “second act of intuitionism” and introduce lawless choice sequences that reflect the fluidity of intuitive continuum. In Philosophy of Mathematics and Natural Science (1949) Weyl explains: “the notion of sequence changes its meaning: it no longer signifies a sequence determined by some law or other, but rather one that is created step by step by free acts of choice, and thus remains in statu  nascendi. This ‘becoming’ selective sequence represents the continuum, or the variable, while the sequence determined ad infinitum by a law represents the individual real number falling into the continuum. The continuum no longer appears, to use Leibniz’s language, as an aggregate of fixed elements but as a medium of free ‘becoming’”. This is how intuitionistic points only exist "potentially", in Weyl's view unlike Brouwer's, points in the lawless part of the continuum can not even be individuated.
Heisenberg recognized in his http://www.archive.org/details/physicsandphilos010613mbp Physics and Philosophy that the probability wave concept in quantum mechanics (p. 41)


  was a quantitative version of the concept of 'potentia' in Aristotelian philosophy


and that the (p. 80)


  concept of the soul for instance in the philosophy of Thomas Aquinas was more natural and less forced than the Cartesian concept of 'res cogitans,' even if we are convinced that the laws of physics and chemistry are strictly valid in living organisms.


cf.Smith, Wolfgang. http://www.thomist.org/jourl/1997/973AWall.htm The Quantum Enigma: Finding the Hidden Key. Hillsdale, NY: Sophia Perennis, 2005.and the resources http://scholastic.us.to/ here
First, B theory is a semantic theory about the proper way to refer to events in time, not a metaphysical theory about past and future events. The view that past and future events are real is called eternalism. It's true that B theory fits better with eternalism than with other metaphysical theories of time, but strictly speaking they are distinct.

Second, eternalism and determinism are also distinct views.
Determinism is the view that the future is determined by the past and by the laws of nature, but it is conceivable that future facts are real although they are not determined by laws (for example: the exact same state A evolves into either B or C at different places or times so determinism is false).

Regarding compatibility with libertarian free will, the crucial aspect is necessity. Libertarian free will is sometimes expressed as follows: an agent could have done otherwise, which, roughly, means that what the agent did was not necessary.

Libertarian free will is incompatible with determinism because if everything happens in virtue of the laws of nature, and if the laws of nature express relations of necessity in the world, then it is not true that an agent could have done otherwise.

However libertarian free will is not strictly incompatible with eternalism.
Saying that future events are real does not mean that they will happen in virtue of necessity so there is room for a combination of libertarian free will and eternalism.

Having said that, this is quite a formal reasoning and our intuitions speak differently. Most defenders of libertarian free will would probably say that it requires that the future is open, i.e. that future events are not (yet) settled for us to have any choice. This intuition can be cast in terms of necessity: one could argue that something that is the case is necessarily the case, so that if every fact is settled in eternity, then everything true (including about future facts) is also necessary, and that therefore eternalism is incompatible with libertarian free will.
The passage is from Plato's Phaedrus 278d4

The Greek word is philosophos (φιλόσοφος). It is translated by Jowett as lovers of wisdom or philosophers. The original text uses the singular.

The text says literally "The term philosopher or something of this kind fits better to him ..." 

The passage is not the origin of the term philosopher. It is used several times in Plato's work. He also uses the verb "philosophein" (φιλοσοφεῖν). 
"Intuition of pure number" is the intuition Poincare inherited from Kant's a priori form of perception in time. Kant recognized two forms of perception that produce synthetic a priori, and therefore "rigorous", knowledge, space an time. The former gives rise to the geometric intuition, and the latter to the arithmetical one. However, after the discovery of non-Euclidean geometries the fallibility of geometric intuition became a consensus in 19th century.  Accordingly, Helmholtz and Poincare amended the Kant's view by suggesting that geometric intuition is not specific enough to single out the Euclidean geometry, and after Riemann not even the geometries of constant curvature, at most it supports any locally Euclidean one. So by the end of the century the only "rigorous" intuition left was the a priori synthesis of multitude in time, the arithmetical "intuition of pure number". See how https://drwilliamlarge.wordpress.com/2012/11/16/kant-and-the-synthetic-a-priori-lecture-5/ Kant explains why 7+5=12 based on this intuition.

I am not sure what the OP means by "intuition related to the knowledge of the properties of numbers", but it sounds more like Hilbert's view than Poincare's. Hilbert thought that we have no Kantian intuition of numbers as such, but rather intuition about manipulating symbols that purportedly represent them, i.e. intuition of symbolic properties. Since not just arithmetic, but all of mathematics, can be seen as symbolic manipulation of formal theories, Hilbert came up with the idea of grounding all of mathematics in the a priori synthetic knowledge of symbols. That was the famous Hilbert programme, see https://philosophy.stackexchange.com/questions/28154/is-there-a-kantian-influence-on-the-formalist-programme/28157#28157 Was there a Kantian influence on Hilbert's formalist programme?
There is an inherent and well-known ambiguity in TSSR (Kuhn, 1962), where it is often unclear if Kuhn is simply describing how Science has been done (or is being done) or if he is offering a prescription on how Science should be done. This is for instance expressed by Feyerabend (1970): 


  Whenever I read Kuhn, I am troubeled by the following question: are we here presented with methodological prescriptions which tell the scientist how to proceed; or are we given a description, void of any evaluative element, of those activities which are generally called 'scientific'? Kuhn's writings, it seems to me, do not lead to a straitforward answer. They are ambiguous in the sense that they are compatible with both interpretations.


Similar thoughts are also given in other chapters of Criticism and the growth of knowledge (1970), which is an excellent companion reading to TSSR. For instance, Masterman (1970) is describing the many different - and sometimes conflicting - ways in which Kuhn is using his paradigms. These ambiguities are clearly related to your question, since the "alignment" between history events and an underlying philosophy is more critical if you are using TSSR for prescriptive purposes.

References

Feyerabend. 1970. Consolidations for the specialist. In: Criticism and the growth of knowledge. eds: Lakatos & Musgrave. Cambridge Uni Press. Cambridge, UK.

Masterman. 1970. The Nature of a Paradigm. In: Criticism and the growth of knowledge. eds: Lakatos & Musgrave. Cambridge Uni Press. Cambridge, UK.
I do not remember any passage where Plato refers to the Jewish religion or to Jewish mythology. 

Sometimes Plato refers to myths he pretends to have heard from Egyptians and possibly he invented some myths by himself. E.g., he refers to the myth of Atlantis and he himself traveled to Italy and had contact with he school of Pythagoras and their myths of transmigration. 

But I do not remember any reference to the Torah. In Plato's time Israel was a Persian province. It did not play any role outside the country. 

I think that Justinus tried a bit to revise history in order to strengthen his message.  
According to https://philosophynow.org/issues/15/A_students_guide_to_Jean-Paul_Sartres_Existentialism_and_Humanism this article in Philosophy Now, Sartre wrote this as a piece of polemic and apologia for athiestic humanism; which is possibly one reason why he later regretted its publication.

Polemic doesn't tend to argue discursively, backing up each claim credibly; it tends to go for greater rhetorical effect - and this means argumentation and reasoning is dropped; it also plays to Satres strength as a specifically literary kind of philosopher - how many philosophers have written plays and novels?

So, in one sense it's not surprising that you've exposed a hole in Sartres thinking.

In this essay, Sartre is defending his conception of existentialism against a number of charges brought against it: 


too focused on the individual, without thinking on the relation between the individual and society, and of human solidarity - a charge made alike by Christians and Marxists.
too pessimistic and dystopic; focusing on the ignominious condition of man; in Being & Nothingness he calls man a 'useless passion' and that all forms of sexual love were doomed to masochism or sadism - Hegels master-slave dialectic in the context of the personal


Sartre takes freedom - the individual free will - as an 'absolute', meaning he begins with that; what 'we choose is always for the better' says as you say, that the individual choosing his actions is evidence that he is choosing for the best.

His next move to the universal, is in a sense a lyrical and oracular move, he  veils himself in the voice of all, and speaks for all - note the use of 'we'; so this is not man, the individual whose fate he's concerned with here, and nor men in their plurality and variety, but man as a species, and therefore as an essence (these are terms in Aristotles categories, that are used in a different way in Aristotelianism; and a term that he reverses in his abandonment of God: existence before essence, not after; for Sartre, 
a man defines his essence by his acts acting in freedom).

This is where his literariness, his poetics come in; it works only if one accepts this as a kind of assertion of destiny; as a kind of prophesying. 

Discursively, though it's questionable exactly on the basis that you've made; and it's the same critique the article levels at him.

His claim doesn't stand up within the text; but this ignores the nature of the essay as a polemic and defence; the question is whether he provides a defence of this position elsewhere in his works.

The article suggests not, and that he's unable to demonstrate  that his ethics, in the terms he's framed them, doesn't lead to moral anarchy.

A closer reading, however may show that he's taken on something of the legislative burden of the Kantian moral code - to only act, as though you're acting for all; and then it would be a question how he's used the scaffolding from Kant to buttress his own position - I'm not enough of an expert to answer this; but hopefully this might prompt someone to offer a better answer.
Thanks to language, we can attract things we do not expect.

Consider the person who doesn't know what cancer is, but knows what a heart attack is.  They spend their entire life trying to avoid a heart attack.  They may use dozens of experimental prophylaxis, one of which may cause cancer.  In the end, they attracted cancer.  But that's not the only way to see it.  The other way to see it is they attracted "things that prevent a heart attack," and one of those things happened to attract cancer.

It is no surprise that schools of thought which suggest things such as The Law of Attraction also preach avoiding hate and trying to become one with Good.  In this example, the individual fought against heart attacks, trying to push them out of their life and attracted everything else in the process.  The Law of Attraction works much better if you presume you use it only to attract, not as a reverse-psychology trick to push things away.

The law actually makes quite a lot of sense if you view things from a value optimization point of view.  Your subconscious will naturally optimize itself to strive for the goals you set for it.  It will find connections you never were aware of, and act on them.

Honestly, the law has been phrased much more succinctly in the fairy tales.  Fairy tales have a strange tendency of being filled with useful information in nice easy to digest units:


  Be careful what you wish for.

How to live [what]? How to live a moral life? Ethics. 
There are many definitions on what philosophy actually is. Yes, the classic definition, 'love of wisdom' is correct--but it is not the whole truth. 

Although, it seems that this question is asking a much more simple question: What are the different types or definitions of philosophy?
On one hand, "philosophy" is defined as formal philosophy: philosophers, logic, ethics, metaphysics, epistemology, etc. 
On the other hand, "philosophy" is defined as armchair (informal) philosophy: "What's your philosophy; what is your weltanschauung?" "What's your purpose in life?" *(See more detail on this below.)

Specifically for self-help books, which range widely on applications, there is a good chance that it will employ some sort of pragmatism. After all psychology developed from philosophy. For an example of another book with the underpinnings of a certain philosophical systems, even though this is not labeled as a self-help book, Zen and the Art of Motorcycle Maintenance ascribes to a type of Asian philosophy. Lastly, everything is not as clear cut as it may seem. There are synthetic philosophies which combine and deviate from the original. Off the top of my head, preference utilitarianism is not the same as classical utilitarianism. Each uses consequentialism, but they are different. 



Similar questions


https://philosophy.stackexchange.com/questions/4426/what-books-can-be-considered-as-philosophy-books What books can be considered as philosophy books? [closed]
https://philosophy.stackexchange.com/questions/527/does-philosophy-belong-to-empirical-science-or-formal-science Does philosophy belong to empirical science or formal science?
https://philosophy.stackexchange.com/questions/32472/is-philosophy-about-living/32491#32491 Is Philosophy about living?
https://philosophy.stackexchange.com/questions/29903/what-are-the-criteria-by-which-we-could-determine-whether-some-field-is-philosop What are the criteria by which we could determine whether some field is philosophy rather than wisdom?




*A much larger--deeper--question is, "What is wisdom." To assume that a self-help book is wisdom itself may be a mistake. To assume that seeing results, or even the results themselves, may not be wisdom. Knowledge is not wisdom. I made that word-memory-swap when the professor of my Intro to Philosophy course asked, "What is philosophy?" picking my raised hand.
The original German reads: http://www.nietzschesource.org/#eKGWB/MA-I-Vorrede-6 "Du solltest Gewalt über dein Für und Wider bekommen". The capitalization in German is required, so in English it is an interpretation of the translator. 'das Für und Wider abwägen' is German idiom for weighing the pros and cons. 

Basically the text says: you should master your pros and cons; meaning, you should not stick to just one position (pro/for), but learn that each position is just a perspective. You should try out different perspectives (pro and con, for and against).

His argument is: every perspective is necessarily limited and therefore unjust. So if you stick to just one perspective (for or against something), it will cost you an intellectual loss, as you're missing out on what the other perspectives have to offer.

Also note that the text is between quotes. Nietzsche is staging an internal discussion by a free spirit, so it may not be necessarily represent his opinion (perspective), although it this case it seems to be.
The end point of Plantinga's defense is that without evil, there is no good.  And by extension of his argument, without free will, there are no real relationships and no real love.

Given that, the logic of applying ethical responsibility/conduct to someone in a position of authority doesn't really apply here, or at least it applies only in an all-or-nothing way - either take the good with the evil, or remove both.

Therefore, if there is a tipping point, an "amount of evil" that is too much and something must be done about it, that's when you must flip the switch and get rid of both free will and any meaningful definition of "good", "relationship", and "love" (based on Plantinga's defense).

How can we ever hope to make such an evaluation? Can we even really comprehend what a reality like that would be like - living like dogs to a master, or like robots to a factory owner, rather than free moral agents?



Note that if we are to make that evaluation (and I am convinced we are not properly equipped to do so), we have no idea what other factors are involved.  For example, is God mitigating evil already so that it is not as bad as it might have been?

Also, this doesn't take into the equation any metaphysical considerations about individual accounting for deeds done in this life, heaven/hell or any other considerations of this life compared to the afterlife.  If you are going to "weigh the evil" and define an amount that is "too much", it really needs to be an equation which weighs all factors, in which case we need more information to solve for "x".
This is actually quite an interesting problem, unique to the modern problem of representative democracy itself.

First, modern democratic societies generally hold individual subjects (and their individual "souls") morally and legally accountable. We rule out collective accountability of families, generations, races, as were common in premodern societies. This is why Trump's proposals to kill the families of terrorists or Israel's destruction of the family homes of Palestinians appear repugnant and regressive.

Second, as Trump and Netanyahu might retort, this is the case only within nations and not between nation-states in conditions of war, which then brings in all the complexities of wartime conventions, which even the United States has begun to abandon...if only unilaterally. If, for example, Americans elect a president who kills some 200,000 Muslims in acts of war, then are jihadis justified in targeting American civilians as responsible voters? Conversely, in countries without representative democracy, are citizens less responsible for violent acts of their leaders and militaries?

In the case of representative democracy, of course, voters are not entirely passive. There is an enfranchisement and "act" for which they could be held accountable. Yet they are not moral agents or "wills" continuous with those who represent them. Once power is invested in the representative, moral autonomy is dispersed. Even with powers of immediate censure or impeachment voters can only respond to moral acts already undertaken. There would seem to be a kind of limited and partial culpability. This might inevitably get "generalized" beyond individuals in states of war. Morality does not seem to fit well with modern statistical contexts. 

The question of class and revolution is somewhat different. A class may be defined as functioning more or less consciously in its own interests. In republics with serfdom, slavery, extreme property or gender inequality, or other practically limited franchises, a dominant class might well be held accountable for representatives acting in their own interests "legally" but immorally against members of their own nation. Though again with some limits to culpability. In most of the modern revolutions, from France to Russia, the elimination of a dominant, "enfranchised" class was driven more by political-military expediency than moral consideration.    

Apart from all these armchair considerations, there are the practical operations of modern capitalist, democratic societies, where the individual is the operative unit, the financial identity, the primary form of representation, and the legal subject. Except for oppribrium and future elections, how does one go about holding voters accountable? Presumably their bad decisions result in various forms of "blowback" or what the Greeks would call the forces of Nemesis. Unfortunately, modern news cycles, national borders, global economies, and media ideologies are such that voters rarely recognize any link between their own votes and later consequences. Where causality is so diffuse or statistical, so too is any sense of moral accountability. 

Note: I am not familiar with contemporary political and legal philosophy as it applies to these issues of "representation," so I apologize for the lack of references. I hope others can provide.           
1) An intensional meaning picks out a set of things in the world, giving the corresponding extensional interpretation.  But the world changes, e.g., new cats are born every minute.  So the derived extensional definition of cat would almost always be incomplete.  An extensional equivalent to the definition of 'cat' would therefore just not be equivalent.

2) Any set of real objects has more attributes in common than you can list.  The list of people on your soccer team may also have in common a sex, a national origin, fit into different ranges of heights, or weights, or hair colors, or blood pressure readings...  Many combinations of those traits may be sufficient to select just that set of beings.  There are too many possibilities for selecting out that exact set of people to guess that the relevant aspect is playing soccer with you currently.  Not knowing which sets of parameters matter, you cannot stop adding options, because you do not know what kind of seemingly irrelevant detail might have been part of the intended interpretation.

3) This is just not true, the extensional definition of something like the number 3 = {2, 1, 0} in mathematical logic is just fine.  It is uncommon in the real world that a list of things is really what you intended to consider, but it happens.  For instance, you can probably list all the different kinds of commercial recording media in existence in 1972 and have a useful extensional definition with relevant applications in historical domains.  Your author is strangely biased.

4) If something meets all the requirements on the taxonomy to be in a species, that thing is in the species.  A given person may have an inadequate stated definition of 'cat', but somewhere, some biologist has one that is absolutely definitive, by the standards of zoology in general.  And you can, in theory, therefore check out all the animals in the world and identify only the cats, giving you a (temporary) extensional definition of 'cat'.

5) is just 2) restated.
See http://plato.stanford.edu/entries/aristotle-logic/ Aristotle's Logic and http://plato.stanford.edu/entries/medieval-syllogism/ Medieval Theories of the Syllogism :


  In the Prior Analytics, Aristotle presents the first system of logic, the theory of the syllogism . A syllogism is a deduction consisting of three sentences: two premises and a conclusion. Syllogistic sentences are categorical sentences involving a subject and a predicate connected by a copula (verb).
  
  The subject and predicate in the categorical sentences used in a syllogism are called terms (horoi) by Aristotle. There are three terms in a syllogism: a major, a minor, and a middle term. The major and the minor are called the extremes (akra), i.e., the major extreme (meizon akron) and the minor extreme (elatton akron), and they form the predicate and the subject of the conclusion. The middle (meson) term is what joins the two premises. 


Thus, the original technical Aristotelian names has been translated into Medieval Latin and the "current" terminology is of Latin origin.



Consider a simple example of http://plato.stanford.edu/entries/medieval-syllogism/#1 Aristotelian syllogism :


  Mortality belongs to all men
  
  Humanity belongs to all Greeks
  
  
    Therefore, Mortality belongs to all Greeks.
  


It is an instance of the Barbara schema (1st figure), where all sentences are universal affirmatives :


  A belongs to all B.


Thus "Humanity (men)" is the middle term, used as subject in the first premise and as predicate in the second. The middle term is what joins the two premises, acting as a sort of "link", and disappears in the conclusion. 

The name of meson ("middle") term is thus quite intuitive.

See https://en.wikipedia.org/wiki/Prior_Analytics Prior Analytics, 25b32-26a2 :


  I call that term middle which both is itself in another and contains another in itself: in position also this comes in the middle. By extremes I mean both that term which is itself in another and that in which another is contained.


The other two are the akra ("extremes"); also this is quite natural.

The first extreme is the "major" (meizon akron) and the last one is the "minor" (elatton akron). 

See http://classics.mit.edu/Aristotle/prior.1.i.html Prior Analytics, 26a16-26a30 :


  I call that term the major in which the middle is contained and that term the
  minor which comes under the middle.


In terms of "modern" set-theoretic interpretation (see https://en.wikipedia.org/wiki/Venn_diagram Venn diagram and http://philosophy.lander.edu/logic/syll_venn.html Venn Diagrams for Categorical Syllogisms), the set corresponding to the minor term is included into that corresponding to the middle, which in turn is included into that corresponding to the major term.

In terms of aristotelian language, the major term is is "more universal" than the middle, which in turn is "more universal" than the minor:


  [Pr.An., Book A, 46a39] In demonstrations, when there is a need to deduce that something belongs, the middle term through which the deduction is formed must always be inferior to and not comprehend the first of the extremes. 

The symbol ⊃ (called "horseshoe") was used a century ago for the conditional connective "if-then", and subsequently replaced by → or ⇒.

The sources are https://en.wikipedia.org/wiki/Giuseppe_Peano Giuseppe Peano and A.N.Whitehead & Bertrand Russell's http://plato.stanford.edu/entries/pm-notation/ Principia Mathematica.



For the "devious" evolution of the symbolism, we can see : 


Florian Cajori, https://books.google.it/books?id=_byqAAAAQBAJ&printsec=frontcover A history of mathematical notations (1928) : SYMBOLS IN MATHEMATICAL LOGIC, §667-on :



  [§674] A theory of the meccanisme du raisonnement was offered by http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Gergonne.html Joseph Diaz Gergonne in an https://books.google.it/books?id=MnQKAAAAIAAJ&pg=PA194 Essai de dialectique rationnelle (1816-1817); there the symbol H stands for complete logical disjunction, X for logical product, I for "identity," C for "contains," and "Ɔ (inverted C)" for "is contained in."
  
  [§685] https://en.wikipedia.org/wiki/Ernst_Schr%C3%B6der Ernst Schröder, [into his http://gdz.sub.uni-goettingen.de/dms/load/img/?PID=PPN717192873|LOG_0016&physid=PHYS_0147 Vorlesungen über die Algebra der Logik, Vol. I (Leipzig, 1890), see page 129], used ⊂ for "is included in" (untergeordnet) and ⊃ for "includes" (ubergeordnet).
  
  [§690] (page 301 of 2nd vol) Some additional symbols are introduced [by Peano into Number 2 of Volume II of his Formulaire]. Thus "ɔ" becomes ⊃. By the symbolism p.⊃ x ... z. q is expressed "from p one deduces, whatever x ... z may be, and q."


In his monograph: http://mathematica.sns.it/opere/138/ Calcolo geometrico (The geometrical calculus according to the Ausdehnungslehre of https://en.wikipedia.org/wiki/Hermann_Grassmann H.Grassmann, preceded by the operations of 
deductive logic, 1888), Peano stress the duality of interpretations of his symbolism, in terms of classes and propositions :


  we shall indicate [the universal affirmative proposition] by the expression 
  
  
    A < B, or B > A, 
  
  
  which can be read "every A is a B," or "the class B contains A." [...]
  
  Hence, if a,b,... are conditional propositions, we have: 
  
  
    a < b, or b > a, says that "the class defined by the condition a is part of that defined by b," or [...] "b is a consequence of a," 
    "if a is true, then b is true." 
  


In Peano, https://archive.org/stream/arithmeticespri00peangoog#page/n14/mode/2up The principles of arithmetic (Arithmetices principia: nova methodo exposita, 1899), we have:


  II. Propositions [page viii]
  
  The sign C means is a consequence of [est consequentia]; thus b C a is read b is a consequence of the proposition a.
  
  The sign Ɔ means one deduces [deducitur]; thus a Ɔ b means the same as b C a. [...]
  
  IV. Classes [page xi]
  
  The sign Ɔ means is contained in. Thus a Ɔ b means class a is contained in class b.
  
  
    a, b ∈ K Ɔ (a Ɔ b) :=: (x)(x ∈ a Ɔ x ∈ b). 
  


Finally, in his https://en.wikipedia.org/wiki/Formulario_mathematico Formulaire (1901, 1st edition: 1895), http://ia802607.us.archive.org/24/items/formulairedesmat00pean/formulairedesmat00pean.pdf page 1, Peano writes:


  Soient a et b des Cls. a ⊃ b signifie "tout a est b".
  
  Soient p et q des propositions contenant une variable x; p ⊃x q, signifie "de p on déduit, quel que soit x, la q", c'est-à-dire:
  "les x qui satisfont à la condition p satisferont aussi à la q".




Bertrand Russell, in his https://en.wikipedia.org/wiki/The_Principles_of_Mathematics The Principles of Mathematics (1903) criticized this dualism:


  §13 [ https://books.google.it/books?id=SNWLAgAAQBAJ&pg=PA12 page 12 ] The subject of Symbolic Logic consists of three parts, the calculus of propositions, the calculus of classes and the calculus of relations. Between the first two, there is, within limits, a certain parallelism, which arises as follows: In any symbolic expression, the letters may be interpreted as classes or as propositions, and the relation of inclusion in the one case may be replaced by that of formal implication in the other. [...] A great deal has been made of this duality, and in the later editions of the Formulaire, Peano appears to have sacrificed logical precision to its preservation. But, as a matter of fact, there are many ways in which the calculus of propositions differs from that of classes.


Russell and Whitehead borrowed the basic logical symbolism from Peano, but they freed it from the "dual" interpretation.

Thus, they adopted Schröder's ⊂ for class inclusion [ https://books.google.it/books?id=ke9yGmFy24sC&pg=PA27 page 27 ] :


  
    a ⊂ b :=: (x)(x ∈ a Ɔ x ∈ b) Df.
  


and restricted the use of the "horseshoe" to the connective "if-then".

Note W&R's decision was obvious, if we consider the following example from https://en.wikipedia.org/wiki/Cesare_Burali-Forti Cesare Burali-Forti, https://archive.org/details/logicamatematic01buragoog Logica Matematica, 1894, page 70:


  
    a Ɔ b . b Ɔ c : Ɔ : a Ɔ c [...]
  
  
  The first, second and fourth [occurrences] of the sign Ɔ mean is contained, the third one means one deduces.






In conclusion, there is no specific "intuition" behind the adoption of certain symbols; we have only a "shift of meaning" from previous symbols to new ones.
It is an interesting observation that you make, since, on the surface, the two "statement functions" appear to express contradictory things. 

Your headline question "How can a statement function make no definite assertion about anything?" is answered with the obvious response : because that is how the author has defined a statement function in the quoted text. When one reads a statement function such as Sx ⊃ Px, one needs to ask "what x?" before one can impose any meaning, and this is what the quantifiers do.

As the author states, the green expressions (statement functions) cannot be translated as a statement, so according to the author's intentions it is not correct to say than the green expressions "match, and so assert" the statement "S are P".  Indeed, according to the quoted text, a statement function makes no assertion.

The author's example shows how quantification of a "statement function" can impose meaning onto the resulting statement, and that different quantifiers can yield quite different symbolic translations and meanings.

EDIT

If you are familiar with the concept of function in mathematics, then just as a mathematical function has no meaning without a domain, in logic a statement function has no meaning until its domain is specified by quantification.
When the author suggests that "we take certain liberties", he means "if we drop the rigours of our logical formalism and look at statement 5 in a non-rigorous, hand-wavy, informal way", then we can translate statement 5 accordingly.

To best understand the formal concept of a statement function, the key word to focus on here is "function".  As I noted in https://philosophy.stackexchange.com/a/31130/8572 my previous answer, a function is only fully defined when we have assigned it a domain (i.e., a universe of discourse).

For example, if S denotes "is divisible by 4" and P denotes "is divisible by 2", then Sx ⊃ Px can only be assigned a meaning when we know the domain/universe from which x is chosen. Otherwise, from a formal point of view, x is just a typographical symbol and the statement function is just (what the author refers to as) a pattern. If the universe is the set of whole numbers then the meaning is obvious and the statement (x) Sx ⊃ Px is true, while the statement (x) Px ⊃ Sx is false.  Of course, from an informal point of view, we can assign a meaning once we know what S and P denote.  

Therefore, the example given here does not contradict the formal statement of page 457, since the treatment given here is an informal one.  

  Is it really problematic for Universal Instantiation to precede Existential Instantiation?


Of course not.

The issue is that if we start "instantiating" ∀x first, then when instantiating ∃x we cannot use the same name used into UI, in order to comply with the proviso of EI that:


  "the name introduced by existential instantiation [must] be a new name".


This means that we will have e.g.  

i) Ad ⊃ Cd --- from 1. by UI

and

ii) Ae ∧ Be --- from 2. by EI [e new, by the proviso]

and we cannot conclude; in order to "move on", we have to instantiate again 1. with the newly introduced name e.
In Karl Marx and the Future of the Human, Cyril Smith makes a statement on this that can be found https://books.google.de/books?id=SP6BIxOQET4C&pg=PA199&lpg=PA199&dq=DIESSEITIGKEIT+marx&source=bl&ots=yFXoQOd9ZK&sig=t-9eYF-8LTIpR14LIebSJhFegyw&hl=de&sa=X&ved=0ahUKEwiOtvXwxZDKAhXBFQ8KHeTJADYQ6AEIHzAC#v=onepage&q=DIESSEITIGKEIT%20marx&f=false here:


  The odd word "Diesseitigkeit" might carry a bit more weight than is sometimes imagined. It is chosen as the opposite of the much more common "Jenseitigkeit", "other-worldliness" or transcendence.


I think the terminology refers to Hegel, e.g. to his Phenomenology of Spirit, where he writes in the Chapter III Force and the understanding; 
appearance and the supersensible world:


  In this, the “inner true,” as the 
  absolutely universal which is purified of 
  the opposition of universal and individual 
  and which has come to be for the 
  understanding, what is disclosed for the 
  first time and henceforth is a supersensible
  world as the true world over and above the 
  sensuous world as the appearing world. 
  That is, over and above the vanishing this-
  worldliness [Diesseits], there is disclosed an persisting 
  other-worldly beyond [Jenseits], an in-itself which is 
  the first and therefore incomplete 
  appearance of reason, that is, which is the 
  pure element in which the truth has its 
  essence.


Diesseitigkeit is an adjectivation of the noun Diesseits (translation: this world), Jenseitigkeit accordingly of Jenseits (translation: the other world). 

As another possible direction, the Historisch-kritisches Wörterbuch des Marxismus [Historic-Critical Dictionary of Marxism](German, found http://dhcm.inkrit.org/wp-content/data/hkwm-feuerbach-thesen.pdf here) states regarding the actual relation to Feuerbach that Marx' criticism is aiming primarily at Wesen des Christentums [The Essence of Christianity] and thesis two is about the concept of Gattung [Category?!, not sure] there. But as I'm not into Feuerbach, I cannot give any more specification on that.

Conclusion

I actually think with Cyril Smith that his materialism is here to be thought as a statement against the priority of thought in dualism and idialism (and, taking the answer of @KentaroTotomo, Feuerbach's wannabe materialism), but would add that as Feuerbach wrote about Christianity, also against the priority of afterlife in there: Thought and truth are not "of another world" and there are no things in themselves, therefore the truth (and good!) can be proven (and have to be!) in practice, that means in a change of this world. This is coherent to the general line of attack in his Theses. Hence, Diesseitigkeit has nothing to do with capitalism.
In the passage from s → n to ¬s ← ¬n the term n does not jump over the chasm between necessity and sufficiency, ¬n does. [This preceding paragraph answers an older version of the OP.]

It is the negation that does the trick. Think of a "condition" as a restriction on the class of things that satisfy it, the stronger the restriction the narrower the class. Normally necessary conditions are weaker than sufficient conditions, but negation always reverses the order of strength: the negation of a weaker condition is always stronger than the negation of a stronger condition.  For example, being a solid is a weaker restriction than being a crystal, but being not a solid is a stronger restriction than being not a crystal (eg: 'wood' is not a crystal, but wood is a solid.) And this is the essence of MT: accepting MT amounts to getting directly from 1 to 4. MT then follows by applying modus ponens to 4.

I don't know if this will help or confuse you further, but modus tollens is accepted even by intuitionists, who have stricter demands on validity of arguments. They interpret logic in terms of proofs and reason as follows: s → n means that any proof of s can be converted into a proof of n, ¬n means that we are given a proof of ¬n. Thus, if we were given s we would acquire proofs of both n and ¬n, and we can not have that. It must be ¬s. If this resonates you may look at https://math.stackexchange.com/questions/838184/contraposition-in-intuitionistic-logic Contraposition in intuitionistic logic? on Math SE, if not disregard.
Because UI and EI rules "works" only with outermost quantifiers, i.e. when we have e.g. (∃x)Px.

If we have instead (∃x)Px ⊃ (∃y)Qy, we cannot apply the quantifier rules to remove them.



According to your question 2, you think that the proof should be 'simpler' as follows :

[1A] i.e. 11) (∃x)(∃y)(Jxy ∨ Kxy)   --- premise

[1C] i.e. 12) (∃x)Lx         --- premise

2) (x)(y)(Lx ⊃ ¬Ly)         --- premise

13) Lo               --- from 12) by EI

14)-15) Lo ⊃ ¬Lo          --- from 2) by UI twice

16) ¬Lo              --- from 13) and 15) by MP

17) Lo ∧ ¬Lo            --- from 13) and 16) by Conj

Now we have a contradiction and thus - according to the IP rule - we have to "discharge" one of the premises to derive this one premise's negation. We may discharge 12), deriving :


  18) ¬(∃x)Lx.


The derivation is formally correct, but what we have proved is:


  
    from the premises : (∃x)(∃y)(Jxy ∨ Kxy),  (∃x)Lx,  (x)(y)(Lx ⊃ ¬Ly), 
    
    it follows ¬(∃x)Lx.
  


Please, note that the derivation does not use [1A] at all; thus (as we can imagine) the derivation boils down to :


  (x)(y)(Lx ⊃ ¬Ly) implies ¬(∃x)Lx.


The textbook's original proof was instead :


  
    from the premises : (∃x)(∃y)(Jxy ∨ Kxy) ⊃ (∃x)Lx,  (x)(y)(Lx ⊃ ¬Ly), 
    
    it follows (x)(y)¬Jxy,
  


which is quite different.
I'm a medievalist. I don't know of any discussion of angels dancing on pinheads, probably because literally every medieval theologian (at least in the Christian tradition) would have regarded angels as immaterial beings. So they don't occupy space (or at the very least, not in the same way bodies do).

Aquinas argues in http://dhspriory.org/thomas/summa/FP/FP052.html#FPQ52A3THEP1 Summa Theologica I q. 52 a. 3 ("Whether several angels can be at the same time in the same place?") c. that two angels can't be in the same place, but not for the same reason two bodies can't be in the same place:


  There are not two angels in the same place. The reason of this is because it is impossible for two complete causes to be the causes immediately of one and the same thing. This is evident in every class of causes: for there is one proximate form of one thing, and there is one proximate mover, although there may be several remote movers. Nor can it be objected that several individuals may row a boat, since no one of them is a perfect mover, because no one man's strength is sufficient for moving the boat; while all together are as one mover, in so far as their united strengths all combine in producing the one movement. Hence, since the angel is said to be in one place by the fact that his power touches the place immediately by way of a perfect container, as was said (http://dhspriory.org/thomas/summa/FP/FP052.html#FPQ52A1THEP1 Article [1]), there can be but one angel in one place.


He writes in http://dhspriory.org/thomas/summa/FP/FP052.html#FPQ52A1THEP1 Article [1]:


  It is befitting an angel to be in a place; yet an angel and a body are said to be in a place in quite a different sense. A body is said to be in a place in such a way that it is applied to such place according to the contact of dimensive quantity; but there is no such quantity in the angels, for theirs is a virtual one. Consequently an angel is said to be in a corporeal place by application of the angelic power in any manner whatever to any place.
  
  Accordingly there is no need for saying that an angel can be deemed commensurate with a place, or that he occupies a space in the continuous; for this is proper to a located body which is endowed with dimensive quantity. In similar fashion it is not necessary on this account for the angel to be contained by a place; because an incorporeal substance virtually contains the thing with which it comes into contact, and is not contained by it: for the soul is in the body as containing it, not as contained by it. In the same way an angel is said to be in a place which is corporeal, not as the thing contained, but as somehow containing it.


There are important medieval questions that do exhibit the phenomenon that the author you've quoted is interested in. One case in point: medieval debate about how God knows things involve some very interesting speculation about philosophical psychology.
The following quotes are from the letter from 16.7.1903


... excessive noise that makes Things tremble = des übergroßen Lärms, von dem die Dinge zittern
...  if you trust in Things = wenn Sie sich an Dinge halten
... in the small Things = an das Kleine


The following quote is from the letter from 29.10.1903


… the very few Things in which something eternal endures = die sehr wenigen Dinge [...], in denen Ewigkeit dauert


The following quote is from the letter from 23.12.1903


… connected to the important Things = mit den großen Dingen […] in Beziehung ist


At all locations the term Thing has no particular philosophical meaning. The term is used just in the ordinary sense of thing (with small initial). I consider it a wrong translation to emphasize the term by a capital initial.

Note: In German the word "Ding" has always a capital initial because it is a noun.
Regarding your question 1 : 


  
  To prevent something from happening, why do we usually search for a cause that is a NC? Both prevention and production of something need the SC, because NCs do not reveal the entire 'picture'. 
  


This appears to be backwards to me.  A SC captures one reason for a consequent, but not necessarily the only reason for a consequent.  Suppose you wish to know if a number is even.  A sufficient condition for evenness is divisibility by 4, but obviously this is not a necessary condition for evenness.  An NC for evenness would be divisibility by 2, and this does "capture the whole picture".

In the quoted text, Hurley states : "scientists try to isolate a necessary condition or group of necessary conditions that, if removed, will eliminate the smog".  Let's suppose: their efforts have succeeded and they have identified the, say, 10 chemicals that cause smog. (For now, let's ignore your point about the difficulty in detecting chemical10.) Then, quasi-formally we have :


smog = (chem1 ∨ chem2 ∨ ... ∨ chem10)


and therefore


¬smog = (¬chem1 ∧ ¬chem2 ∧ ... ∧ ¬chem10)


Some of your confusion may arise from the fact that the disjunctive statement for smog (ie 3) is both a NC and a SC for smog since we are assuming that scientists have identified all of the chemical components of smog.   Suppose that 'smog' were not defined by 3, but instead by the statement 


An SC for smog = chem1 ∨ chem7. 


Then 5 is not a NC for smog since we can still have smog if there is no chem1 or chem7 present - e.g., just chem3 is present in the air.  In other words, a SC is sufficient to cause a consequent, but it is not the only way to cause a consequent.  

If we wish to eliminate smog, then 4 (the conjunctive statement for ¬smog) tells us that we must necessarily eliminate each of the 10 chemicals.  Again, this is both a NC and a SC for no smog since we are assuming that scientists have succeeded in identifying all of the chemical constituents of smog.  Suppose that ¬smog were not defined by 4, but instead by the statement 


¬smog = ¬chem4 ∧ ¬chem8. 


Then 6 is a NC for not having any smog, but 6 is not a SC since other problem chemicals may be present.  The Argument Form  of 6 is the 'mirror opposite' of the Argument Form of 5 (the subgroup of the disjunctive statement illustrated in the previous paragraph). Beware that I use 'mirror opposite' to describe the relation between NC and SC in the two examples, not to the formal content of 5 and 6 (since 5 and 6 are not the negations of each other): ie, 5 is a SC but not a NC, while 6 is a NC but not a SC, hence 'mirror opposite'. The use of 'mirror opposite' is probably not the best choice of words since it is perhaps too strong in this context.

The reason I have bolded try in the text quoted from Hurley is that this may be why you question the case "but Chemical 10 is fatal but hardly detectable".  If scientists have not succeeded in identifying all of the constituents of smog, or are unable to detect all of the constitutents, then establishing NCs and SCs are more selective.  Assuming other unknown or undetectable chemicals are required and not listed, the disjunctive statement for smog would become SC but not NC, while the conjunctive statement for ¬smog would become NC but not SC.
Consider Px01; it is clearly true for both cases : x=0 and x=1, i.e. for all elements of the domain.

Thus, ∀x∃y∃zPxyz is true. But this is equivalent to : ¬∃x¬∃y∃zPxyz which is the negation of the right disjunct.
First, I have read only secondary works on Rawls and have not read "Theory of Justice" itself, but it is on my list. Unlike Rand, Rawls was an analytic philosopher with a distinguished background, and was among the first to propose ways in which the Anglo-American tradition could revisit "value" questions such as justice, which had long been proscribed by the logicians and specialists.

The book is supposed to be quite rich in itself, full of philosophical excursions, not just a simple plan. His main target is utilitarianism, and I would agree there are many reasons to find utilitarianism unsatisfactory. He attempts to recover something of Kant, without the idealism. 

I'm not sure, but I would not call him necessarily capitalist or "objectivist light." His "veil of ignorance" is, I feel, an excellent way to update elements of the Kantian categorical imperative and the "state of nature." His "difference principle" allows for social inequality and hierarchy, only to the extent that it can be shown to benefit the least empowered stratum of society, as in the training of doctors, for example.

So while it is pragmatic, it is fundamentally egalitarian, closer to Habbermas than Rand. The work is complex enough that it might to read and applied in different ways. The Marxist Koji Karatani claims that Rawls did move closer to socialism in his later years and in the introduction to later editions.

I have only read a bit of Rand and secondary texts, so can offer only an "opinion," as some committed Objectivists have hotly reminded me on this site. But as far as I know, Rand did not really engage with other philosophers in any professional capacity. I don't think there is any Rand commentary on Wittgenstein, Frege, Fichte, possibly not even on Kant. It is unclear how much philosophy she read, and I have no idea of she read beloved classics in the original or in translations only.

This is one reason why she is "not taken seriously." Among professionals Nozick was most sympathetic to her and even he didn't find her credible as a philosopher. Certainly, it does not help her case that she wrote capitalist bodice-rippers, purveyed "elitism for the masses," made a habit of rather vile "provocative" remarks in the limelight, and cast a such wide spell over impressionable American minds as the anti-liberal "contrarian" and Nietzschean she-devil of the Chamber of Commerce. But I digress...          
The English word value form translates the German Wertform.

It appears for the first time in Marx, Karl: Das Kapital, Band 1, Abschnitt 1, Kapitel 1, Paragraph 3, entitled "Die Wertform oder der Tauschwert".

Marx states that goods can be viewed from two different aspects: 1) Their natural form - they are made from iron, linen cloth, wheat, and 2) their value form (Wertform) - they represent a value, expressed in the form of money.

Hence one should not over-interpret the term form in the word value form. I think one does not need not relate it to the philosophical concept of form introduced by Plato or used by Hegel.  
Gödel was a young man in search of a place to belong, many young intellectuals were attracted to the Vienna Circle for its pluralism and tolerance. But it wasn't purely social. Gödel was clearly interested in mathematics, in 1925-26 Schlick, the circle's founder, gave lectures on philosophy of mathematics which Gödel attended. But it was Carnap, who really pulled Gödel in and turned his sights towards logic. https://dash.harvard.edu/bitstream/handle/1/3153305/Goldfarb_OnGodelsWay.pdf?sequence=2 Goldfarb in On Gödel's Way In describes Gödel's path towards the incompleteness theorem that begins with Carnap's 1928 lecture, and his pseudo-completeness theorem based on a question begging definition of logical consequence. 

It is hard to say if Gödel's later philosophy of mathematics was determined by his entry jewel, the incompleteness theorem (it certainly played a key role in his arguments), or if it only confirmed his pre-existent disposition. In any case, in the early years he was clearly more interested in logical and linguistic aspects of logical positivism than in its epistemology. By the way, although Gödel's mature philosophy is often glossed as Platonism, it is closer to Aristotelian realism, where ideal objects exist "beside" material ones as their forms, not in a separate realm. In particular, Gödel was self-admittedly influenced by Husserl's modernization of Aristotelian realism.

By the way, Quine was also closely associated with the circle in 1930s, and boy did he and Gödel break logical positivism.
Your argument is basically Pascal's wager.  You've simply replaced heaven/hell with immortality/death.

Accordingly, any argument for or against Pascal's wager will be valid in this scenario.  For example, your scenario ignores the possibility that there may be a different wager available for immortality with better odds, if you'd just wait a little while longer.  In fact, given that the mathematics regarding infinities have been substantially improved since Pascal's time, there are a multitude of arguments which stem from the ability to properly apply value theory with infinities and infinitesimals.
Nietzsche writes in the second aphorism from the section What I Owe to the Ancients of his work Twilight of the Idols, or, How to Philosophize with a Hammer (1888):


  I am a complete skeptic about Plato, and I have never been able to join in the customary scholarly admiration for Plato the artist. The subtlest judges of taste among the ancients themselves are here on my side. Plato, it seems to me, throws all stylistic forms together and is thus a first-rate decadent in style: his responsibility is thus comparable to that of the Cynics, who invented the satura Menippea. To be attracted to the Platonic dialogue, this horribly self-satisfied and childish kind of dialectic, one must never have read good French writers — Fontenelle, for example. Plato is boring [my emphasis]. In the end, my mistrust of Plato goes deep: he represents such an aberration from all the basic Greek instincts, is so moralistic, so pseudo-Christian (he already takes the concept of "the good" as the highest concept) that I would prefer the harsh phrase "higher swindle" or, if it sounds better, "idealism" for the whole phenomenon of Plato.


Nietzsche considers Plato boring due to his style of writing in his dialogues. But Nietzsche's rejection of Plato goes deeper and is based on the content of Plato's philosophy, see the quote.

The quote above partly supports your first proposal. But it does not support your proposals two and three.
I don't know if the objection was raised but I believe that naturalised epistemology proponents have the resources needed to answer the objection. The reason, I think, is that being willing to revise one's belief in front of contradictory experience is not the same as not having the belief outright, or being sceptical about it.

It would have been inappropriate to raise the objection against someone who, a few centuries ago, would have said "I believe physical space is fundamentally euclidean but I will revise my belief if an alternative works better". Although it seemed obvious to many (and even, for authors like Kant, a priori true) that physical space was euclidean, it turned out that it is better conceived of as non euclidean. Such a person could have been sincere: no doubt she could have adopted relativity, as many did, in front of crucial experiences. The fact that she strongly believed that space is euclidean, and acted accordingly, does not alter her sincerity when she said she would revise this belief if necessary.

One could argue "well, you're not really willing to revise beliefs such as 'red is a color' because if you did, you'd only change the meaning of 'red' or 'color', so you're not sincere when you say you would revise anything". This argument misses the point: it's not obvious whether we changed or not the meaning of 'space' when we switched to non-euclidean geometry, and the defender of NE will say that meaning is a dubious, or at least a flexible notion and that there is no fact of the matter whether it is the meaning of 'space' or our beliefs about space that we changed. If it turns out that our notion of color is not as appropriate as we think and that it must be redefined in such a way that red is no more a color (or perhaps only in certain widespread contexts), then why not switch to this new framework?

Perhaps the closest to an insincerity objection I can think of is the charge that Quine claimed that even logic is revisable, and was at the same time among the most conservative about first order logic against alternative logics. I heard this objection quite often informally. It amounts to suggest that Quine was not really sincere when he said that he thought logic to be revisable. However Quine argued that logic is so central to our conceptual schemes that the evidence needed to revise it would be tremendous, so again, all this merely shows that being willing to revise a belief if an alternative turns out to be better (however unlikely the prospects) is different from being sceptical outright, and that it is not even incompatible with holding the belief very firmly (if the prospects of revision are very unlikely).

If NE is sceptical about meaning, a more subtle objection could target the view that there are no meanings: after all, NE rests on a scepticism about a priori meaning and analyticity. The objection would go: "you say you don't believe in analyticity but you show otherwise". I'm not sure that kind of objection can get off the ground because analyticity is not a trivial, common sense concept that would be implicit in so many arguments. At least the burden is on the attacker to show that a NE defender is using the notion. Perhaps the notion of meaning is more common sense and often used implicitly, but the defender of NE can argue that she has an aposteriori conception of meaning as use, and that what she is sceptical about is the idea that meaning is a priori.
As Jo Wehler pointed out, Quantum Mechanics made Laplace's demon impossible based on empirical evidence. 

But if we ignore QM, your line of reasoning becomes very interesting: Isn't there  a contradiction in the fact that if Laplace's demon could predict future events, she could also changes those events based on that knowledge so that the prediction is invalidated? In fact mathematician David Woplert used reasoning similar to yours to prove that Laplace's demon is impossible, no matter which laws of physics govern the universe.  In a nutshell, he proved that no entity could ever fully predict a universe that it is part of. The only way Laplace's demon could pull this off is if they were outside of the universe (whatever outside of the uinverse means). 

The idea is the following: Both observation and prediction are formalized in the concept of inference device, and he defines strong (i.e. universal) inference devices and self aware inference devices. Using what he calls inference complexity, he shows that there are limits to what such devices can predict, similar to the way the halting problem shows the limits of universal Turing machines.

His result is analogous in a way to Godel's "No theory can prove it's own consistency", in that he shows that no universe can completely predict itself (since physical inference devices are embedded within this universe).

Here's the original http://ti.arc.nasa.gov/m/pub-archive/1476h/1476%20%28Wolpert%29.pdf article and a http://www.scientificamerican.com/article/limits-on-human-comprehension/?page=1 general explanation of the idea. 
What we have here are not logical arguments, but their pragmatic replacements, cost/benefit judgement calls. But your intuition is not far off, the problem is in the basis for judgement. In practical examples that basis is clear and there is even implied quantification of cost/benefit. Applying to Harvard presumably requires a lot of effort, saving this effort produces an obvious benefit, the same with shark attacks in Maine, assuming you enjoy swimming. Obvious benefits are accompanied by minimal costs due to low probability of adverse effects.

But what exactly is the cost/benefit in "you shouldn't bother eating healthy since death is inevitable"? Saving effort on healthy eating? If so, the obvious extension is "you shouldn't bother living since death is inevitable". But if the latter is not acted upon then living is apparently recognized as having a benefit in itself, while the impact of healthy eating on that is obviously ignored in the original "judgement". Similarly, "science is pointless, since absolute knowledge is impossible" suggests that the "point" of science is "absolute knowledge". If that is the case, good call! However, usually science's goals are seen as far more modest and practical. 

The difference between validity and soundness is that a sound argument also has true premises. Loosely applying it here these "arguments" are "valid" if the "point" they suggest is accepted as the basis for judgement. But once the said "point" is spelled out it becomes very hard to see how this basis is sound. 
I am not an anti-realist, but since none stepped up I'll try to explain as I understand it. Dummett, the founder of modern analytic anti-realism, emphasizes that unlike realism, anti-realism is not a unified doctrine, one can be an anti-realist about some specific domain (mathematics, physics, ethics, past, future, etc.), and a realist about the rest. The motive behind it is that for statements to have meanings they must be understandable, and understanding them means being able to access evidence for or against them because meaning can only be communicated to others overtly. 

Dummett's original position is expressed in http://www.jstor.org/stable/4544778 Reality of the Past, and is simply that all we can mean by claims about the past reduces to organizing traces of it in the present, or rather of what can be usefully treated as "traces of the past". Under his moderate version of anti-realism, justificationism, we do not commit to "reality" of such claims, but neither do we deny it. For instance, consider "king James II had migraine on the day of his 32 birthday". If there is a record of it somewhere then we know how to understand it, but what if there is not? What does it mean exactly? That it "really" did happen out there? But if we can have no access to out there in principle it is questionable that we "really" understand what that means. How then can it be confirmed or refuted? It would seem that we are implicitly imagining "in principle" something like a time machine. What about "Hilbert had discalculia"? Discalculia is a learning disorder that was only identified in 1974, Hilbert passed away in 1943. Even more than a time machine would be needed to make sense of this one. 

The more concrete a statement, the less it is removed from the present, the stronger the "feeling" that we "really" do understand it regardless of access. But as statements get more general and further removed their meaning reduces to little more than this is a useful way to organize available trace record. And on the available record there is little distance between realists and anti-realists, but anti-realists do not attach any metaphysical add-ons to it, and reserve judgement on the unknowable. So "the very first mammal appeared in Africa" has no logical value, true or false. In practice, back projection of trace statements is a handy mental shortcut, the same one we routinely take with everyday objects or even with theoretical entities like atoms, the same one our visual cortex takes to fill in patterns. But a shortcut is all it is, and it produces illusions just as well as it detects patterns.

Is this counterintuitive? Very. Dummett himself http://www.nordprag.org/papers/epc1/Risberg.pdf after 40 years of anti-realism called it "coherent but repugnant", and experimented with softening justificationism about the past by placing it into subjunctive mood. So the past tense is meaningful if "someone suitably placed could have verified it". Presumably, "suitably placed" allows for something like a time machine to do the placement, so "king James II had migraine on the day of his 32 birthday" would clear the hurdle, but I am not so sure about the aspects of Big Bang not recoverable from the current universe. See http://www.nordprag.org/papers/epc1/Risberg.pdf Rispberg's Objectivity of the Past.

There is a stronger version of anti-realism, called contructionism, which goes beyond justificationist reservation of judgment, and positively claims that history is socially constructed rather than "real", and even the terms in which it is expressed only mean in the cultural context of the constructors (and not what they ostensibly purport to mean). This is more often applied to human rather than natural history, and is a common theme in social and cultural criticism. Orwell immortalized a sinister version of it in 1984, "he who owns the present owns the past; he who owns the past owns the future", which was approximately practiced in some communist and fascist countries. See more in https://books.google.com/books?id=FeVdNxyFiKsC&pg=RA3-PT124&dq=anti-realism++history+constructionism&hl=en&sa=X&ved=0ahUKEwiyo7iwjPHKAhVV8mMKHTWCAyoQ6AEIHjAA#v=onepage&q=anti-realism%20%20history%20constructionism&f=false Pataut's Anti-realism about the Past and https://books.google.com/books?id=LIiJAgAAQBAJ&source=gbs_navlinks_s Burr's Introduction to Social Constructionism.
Popper expresses his position on the testability of statements about probability most clearly at the end of Section 68 of LScD, see also Section 66. His position is that we have to make a methodological rule about what relative frequencies should be deemed consistent with a probability estimate. That rule, he maintains, should not be arbitrary but should be a result of the accuracy with which the rule can be tested with available technology. In LScD, Popper advocated the frequency theory of probability. He later changed his mind and adopted a propensity interpretation of probability but this did not change the substance of his position on the testability of probability statements. The propensity interpretation postulates some sort of measure over the set of possible states, but Popper didn't provide any explanation of why this measure was supposed to be relevant as far as I can tell.

A more satisfactory explanation of the testability of probabilistic statements has been supplied by David Deutsch. Statements of the sort commonly described as probabilisitic http://arxiv.org/abs/1508.02048 can be tested when the laws of physics provide a measure over the set of possibilities that respects the probability calculus. Such a measure has been http://arxiv.org/abs/quant-ph/9906015 derived in the context of quantum theory. See also a https://www.youtube.com/watch?v=wfzSE4Hoxbc lecture he has given on this issue.
Translating Heidegger

I will translate this sentence in two steps, trying to extract what I take it to say. First, the more literal translation:


  Being the reason for a being defined by a nonentity, that means being the reason of a nothingness.


Grundsein consist of "Grund" = ground, basis, foundation,cause, reason and "sein" = being. I hold "reason" to be the best translation, as it seems to point at a relation of inference and not a material connection.

Now, as we are speaking about ontology and a criticism of German Idealism (and neo-kantianism in particular), I think that what I translated as "nonentity" can be held to mean "negativity". "Nichts" is nothing else than the absence of everything, pure negativity.
So if we have a reason to state something that we can only define negativly, do we really have reason to state anything meaningful? I think Heidegger here insists that we do not.  

This is supported by the fact that "Nichtigkeit" in a literal common meaning could be described as "something that has no importance whatsoever" with a prejorative connotation. I do not know about the native connotations of "nothingness", so I do not know if the first approximation is a good one here.

Having said this, a second step could be a reformulation:


  Being the reason for a being that can only be defined negatively means being the reason for a concept without any meaning or importance.


And this in fact means that whatever we have reason for to state, if it can only be defined negatively, it cannot be anything that is in an ontological sense. And in fact that it isn't even a reason in any meaningful sense, because it is not the basis for a valid inference.

So while Heigegger is said to have many neologisms, I think he often only exaggerates certain, sometimes only marginal connotations by substantivating in an unusual way. I take it to be a particular way of making neologisms, because it is not only inventing a word to have a technical symbol for a meaning that I want to have an original sound, like Peirce's "Pragmaticism" and the like. Heidegger plays with the german language and its native connotations and does not simply introduce a symbol for the meaning he wants to have it. 

(For me, this is where the positive aspects of his writings, thinking and living end, but this is another story.)

About Neologisms in German and by Hegel

In German, it is normal to make new words out of others without making them inconceivable. If I say Schifffahrtskanalaufsichtsbevollmächtigter (authorized person [Bevollmächtigter] for supervising [Aufsicht] a canal [Kanal] for the ride [Fahrt] of ships [Schiff] => 5 Words and it can get even worse!), every native speaking German will get what I am talking about, although I just made it up. German is THE language when it comes to aggregation of substantivated words. And sentences. There are books consisting of a single sentence. So while it may not have an inherent beauty (these words feel ugly, really), it is common. 

It may get beautiful if it becomes more of a playing, with suprising, exciting outcomes like expressing something clearly in one word you would have to think of a description taking a whole sentence. And, as mentioned, this is held to be one of Heidegger's strenghts.

With Hegel, I think it is another case. He sometimes, if he criticizes or more general: writes about other philosophers, can be very metaphorical in his language so that you have to develop a feeling, an intuition for the meaning. This is also the case if he gets into phenomenology. But when it comes to his actual argument, the terms are quite technically defined. The problem is getting the difference between these two aspects of almost lyrical writing and the necessary construction of the concept of philosophy as a science, especially in the Phenomenology of Mind.

Here, the "uglyness" does not come from the neologism as such, but the frustration of having the impression of reading a wall of text, a mere sequence of symbols you cannot conceive. If one can parse the sentence there is in fact a certain beauty in how brilliantly he is able to describe something that is seemingly undescribable (e.g. the phenomenological parts). But his neologisms are really technical and not beautiful at all.
If you are just starting philosophy, good for you. However, you have picked a pretty tall mountain for your first climb. I must confess that I have never read Being and Nothingness, but I can say a little about the term being, which does take some getting used to.

Sartre was influenced by (or, some would say misinterpreted) Heidegger, who is often credited with returning modern philosophy to the "question of being." Heidegger claims that the Greeks were the first to have a distinct term for "being" and were thus enabled to think about the distinction between some "thing" and the "existence of" that thing. In some sense we might say that "being" or "existing" is that which all things have in common, even dreams, fairies, words, trees, people, and theories. They may have very different modes of existing, but we might say all... exist.

But what does this mean? The first thing is to notice that, as with much philosophy, it brings into view something we take for granted, something that becomes invisible to us. Part of Heidegger's argument was that the Greek origins of philosophy lie in this very "not taking for granted" this state of just... existing. Or, as he put it "being there" or Dasein. 

One way to get a feel for it is just to look at the words for being. Something exits, is, will be, was, might be, cannot be. Is it the same as saying something is real, actual? When we say an apple is fruit and an apple is red...are we saying it is "identical to" fruit or "equal to" fruit? Just think about the words and let their oddity sink in.

When Heidegger "returned" to being, what he meant was that he reopened "ontology," the study of "what things actually exist." That is one of the main branches of classical philosophy, along with logic, ethics, and "epistemology," or how we come to "attain and verify knowledge." Since Kant, philosophy had moved away from "useless arguments" about ontology to focus on epistemology or "how we know" what we know. Heidegger and his lineage, including Sartre, turned back to the close observation of being, or in what manner things around us exist. What organizes those things? Are we just an empty center of "beings" or "existences" encompassing our own... being? 

This is not an explanation, obviously, but I hope it gives you a feel for the approach. I would encourage you to look at some guide books, philosophical dictionaries, and other references on "ontology" and "existentialism." Sartre's "formal" work is dense and difficult. A massive French misinterpretation of Heidegger written on amphetamines, some might say.  It builds on a very complex set of issues and terminologies that pass from Descartes through Kant, Husserl, and Heidegger. So it is hardly surprising one doesn't just "get it."

One final tip. Always look at the etymology. Take the words "being" or "is" or the French or Greek, or any other apparently common words you encounter in philosophy, and just look back at the history of the word's parts and meanings. We take words for granted, and in philosophy you have to "freeze" them, put them in a specimen jar, and examine them carefully, noting how odd they really are.    
1) Free will - according to a libertarian view - is defined by the following criteria:


Liberty: Under identical conditions it would be possible to decide or act in a different way than one actually did.
Intelligibility: The actor can explain and show the reasons why he decided and acted as he did.
Authorship: It is the person in question who decides and acts. The person is not forced.


Advocates of free will differ how strict they interpret these criteria. The contra-position to a libertarian view is a deterministic view. Our subjective and conscious experience conforms to a libertarian view. But the only scientific view (neuroscience), which I consider to have the ability to explain the phenomenon, is a deterministic one. 

For the whole issue see e.g., Walter, Henrik: Neurophilosophy of Free will. (2001)

2)  Of course we are influenced by outside factors. Most of all we are influenced by our previous experiences with our fellow men and with the physical world. In a given situation we do not just react to external stimuli. Instead our reactions depend also on our internal state. The latter is determined by what we have learnt and experienced. 

Being totally independent in our decisions would not mean to decide but to play at dice (random choice).
I don't like to resurrect old threads, but I'll give this one a go since this might help clarify issues for others as well. The blogger is getting at what is come to be known as "Ramsey's Problem."

Ramsey's problem is a simple question. A universal is something that runs through many distinct particulars. One universal runs through many particulars. Redness is instantiated by the fire hydrant, my lollipop, and my flower. A particular is something that runs through many universals. My particular lollipop instantiates redness, sweetness, and sphericity (if geometrical shapes are universals at all). How then do we distinguish a universal from a particular? This problem is supposed to be insurmountable for someone who holds to a universal/particular distinction. If you cannot draw a proper distinction to distinguish particulars from universals, then why hold to such a distinction in the first place?

Bundle theorists say that there are no such things as particulars, only universals which are tied together by a relation of compresence. Compresence is a relation that holds between any two properties of the same thing. Bertrand Russell's complex of compresence is a class of universals, where each member has the compresence relation to each other members. A complete complex of compresence (CCC), as Russell defines it, is a complex of compresent universals where no further universal can be added because if there was another, it would fail to have the compresence relation with at least one of the members in the group. To the Bundle Theorist, particulars are complete complex of compresent (CCC) universals.


  If we cannot trace back from a finite number of properties to a
  particular that will bear properties 
  then why even bother with particulars at all?


True, if there is no ultimate possessor of the universals in question, then. . . why bother with particulars, whatsoever? So you can't hold to the particular/universal distinction.


  Why not just say an object is a chain of properties? Perhaps this chain is finite in the number of properties that compose it. But if a philosopher wishes to maintain that “has” is a universal, then it seems based on the reasoning we considered in section IV.


If the particular is simply something which is a matter of a complex of compresence, then it's a universal. As I read section IV, this would lead to an infinity of properties. It is far more probable that there are not an infinity of properties (if someone thinks otherwise, I want to know what kind of truthmaker they are using for it). So, even the Bundle theory is plagued with massive problems.

Let me elaborate a bit more on infinite regresses, since a lot of people have a problem with understanding this.


  There is a relation C, in which A and B stand; and it appears with both of them. . . . The relation C has been admitted different from A
  and B, and no longer is predicated of them. Something, however, seems
  to be said of this relation C, and said, again, of A and B. And this
  something is not to be the ascription of one to the other. If so, it
  would appear to be another relation, D, in which C, on one side, and,
  on the other side, A and B, stand. But such a makeshift leads at once
  to the infinite process. The new relation D can be predicated in no
  way of C, or of A and B; and hence we must have recourse to a fresh
  relation, E, which comes between D and whatever we had before. But
  this must lead to another, F; and so on, indefinitely.
  –––, 1893. Appearance and Reality, Oxford: Oxford University Press.


Bradley's Regress: The early Russell was a believer in transcendent Platonic universals. A relation is a universal and gets exemplified by two particulars when the relation relates two particulars.  So, to give an example. The proposition, "The rose is red." has about 3 entities in play, (1) the rose, (2) the universal redness, (3) the relation of rose having redness. 1 & 2 are not enough. You cannot get a red rose by lumping redness and the rose together, you need something more. This 'something more' is what we call a 'relation,' which ties the redness to the rose, so that it is red. This 'having' is what is known to be essential to making the proposition < The rose is red. > true. You can think of this as the sort of metaphysical glue which ties two entities, A and B, together. 

F. H. Bradley argued that if there are two entities, A and B, and are in a relation with each other, call it C, C is what is being exemplified by the two particulars (I'll come to this later). Since exemplification is yet another relation, it is an independent universal entity, call it D. Now if C is exemplified by A and B, by the exemplification relation D, then there must be another exemplification relation. . . and so on, ad infinitum. Thus, we won't have explained anything we set out to explain.

Few comments. Infinite regresses in causal chains is one thing, but this is a kind of infinite regresses in the sense of constitution, so whatever arguments that might work in appealing to an infinite regress in causation, fails here. If you posit an infinite set of entities, you are multiplying them to explain something, but you're never explaining what metaphysically grounds them. Your metaphysical pudding, gets pushed under the rug, and what do you do when you see the lump elsewhere? You keep pushing it, again, and again, and again. . . It's for this reason that philosophers see that becoming a realist is pointless, since its theories have too much complexity and make you posit entities ad infinitum, which in the end don't serve to explain anything but bloat your theory. Why not become a nominalist and avoid all this trouble? (That's not to say that nominalism doesn't have the same problems :)) This is one reason why one should 'drop' the theories. I've been charitable enough in my reading to allow for such a regress (most people simply reject this kind of talk, an infinity of posits don't seem to be able to explain anything), since should this infinite regress ensue, there would be an infinity of properties.  

Faced with this, something's gotta give. Realists have since then argued that exemplification is a non-relational fundamental tie, however, how does this not seem ad-hoc? Can it be motivated independently to avoid Bradley's regress? Certain realists can definitely do that. Certain realists, in other words, think that the exemplification relation is not on par (not in the same category) with other relations. This reply would work and avoid Bradley's regress, should one be able to independently motivate this.

If both the theories in offer are faced with such massive problems, what then is to become of the picture?

Here are my points now. Metaphysicians are willing, although not happy, to admit brute facts into their ontology. It is still a negative for their theories. A brute fact is something that can't even in principle be explained, a primitive concept is something which cannot be further analyzed. Bundle theorists take the compresence relation to be a further unanalyzable affair, whereas, the ones who uphold a universal/particular distinction hold instantiation to be an unanalyzable affair. 

The resemblance nominalist takes resemblance be primitive, some people take naturalness as a primitive, realists take instantiation to be a primitive, bundle theorists take the compresence relation to be primitive. How then, is the debate advanced? The endeavor is to keep primitives to a bare minimum and look for other reasons to accept or deny the theories available.

I won't be giving an answer as to who is right, but if you're interested and engage with me (provided you think I've explained enough), I will give you directions where you can look for them :).
No, he didn't, because he didn't agree with your premises. It is central to his entire outlook that alienation can be overcome.

In particular, he would not have agreed with your statement that "Some people are bound to be stuck in jobs they don't like, and which don't allow for any form of self-fulfillment."

One way into understanding Marx's view of communist society is to start with https://www.marxists.org/archive/marx/works/1845/german-ideology/ch01a.htm the following sentence in The Communist Manifesto (1848):


  In place of the old bourgeois society, with its classes and class antagonisms, we shall have an association, in which the free development of each is the condition for the free development of all. [emphasis added] 


The other passage that comes to mind, in which he makes his view crystal clear that in communism people won't have jobs in the sense of a productive activity that they engage in to the exclusion of others and which defines their role in society, is https://www.marxists.org/archive/marx/works/1845/german-ideology/ch01a.htm in The German Ideology (1845):


  Further, the division of labour implies the contradiction between the interest of the separate individual or the individual family and the communal interest of all individuals who have intercourse with one another. And indeed, this communal interest does not exist merely in the imagination, as the “general interest,” but first of all in reality, as the mutual interdependence of the individuals among whom the labour is divided. And finally, the division of labour offers us the first example of how, as long as man remains in natural society, that is, as long as a cleavage exists between the particular and the common interest, as long, therefore, as activity is not voluntarily, but naturally, divided, man’s own deed becomes an alien power opposed to him, which enslaves him instead of being controlled by him. For as soon as the distribution of labour comes into being, each man has a particular, exclusive sphere of activity, which is forced upon him and from which he cannot escape. He is a hunter, a fisherman, a herdsman, or a critical critic, and must remain so if he does not want to lose his means of livelihood; while in communist society, where nobody has one exclusive sphere of activity but each can become accomplished in any branch he wishes, society regulates the general production and thus makes it possible for me to do one thing today and another tomorrow, to hunt in the morning, fish in the afternoon, rear cattle in the evening, criticise after dinner, just as I have a mind, without ever becoming hunter, fisherman, herdsman or critic. This fixation of social activity, this consolidation of what we ourselves produce into an objective power above us, growing out of our control, thwarting our expectations, bringing to naught our calculations, is one of the chief factors in historical development up till now. [emphasis added]

Nietzsche mocked German idealists at length, but I think calling him a materialist is a bridge too far, same as for all his anti-Christianity it is not clear that he was an atheist. He inherited his metaphysics from Schopenhauer, transforming his World Will into will to power, who can be seen as irrationalizing Hegel's Absolute Geist with a side of that "intellectual intuition" that Kant kept rejecting but couldn't let go of. Nietzsche's is a highly personalized and individualistic philosophy focused on human condition and action, like existentialism, barely a realism but hardly materialism, and with panpsychic overtones perhaps. 

He explicitly rejected and mocked the dominant version of materialism of his day, atomism. As Nietzsche writes in http://www.gutenberg.org/files/4363/4363-h/4363-h.htm Beyond Good and Evil:"As regards materialistic atomism, it is one of the best-refuted theories that have been advanced, and in Europe there is now perhaps no one in the learned world so unscholarly as to attach serious signification to it, except for convenient everyday use (as an abbreviation of the means of expression)". Moreover, he joined Hume in deflating the categories of substance and causality, along with the logical laws of identity and contradiction, all of which he saw as crutches of intellect clinging to the ephemeral stability of Being, and inadequate for capturing the Becoming of life, which only truly manifests itself in willings and urges:"Psychologists should bethink themselves before putting down the instinct of self-preservation as the cardinal instinct of an organic being. A living thing seeks above all to DISCHARGE its strength — life itself is WILL TO POWER".

Marx passed away in 1883 and Nietzsche started writing about philosophy only in 1878. He probably did not gain enough prominence for Marx to notice in his waning years. As for the influence the other way, Clark and Leiter write in http://rads.stackoverflow.com/amzn/click/0521189918 Nietzsche: Daybreak, "there is no evidence, however, that Nietzsche ever read Marx". He was aware of socialists and Young Hegelians more broadly, like Strauss, Stirner and Feuerbach, and yes, his individualism and emphasis on the historical role of "exceptional individuals", was antithetical to socialism and historical materialism, and his philosophy of life was antithetical to everything rationalism, especially Hegel. This said, he did embrace the Heraclitean aspects of Hegel, the becoming, the flux of life, irrationalized and vitalized by Schopenhauer. So there is one point of contact between Nietzsche, and especially early Marx of Young Hegelian days and https://en.wikipedia.org/wiki/Marx's_theory_of_alienation alienation from Economic and Philosophic Manuscripts of 1844 (Stirner wrote in a similar spirit), — the https://en.wikipedia.org/wiki/Dialectic#Hegelian_dialectic Hegelian dialectic.

See also online discussions concerning https://www.reddit.com/r/askphilosophy/comments/3417z9/to_what_extent_was_nietzsche_familiar_with_the/ Nietzsche on Marx, and http://groups.able2know.org/philforum/topic/4377-1 Marx on Schopenhauer.
I would suggest it is because he didn't have active followers in large numbers until after his death.

Aristotle was subject to the same charge as Socrates at the end of his life, though he was exiled rather than killed.  So the degree of disruption, the intention to be disruptive, and the actual hostility evident all seem less important in this particular charge than the number of people affected.

(Although by some accounts, Aristotle's sentence was all about racism and revenge.  Aristotle's father was Medean in origin and Athens had gone to war against Alexander the Great -- Aristotle's family's king and his own prior student.)

Athens had very active courts, but no written laws.  In the spirit of absolute democracy, elected jurors voted on everything and their decisions were bound by no precedent.  So the number of people who directly met the offending opinions and were offended probably controlled whether your case went forward toward prosecution more than any specific definition of the crime involved.
I don't think this has anything to do with morality or mudslinging specifically, the possibility of regress is created by the ability of talking to represent something else. A talks about B, B talks about A talking about B, A talks about B talking about A talking about B, etc. That talking is accusing accompanied by moral judgements just comes along for the ride. Indeed we do not even need B, A can talk about A talking about A talking about A, talking about A, sometimes politicians do that too with accusing replaced by praising.

This regress appears every time something has the ability to represent something else, Aristotle used it to criticize Plato's ideal realm. Since idea can represent an object, or another idea, the realm containing all of them would have to be populated not only by ideas of objects, but also ideas of ideas of objects, ideas of ideas of ideas of ideas of objects. It seemed a bit excessive, so he disposed of the separate realm, and embodied ideas as forms of objects instead.

One can do something more interesting than regress with ability of sentences to represent, or refer to, other sentences. A sentence may not just refer to a sentence that refers to a sentence, it may refer to itself. And if it does so in a special way we may get a paradox, e.g. "this sentence is false" is true if and only if it is false. This is like A accusing himself of lying, or mudslinging, the https://en.wikipedia.org/wiki/Liar_paradox Liar paradox.
Bryan Magee, https://books.google.it/books?id=cfMD0RSjnEwC The Philosophy of Schopenhauer (1997) has Ch.14 dedicated to: Schopenhauer's Influence on Wittgenstein.


  [page 310] This influence can be asserted with absolute certainty; it is clear in the notebooks, and Wittgenstein himself stated in conversation that when he was young he believed Schopenhauer to have been fundamentally right [...].


This influence seems qalso present into 5.62-63, with the critique of solipsism:


  5.6 The limits of my language mean the limits of my world.
  
  5.62 This remark provides the key to the problem, how much truth there is in solipsism.
  
  For what the solipsist means is quite correct; only it cannot be said, but makes itself manifest.
  
  The world is my world: this is manifest in the fact that the limits of language (of that language which alone I understand) mean the limits of my world.
  
  5.63 I am my world. (The microcosm.)
  
  5.631 There is no such thing as the subject that thinks or entertains
  ideas.
  
  If I wrote a book called The World as I found it, [...]
  
  5.632 The subject does not belong to the world: rather, it is a limit of the world.
  
  5.64 Here it can be seen that solipsism, when its implications are followed out strictly, coincides with pure realism.


Compare: 


  6.373 The world is independent of my will.


with Schopenhauer's first sentence of https://www.gutenberg.org/files/38427/38427-pdf.pdf The World as Will and Idea :


  "The world is my idea".

This is just an old paradox in discussions of free will.

You are free to do whatever you desire. But you are not free to choose your desires. Similarly, Marx said, "man" makes his own history, but not under the historical conditions of his choosing. And Mill attempted to secularize the paradox by observing that we are slaves to habit, but can step back and form those habits. We can, in some measure, both rely on causes and effects and intervene between them. 

The idea, which arises in many forms, is that "freedom" is indeed inevitably paradoxical. There is no such thing as "absolute" freedom nor "absolute" constraint. There are only indeterminacies and determinations on different levels, of which one may or may not be aware.  
The statement


  This thing is a nourishing bread


can be expanded into:  


  This thing was a nourishing bread in the recent past, and will be a nourishing bread in the near future


Hume argued, however,  that such a statement would be an invalid way to describe what we know and experience. One reason is that, according to Hume, we cannot justifiably assert anything about the future. So an improvement would be:


  This thing was a nourishing bread in the recent past (and  that's it)


And nothing is rationally implied about what will happen in the future. In particular, the possibility that the past nourishing bread will turn into a poisonous one cannot be ruled out.

A consideration of causes cannot be used to argue against Hume, because Hume's thesis includes a related criticism against the very idea of cause. The most we can tell about causes, according to Hume, is that events of one type were consistently followed by events of another type - until now. Again we cannot, according to Hume, rationally assert anything about causal relations continuing to hold in the future. So nothing about causes, as well, would preclude the possibility that a nourishing bread will turn just like that into a poisonous one.
The OP quote draws a distinction between determinism ("hard determinism"), and causal completeness ("less absolute determinism"). The former means that the current physical state of the universe predetermines its future state in every detail, i.e. it is a "sufficient cause", this is the Laplacian view of classical mechanics. The latter means that although the current physical state is not a sufficient cause it is a complete one, nothing else has any causal effect on future states either, whatever is not physically determined is purely indeterministic. 

Whether this has an effect on free will is controversial, see https://philosophy.stackexchange.com/questions/32397/causal-influence-of-the-mental-on-the-physical/32430#32430 Is there a causal influence of the mental on the physical? For you to sometimes choose strawberry and sometimes chocolate "in exact same circumstances", we have to additionally assume that microscopic indeterministic processes of quantum mechanics are sufficiently amplified to affect macroscopic behavior of the brain. In other words, there needs to be a trigger mechanism, such as the one in the Geiger counter, which amplifies an indeterministic atom decay into a macroscopic click. Whether such a mechanism exists in the brain is currently unknown, but many free will libertarians (Compton, Popper, Eccles, Kane), and even some compatibilists (Dennett, Mele), believe that it does, see http://www.informationphilosopher.com/freedom/two-stage_models.html Two-Stage Models for Free Will. There is also a problem with the "exact same circumstances" in the question, because quantum indeterminacy excludes exact registration or reproduction of a state, so the question itself presupposes classical intuitions. Strictly speaking, under quantum mechanics it can not even be asked, the best we can do is ask if it can happen in "similar" circumstances.

Kane's suggestion is that the system of firing neurons can become chaotic in some circumstances, which would mean that the macrostate of the brain becomes sensitive to even microscopic quantum fluctuations. This by itself does not resolve the issue of free will however, because the question of conscious control over the outcomes also has to be addressed. How to address that, and when exactly quantum indeterminism is injected into the decision process, are also subject to controversy. Libertarians tend to place it closer to the time of physical action, while compatibilists place it earlier in the deliberation process.  

Kane pays special attention to effects of quantum indeterminacy on free will, you can read a short version of his account in http://www.tandfonline.com/doi/pdf/10.1080/13869799908520971 On Free Will, Responsibility and Indeterminism, see also http://www.informationphilosopher.com/solutions/philosophers/kane/ online review. Mele's book https://books.google.com/books?id=svdgBwAAQBAJ&source=gbs_navlinks_s Free Will and Luck is a comprehensive survey of most current positions on both indeterminism and control issues.
I'm not sure I grasp your question or the "rebuttal." 

First, "honesty" is not necessarily related to logical fallacies or truth. It is simple consistency between what people say and what they believe, rightly or wrongly.

I would note, as an aside, that the author suggests that Kant's categorical imperative is rooted in the structure of language, which may be a modern interpretation posed by Habbermas and others, but is not exactly how Kant would put it. However, we can stick with the language analogy here, since it makes sense.

Kant assumes that the way to judge moral behavior can be understood logically and abstractly by "universalizing" propositions, as we do when we say to a child: "What if everybody did that?" The case of lying makes this rather obvious. If everybody lied, then "lying itself" would not work, since a lie only works on the supposition that people are not lying. This is, again, readily seen in daily life, where those who constantly lie find themselves no longer believed, Trumpism notwithstanding.

People can, of course, lie, utter fallacies or nonsense, make erroneous statements knowingly or otherwise. But the exceptions prove the rule. Language simply would not function if it were systematically inaccurate and inconsistent with beliefs.
Or so Kant claims. While he is correct at one level, the focus on "language" does reveal the shortcomings of this view. For, as we now understand, language can "behave" in many ways, and the half-truths or emotional appeals of ideology or advertising, for example, can be effective without claims to truth. Since Kant's philosophy is not about language per se but about reason, it rests perhaps on firmer, if more abstract, grounds.  
With regards to "space and time", there's several problematic things happening at once which make them ineligible for being "things in themselves." For Kant, what is clear is that time and space are the conditions of sensibility, i.e. they are (at a minimum) a framework our mind applies to things in order to convert them into representations. These representations are then taken under the categories (a similar sort of application of our minds) to render things objects.

Whatever else they are, they are not themselves things -- and this is where there's great debate among contemporary Kant scholars centering around whether Kant is suggesting that space and time are merely conditions we apply to sensible things to make them representations (Vorstellung) or whether space and time have a separate metaphysical existence that relates in some other way to our mind's need to apply categories. For way too much reading on this, you can look at http://plato.stanford.edu/entries/kant-spacetime/ Kant's view on space and time at the SEP.

With respect to "perfectly rational minds" (d), the waters here are going to pretty murky. And this is an area where I think I disagree with at least two common posters. First and foremost, a perfectly rational mind is going to be noumenal since it is going to be able to act as a law for itself and undertake actions without being subject to laws of nature (i.e. determination). 

The question, however, is whether something being noumenal makes it identical with a thing-in-itself. Both are inaccessible to the forms of representation (time and space) and the twelve categories of the understanding. Things-in-themselves are inaccessible since as they pass through the "meat-grinder", they become representations which are somewhat accessible and objects which are things we can know.  

https://en.wikipedia.org/wiki/Noumenon#Noumenon_and_the_thing-in-itself Wikipedia and several https://philosophynow.org/issues/31/Kant_and_the_Thing_in_Itself articles capture the debate. I think the strongest evidence in favor is that Kant does at one point identify the two. Guyer and Wood (quoted at wikipedia) note:


  The concept of a noumenon, i.e., of a thing that is not to be thought of as an object of the senses but rather as a thing-in-itself [...]"; But note that the terms are not used interchangeably throughout. The first reference to thing-in-itself comes many pages (A30) before the first reference to noumenon (A250).


For some this is enough to identify thing-in-itself with noumenon. But that doesn't fully resolve things. A further question is whether there is something it is like to be a thing-in-itself. And then whether on Kant's view there's anything we can know about noumenals.

Judging by the author's choice, I would say the author does not think the two are identical. Instead, she sees the rational mind as a type of active will with powers.

For "Actions that conform to the moral law", it's not clear these are things that have their own separate existence at all. And if they don't they cannot be things-in-themselves. But I would say you're getting it wrong when you suggest "they can be performed by humans and so are Phenomenal."

Instead, I would suggest that these actions qua actions in conformity with the moral law cannot be seen as such in the phenomenal world since the conformity does not happen there. (This account is repeated across Groundwork, Critique of Practical Reason, Metaphysics of Morals, and Religion)
Comment

There is a background of W's Tractatus that we cannot forget: Frege's https://en.wikipedia.org/wiki/Begriffsschrift Begriffsschrift and http://plato.stanford.edu/entries/type-theory/#1 Type theory formulated in W&R's http://plato.stanford.edu/entries/principia-mathematica/ Principia Mathematica.

W's interest on logic (see e.g. Michael Potter, http://rads.stackoverflow.com/amzn/click/0199596352 Wittgenstein's Notes on Logic (2008)) has been stimulated by the discussions with Frege and Russell on logical matters, and Frege's Begriffsschrift is "a formula language, modeled on that of arithmetic, of pure thought." 

See:


  3.323 In everyday language it very frequently happens that the same word has different modes of signification — and so belongs to different symbols—or that two words that have different modes of signification are employed in propositions in what is superficially the same way. [...]
  
  3.324 In this way the most fundamental confusions are easily produced (the whole of philosophy is full of them).
  
  3.325 In order to avoid such errors we must make use of a sign-language that excludes them by not using the same sign for different symbols and by not using in a superficially similar way signs that have different modes of signification: that is to say, a sign-language that is governed by logical grammar — by logical syntax. (The conceptual notation [the "concept-script"] of Frege and Russell is such a language, though, it is true, it fails to exclude all mistakes.)


It seems to me that the purported "Russell's misunderstanding" has some reason in W's text.

Having said that, it does not seem to me that Ramsey share Russell's point of view; see his https://books.google.it/books?id=1st-3kYOEPQC&pg=PA270 CRITICAL NOTICE (1923):


  it is possible that [Mr Russell's Introduction] is not an infallible guide to 
  Mr Wittgenstein's meaning. "In order to understand Mr Wittgenstein's book," says Mr Russell, "it is necessary to realize what is the problem with which he is concerned. In the part of his theory which deals with Symbolism he is concerned with the conditions that would have to be fulfilled by a logically perfect 
  language." This seems to be a very doubtful generalization; there are, indeed, passages in which Mr Wittgenstein is explicitly concerned with a logically perfect, and not with any language, e.g. the discussion of 'logical syntax' in 3.325 ff.; but in general he seems to maintain that his doctrines apply to ordinary languages in spite of the appearance of the contrary (see especially 
  4.002 ff.). This is obviously an important point, for this wider application greatly increases the interest and diminishes the plausibility of any thesis such as that which Mr Russell declares to be perhaps the most fundamental in Mr Wittgenstein's theory; that " in order that a certain sentence should assert a certain fact there must, however the language may be constructed, be something in common between the structure of the sentence and the structure of the fact". 


Ramsey discuss at lenght this "fundamental theory", based on the central concepts of: picture, fact and (logical) form.

See also:


  We must now turn to one of the most interesting of Mr Wittgenstein's theories, that there are certain things which cannot be said but only shown, and these constitute the Mystical. The reason why they cannot be said is that they have to do with the logical form, which propositions have in common with reality. 
  
  Also he says that "The feeling of the world as a limited whole is the mystical feeling" 6.45). But I do not think we can follow Mr Russell in deducing from this that the totality of values of x is mystical, if only because "The world is the totality of facts, not of things" (1.1). And I think that 'limited' gives the key to the sentence quoted above. The mystical feeling is the feeling that the world is not everything, that there is something outside it, its 'sense' or 'meaning'. 


See also the conclusion of https://books.google.it/books?id=1st-3kYOEPQC&pg=PA155 FACTS AND PROPOSITIONS (1927):


  In conclusion, I must emphasise my indebtedness to Mr Wittgenstein, from whom my view of logic is derived. Everything that I have said is due to him, except the parts which have a pragmatist tendency, which seem to me to be needed in order to fill up a gap in his system. But whatever may be thought of these additions of mine, and however this gap should be filled in, his conception of formal logic seems to me indubitably an enormous advance on that of any previous thinker. 
  
  My pragmatism is derived from Mr Russell; and is, of course, very vague and undeveloped. The essence of  pragmatism I take to be this, that the meaning of a sentence is to be defined by reference to the actions to which asserting it would lead, or, more vaguely still, by its possible causes and effects. Of this I feel certain, but of nothing more definite. 


The statement: "the meaning of a sentence is to be defined by reference to the actions to which asserting it would lead, or, more vaguely still, by its possible causes and effects" seems to anticipate the second Wittgenstein. 
This relates to the irrevocable nature of the act. Once one acts, I cannot take it back--what's done is done. My actions gain a kind of force of the actual beyond the reach of reversible possibilities. We do not experience temporal reversibility. Past responsibilities are irreversible and, like a kick in the gut, you are likely to stew over the embarrassing or missed opportunities. It can eat at you and really make you "nauseous." This kind of fate and dread can be horrifying and exhaustive of one's freedom. In the case of "I want to do this," my need to make myself is still in place because my act is still within the mode of the non-actual or possible relations. We are condemned to be free because of the possible or non-determinate essence as existence.

If you connect this to Sartre's classic line "hell is other people," you will recall this is because they have a "tiny" or "distorted" image of you similar to the reflection produced of ourselves in the eyes of others. They render you with the impoverishment of possibilities and this narrows the esteem you are due. You are not granted your space or wiggle-room to be you, as you! Sartre was well aware that one of the common features of human nature is the need to have another ace up the sleeve, which comes with risk and insecurity, but it also offers the freedom of a wider world of auto-genesis.   
Regarding the connection between Idealism and Phenomenology

The Phenomenology of Mind (sic!) by Hegel is considered to be the climax of German Idealism (and probably idealism as a whole) and uses many phenomenological examples, e.g. in Chapter II "salt" as white, having a cubic shape and tartness (etc.).:


  This salt is a simple "here" and is at the same time manifold; it is white and also tart, also cubically shaped, also of particular weight etc.


I think this to be only consequent, as Idealism's main assumption is that it is the human thought/perception that determines all reality that is of philosophical interest (see the http://plato.stanford.edu/entries/idealism/ SEP article). Therefore, the phenomenology should be one aspect of it.

Locke as an avantgarde thinker consequently intuitivly used empirical examples without methodologically reflecting on this (as far as I know).

Regarding phenomenology as philosophical method (Husserl)

Husserl's phenomenology as philosophical method, if it is allowed to say this, is not "revolutionary" at all. The ideas of intuitive understanding and intellectual intuition have been kantian ideas (§77 Critique of Judgement, here limiting concepts of our own capabilities, i.e. something not achievable for us as humans), that Schelling, Fichte, Hegel and Hölderlin tried to establish as philosophical methods around 1800 already. This is described in Eckart Förster's The 25 Years of Philosophy, chapters 7-9.

He explicitly describes in chapter 7 how two "traditions" evolved after Kant leaving "loose ends" in his philosophy (see Critique of Judgement, §57, Ak. 5:341, where he states that the reason for the unity of reason cannot be found within the bounds of sensuality): One looking for the first principle of philosophy with the help of intellectual intuition (Reinhold and Fichte), the other coming from Jacobi's reception of Spinoza using the idea of an intuitive understanding (Goethe without methodologic reflection, Hegel as culmination, Schelling and Hölderlin somewhere in between).
Carnap was a http://plato.stanford.edu/entries/compatibilism/ comptabilist. From the Carnap's "Philosophical Foundation of Physics" as quoted in the "Cambridge Companion to Carnap" p 303: 


  Free choice is a decision made by some one capable of foreseeing the consequences of alternate action and choosing that which he prefers. There is no contradiction between free choice understood in this way and determinism, even of the strong classical type.’


A more extensive version of the quote (from the same book, but I don't have an exact page number): 


  ‘Predictability and compulsion are two different things. It is compulsion only when one is forced by outside agents to do something against one’s desire. But if the act springs from one’s own character in accordance with the laws of psychology, then we say that one acts with free will, that is, personal preference of selecting one out of many possibilities. If no compulsion is involved, which means that the choice is based on his own preference, arriving out of his own character, there is no reason for not calling it free choice. It is true that his character caused him to choose as he did and this in turn is conditioned by previous causes. But there is no reason to say that his character compelled him to choose as he did, because the word ‘compel’ is defined in terms of outside casual factors. Free choice is a decision made by some one capable of foreseeing the consequences of alternate action and choosing that which he prefers. There is no contradiction between free choice understood in this way and determinism, even of the strong classical type.’

Lacan's views are based on https://en.wikipedia.org/wiki/Roman_Jakobson Roman Jakobson's analysis of language:


https://books.google.it/books?id=MkNwSQHa2w4C&pg=PA49 “Two Aspects of Language and Two Types of Aphasic Disturbances”, page 49-on.


According to Jakobson:


  Speech implies a selection of certain linguistic entities and their combination into linguistic units of a higher degree of complexity. At the
  lexical level this is readily apparent: the speaker selects words and combines
  them into sentences according to the syntactic system of the language
  he is using [...]. Hence the concurrence of simultaneous entities and the concatenation of successive entities are the two ways in which we speakers combine linguistic constituents.
  
  Any linguistic sign involves two modes of arrangement.
  
  1) Combination. Any sign is made up of constituent signs and/or occurs only in combination with other signs. This means that any linguistic unit at one and the same time serves as a context for simpler units and/or finds its own context in a more complex linguistic unit. Hence any actual grouping of linguistic units binds them into a superior unit : combination and contexture are two faces of the same operation.
  
  2) Selection. A selection between alternatives implies the possibility of substituting one for the other, equivalent to the former in one respect and different from it in another. Actually, selection and substitution are two faces of the same operation.
  
  Selection (and, correspondingly, substitution) deals with entities conjoined in the code but not in the given message, whereas, in the case of combination, the entities are conjoined in both, or only in the actual message. The addressee
  perceives that the given utterance (message) is a combination of constituent
  parts (sentences, words, phonemes, etc.) selected from the repository of all possible constituent parts (the code). The constituents of a context are in a state of contiguity, while in a substitution set signs are linked by various degrees of similarity which fluctuate between the equivalence of synonyms and the common core of antonyms.
  
  These two operations provide each linguistic sign with two sets of
  interpretants, to utilize the effective concept introduced by Charles
  Sanders Peirce: there are two references which serve to interpret the sign - one to the code, and the other to the context, whether coded or free, and in each of these ways the sign is related to another set of linguistic signs, through an alternation in the former case and through an alignment in the latter. A given significative unit may be replaced by other, more explicit signs of the same code, whereby its general meaning is revealed, while its contextual meaning is determined bv its connection with other signs within the same sequence.


Thus, we have two "dimensions" : the "horizontal" one, i.e. the message (or context), and the "vertical" one, i.e. the code.

Jakobson maps the dicothomy combination (horizontal) - selection (vertical) on the dicothomy: metonymy-metaphor.

Metaphor works on the relation of similarity, while metonymy works on the relation of contiguity; see this example from Umberto Eco: 


  Granted that both the «dog» and the «friar» possess the same connotative marker of «fidelity» (to their master) and «defense» (dogs defend their masters and friars defend the principles of the religion) it was easy during the twelfth century to invent for an order of mendicant friars (the Dominicans) the metaphor “dogs of God” (domini canes). [... a ‘similarity’ between semantic markers]. On the other hand [...] substitution by contiguity is based on the fact that, given a ready-made syntagm, established habits will permit one of its elements to be substituted for another. Thus given the accepted semiotic judgment "the
  President of the United States officially lives in the White House" it is easy to use "the White House" as a metonymy for "the President of the United
  States".


Thus, in both cases, we have substitution; substitution of a signifier w with a new one w' which has a relation with w: a relation of contiguity (metonymy: w and w' are "usually" connected in a sentence) or a relation of similarity (metaphor: w and w' share some connotation).

Consider U.Eco's example of metonymy: if, instead of saying "President Obama declared ..." we say "the White House declared..." we have substituted the signifier "President Obama" (w) with the new signifier "the White House" (w') both denoting in this context the object: the President Obama. The substitution is grounded on a relation of contiguity based on the usual context: "the President lives in the White House".

In the case of metaphor we say "domini canes" instead of "Dominicans"; again we are substituting in the phrase a signifier w ("Dominicans") with a new one w' both denoting in this context the same object: the friars. The substitution is grounded on a relation of similarity between the two based on the fact that the «dog» and the «friar» possess the same connotative marker of «fidelity» (to their master) and «defense». 



Finally, Jakobson consider also dreams:


  A competition between both devices, metonymic and metaphoric, is manifest in any symbolic process, be it intrapersonal or social. Thus in an inquiry into the structure of dreams, the decisive question is whether the symbols and the temporal sequences used are based on contiguity (Freud's metonymic "displacement" and synecdochic "condensation") or on similarity (Freud's "identification and symbolism").

It should be said that Husserl was philosophically averse to Kant's "creative" transcendental subject, perhaps due to the dominance of absolute idealist interpretations of him at the time, and preferred to derive his lineage from Hume, whom he credits as the principal forerunner of phenomenology. See https://books.google.com/books?id=7n4JBgAAQBAJ&source=gbs_navlinks_s Mall's Experience and Reason on their connection, which quotes Husserls' 1919 letter to Metzger:"I have learnt incomparably more from Hume than from Kant. I possessed the deepest antipathy against Kant, and he has not (if I judge rightly) influenced me at all". 

This is likely exaggerated, Kant was in the air of the times, and Husserl did draw parallels with him already in Logical Investigations (1901), while reinterpreting his "synthetic" notion of a priori into intuitive one, and https://books.google.com/books?id=7EIFkisyg1MC&pg=PA227&lpg=PA227&dq=natorp+husserl+adopt+transcendental+idealism&source=bl&ots=Lp5oeBPzni&sig=IcKMsEJExzlL86UzQcrQ6xl2PDg&hl=en&sa=X&ved=0ahUKEwi9-u-17oLMAhXmnYMKHb4bDQcQ6AEIIzAB#v=onepage&q=natorp%20husserl%20adopt%20transcendental%20idealism&f=false adopted the label and terminology of transcendental idealism around 1915, apparently at Natorp's prompting. There are also undeniable parallels between his approach and that of contemporary neo-Kantians, especially in the early works. The Crisis, on the other hand, is a late work, not completed in Husserl's lifetime, and written under pronounced influence of existentialism, in particular Heidegger's. One has to keep in mind though that what appears to be Kantian framework in Husserl may be at least partly attributable to their common root in Hume. I recently came across a very nice summary of Husserl's theory of cognition in https://air.unimi.it/retrieve/handle/2434/241656/325635/OntologicalStatusEssencesHusserlPreprint-libre.pdf Zhok's Ontological Status of Essences in Husserl’s Thought, which makes Husserl's affinities and breaks with Kant more transparent.

What Husserl kept and developed beyond Hume was the recognition of the creative role of mind in cognition. Productive imagination (term shared with Kant) plays a dual role of aiding apprehension in perception, producing perceptual unities like objects, and engages in "free play" to produce what Kant called synthetic a priori intuitions in arithmetic and geometry. In fact, Husserl expands its role even further, it is responsible for memory recalls and "eidetic variation" of acquired perceptual proto-concepts that sharpens their boundaries, and forges them into full fledged essences ("eidoses"). As a result, Husserl gives a more satisfying account of empirical concept formation, which was a major unresolved problem for Kant, see http://philpapers.org/rec/PIPKOE Pippin's Kant on Empirical Concepts. He could not explain how exactly definitive concepts are formed from the undifferentiated "manifold of sensation", and his German idealist successors turned it into "construction of reality" from mental categories. 

And here we come to a major break with the Kantian theory of sensibility, Husserl rejects the undifferentiated manifold, and the idea that percepts are synthesized from "sense data". The latter is seen as ex post facto extraction from what is originally given to consciousness as already partially structured and unified, if obscurely (this was later confirmed by empirical cognitive science). In other words, rather than having two determinates, "sensibility" and "manifold" interacting, Husserl insists that all determinacy is only forged in the act of perception itsel. No determinates can be presented as "interacting" prior to it, dissolving the question of whether the content of perception "pre-exists" in reality, or is generated by mind. 
This aspect of perception, which apprehends idealities as immediate unities, Husserl terms categorical intuition, and together with eidetic variation, which shapes concepts into definitional maturity, it forms the process of ideation. Thus, Husserl sails between the Scylla of passive reception of impressions à la Hume, and the Charybdis of German idealist "construction of reality" by the mind.

Categorical intuition releases Husserl from the need to keep perhaps the most implausible part of Kantian picture, the forever immutable a priori categories and forms of intuition. But it is not the intellectual intuition of Spinoza and Fichte, it captures invariances of sensuous experience, not "glimpses" of things in themselves. But with it Husserl can be more generous on what is almost a vanishing point in Kant, the unknowable X. The transcendence, as Husserl calls it, is that content of consciousness that "points beyond" consciousness itself, given to it as not its own but foreign, subject to pre-cognitive awareness as the "raw matter" of sensuous experience. The limited creative ability to perceive wholes, however weak and partial, ability that Kant denied us completely as "intellectus archetypus", allowed Husserl to remove some of the other-worldliness surrounding Kantian "supersensible substrate of experience", although as for Kant it remains beyond the reach of knowledge. 

There are many other divergences, I'll mention one of particular interest to me. In the Second Analogy Kant gives a notorious transcendental argument for the a priori status of strict causality as condition of the possibility of our forming temporal succession of events (since they come with no time labels attached). Husserl's analysis of perception  shows instead that the "now", like "sense data", is an ex post facto abstraction. In perception we instead encounter the "specious present" (the idea likely coming from James, along with the "stream of consciousness"), a short but dynamic duration with markers that explicitly link it to neighboring durations in the time succession, like coming and going notes in the apprehension of a melody (this was also confirmed by empirical psychology). Thus Husserl again grants us an immediately holistic grasp, however obscure and fleeting, this time of becoming. This removes another issue that caused Kant much grief (in his theory of free will), the necessity of unbreakable causal chains. 
The meaning is: "dream", "chimera". 

See https://en.wikipedia.org/wiki/Primary/secondary_quality_distinction Primary/secondary quality distinction and https://en.wikipedia.org/wiki/Mechanism_(philosophy) Mechanism.

The idea is that our way to "see" and perceive the properties of things outside us is determined by the actions external objects elicit on our sense, but in no way we are licensed to infer from our perception that external objects are "exactly" as we perceive them.


  "I think that tastes, odors, colors, and so on are no more than mere names so far as the object in which we locate them are concerned, and that they reside in consciousness." - Galileo Galilei, https://en.wikipedia.org/wiki/The_Assayer The Assayer (Il Saggiatore, 1623).
  
  "[I]t must certainly be concluded regarding those things which, in external objects, we call by the names of light, color, odor, taste, sound, heat, cold, and of other tactile qualities, [...]; that we are not aware of their being anything other than various arrangements of the size, figure, and motions of the parts of these objects which make it possible for our nerves to move in various ways, and to excite in our soul all the various feelings which they produce there." - René Descartes, https://en.wikipedia.org/wiki/Principles_of_Philosophy Principles of Philosophy (Principia philosophiae, 1644 - Les Principes de la Philosophie, 1647).

Please excuse my lack of quotes and perhaps improper terminology. Heidegger is abound with very specific terminology. 

To be responsible but not accountable is a very subtle distinction in most concepts of the word. But the difference is clearly defined in Heidegger's definition of Dasein, "This entity which each of us is himself…we shall denote by the term 'Dasein'". Since Dasein is being of and in accordance with its true self "Being-in-the-world", the responsibility is in acting in accordance with this self. 

You are therefore not accountable to any rules or demands. You are acting naturally as you should and are taking into account nothing but what is encapsulated in the definition of a Dasein. 

Accountability is instead an attribute of an object that is "ready-at-hand", because its purpose is ascribed to it. Since a Dasein has no externally assigned attributes or roles, Dasein is not accountable to anything but itself (and only in terms of being responsible to be itself).

Also look up...


"Thingness": This should help add more depth to the foundational concept that helps elucidate the personal nature of Heidegger's concept.
"The Them-self": This should give you specific references to better understand difference between Heidegger's definition of one's true self (Dasein) and the general conception that we are agents interacting with and adapting to the world around us.

Your question highlights an important issue with respect to different interpretations of probability. The frequentist has great difficulty attaching a probability to a single event. Strictly speaking, there cannot be a frequency of a single event, so frequentists tend to wave their arms a lot and claim that we can consider something to be an instance of a long run of trials in principle. Such a claim is not plausible in general. What is the probability that Hillary Clinton will become the next US president? (This is written in 2016 with the primaries still in progress.) Such an event, if it happens, will be unique: there cannot be a long run frequency of it. If you try to assess its probability as a frequency you cannot get any sensible value for it. What is the frequency of a female president? Zero. What is the frequency of a democrat president? About a half? What is the frequency of a democrat president given that the previous president was a democrat? Less than a half. Whatever frame of reference you choose will give you a different answer. Frequentists might try to tough it out and say that such an event does not have a probability, because it lacks a frequency, but this is implausible. You can bet on Hillary to win (or not win) and betting odds imply probabilities. 

The virtue of the epistemic approach to understanding probability is that the derivation of the probability calculus can be made without reference to frequencies or possibility spaces, but by starting from simple assumptions about how decisions are made under uncertain information, and about what constitutes a bad decision. We all have to make decisions, and we almost always have to do so with imperfect information. Frequently we make bad decisions, and often this happens because we have failed to quantify the uncertainty properly. One approach to deriving probability is to take a bet as a paradigm case of a decision under uncertainty, and a Dutch book as a paradigm case of a bad decision. (A Dutch book is a combination of bets that results in you losing, no matter what happens.) A fairly remarkable result, first proved by Bruno de Finetti, is that from this consideration only, if you wish to avoid making bad decisions, your calculus of uncertainty must conform to the probability calculus. Of course, this is a fairly limited concept of 'bad decision' - it corresponds to nothing more than maximising expectation value, and as many theorists have pointed out, it is not always the best strategy to maximise expectation value. Nevertheless it is a powerful concept: it shows that we can derive probability theory from decision theory. 

This provides you with the answer to your question: probability is used to make decisions because properly understood it is exactly that quantity that allows us to make decisions under uncertainty without falling into straightforward errors of judgement. 
The background of Popper's discussion is https://en.wikipedia.org/wiki/Rudolf_Carnap Rudolf Carnap's Der logische Aufbau der Welt (1928), Engl.transl.1967.


  [§ 1] The word "object" is here always used in its widest sense, namely, for anything about which a statement can be made. Thus, among objects we count not 
  only things, but also properties and classes, relations in extension and intension, states and events, what is actual as well as what is not. 
  
  [§5] Since we always use the word "object" in its widest sense (§1), it 
  follows that to every concept there belongs one and only one object: "its 
  object" (not to be confused with the objects that fall under the concept). 
  In opposition to the customary theory of concepts, it seems to us that the 
  generality of a concept is relative, so that the borderline between general 
  and individual concepts can be shifted, depending on the point of view.
  
  [https://books.google.it/books?id=WgY2ZMsJtQgC&pg=PA247 §158] Concepts are usually divided into individual concepts and general concepts; the concept Napoleon is an individual concept; the concept mammal, a general concept. From the standpoint of construction theory, this division is not justified, or, rather, it is ambiguous, since every concept, depending upon one's point of view, can be considered either an individual concept or a general concept. We have stated this earlier (§5) and have derived from it the justification for speaking of the object which corresponds to a given concept. [...] In the ordinary view, some of the concepts in this example [i.e. the dog (species) is a class to which my dog Luchs belongs] would have to be called individual and others general. But each of them (except for the last one) is constructed as a class or relation extension, and each of them is an element of the preceding class or a term of the preceding relation extension; thus, each of them is a generality of other objects. What is the reason that, in the ordinary view, e.g., the species dog and the sense quality brown are considered something general while the dog Luchs, and a given world point, and a given experience are considered something individual, and that frequently only the latter are called "objects", while the former are called "mere concepts"? 


According to Popper, this approach, considering the distinction between individual and universal concepts as conventional is wrong.

There are "real" individuals, like Napoleon, and they are used to define individual concepts; the concept "Napoleon's generals" is obviously the name of a class with more than one individual, but it is an individual concept because we cannot define it without using a proper name: Napoleon.

Popper's critique is related to abstraction and the possibility of an inductive reasoning: if there is a "break" between individuals and universals, we cannot "generalize" from a collection of individual cases to a general statement a law. 
Logic is not the source of content; it is only a means by which we may verify the validity of our reasoning. Descartes' argument, "I think therefore I am," represents his effort to find a source of content within the "light of reason" about which he could be certain. However, he recognized that the light of reason is not a source of truth capable of instilling the same degree of certainty as God's revealed truth: 


  "But above all else we must impress on our memory the overriding rule
  that whatever God has revealed to us must be accepted as more certain
  than anything else. And although the light of reason may, with the
  utmost clarity and evidence, appear to suggest something different, we
  must still put our entire faith in divine authority rather than in our
  own judgement." (Principles of Philosophy, Part 1, sec.76, AT VIII-1,
  39; CSM I, 221)


Not everyone recognizes the Holy Scriptures as a source of absolute truth, but  Descartes pointed out that by grace the its divine authority may be revealed to us:


  "Now although it is commonly said that faith concerns matters which
  are obscure, this refers solely to the thing or subject-matter to
  which our faith relates; it does not imply that the formal reason
  which leads us to attend to matters of faith is obscure. On the
  contrary, this formal reason consists in a certain inner light which
  comes from God, and when we are supernaturally illumines by it we are
  confident that what is put forward for us to believe has been revealed
  by God himself. And it is quite impossible for him to lie, this is
  more certain than any natural light, and is often even more evident
  because of the light of grace." (AT VII 147/CSM II 105)

Consider the case of numbers. Frege, for instance, argues that numbers exist as abstract objects. Here is an outline of his argument:


  The language of mathematics purports to refer to and quantify over abstract mathematical objects. And a great number of mathematical theorems are true. But a sentence cannot be true unless its sub-expressions succeed in doing what they purport to do. So there exist abstract mathematical objects that these expressions refer to and quantify over. (http://plato.stanford.edu/entries/platonism-mathematics/ SEP)


For example, it would be odd to accept the following


  There are prime numbers between 10 and 20


as true, but to claim that there are no numbers. One could take another approach and say that it is true that there are numbers, but nevertheless that numbers do not exist.

But since the existential quantifier (∃) is used in expressing the above sentence, one would have to distinguish different sorts of existence, e.g. existence as expressed by ∃ and physical existence (or explain otherwise what is expressed by ∃). Note that this might amount to taking physical existence to be a property.

The main point is this. We talk about numbers, fictional characters, musical compositions, etc., all of which are http://plato.stanford.edu/entries/abstract-objects/ abstract objects, and we can make true claims about them (e.g. 'Sherlock Holmes is more famous than any real detective'). These of course do not exist in the same sense that physical objects do, but it does not necessarily mean that they do not exist in any sense of http://plato.stanford.edu/entries/existence/ existence.



Update

You asked:


  We consider concepts such as electromagnetic field, neutron, and gene to be physical entities. Yet they are as abstract as mathematical or social constructs. Why are the former considered physical while the latter aren't?


First off, anything physical is by most conceptions not abstract. The distinction is usually between abstract objects and concrete objects, where the physical objects are supposed to be some subset of the latter.

One common conception defines abstract objects as follows:


  An object is abstract if and only if it is causally inefficacious. (http://plato.stanford.edu/entries/abstract-objects/#CauIneCri SEP entry on Abstract Objects)


The entry continues:


  Concrete objects, whether mental or physical, have causal powers; numbers and functions and the rest make nothing happen.


So the distinction is not arbitrary. This does, however, fit your statement that anything that has a causal effect on the physical world is itself physical.
It does bring in more than (ephemeral) security of foundations, but what it is more of is different for different people. The early intuitionists like Brouwer and Weyl saw mathematics as free play of a Kantian creative subject, and to them "excesses" of classical mathematics were simply unfaithful to the mathematical intuition of that subject and his other cognitive faculties. This is particularly obvious in Weyl's critique of the "atomistic continuum" of classical mathematics versus intuitive continuum that appears not as "an aggregate of fixed elements but as a medium of free ‘becoming’", and his general longing:"Where is that transcendent world carried by belief, at which its symbols are directed? I do not find it [in classical mathematics], unless I completely fuse mathematics with physics and assume that the mathematical concepts of number, function, etc. (or Hilbert’s symbols), generally partake in the theoretical construction of reality in the same way as the concepts of energy, gravitation, electron, etc.", see https://philosophy.stackexchange.com/questions/30154/is-aristotles-resolution-of-zenos-paradoxes-vindicated-by-motion-in-the-intuit/30188#30188 Is Aristotle's resolution of Zeno's paradoxes vindicated by motion in the intuitionistic continuum?

Bishop, the founder of constructive analysis, later had equally strong feelings. In a 1974 lecture titled Crisis he wrote "There is a crisis in contemporary  mathematics, and anybody who has not   noticed   it  is  being  willfully blind. The  crisis is due to our neglect of philosophical issues..." and in his diagnosis of the crisis's cause as idealistic excess remarked that "it is difficult to believe that debasement of meaning could be carried so far" referring to the non-standard analysis, see https://arxiv.org/abs/1110.5456 Katz's Meaning in Classical Mathematics: Is it at Odds with Intuitionism? It is a bit ironic that Cantor, the most Platonist of all Platonists had strong words against infinitesimals too, see 
https://philosophy.stackexchange.com/questions/33310/what-is-the-philosophical-difference-e-g-according-to-cantor-between-the-infi/33329#33329 What was Cantor's philosophical reason for accepting the infinite but rejecting the infinitesimal? However, Bishop does not simply dismiss classical theorems:"Every theorem proved with idealistic methods presents a challenge: to find a constructive version, and to give it a constructive proof... Very possibly classical mathematics will cease to exist as an independent discipline." 

This kind of passionate attitude is however quite rare among working mathematicians. But many of them view constructive mathematics favorably because it delivers more in the practical sense: explicit constructions and computations, that can be used not just to prove pure existence but to construct and explore explicit examples, error estimates that are needed if theoretical manipulations are to be made practically feasible and implementable, etc. Bishop himself writes:"It is clear that many of the results in this book could be programmed for a computer... As written, this book is person-oriented rather than computer-oriented. It would be of great interest to have a computer-oriented version". But at the other end of the spectrum we find http://www.jstor.org/stable/30226269 Tait's Against Intuitionism: Constructive Mathematics Is Part of Classical Mathematics, who as the title suggests, holds that one can accept some self-restrictions for the sake of constructive purposes, while remaining a classical mathematician:"But the notion of computability, though important within mathematics and in applications, is a mathematical notion, understood in terms of the notions of number and (extensional) function. The search for constructive proofs and for constructively provable analogues of classics theorems is well motivated. But it is a search within the common domain of mathematics and is not based on some alien circle of ideas."

More recent philosophical intuitionists, like Dummett, Tennant and Wright, are somewhere in between, their concerns are semantic and epistemological, like Weyl's and Brouwer's, but more pragmatic and less Kantian. I find http://www.blackwellpublishing.com/content/bpl_images/content_store/sample_chapter/0631218696%5Cjacquette.pdf Dummett's What is Mathematics About? quite insightful.
The http://plato.stanford.edu/entries/private-language/#OveWitArgInt SEP article does a good job of pulling together various places in Philosophical Investigations over which the private language argument sprawls (including the rule-following paradox, and the beetle in a box), as well as surveys its various readings and misreadings. Unfortunately, this obscures the argument itself. Jacquette gives a cogent summary of the core argument and its "extensions" in http://webcache.googleusercontent.com/search?q=cache:sammelpunkt.philo.at:8080/399/1/12-1-94.TXT Wittgenstein on Private Language and Private Mental Objects. Here is the key passage from PI §258 (but it is hard to decipher without working through §§244–271):


  "I will remark first of all that a definition of the sign cannot be expressed. But still I can give myself a kind of ostensive definition. How? Can I point to the sensation? Not in the ordinary sense. But I speak, or write the sign down, and at the same time I concentrate my attention on the sensation -- and so, as it were, point to it inwardly. But what is this ceremony for? for that is all it seems to be! A definition surely serves to establish the meaning of a sign. Well, that is done precisely by the concentrating of my attention; for in this way I impress on myself the connexion between the sign and the sensation. But "I impress it on myself" can only mean: this process brings it about that I remember the connexion right in the future. But in the present case I have no criterion of correctness. One would like to say: Whatever is going to seem right to me is right. And that only means that here we can't talk about 'right'".


For sign to have a meaning it must be possible to use it wrongly, because language is a rule-governed activity. In a community other speakers are available to correct the speaker, or the speaker can even internalize the "rules" and use them privately, but on things that are at least in principle publicly accessible. There is no such check on private sensations, whatever seems right is right. And Wittgenstein addresses the obvious rebuttle, "but surely I can appeal from one memory to another", by comparing it to "looking up" an imaginary timetable:


  "If the mental image of the timetable could not itself be tested for correctness, how could it confirm the correctness of the first memory? (As if someone were to buy several copies of the morning paper to assure himself that what it said was true)... But justification consists in
  appealing to something independent". 


With no possibility of error private signs are meaningless. Does this imply the non-existence of private mental entities? Not immediately, Wittgenstein himself talks about "pre-linguistic" in PI §541, but that is little consolation since it renders at least any talk of them meaningless. Does the difference between types and tokens matter? In the argument we do not even reach a point where the nature of sensations comes into play, and Wittgenstein's own position was that there is no such thing as "mental content", only language games, he indulges in it just for the sake of the argument. A champion of the distinction, Davidson, who based his "anomalism of the mental" thesis on it, didn't think so either, see a Davidsonian reading of Wittgenstein in http://www.yorku.ca/cverheg/documents/howsocial.pdf Verheggen's How Social Must Language Be?

But there is something else. Wittgenstein's argument is best understood as a transcendental argument in the Kantian sense: use of signs requires criterion of correctness, public access supplies such a criterion, therefore it is a condition of its possibility. "Therefore" here is not a logical inference, it is what Peirce called abduction, an ingenious explanatory hypothesis. But who is to say that the speaker herself does not host something of a community, with different modes and faculties acting as checks on each other? Aren't multiple memory recalls and comparisons akin to different speakers intervening to correct the use of a public sign? The morning paper analogy limps badly, especially on Wittgenstein's own view of the mental, there is no making copies of that. So different memory recalls are somewhat independent verifiers. It seems that Wittgenstein's criterial skepticism covertly invokes the underlying unity of  Cartesian "I", which he officially rejects.

Kant once gave a transcendental argument that for us to establish temporal succession of events we must presuppose the law of causality, because events do not come with time stamps on them. He identified a real puzzle and offered an ingenious solution to it, which nonetheless modern cognitive science more or less established to be wrong, see https://philosophy.stackexchange.com/questions/33490/in-what-fundamental-ways-if-any-does-husserl-break-with-kant/33498#33498 In what fundamental ways, if any, does Husserl break with Kant? Wittgenstein's puzzle is equally real, there has to be something that acts as a check for a private language to make sense, and what plays that part for public languages isn't available. But in contrast to Kant, at the moment the jury is far out on whether his skeptical solution is empirically correct.
Actually, chapter VIII of http://selfpace.uconn.edu/class/percep/SellarsEmpPhilMind.pdf Empiricism and the Philosophy of Mind (EPM), and section 35 in particular, do not contain any arguments against the Given, certainly not the main argument. The role of chapter VIII (whose title is "Does Empirical Knowledge Have a Foundation?") to present the typical account of empirical knowledge that is associated with the Given, and then to suggest an alternative. The chapter just presents one account beside another. It does not argue against the account of the Given.


  32) One of the forms taken by the Myth of the Given is the idea that there is, indeed must be, a structure of particular matter of fact such that ...  
  
  35) But what is the alternative? We might begin by trying something like the following ...


Secondly,  by "authority" Sellars refers to the ability to provide epistemological justification.


  Now, the idea of such a privileged stratum of fact is a familiar one, though not without its difficulties. Knowledge pertaining to this level is noninferential, yet it is, after all, knowledge. It is ultimate, yet it has authority. (32)
  
  The essential point is that in characterizing an episode or a state as that of knowing, we are not giving an empirical description of that episode or state; we are placing it in the logical space of reasons, of justifying and being able to justify what one says. (36)


Again, in chapter VIII Sellars does not present any arguments against the presumed authority of the Given. He just presents an alternative account of authority.

For an example of a place where Sellars does argue against the Given, see section 6:


  It is clear from the above analysis, therefore, that classical sense-datum theories --I emphasize the adjective, for there are other, 'heterodox,' sense-datum theories to be taken into account --are confronted by an inconsistent triad made up of the following three propositions:
  A. x senses red sense content s entails x non-inferentially knows that s is red.
  B. The ability to sense sense contents is unacquired.
  C. The ability to know facts of the form x is ø is acquired.
  A and B together entail not-C;
  B and C entail not-A;
  A and C entail not-B. (6)

Where is the line drawn between immoral inactivity and a simple lack of action?

Under a Kantian framework, inactivity is immoral when it violates a moral obligation you have. This is generally never, since moral obligations are generally negative (i.e. "don't kill someone" is a moral obligation). Kant does posit an ambiguous duty of beneficence, which states that we have a duty to help others. He doesn't say to what extent we have to help others, so it's still unclear if we should vote for Hillary to stop Trump (or vice versa). To be honest, this duty is usually ignored. The main point here, regardless of the duty to help others, is that if Trump or Hillary wins the election, blame can not be placed on any individual who failed to vote. In fact, it's not the voters' fault at all. If Trump does something stupid, only Trump can be blamed. 

A utilitarian framework provides a clearer bright line. All inactivity, in the exception of one case, is immoral. It is only moral if any action at all would make the situation worse. The thing is, we have to take into account others' actions here, too, unlike under a Kantian framework. So, if we think Obama is a better president than Hillary or Trump, we should abstain from voting so he can remain president, right? Except, other people will vote for Hillary or Trump, rendering our action moot. So, we have to vote for the "least-worst" candidate under this framework.
If this interests you, some utilitarian writers include Jeremy Bentham and John Stuart Mill. However, while I believe both discuss inactivity, neither of them specifically describe political participation obligations or the lack thereof, which is more dense.  
At most, axioms and rules for first-order logic (with equality) may define the concept of "logical truth", assuming the standard semantics and equating validity with logical truth.

What are logical truths ? They are formula which are true irerspective of the domain of discourse, i.e. truths that are not topic-specific, like:


  p → p  or  ¬ (p ∧ ¬ p).


But the philosophical issues related to http://plato.stanford.edu/entries/logical-truth/ Logical Truth are many and interesting.
"Free will" is not a monolith. The reason that no person considers the issue futile to discuss is that if the determinism of behavior is a given, but we keep using the term, then what do we actually mean to say when we claim to have willed an action?

The question that arises from discussions about free will is typically not whether we can change our behavior, but whether it's right to hold people responsible for their actions. If so, then what level of coercion or force is required to eliminate what we think of as free will, and how does this differ from the overall deterministic nature of the world?

Most philosophers of any note have weighed in on some aspect of this question. Some books to start with (just off the top of my head) would be https://en.m.wikipedia.org/wiki/Elbow_Room_(book) Elbow Room by Daniel Dennett, or http://rads.stackoverflow.com/amzn/click/019925494X Free Will, a collection of notable essays and papers on the subject dating back to the seventies (Ed. Gary Watson).
Your utility assessment does not include the utility of the amusement park owners/operators. Under the premium pass scheme they earn more money, which (presumably) provides them with utility.

You can also argue this in a slightly different way, using the idea that one man's premium is another man's discount.  Given that the owner is able to charge a premium for fast passes, it is likely that they could increase prices overall and still make out economically.  This uniform price increase would price some people out of the market all together.  By offering what can be considered a discount from this higher price to people who are willing to wait, the owner is offering his/her services to more people overall.

Finally, you could argue that the utility for a person is not linear.  Suppose that you were able to quantify the "degree of amusement" and found that getting 3 or 4 rides/hour generated 1 unit of utility and getting 5 rides/hour generated 9 units of utility (people with fast-passes come out even happier since they weren't frustrated by waiting in line).  Then even if there is some cost for dispersion between the guests, there can be conditions where some dispersion maximizes utility.  This points out one of the main difficulties in utilitarian assessments: what is the metric that we can use to adequately compare different features of our experience?

Aside

At first I though the non-linear utility argument would be simply a pedantic ploy, but now I think it might have some sense (for some people).  For long enough wait times, the enjoyment derived from the ride itself doesn't outweigh the frustration from having to wait for so long, i.e. there is some sort of cost to waiting too long.  To me at least, waiting for one or two cycles really isn't frustrating at all, so at that rate of throughput, there is zero "frustration cost".  Between these two extremes the utility will rise more than linearly with the inverse wait time: a linear part just from the fact that you can hit more rides if the wait time is shorter, and then a "bonus" that your degree of frustration decreases as the wait time goes down.  So it is not totally implausible to invoke the non-linear utility argument.

Prior, A. N. "http://go.galegroup.com/ps/i.do?id=GALE%7CCX3446801182&v=2.1&u=uarizona_main&it=r&p=GVRL&sw=w&asid=5327b27f12b49923b785c958133fcb14 Logic, Traditional." Encyclopedia of Philosophy. Ed. Donald M. Borchert. 2nd ed. Vol. 5. Detroit: Macmillan Reference USA, 2006. 493-506. Gale Virtual Reference Library. Web. 20 May 2016.


mentions


Timothy Smiley. "http://www.jstor.org/stable/2963679 Syllogism and Quantification." The Journal of Symbolic Logic 27, no. 1 (1962): 58-72.


Smiley's abstract:


  Anyone who reads Aristotle, knowing something about modern logic and
  nothing about its history, must ask himself why the syllogistic cannot be
  translated as it stands into the logic of quantification. It is now more
  than twenty years since the invention of the requisite framework, the
  logic of many-sorted quantification.


He concludes:


  If the Aristotelian logic, after a long pre-eminence and a shorter period
  of disrepute, is now more temperately regarded, the change is surely due
  to Lukasiewicz' formalisation of the traditional syllogistic in the 1930's,
  and his bringing modern techniques and ideas to bear on the resulting system.
  But the price paid for a rehabilitation of the traditional logic through an
  algebra of the Łukasiewicz type is a certain divorce from the main current
  of modern logic: Łukasiewicz was even led to conclude (op. cit. [http://plato.stanford.edu/entries/lukasiewicz/ Łukasiewicz, Jan. 1957. https://isidore.co/calibre/browse/book/5785 Aristotle's syllogistic from the standpoint of modern formal logic. Oxford: Clarendon Press.
  ], p. 130) that
  the syllogistic of Aristotle "exists apart from other deductive systems,
  having its own axiomatic and its own problems." The result is a certain
  ambivalence in the current attitude towards the old logic - when we compile
  our World Team of logicians we tend to include Aristotle as (non-playing)
  captain. This attitude, at once admiring and dismissive, is well illustrated
  in Łukasiewicz' conclusion that "The syllogistic of Aristotle is a system the
  exactness of which surpasses even the exactness of a mathematical theory,
  and this is its everlasting merit. But it is a narrow system and cannot be
  applied to all kinds of reasoning, for instance to mathematical arguments.
  … The logic of the Stoics, the inventors of the ancient form of the propositional calculus, was much more important than all the syllogisms of
  Aristotle. We realize today that the theory of deduction and the theory of
  quantifiers are the most fundamental branches of logic." (p. 131.)
  
  It would of course be absurd and anachronistic for me to try to vindicate
  Aristotle's choice of subject-matter by suggesting that he was consciously
  guided by anything like the modern idea of quantification. But without
  committing this mistake there are two observations which I think may
  properly be made. One is that if it is anachronistic to suggest that Aristotle's
  logic is 'really' a theory of quantification then it is equally anachronistic
  to suggest that it is 'really' a theory of primitive functors A, I, etc. As
  Łukasiewicz himself remarks in his book, "the logic of Aristotle is formal
  without being formalistic"; and what I have for the sake of convenience
  called the 'traditional' theory in § 2 is, both in its conscious conception as an
  algebra of non-empty classes and in its formalistic vocabulary and axiomatisation, as distinctively 'modern' as the logic of quantification. The
  other remark to be made is that the logic of many-sorted quantification
  is in no sense something existing "apart from other deductive systems".
  Not only is it formally no more than a systematic reduplication of the
  standard single-sorted logic, but it is also the obvious framework for the
  formalisation of a whole range of mathematical theories: any branch of
  geometry will furnish one example and Russell's or von Neumann's set
  theories another. I should like therefore to think that the translations
  introduced above would help to counter the suggestion of even a residual
  incompatibility between the modern and the Aristotelian formal logic.


  How is zero different from nothing? 


From a mathematical point of view, the answer is as follows:

Nothing is a set and zero is a number. Nothing is the empty set, i.e. the set with no elements. While zero is the cardinality of the empty set,  i.e. the number of its elements. 

Sets themselves are the objects of the mathematical discipline of set theory. They are the base of all other mathematical disciplines. 

In addition, the number zero plays a fundamental role in structures like the additive group of integers: 

x + zero = x


for any integer x.
Judith Butler is a post-structuralist feminist. See https://en.wikipedia.org/wiki/Judith_Butler Judith Butler: her "origins" are with http://plato.stanford.edu/entries/merleau-ponty/ Maurice Merleau-Ponty and http://plato.stanford.edu/entries/beauvoir/ Simone de Beauvoir, http://plato.stanford.edu/entries/feminism-psychoanalysis/ Julia Kristeva, Jacques Lacan and Luce Irigaray, http://plato.stanford.edu/entries/derrida/ Jacques Derrida.

This places her squarely in the "continental" stream of thought. Specifically, that's going to put her pretty close to Derrida. Despite the phrasing, there's also not much of a difference between structuralists and post-structuralists so you could also call her a structuralist without losing too much meaning.

Even though she's from the US, there's not really any way to consider her an analytic philosopher -- either based on influences or writing style. She is most definitively not in the http://plato.stanford.edu/entries/analysis/#6 analytic tradition.

For more about her positions see http://plato.stanford.edu/entries/feminism-gender/ http://plato.stanford.edu/entries/feminism-gender/



For more on the divide, how it works, and why we think she's a thoroughly continental figure.

https://philosophy.stackexchange.com/questions/4311/what-is-the-origin-of-the-continental-vs-analytic-divide What is the origin of the Continental vs. Analytic divide?

https://philosophy.stackexchange.com/questions/21292/do-some-continental-philosophers-deliberately-obfuscate-their-writing-why Do some continental philosophers deliberately obfuscate their writing? Why?
As said above the terminolgy is "fitted on" Barbara:


  "A belongs to all B and B belongs to all C; therefore..." 


The "middle" (meson) is in the middle and major and minor are the "external" ones, called "extremes" (akron). This is not true for other figures.

Thus, the subsequent "revised" explanation: the middle is the term occurring in both premises.

Note: 


https://en.wiktionary.org/wiki/Akron akron: Ancient Greek ἄκρον ‎(“extremity, peak”)
https://en.wiktionary.org/wiki/meson meson : Ancient Greek μέσον ‎(“middle”).




See Prior Analytics, I, 25b32-26a2:


  Whenever three terms are so related to one another that the last is in the middle as in a whole, and the middle is either in, or not in, the first as in a whole, the extremes must be related by a perfect deduction [sullogismos]. I call that term middle which both is itself in another and contains another in itself: in position also this comes in the middle. By extremes I mean both that term which is itself in another and that in which another is contained.

https://en.wikipedia.org/wiki/Syntactic_ambiguity Amphiboly or amphibology stays for Syntactic ambiguity, i.e.


  a situation where a sentence may be interpreted in more than one way due to ambiguous sentence structure.


Ambiguity is also the word used in the translation of https://en.wikisource.org/wiki/The_Sophistical_Elenchi Sophistical Refutations:


  [165b23-166a22.] Examples such as the following depend upon ambiguity: ‘I wish that you the enemy may capture.’ And ‘He who knows that, that knows’; for by this phrase one may signify as the knower either him who knows or that which is known.


The ethymology for the Ancient Greek http://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.04.0058:entry=a%29mfi%2Fbolos ἀμφίβολος is:


  I. put round, encompassing, Eur.
  
  II. attacked on both or all sides, Aesch.
  
  III. doubtful, ambiguous, Plat., Xen., etc.


Thus, we have a "shift of meaning" from II to the figurative usage III: a sentence that can be undestood in two different ways not because the words per se are ambiguous, but due to the syntactical construction of the phrase.
Yes.

See https://en.wikisource.org/wiki/The_Sophistical_Elenchi Sophistical Refutations:


  [166b1-166b9] An argument depending upon accent [https://en.wiktionary.org/wiki/%CF%80%CF%81%CE%BF%CF%83%E1%BF%B3%CE%B4%CE%AF%CE%B1 προσῳδῐ́ᾱ ‎(prosōidíā) the tone or pitch of a word] is not easy to construct in unwritten discussion; in written discussions and in poetry it is easier. Thus (e.g.) some people emend Homer against those who criticize as absurd his expression to men ou katapythetai ombro [τὸ μὲν οὖ καταπύθεται ὄμβρῷ]. For they solve the difficulty by a change of accent, pronouncing the ou with an acute accent. [footnote: They emend οὖ to οὔ, ‘Part of which decays in the rain’ to ‘It does not decay in the rain’ (Iliad, XXIII 328).] Also, in the passage about Agamemnon’s dream, they say that Zeus did not himself say ‘We grant him the fulfilment of his prayer’ [δίδομεν δέ οἱ εὖχος ἀρέσθαι], but that he bade the dream [διδόναι] grant it. Instances such as these, then, turn upon the accentuation.


That's all.
'Chicane' is an aspect of a racecourse or (perhaps its only remaining use) a golf course that is idiosyncratic to it, and the accommodation of which is about local knowledge or luck, not related to the overall quality or the more general skills of the competitors.

(In particular, a chicane is a place where a road has purposely injected narrow turns that cannot be seen very far ahead of time.

In Europe (or in New England) these can be logical, e.g. for traffic control, or to protect historical features.  In the newer parts of the New World they are more often attempts by surveyors to follow a line of longitude and a city grid structure at the same time, with no general rule as to when exactly to adjust the block size to synchronize these two competing goals.)

The nature of Common Law, is that it derives from history, agreements and argumentation as contrasted with other forms of law that would be known to Bentham, such as continental Civil Law, which derives from principles stated in a constitution; Uniform Military Law, which derives from a clear focus on efficiency and completeness in decision making; or even Church Law which has an ultimate unchanging anchor in scripture so that interpretation can only vary back and forth within fairly narrow bounds.

Compared to those, then, Common Law systems contain a great quantity of internal structure that is only very vaguely related to any logical structure, since it has simply evolved over time without any anchor other than the agreements among the nobility, the decisions of governing bodies, the trends of individual jurists, and other cultural conventions.

To someone of a modern scientific bent, who would prefer things be based on general principles and deduced from logical aspects, this is metaphorically the same kind of local, arbitrary unfairness that a racecourse or golf course riddled with an unexpected lack of uniformity presents.

So it is not so much about favoring the rich as about favoring the local, those with long or voluminous memories, the charismatic who persuade via sophistry and those with time to spend ferreting out idiosyncracies. This includes many varieties of the wealthy but excludes others, for instance, businessmen with times to market, and foreigners in general, especially the operators of complex international concerns.

(Sorry to be wordy, I often find such details more fascinating than they are due.)
You don't mean the idea of free will, you mean the value of autonomy.

Clearly the only reason to legislate anything is to limit the expression of free will.  If we did not believe in free will, we would pursue something like https://www.thevenusproject.com/ https://www.thevenusproject.com/, stop trying to control behavior and just try to predict it and shape it via technology instead.  So, their existence presumes free will, and does not contradict it.

Autonomy has been put forward as a basic principle of ethics by many, including Kant.  But such ideas generally aim to universalize autonomy or spread it to as many individuals as possible.  Very few cogently argue for simply increasing the autonomy of the majority even if this severely limits everyone else.  Extreme libertarians do, but they can do so only by presuming that liberty and property are the only rights that really matter.  (I would argue that by not at least covering the traditional range of Cardinal Virtues, i.e. not including safety and reciprocity as concerns, this is itself a position that reflects a certain level of privilege, and should be distrusted.)

Defending your choice to act upon chosen biases does not increase the general level of autonomy across the board, if at all.

First of all, the bias itself is not generally a choice, it is a traditional dictate, and so it does not really reflect autonomy.  To be free to question it increases one's autonomy.  Having counterexamples visible to you opens to you the opportunity to question the bias.

If those counterexamples do not arise from simply refusing to allow baseless application of the bias in place of logic and fairness, then the bias will be proven to have a point, we will figure out how to accommodate the facts of life, and the resistance will go away.  (We don't, for instance, insist that one hire children on par with adults, or make onerous adaptations for someone like a blind graphic artist.  We only truly challenge traditional biases that seem to have no realistic basis.)

Second, strong enough biases severely limit the autonomy of certain individuals while reversing them limits the autonomy of a wider range of people, but only mildly.  

Let me offer an example now in our past: In highly religious areas of the U.S., it used to be traditional to shun the divorced.  My grandmother, who had been a schoolteacher, therefore, lost her occupation, in addition to her husband, when he left her.  She and her children suffered considerably until she could earn the money (as a house servant -- one of the few jobs she was any good at that did not force people to interact with her 'morally') to move to a more populous, less religious, region of the country, where she could return to teaching.

On the other hand, just insisting parents should trust her to continue doing the job she had always successfully held might have required they explain some difficult facts to their children, but would not have harmed anyone severely.  Several decades later, teachers' unions negotiated laws that prevented immediately firing divorcees from educational settings.

When you balance it all out, it is highly ambiguous whether the overall level of autonomy has been raised or lowered by instituting such a rule.  Teachers are now free to conduct their marital lives the same way everyone else can, but people can no longer protect their children from others who think it is OK to get divorced under some circumstances (like long-term abandonment.)

So, if you want to argue against anti-discrimination laws from the value of autonomy, it can be done only by taking the strange libertarian perspective of those whose main problem in life is being told what to do, over the perspective of people who are marginalized into poverty or death by the refusal to consider them potentially equal.

If you attempt to consider all perspectives equally and to consider more severe losses more highly than minor limitations, you ultimately find the patterns of discrimination around us are reducing the overall balance of autonomy, which makes them immoral according to the most commonly expressed ethical formulations, which are often a balance of Kantian fairness and Utilitarian perspectives.
It seems clear in context that what one is meant to be wishing for when wishing for eternal recurrence is the repetition of this moment now. The point is to always live in such a way that you would not want any alternative version of the current moment more than the one that is already happening, if you could back off and consider it in context for arbitrarily long, because this moment can be expected to lead into to moments you would wish never to lose.

E.g. one appearance is:


  What, if some day or night a demon were to steal after you into your loneliest loneliness and say to you: 'This life as you now live it and have lived it, you will have to live once more and innumerable times more' ... Would you not throw yourself down and gnash your teeth and curse the demon who spoke thus? Or have you once experienced a tremendous moment when you would have answered him: 'You are a god and never have I heard anything more divine.' (The Gay Science)


The moments (in this case the ultimate single moment) you would wish to have return forever should offset every moment you might wish had turned out differently.  Whatever others must suffer for you to regain those peaks is both largely irrelevant, and completely outside your power to control.
I will try to paraphrase (not literally translate) what the quote says:

First sentence: Thesis.


  Man isn't as fragile as rose, a self-sufficient being, but even more, so that he can be brought out of his equilibrium by such simple phenomena as vapour or a drop of water, because he has to think about it.


Second sentence: Explication.  


  He (identified with his thinking!) has to evolve, include every single phenomenon into the framework of his thinking, and therefore his self-conception is always endangered by the universe (read: nature/phenomena) to be challenged and eventually "crushed". Man then has to reinvent himself, the old self is killed, and a new, more noble one, is born. But in the end, it is man how "kills" himself, not nature.


The http://degaulle.lyc.ac-amiens.fr/matieres/philosophie/guyon/corriges/pascalrosopensant.htm link out of the comment of @MauroAllegranza pretty much contextualises this historically as I understand (only six years french in school, maybe I got all wrong ;). 

Therefore, the violability allegorically expressed in the first sentence is nothing more than the other side of the medal of "Toute notre dignité consiste donc en la pensée." - All our dignity consists therefore in the thinking. - The sentence following your quote within the very same Pensée, leading to a notion of morals. It is our source of nobility to cope with the universe in thinking, always throwing over our obsolete self-understanding.
You can check the http://philpapers.org/surveys/ philpapers survey. 


  The PhilPapers Survey was a survey of professional philosophers and others on their philosophical views, carried out in November 2009. The Survey was taken by 3226 respondents, including 1803 philosophy faculty members and/or PhDs and 829 philosophy graduate students. 


One question was whether the participants believed in scientific realism or anti-realism. The answer was:


  Accept or lean toward: scientific realism     699 / 931 (75.1%)

(E) three swimmers only can ski as well.

If the sportsmen (those practising at least one sport) got 8 or 9 as a mark and there were 9 pupils who got less than 8, we have to deduce that the 9 do not practice sports at all.

Thus, 25 minus 9 equal 16: the sportsmen.

We have 13 plus 11 plus 8 equal 32 sports practiced overall with no one practising all three sports; thus, each sportman must practice exactly two sports.

Thus of the 16 sportsmen, we have that: 13 are cycling and 3 not-cycling, that implies that the three not-cycling must practice swim and ski.
This might be helpful:


  The distinctive feature of the [ontological] arguments ‒ at least according to the traditional Kantian method of classification ‒ is that they proceed from premises which at least some defenders of the arguments allege can all be known a priori. Consequently, it would be most appropriate to call these arguments 'a priori arguments for the existence of God'. However, following Kant, it has been established practice to call these kinds of arguments "ontological arguments," and I see no urgent reason to depart from this tradition. (https://books.google.com/books?id=qg0spmMuC98C&pg=PA1&redir_esc=y#v=onepage&q&f=false Ontological Arguments and Belief in God)


But note that not all arguments for the existence of God are ontological, as you suggest. By the above definition, for example, arguments from something like the complexity of life to the existence of God would not be ontological arguments, since they proceed from empirical facts.

Also, the names that you suggest might be too narrow. http://plato.stanford.edu/entries/ontological-arguments/#TaxOntArg SEP lists several kinds of ontological arguments:


  
  definitional ontological arguments;
  conceptual (or hyperintensional) ontological arguments;
  modal ontological arguments;
  Meinongian ontological arguments;
  experiential ontological arguments;
  mereological ontological arguments;
  higher-order ontological arguments; and
  ‘Hegelian’ ontological arguments;
  

I am going to give the overextended postmodernist view here, springing originally from Wittgenstein and psychoanalytic thinkers like Lacan.  I am doing so just so that both ends of this range are pinned down.  In some sense I think this is 'the truth', but it is far too difficult to actually use, and may not be worth considering in the context of teaching logic at all.


  If the symbols exist, then they exist where? (In case of alphabets, if I want to be painfully philosophical, I may be tempted to say that the alphabets exist in some "imaginative world" of my mind - which will in this case be "collection".)


From that point of view the symbol is its intended effect upon people, so in that sense it exists.  They exist in the realm of human intention or expectation and are backed up in the realm of the human imagination, including our simplified memories of the real past.

The letters of the alphabet do not exist as physical or even mental 'objects', they take variant forms and can be substituted by any potential form, for instance in binary coding, without loss of their power to be the letters that they are.  I cannot put that object into your mind, I can only intend to, and accept the degree to which I do or do not succeed.  If you do not already have a sense of the intention behind 'A'-ness, I cannot show you an A.

We learn this notion of 'A'-ness by playing out the effects by rote until they are natural to us: the notion is the collection of memories of its effects and imaginings about its potential deployments.  So I can have a symbol in my mind only if I know it has an intended purpose, and I use that symbol to evoke a complex of memories and images in another person's imagination (or in my own).


  Is it even meaningful to ask 'where the symbols exist'?


In order for the question to make sense, it has to be stripped of the basic assumptions we have about mental objects, or it becomes circular.  Mental objects as real things are themselves simply symbolic and any realization of an idea is made up of symbols.  Symbols are the things that symbolize, and that is not helpful.  So the idea of a mental or symbolic realm becomes baseless and circular.  One simply has to insist it into existence by fiat, which is unsatisfying.

Instead, you need to back off from the situation within your mind into the social realm.  Once you see symbols or thoughts in terms of their usage in communication, then it becomes clear that we abstract expected usages into symbolic representations using some kind of 'cleaning up' mechanism that is largely similar among human beings.  That is how you the above positions ends up saying that symbols are 'expectations' and nothing more.


  I think that it is necessary to have a Theory of Collection because the phrase "[w]e have some symbols" is very much vague. Consider the following question for example,


We have an intuition of collection that empowers us to span the gap between parts and wholes without thinking about it too much.  We can take that as our basic 'Theory of Collections', but it is not very much of a theory.  Attempting to express it logically turns out to be extremely difficult, and to lead into conflict with very basic concepts like universality or negation.  All of this is tied up in one neat package by Russel's Paradox.


  Does the meaning (or sense) of "have" in "have some symbols" the same as that of "have" in "have a doll"? How can you say that?


No, it is the same as that in "we have laws" or "we have nations".  By the laws we do not mean their impressions upon paper, we mean the expectation they encode.  Likewise, by a nation we do not mean its people.  When all the Romans had passed away, there was still Rome as an exemplar 'nation' upon which other nations built their legal systems, and even their languages.

These things are not physical objects, they are abstractions that hold our expectations of how things should happen -- they reify social processes.  They are 'the content of language-games', which occupy one side of a natural duality between things and the rules we insist upon applying to them.
The most popular opinion right now is that physics is deterministic, simply because that assumption has lead to great success.  We don't know whether it is actually true or not, but we do often assume it.

However, in all real world cases, we do not have perfect information about the system.  Thus real world physics' predictive power is less than perfect, even if the underlying theories were perfect.  This would suggest that, in real life situations, it is effective to treat physics as a nondeterministic process.
On a certain level, the argument that all ethical theories can be construed in  consequentialist terms is true. This is exactly because the particular set of consequences we want to maximize is not stated in making this assessment, but this elasticity is also a weakness of this claim.

For instance, if we want to represent the Kantian account in "consequentalist" (or perhaps more broadly calculative) terms, then I don't think it's sufficient to say that we want to maximize the "use of acceptable means." Instead, (working just from one formula -- the formula of humanity) it seems like we want to 


Maximize the consideration of rationality where ever we encounter it as an ends
Set at a value of negative infinity in our system any treatment of a person as a mere means
calculate in terms of maxims of actions with relation to 1 rather than merely extrinsically (i.e., positives only occur when we have a maxim motivated in this way -- not just when we have an action that would correspond to this maxim).


But now this doesn't look very much like a consequentialist matrix, because actions in 2 are completely excluded from the realm of conceivable moral action, and that we are evaluating not what happens as a result of actions but that we are evaluating whether our maxim bears the right relation to this principle. Which on Kant's theory is inaccessible.

So then yes, each agent would be maximizing the value of their maxims (and absolutely not engaging in the actions contrary to the CI or treating others as mere means), but they would have no ability to calculate whether they have achieved anything positive vis-a-vis this maximization. (Since the Kantian moral will in its classical version is not inside of the manifolds of sensibility or the categories of understanding, we can never know when we commit moral actions, because we have only access to our past actions in the world and not our prior moral will; conversely, we can identify some patently bad actions directly -- like lying).



Similar conundrums arise if we try to look at virtue theory as a consequentialist theory. Looking just at Aristotle's account, Nicomachean Ethics BK I Chapter 7 identifies what we are trying to maximize as our human function (i.e. our humanity). As the subsequent parts demonstrate, the way we do this is by applying practical wisdom to certain emotional and rational states and finding the balance that matches (a) our species, (b) our specific abilities (if I'm say genetically predisposed to being strong or weepy), (c) the precise circumstance, and (d) my growth vis-a-vis (a) and (b) through my choices of action.  And then we have to look at the natural unit of human beings as being not the individual but the polis.

The root problem here is similar but not identical to the Kantian case. The similarity is its difficult to calculate this. But Aristotle is going to give different reasons: (1) those of us who lack phronesis won't know the optimal conditions and behaviors, (2) phronesis can include situational factors in a way that makes it so it's not always clear there is one action that should be taken. (3) Since virtue is about seeking means, these means will be such that an action that was virtuous (or at least virtue-forming for one individual) is now vicious for the same individual.



On the flip side consequentialism depending on what we are optimizing can be articulated in other terms as well. For instance, you could identify the the end as a teleology and make mean-seeking towards that end the implementation method.

From of all of this, I personally would say, yes, any theory can be represented as a form of consequentialism, but for the key competing views the results are going to be so pretzeled as to make that a highly inefficient way of describing the view.

Does that undermine Friedman's quote? I don't know, but I don't know if Friedman's quote is trying to claim that all ethical theories are consequentialist. If so, I'd say he's wrong. If instead what he's saying is that the ends don't justify the means is actually a different objection masquerading as a truism -- then yes, I'd agree to that. 

E.g., 

 A: this plan saves the most people on the planet. We just need to bomb every orphanage.
 B: "the ends don't justify the means"


vs.

 A: this plan saves the most people on the planet. We just need to bomb every orphanage.
 B: Murdering orphans is wrong enough that it doesn't matter whether this saves more people than other plans.


Version 1 just hides the objection; version 2 states it. And as we carve out more and more specific modifications to the values we use for our equation, adding asymptotes etc., it becomes no more efficient or useful to think in utilitarian terms than to think in the terms more natural to the other theories.
Your interpretation is a bit wide of the mark.  Inanimate things do not appear to work under purely deterministic principles, at least at the quantum level.

The accepted version of Everett's (https://en.wikipedia.org/wiki/Hugh_Everett_III https://en.wikipedia.org/wiki/Hugh_Everett_III) view in "Many Worlds" as a model is that every particle constitutes an observer.  But the more particles are involved, the more the mass will behave like a macroscopic measurer.

If one particle bounces off of another, the effect is determined by the interaction of the two particles as waves, so it is just as uncertain as our human observation via an instrument would be.

But we do not observe one particle as it bounces off one other, we see objects with significant mass collide.

We don't see uncertainty because two more uncertain things together are more certain than each uncertain thing separately.  Simultaneous probabilities do not add, they multiply.

The uncertainties for each particle involved in a macroscopic physical event all multiply, and since all of them are probability distributions with values less than one, the result quickly gets very close to zero uncertainty in the resulting outcome.

In other words, as far as "Many Worlds" goes we are not special because we think, we are just special because we're big and we stick together.

The worlds that accommodate our macroscopic experiences are more likely as "pasts" for future events. All the highly unlikely worlds in between also exist, but they readily merge into more likely timelines as irrelevant deviations.
There is an extra premise for this argument to become an argument against change. Judging by how Parmenides and Zeno generally argued it might be something like this: since the present is fleeting and words do have meanings time and change must be illusions, and only the unchangeable meanings truly exist. This would also be an argument for Plato's immutable Ideas. Quine, Davidson, Wittgenstein, and other supporters of "meaning is use" deny this premise, they deny that meanings are entities, let alone ideal entities in the sense of Parmenides and Plato, see https://philosophy.stackexchange.com/questions/33865/do-wittgenstein-and-quine-give-the-same-criticisms-of-semantics/33872#33872 Do Wittgenstein and Quine give the same criticisms of semantics?

Quine specifically avoids dealing with meanings altogether, he considers them a hopelessly obscure notion. In Word and Object he rephrases the problem of meaning as the problem of translation: we understand what others "mean" when we can produce a translation manual that results in actions mutually accepted as accomplishing set goals, see more in https://philosophy.stackexchange.com/questions/29117/what-is-quines-rebuttal-to-grice-and-strawsons-in-defense-of-dogma/29122#29122 What is Quine's rebuttal to Grice and Strawson's In Defense of Dogma? Word and Object discusses the "indeterminacy of translation", Quine argues that translation manuals would serve communication purposes just as well whether "rabbit" refers to the whole rabbit, or to "undetached rabbit part". Not only is "meaning" obscure, but reference is also "inscrutable". As he later quipped in a reply to Parsons:


  "In psychology one may or may not be a behaviorist, but in linguistics one has no choice. Each of us learns his language by observing other people's verbal behavior and having his own faltering behavior observed and reinforced or corrected by others. We depend strictly on overt behavior in observable situations." 


So yes, to Quine "George Washington" is a cipher for contexts in which the name is used "today", and so is the rest of the language. It ultimately reduces to coordinating actions and interactions. 

This would make everything we talk about "illusory" by Parmenides's lights, but his conclusion that something absolute must "truly" exist over and above it does not follow. Quine's criterion of existence is pragmatic: we accept existence of an object if it is "indispensable" in our governing conceptual scheme, everyday or scientific. So to him not only George Washington, but also atoms, electrons, and even natural numbers and time, exist. None of it is unchangeable however, times change, and conceptual schemes change with them. Quine's ontological positions are discussed more under  https://philosophy.stackexchange.com/questions/34144/does-quines-dissolution-of-the-analytic-synthetic-distinction-challenge-mathema/34155#34155 Does Quine's dissolution of the Analytic/Synthetic distinction challenge mathematical realism?
http://philpapers.org/ http://philpapers.org/
"PhilPapers is a comprehensive index and bibliography of philosophy maintained by the community of philosophers. Using advanced trawling techniques and large scale crowdsourcing, we monitor all sources of research content in philosophy, including journals, books, open access archives, and personal pages maintained by academics. We also host the largest open access archive in philosophy. "
Short answer: The passage you're thinking of occurs at the beginning of §52. Here's Stambaugh's version:


  The explication of everyday being-toward-death stayed with the idle talk of the they: one also dies sometime, but for the time being not yet. (p. 236)


Longer niceties: You're right to highlight the evasion in the "everyone." In §51, Heidegger address this more or less head on, where he deals with the similar idea: "One also dies at the end, but for now one is not involved."


  The public interpretation of Da-sein says that "one dies" because in this way everybody can convince him/herself that in no case is it I myself, for this one is no one. (p. 234)


This mode of evasion he characterises as a "tranquillisation" (Beruhigung), a way of avoiding death even up to the end. However, while its important for Heidegger's initial characterisation of the everyday attitude towards death as a way of avoiding death, it's not the main evasion (and this will bring us closer to what to do with "I will die").

Returning to §52, Heidegger notes that:


  In the "also sometime, but for the time being not yet," everydayness acknowledges something like a certainty of death. (p.236)


In short, just affirming "I will die" can simply be yet another way of avoiding taking death seriously. After all, this "I" needn't be me. It could be understood as just another appearance of the "one" (das Man), and so he adds:


  They say that death is certain, and thus entrench in Da-sein the illusion that it is itself certain of its own death. (p.237)


It's also worth noting that "I will die" again sounds like it has a temporal displacement: "I will die, someday, but not yet". What's important is how this is held:


  Thus the they covers over what is peculiar to die certainty of death, that it is possible in every moment. Together with the certainty of death goes the indefiniteness of its when. (p. 238)


What's at stake in this isn't just something in the imagination; it isn't even really about death per se; its something in one's attitude towards life itself. Authentic being-towards-death "brings [Dasein] face to face with the possibility to be itself" (p. 245). It's this encounter---with the possibility of being itself that ultimately characterises authentic being-towards-death.
A capitalist society is based on the systemic exchange of commodities. In this system, the application of labour to materials is itself a commodity; so workers are paid (a "wage") "for their labour". Otherwise they would be unable to buy commodities, and the system would not be based on systemic exchange of commodities.

But there must be some mistake in that. If I sell a ton of apples, this operation cannot create value, and will only transfer value if it is a lopsided purchase. If the apples are sold at their value, neither buyier nor seller will gain anything. Of course, in real practice, purchases are often made above or below the value of commodities; but this cannot be the rule, or the systemic exchange of commodities won't endure. Which means, as a whole, as a system, those deviations from value must cancel each others.

But how does it happen, then, that a profit is made in the apple trade?

That's because the producers of apples do not, in a capitalist society, sell apples. Instead, they sell their ability to work - what is called "labour power". But "labour power" is a different commodity from apples, and it has a different value. So there is a quid pro quo here: the company producing apples buys one commodity - the labour power of its workers (and it buys it, in normal conditions, at its full value) - but the end result of the operation is that it has now a stock, not of labour power, but of apples. If the value of apples is bigger than the value of the labour power implied in their production, then you have a systemic transfer of value - from workers to employers - that does not violate the conditions for a sustained system of commodity production.

(As it is easy to realise, if the value of the labour power implied in the production of a commodity is not smaller than the value of that commodity, then the production of that given commodity is impossible under capitalist conditions, or, in other words, if it is produced, it must be produced as a non-commodity.)

Evidently, all this is possible because labour creates value; in labouring, human beings create more than they expend.

But that is what Marx and Marxists call "wage slavery": the systemic transfer of value, from workers to employers, that keeps workers' economic earnings always close to the socially acceptable subsistence minimum.
There's two features in Marxism (here I'm working from its Hegelian background primarily as I think these problems transfer) that conspire to enable the objection that it is anti-individual:

First, following Hegel, the Marxist picture is such that the whole is the real. In the Hegelian picture, this whole is "spiritual" but in the marxist version it's somehow merely a material whole. Consequently, the individual is not of prime importance as in views like existentialism. Instead, the individual is a part of something larger.

This by itself does not eliminate the place for the individual. But it conspires with a further feature to do so. On this sort of picture, there's a sense of how the individual should then relate to and be a part of said social whole. One specific place this comes up is in the idea of what thinking is to be used for.

On the Hegelian version, the way in which the individual should think is necessitated by the structure of thinking. Hegel specifically excludes revelations and geniuses from his idea of how we should think. In other words, every being gets a part to play in the inevitable unfolding of "progress" in the Concept whether as a thinking bit or a material bit. This happens dialectically so that each element is to be accepted in all of its difference. The rub being that on this picture you cannot choose not to advance.

Thus, for instance, if as Hegel claims Christianity is superior to Judaism, then making the individual choice to follow Jewish religion (all his terms here -- not me), then you're just plain wrong. Similarly, if your form of Christianity involves personal faith, it's also wrong for Hegel. In other words, progress, freedom, and thinking, but all have a predetermined course. (See Charles Taylor, Hegel (Cambridge 1977), p. 185 and Phenomenology of Spirit 415)

My sense is that Marx gets rid of the thinking bits (as a Hegel scholar I don't really know how this part works) but winds up with a similarly deterministic (and thus anti-individual) account of thought and progress. For instance, you're not allowed to decide that you don't mind being alienated from your labor; that just has the role of sin in previous views of being something you are bound to be if you don't properly relate to your work.



For Hegel, this would not be anti-individual or anti-freedom, but this reply to the objection hinges on some fancy footwork. If Hegel is right about the nature of consciousness and thought and then metaphysics, then it follows that freedom is the self using reason to pursue the goals of reason. And the goals of reason are deterministically knowable. In other words, Hegel is pro-individual and pro-freedom if it is the case that the Concept determines what the individual should do and has them pursue it.

But this is a very unsatisfying reply if you're committed to a more robust concept of individual or freedom. Or to put it another way, if you believe in a freedom as incompatibilism such that actions are free when the individual can choose their actions or their action-shaping preferences without regard for a unified idea of progress, then this is unconvincing.

To make it a bit more practical, for Hegel, you should contribute to society, and society will have certain ideals and values. To pick a near contemporary example, for a while the laws regarding gay marriage varied by state. If it was necessary that gay marriage be allowed, then states restricting it could not be allowed. Since it's become legal in all states, we've also seen periodic clashes that take it further -- should individuals be required to acknowledge or participate in the gay marriages of others? If there's a unified idea of progress and something is part of it, then on the Hegelian picture, there's no right of conscience to refuse to accept it or participate in it. 

Hegel doesn't find this problematic precisely because society trumps the isolated individual but incorporates the individual qua living, reasoning bit of the whole. If what we want is individuals who are free to be separate, then Hegel opposes this as an illusion (an immediacy and unmediated state).
There is an external world and there is us. Our illusions do not change external world but can change our own state of mind and thus our attitude, behaviour, and responses to situation. Now, if illusion produces a result that makes us more adaptable to our surroundings, then it might be considered to be desirable (pragmatically).
A very good and often used example is that if you have fear of speaking in front of large crowds then you must imagine that the room is empty. This lowers your anxiety and thus helps you speak better because your own anxiety was making you less adaptable to the situation (where best thing for you would obviously be to speak). 
Some would say that this is not exactly going against reality but actually diminishing an irrational and unreal fear by thinking of contrast. Here, I am reminded of Victor Frankl's book, "Man's Search For Meaning". In the second part "Logotherapy in a Nutshell", he talks about antcipatory anxiety. It is according to him counterable by paradoxical intention. It is not exactly creating an illusion though.

The point is in order to remove a fear, best thing would be not to think it. Thinking about it makes you aware of it even more and that causes a viscious cycle of action and reaction (a sort of system with a positive feedback greater than unity) that results in hyper-sensitisation to the problem and thus more severe symptoms. That would require either understanding its extent and not over-reacting or ignoring or thinking of something else, or thinking the event to be something else. Sometimes, the last option is most easy and immediate. However, the illusion may actually cause more problems. Thinking that there is no one in room, you may blurt out something that the audience may not like or is improper, hence ruining everything.

Because our reactions to the world may not always be in a way that best ensure our interests (because of mental factors and the fact that we can think) and the very fact that what is does not mean what ought to be, sometimes it is better pragmatically to artificially produce those responses, by changing the mental factors, that are best according to our needs and interests. Determination of that requires extensive understanding in itself. However, if it is possible then it is an option.

However, if you specifically want to aks why people choose an illusion over reality and not whether and when they should choose it, well that is question related mostly to psychology and not philosophy. Illusions appear real. You have to work to see through them, What would be an incentive for a person to do something which would take away from him what is making him happy? And even if there is some, some people might ignore it if it is not clearly visible to them. It is not surprising that some people refuse to work (apply extra thinking) to make themselves unhappy (or so they feel).
The Italian words could be "L'essere del nulla" or simply "il nulla". The etymology must be the same as of the English word, that is, from the Latin https://en.wiktionary.org/wiki/nullus#Latin nullus meaning literally (ne) "not" + (ūllus) "any".

I do not know an exact Greek tradition that investigated nothingness and influenced Leonardo but I know that his environment could sometimes be described as neo-Platonic. On that trail and according to it the property is described to contain the things which it describes i.e. nothingness contains the things that do not exist.

Intuitively we describe things that are (beings) as our sensory perceptions. That is nature, everything we see and feel comes from nature and returns to it. Everything we see is also in the present, thus we know that nature is certainly in the present. We do not see things that are not. But we know things can stop being. By our past experiences we know that things we knew of are not there any more, the present, in which we make this observation and is the future of our past. By deduction we can say that things will change in the future to the point of not being as they have changed with the passing of time. Thus things that are not are found only in time and words because because of time we know that things are not and with words we can refer to them while we cannot directly experience them.


  Nothingness holds the highest position and its grasp extends to
  things with no being


Because things that are not are more numerous and descriptive of being than the things we immediately see. While I am not well read in regards to Greek Idealism it seems that this definition extends the typical of what a form is as the essence of an object. In the idealist sense I understand the form to be a prototype object that every true object of this kind exist in reference to. Leonardo here uses a definition that is modern and mathematical in essence. An important dimension of mathematical work consists of identifying an object under question and abstracting it as much as possible in a way that the mathematical object could describe anything of that type. I.e. 2πr and 2π*r(squared) describe the geometric properties of any circle, not a specific circle, every cirlce. A circle with r = 5 meters we might have in front of us is not the essence of the circle because it is not every circle, but just one. The essence of the circle extends to the non-being circles that every existed and will exist. That is as with the being of humans, animals and trees. More will have existed and will exist than in our present and even more are their possibilities that will never exist but still would be described as human, animal and tree. In this sense the study of http://mathworld.wolfram.com/Topology.html topology in mathematics is relevant, but only to a certain extend, because several geometric specific properties are included. Thus we can say that being and nothingness constitutes everything and there is a mathematical intuition for that.
From a few different directions, there have been attempts to decouple value from behavior in recent religious or political philosophies.

Such moves are often motivated by feminism or other kinds of inclusiveness, as they restore the value of being itself, or the inherent value in being valued.  So they are often initially motivated by the inequality of the valuations of being vs doing.


the Ethics of Care attributes value both to the carer and to the one cared for in a bond between two people.  Caring is not entirely, or even primarily a result of the carer's behavior.  It is also an aspect of our ability to allow relationships and the bonds out of which they are made to continue and to provide value for others' actions.  Otherwise, the behavior of carers in caring loses its inherent natural logic and must be recast in the form of some other system of reward or self-judgement.
the New Age notion of chosen destiny has a similar notion of the value of others as opportunities for resolution, growth, competition, etc.  It is not your destiny that provides value, but the way it interlocks with others'.  It is the "Non-Player Characters" in our lives that are the actual source of our own leverage for improvement. And they are not more valuable by being ethical, but by being appropriately cast.
From a more general pacifist/feminist point of view, men have traditionally attributed to women, more than themselves, some quasi-magical sense of greater inherent personal worth which is too easily then removed, manipulated or denied, in ways that disempower women individually and as a group, while devaluing men by reducing them to their products.  Most measures of human value declare this 'love we owe' in some way beyond comparison: human value is infinite, equal in everyone, an epiphenomenon of the value of the one doing the valuing, completely subjective, etc...  But that is a false equivalence declaring something unequally distributed to be equal, at the cost of those to whom we assign value through the real thing whose value is being obscured.  (So we can somehow love our enemies as much as our families, because we are ordered to, and still shoot them.)

This is a complex point that Kant makes in the Religion within the bounds of reason alone text, but the answer in that text is that for Kant once we have made a choice for evil, we can become incapable of later choosing for the good. People who have only read the Groundwork of the Metaphysics of Morals might be shocked by this as it seems to go against the idea at work there.

In part this is Kant's attempt to deal with disposition and habit. Habit is a topic he also worked on in the Metaphysics of Morals (not the Groundwork). 

Looking just at the Groundwork, Kant seems to believe we are radically free as in we are rational and then able to act freely on our rationality. To do so is to make the maxim of our action correspond to the categorical imperative in its universality, treatment of humanity, and community of rational ends (inter alia). On this picture, we are not radically good or radically evil as nothing outside the will can affect the will. (This is a very Cartesian picture of the moral self -- and one that some sympathetic Kant interpreters (fan-fiction writers?) reject as being in the Groundwork). 

Here, a major distinction is the third antinomy between the determination of the physical (phenomenal) world and the need for freedom and spontaneity for morality to possible and as a feature of our experience of ourselves.

Critique of Practical Reason presents a similar picture but a different argument for how we are capable of morally free choices. (The argument in the Groundwork is section III, a part where Kant tries to prove you can get moral freedom from the nature of freedom and rationality directly).

The rub is that it seems kind of clear that the choice to be moral is not equally accessible to everyone. Kant is well aware of this in his lectures on ethics (well before and continuing through to the Groundwork), his lectures and writing on Anthropology, his Metaphysics of Morals, and his Religion.

The Religion text tries to explain (a) what makes us do wrong, (b) how we can biased for or away being able to make moral choices, and (c) the role of God in the Kingdom of Ends (hint: God doesn't not provide moral laws to us except as a representative for the weak of moral reasoning). The first two questions are primarily dealt with in the beginning of the text.

The basic answer is that as animals we have three basic predispositions: (a) animality, (b) personality, and (c) humanity. The meanings of the last two terms is not as they might seem. Personality means that we are social. Humanity here is a synonym for rationality. As such, the predisposition to humanity is a predisposition to moral goodness. 

Working against this, however, is that we have a Hang (propensity) to evil. The problem is that once we've given into this propensity, we become evil and the choice for good becomes more difficult, because our reasoning is no longer on a blank slate. Here, Kant distinguishes Wille and Willkur with the Wille remaining fundamentally free and able to make any choice (as on the Cartesian picture) but the Willkur being affected by the choices we have made and limiting the maxims presented to the self.

Kant claims that all of us have made the choice for radical evil. He uses in part in an empirical argument and in part points out the degree to which our predispositions can be manipulated to evil. (To get you more of the details I need to be in my office with my copy of Religion or open up some old papers).

This picture probably seems unconvincing to many readers today. To the astute reader, this picture should sound familiar. Basically, Kant has transposed the Lutheran account of moral responsibility and original sin (in this case original to all in that each sins) into his moral system.

Now, we can finally answer your question: for Kant, without God, people who are depraved cannot make the change for the better because the restriction of the will is not something they can overcome (since it affects their wills).
Each of the input lines represents a different proposition. This should be intuitive because different lines are independent of each other, just as different atomic propositions are. So what you originally wrote would be p v ~q. To get p v ~p you have the use the same line (the same p) twice.
Simply put, the speaker begs the question. Their argument seems to be structured like this:


  
  The propositional content of the two characters' knowledge can be exhaustively expressed by "Bill has been treed by a moose"
  The two characters respond differently to their equivalent propositional knowledge.
  Therefore there is such a thing as non-propositional "self-knowledge" e.g. "I am Bill"
  


The problem, of course, is that "I am Bill" is a proposition (and, in http://semanticsarchive.net/Archive/DFkMzlkZ/NinanCompass.pdf the related literature I mentioned in my comment, is treated as such), and should have been included up in premise 1. Why is it not? The speaker glosses over that completely and takes it for granted, then seems to pull some sort of sleight of hand, arguing (vaguely) "because these two people responded differently to the same propositional knowledge, they must have some non-propositional knowledge. Here it is!" That itself begs another question: why must two people have non-propositional knowledge, if they act differently in response to propositional knowledge? They may have different temperaments, beliefs, et cetera. 

My answer to your title question is thus that "I am Bill" is a proposition - one which indicates that two senses ("I" and "Bill") point to the same referent (the individual named Bill). The transcript you've linked simply asserts that it's not a proposition, without arguing for that position.
To answer this, its helpful to have some background on Whitehead's understanding of rationalism. In Process and Reality (42) Whitehead defines rationalism as the hope that we can create a general theory, such that everything we find in experience can be held up as an example of that theory.  He calls it a "hope" since Whitehead argues there will always be unknowable unknowns that prevent us from completing such a theory. Rationalists are those who nevertheless hold onto this hope, as an "ideal which is seeking satisfaction". In this respect, for Whitehead rationalism is a tipping point where science/philosophy crosses over into religion. It always falls short of being a religion because it remains an ideal, beyond reach, rather than a premise upon which a religious dogma can be formed. According to Whitehead, the Enlightenment is an epoch when this ideal thrived. 

Whitehead argues that modern science is anti-rationalist because it has given up this ideal and become self-content and professionalised - he asserts that science increasingly is a faith that is built on weak, enfeebled, superficial or arbitrary starting points and premises. It relies on technicians who blindly following habit, using technical instruments instead of imaginative thinking, mistaking abstractions for concrete reality, and accepting contradictions as good enough. 

His books go into this in more detail, drawing out the kinds of paradoxes and contradictions that underly scientific enterprises. For example, he offers this retorsive argument: scientists make experiments in which they rely on final causation (for instance, taking photographs in order to study features of the environment) but then propose models in which there is only efficient causation - without attempting to reconcile the contradiction between what they are doing and saying. Whitehead argues this willingness to ignore the paradoxes of science is anti-rationalist, since it leads science into ruts and blind alleys, instead of encouraging scientists to explore the problem space more widely and imaginatively.  

In response to Cort Ammon's statement:


  Whitehead's argument is that science as a whole is simply not 
  interested in "justifying its faith or to explain its meanings."
  
  Given this trend is quite strong today, and Whitehead was an author on a 
  then undisputed mathematical approach to proving all true statements in 
  mathematics, it's no surprise that he would happily use such strong words. 
  It's not until Gödel showed that not only did PM not accomplish its goals 
  but also that no such document could ever accomplish 
  them that Whitehead's bubble was popped.


I disagree. Whitehead worked on PM for over ten years with Russell, publishing in 1910, 12 and 13, and then abandoned the project. PM's logicism was therefore unproven and incomplete. It was never 'undisputed'. 

It is also false to infer Whitehead was "happily using such strong words" until his "bubble was popped" by Gödel. Gödel's publication was in 1931. Russell and Whitehead worked on PM twenty years earlier, and Whitehead had long since moved onto other projects. Whitehead indirectly acknowledges Gödel’s proof in 1938, writing: "Today, even Logic itself is struggling with the discovery embodied in a formal proof, that every finite set of premises must indicate notions which are excluded from its direct purview." (MT 2). Whitehead immediately adds that philosophy "should never start from systematization." He credits this to William James, whose "intellectual life was one protest against the dismissal of experience in the interest of system. He had discovered intuitively the great truth with which modern logic is now wrestling." (MT 3). I believe that, doing PM, Whitehead already intuited this great truth - the shortcomings of logical formalism. Reading Whitehead's Process and Reality (1929) confirms this. E.g. Whitehead writes that systems "do not exhibit mere illogicalities. They suffer from inadequacy and incoherence" (6) - For Whitehead, Gödel's proof was redundant... but nice to have. 

PS. For those interested in Whitehead, Thinking with Whitehead, by Isabelle Stengers is a great read. 
Consider splitting a set in two based, one subset of which the elements satisfy the predicate, and one subset of which the elements don't satisfy the predicate. If the predicate is stronger, the Yes-set will be smaller ("the stronger the restriction, the narrower the class"). Therefore, the No-set will be bigger. And since it works both ways, this means that the negation of the predicate is now weaker.

This does not only work for predicates that become stronger or weaker. If we have a strong predicate, that means the Yes-set is small. Since the No-set is the complement of the Yes-set, it has to be big, and therefore the negation of the original predicate (that is, the predicate of the No-set) has to be weak.



The same, mathematically.

Suppose we have a set X and a predicate P. Then Y = {x ∈ X ∣ P x} and N = {x ∈ X | ¬P x} partition X, that is, Y ∪ N = X and Y ∩ N = ∅.

Since "the stronger the restriction, the narrower the class", Y will be smaller when P is stronger. And since N = X ∖ Y, this means that N will be greater, therefore, ¬P will be weaker. A similar argument can be made when P gets weaker: Y will be greater, so N smaller, therefore, ¬P will be stronger.
Let's say you and I engage in a voluntary trade where you give me A and I give you B in return.

Moral "problem"

A moral problem only arises out of the false assumption that the traded items have some objectively assignable values, like $10 or $20. Then if A has less value assigned to it than B then I lose and you win, and vice versa.

Problem solved: values are subjective and "opposites attract"

The problem vanishes when it is recognized that in a voluntary trade each party values what they receive higher than what they give up. In the above trade, I ranked A higher than B, while simultaneously you ranked B higher than A. We ranked them exactly opposite of each other, which is why we traded in the first place. Every voluntary trade arises out of such opposite rankings by the two sides of the trade.

The "marginal revolution"

Why do different people rank things differently? Part of it is personal preference and taste, but a very important aspect is how many units of something they already possess. The more of something I have, the less subjective value I place on an additional "marginal" unit of that thing. Because people have different amounts of things (goods, money, time, skills, friends, etc.) their rankings differ from each other, which causes them to trade those things amongst each other.

When "Have horse, want cows" met "Have cows, want horse"

Example: I have 20 cows and no horses, you have 5 horses and no cows. We agree to trade one of my horses for two of your cows. Why? Because I subjectively value getting my first two cows higher than keeping my "marginal" fifth horse, while you subjectively value getting your first horse higher than keeping your "marginal" 19th and 20th cows. So we trade and are both subjectively better off than before.

Entrepreneurs and profits

The same reasoning can be applied to entrepreneurs trading things they have (ingenuity, money raising ability, connections, demand forecasting skills, people skills, etc.) to get things that they want (money, prestige, etc.) On the other side of the trade you have customers who trade the things they have (money) for things they want (gadgets/services provided by entrepreneurs). In the trade, the two sides rank things opposite each other, e.g. the entrepreneur ranks $100 higher than the gadget he is selling, while the buyer ranks the gadget higher than the $100 he is spending. A win-win trade is born.

But profits are not forever

If the entrepreneur is making lots of profit, say 50% on each gadget, other entrepreneurs come in to offer competing products, and more competition means more supply which results in falling prices and narrowing profits. So the entrepreneur's initial high profits are a limited time reward for offering something that is so in demand that customers are willing to pay good money for it. The higher the profits, the faster other entrepreneurs jump in and reduce the margins. This is how the market rewards innovation but once innovated drives down prices so that consumers keep getting new things that keep getting cheaper.

I had fun writing this and hope some folks like reading it. Cheers!
Russell's theory of definite descriptions is primarily concerned with denoting phrases (e.g. "the present king of France"), which are linguistic expressions that purport to refer to some object. The definite article in English is just one type of linguistic device that creates denoting phrases, but it is not essential to the theory. I don't know much Russian but I'm sure it has ways of forming denoting phrases (even if it's only determined from context).

The problem that Russell saw with denoting phrases is that if you assume that every denoting phrase must refer to some existing entity, then you get a weird ontology in which pretty much everything that can be talked about exists. This problem does not seem to be language-specific.

Russell's solution is to construe denoting phrases as existential claims. E.g. "the present king of France is bald" should be understood as "there is a thing such that it is a king of France and it is the only such thing and it is bald". In the latter phrase there is no direct reference to any object, and so the question of whether some nonexistent object exists in some sense does not arise; the sentence is simply false, since it says that there is something while actually there isn't.
I don't know philosophers who've argued that democracy is inherently flawed, and I think such an argument would be naive (given the right population with a right culture, democracy might be good), but https://philosophy.sas.upenn.edu/bio/guerrero Alexander Guerrero is spearheading a sophisticated proposal he calls lottocracy (see https://en.wikipedia.org/wiki/Sortition sortition). 

You can read his own popular summary https://aeon.co/essays/forget-voting-it-s-time-to-start-choosing-our-leaders-by-lottery here, while a paper on the topic is behind a paywall http://onlinelibrary.wiley.com.proxy.library.cornell.edu/doi/10.1111/papa.12029/pdf here. His argument is that democracy, given certain contingent facts (which he argues are true in the United States), is flawed and should be replaced by a lottocracy wherein people are assigned political positions based on chance, and are educated on their jobs by specialists in a period leading up to their term of service.

The contingent facts in question are straightforward and include: that people are by and large ignorant of much of the relevant political issues; that elected officials cannot easily be held accountable for how well they've represented the interests of the public; that elected officials often lack the qualifications to perform their duties effectively; and so on.

Guerrero argues that his lottocratic system, given the above conditions, can do a better job. It is maximally egalitarian, in that leaders are chosen completely by chance. It solves the problem of ignorance, since those chosen are educated by experts, and the remaining ignorant masses can trust that the people in charge know what they're due. It renders the question of accountability irrelevant, since there is no electoral process, and in the same way it solves the problem of pandering.

It's important to note that Guerrero is reluctant to recommend applying the lottocracy to other nations. I first became familiar with his theory in a talk he gave, and he mentioned being terrified that members of foreign governments had contacted him to ask about implementation - he deems it crucial that the contingent conditions be met, and he disclaims sufficient knowledge of, say, assorted Middle Eastern politics to say whether those conditions in fact hold. If they don't hold, then another system, including democracy, might be more ideal.

So while this philosopher doesn't consider democracy "inherently" flawed, he does discuss its flaws pretty seriously.
This is more a series of comments than an answer.

First, don't get distracted too much by Durant's small list. For example: yes, "essence" appears in Id1 (cf. http://plato.stanford.edu/entries/spinoza/#GodNatu SEP on referring to the Ethics). In http://www.thelatinlibrary.com/spinoza.ethica1.html Latin, he writes:


  Per causam sui intelligo id cujus essentia involvit existentiam sive id cujus natura non potest concipi nisi existens.
  
  By self-caused, I understand that whose essence involves existence or that whose nature cannot be conceived except as existing (My translation)


It's hard to imagine that there's an extant English translation that renders "essentia" as anything other than "essence."

Id4 is similar:


  Per attributum intelligo id quod intellectus de substantia percipit tanquam ejusdem essentiam constituens.
  
  By attribute I understand that which the intellect perceives of substance as constituting its essence.


When Durant says "he uses the term substance where we should write reality or essence", he isn't claiming that the words "essence" or "reality" don't exist for Spinoza—both essentia and realitas are technical terms in Scholastic Latin—what he means is that where Spinoza has written 'substance' (substantia) he uses it in a way that is closer to how we use "reality" or "essence" rather than how we use "substance". Thus, for example, when he writes (in Ip14) that "besides God no substance can be granted or conceived" (Elwes translation), it's fairly obvious that "substance" here means something other than what we normally take it too. Similarly, when Spinoza defines "substance" in 1d3:


  "By substance, I mean that which is in itself, and is conceived through itself: in other words, that of which a conception can be formed independently of any other conception." (Elwes translation)


This sounds very little like how we tend to speak of "substance". Among other things, why does "conception" enter into this definition of "substance"? Of course, whether it in any obvious sense sounds like "reality" or even "essence" can only be seen by following how Spinoza uses "substance" within the Ethics. And here we come to what is actually Durant's point, which he states pretty clearly in the paragraph after the one you quoted:


  Spinoza is not to be read, he is to be studied;... in these brief two hundred pages a man has written down his lifetime's thought with stoic sculptury of everything superfluous.... You will not understand any important section thoroughly till you have read and pondered the whole (p. 186–187)


The point isn't that Spinoza's language is outmoded or that his Scholastic terminology distorts what he's trying to say. Its that Spinoza's writing-style in the Ethics makes virtually ever term he uses imbued with odd meanings and it would sound just as odd had he written it in Dutch or even English.
Think of ∀xP(x) as an implicit conditional: ∀x(xϵU → P(x)), where U is the universe. In an empty universe the antecedent is always false, hence the conditional is vacuously true. In contrast, ∃xP(x) is an implicit conjunction ∃x(xϵU ∧ P(x)), so it is vacuously false. This is in line with the standard way of transcribing "all humans are liars" with a conditional, but "some humans are liars" with a conjunction (here all humans form the universe of discourse), and the closest predicate calculus can approximate  intuition, see https://math.stackexchange.com/questions/1487910/why-cant-we-use-implication-for-the-existential-quantifier Why can't we use implication for the existential quantifier? 

If we wish to drop the universes from notation, but to end up with the same truth values for the empty universe, we are forced to adopt the universal-statements-are-true convention. The same is needed for uniformity of notation with http://hume.ucdavis.edu/mattey/phi112/transcribe1_ho.pdf restricted quantifiers in mathematics, like ∀x>0 P(x), which by convention is interpreted as ∀x(x>0 → P(x)). The intuitive qualms about this convention are of the same nature as those about the material conditional being vacuously true for false antecedents, so this is not a quantifier specific issue, see https://philosophy.stackexchange.com/questions/34082/why-are-conditionals-with-false-antecedents-considered-true/34084#34084 Why are conditionals with false antecedents considered true? 
Attributes, for Aristotle, scholastics, Descartes, and Spinoza alike, are the non-accidental qualities/properties expressed in language by predicates, as substances are expressed in it by subjects, to which they are predicated. Taken together, they make a substance what it is, hence they are essential (unlike accidental properties), constitute its essence. Substances that do not share attributes have nothing in common, and the more attributes they have the more "real" (concrete) they are. God, as the ultimate reality, is the "substance of infinite attributes", but according to Spinoza "the human mind has an adequate knowledge of the eternal and infinite essence of God". Here are some examples from http://www.sacred-texts.com/phi/spinoza/ethics/eth02.htm Part II of Ethics:


  PROP. I. Thought is an attribute of God, or God is a thinking thing.
  
  PROP. II. Extension is an attribute of God, or God is an extended thing.


A somewhat more idiosyncratic use of "attribute" by Spinoza corresponds to what we would call "aspect" or "perspective", in which a substance is unfolded or under which it is considered. In particular, God and Nature are the same substance considered under different attributes (which is perhaps why we have an adequate knowledge of it). Here are some examples, again from Part II:


  PROP. V. The actual being of ideas owns God as its cause, only in so far as he is considered as a thinking thing, not in so far as he is unfolded in any other attribute...
  
  Note to PROP. VII. For instance, a circle existing in nature, and the idea of a circle existing, which is also in God, are one and the same thing displayed through different attributes. Thus, whether we conceive nature under the attribute of extension, or under the attribute of thought, or under any other attribute, we shall find the same order, or one and the same chain of causes - that is, the same things following in either case. Thus, whether we conceive nature under the attribute of extension, or under the attribute of thought, or under any other attribute, we shall find the same order, or one and the same chain of causes - that is, the same things following in either case.


Several aspects of interpreting Spinoza's theory of attributes are controversial. For instance, he ultimately concludes, in contradistinction to all his predecessors, that there is but one substance, God=nature, and despite mentioning its infinite attributes names only two of them in Ethics, thought and extension. In the early https://archive.org/stream/spinozasshorttre00spinuoft/spinozasshorttre00spinuoft_djvu.txt Short Treatise those are the only two through which God can be known, and omnipotence, eternity, immutability, and infinity are termed "propria", because "they are only Adjectives, which cannot be understood without their Substantives. That is to say, without them God would indeed be no God, but still it is not they that constitute God ; for they reveal nothing of the character of a Substance, through which alone God exists". In Ethics the "propria" disappear altogether, but eternity appears in the oft-mentioned https://en.wikipedia.org/wiki/Sub_specie_aeternitatis sub specie aeternitatis,  "under the species of eternity", in a sense similar to "under the attribute":


  Corollary II to PROP. XLIV. It is in the nature of reason to perceive things under a certain form of eternity (sub quâdam æternitatis specie).


SEP has a nice article on http://plato.stanford.edu/entries/spinoza-attributes/#IdeAttSub Spinoza's Theory of Attributes.
The negation of "there are at least two..." is "there is at most one..." i.e. either "there is no..." or "there is one and only one...". Therefore


  ¬❷xPx ≡ (¬∃xPx) ∨ (∃!xPx)


where ∃! is the https://en.wikipedia.org/wiki/Uniqueness_quantification unique existential quantifier defined by


  ∃!xPx ≡ ∃*x(Px* ∧ ∀y(Py→y=x))


By definition


  ✌x¬Px ≡ ¬❷xPx


Hence (replacing Px by ¬Px)


  ✌xPx ≡ ¬❷x¬Px ≡ (¬∃x¬Px) ∨ (∃!x¬Px) ≡ (∀xPx) ) ∨ (∃!x¬Px)


so ✌xPx means "either all objects have property P, or else exactly one object does not have property P" – in other words, "at most one object does not have property P".
You write:


  Any statement can be interpreted to mean anything
  
  This is surely true in a strict sense


Hermeneutics is the science of interpretation of texts, which might be relevant; here, they start off with the proposition:


  Not every interpretation of a text is equally valid 


The question then is to determine which interpretations are valid, and why.
Unfortunately, we do not have a satisfactory theory of meaning (semantics) of natural languages, i.e. of understanding words, or even of using them (pragmatics). Kripke's causal theory of reference for proper names comes closest to a consensus, but only if it is narrowly restricted to proper names, and even then it is not too close. The alternative theory, that we pick out referents by definite descriptions, still has many supporters, and http://www.acsu.buffalo.edu/~jbeebe2/Beebe%20Undercoffer%20Individual%20and%20Crosscultural%20Differences%20in%20Semantic%20Intuitions.pdf recent experiments to test folk intuitions on this score were inconclusive. Moreover, the two theories have complementary problems, see http://tedsider.org/papers/revenge.pdf Kripke's Revenge by Sider:


  Over 100 years ago Frege (1952/1892) pointed out the problem with Millianism:
  sentences containing co-referential names seem semantically inequivalent... Within the propositionalist tradition, the natural alternative to Millianism
  is that the semantic content of a name is the same as that of an identifying
  definite description... But, new linguistic data suggested, knowledge of identifying descriptions is not required for linguistic competence. Moreover, definite descriptions do not fix the referents of names, nor do names behave like descriptions in the scope of modal operators. The data of Kripke et al. is genuinely puzzling. It in no way undermines the old Fregean arguments against Millianism; it simply is new, conflicting data. Thus, many recent theories seek reconciliation, accommodation of both Kripkean and Fregean data.


Kripke's and Putnam's attempts to extend the causal theory to natural kinds (like wood, red, bee, etc.) remain controversial, see e.g. https://www.jstor.org/stable/4321106 Ben-Yami's Semantics of Kind Terms, and even they did not attempt it for artificial kinds. Scientific units seem to involve aspects common to names, and both kinds.

With old units that predate modern science, like foot or meter, one can imagine some ancient baptism and chains of transmission that led to their adoption and spread before the French Convent ordered physical prototypes to be made. New units however, like joule or ampere, were exclusively specified by definite descriptions, and even with the old ones the Bureau of Weights and Measures consistently moved away from physical prototypes. The meter was not tied to the Paris prototype since 1927, so even Wittgenstein's discussion of it was already moot, let alone Kripke's, and http://www.us-metric.org/si-unit-definitions/#meter the current description adopted in 1983 is "the length of the path traveled by light in vacuum during a time interval of 1/299 792 458 of a second”. 

Definite descriptions allow for more uniformity and precision, and so are preferred in science in "official" capacity. But does it mean that in practice scientists measure distances traveled by light in vacuum when they need to use a meter? Surely not. They use imperfect prototypes produced using perhaps less imperfect prototypes, which may or may not ultimately link to the official standard (this is similar to causal chains but not connecting to a baptism). Casual speakers' connection to the official description is even more tenuous.

Propositional semantic theories, like Frege's or Kripke's, may be looking for theoretical unity where none is to be had. Linguistic practice is heterogenous, with multiple ways to pick up usage. Kids may learn to use "meter" in sentences correctly by mimicking and inferring, without bothering to know what it "looks" like. Another problem is that propositional theories seek to assign meaning and reference to expressions in isolation, whereas indications are that linguistic use is holistic, in addition to opportunistic and eclectic. The use of words is learned from how they combine with other words and/or used in pragmatic situations, not so much from their propositional meaning and/or reference. Some of this is addressed in http://www.iep.utm.edu/conc-rol/ inferential semantics.
One thing to always keep in mind: Nietzsche wrote in German. And referring to translations without double-checking (with the original language, if possible!) is always problematic.

The original lines read:


  Wer mit sich unzufrieden ist, ist fortwährend bereit, sich dafür zu rächen: wir Anderen werden seine Opfer sein, und sei es auch nur darin, dass wir immer seinen hässlichen Anblick zu ertragen haben. Denn der Anblick des Hässlichen macht schlecht und düster.


In the english translation, the first "ugly" is missing. And the main verb in the last sentence is missing in both languages. This is a poetical wording. I will fill in the missing words for fuller understanding:


  Whoever is dissatisfied with himself is continually prepared to avenge himself for this[:] and we others will be his victims if only by having to endure his [ugly] sight. For the sight of something ugly makes one [feel] bad and gloomy.


In the end, the last sentence is explanatory for the statement just before, i.e. why we will be victims if having to endure one's ugly (i.e. revengeful!) sight if he isn't able to 'attain satisfaction with himself'? Because it makes us  (feel) bad and gloomy.

The interpretations may vary, but as I take it, feeling bad and gloomy and becoming/being bad (in the sense of degenerated, mean) and gloomy is pretty much the same here.
A few lines down the paragraph Malcolm explains a key part of his objection by referencing Wittgenstein:"I believe  that Wittgenstein has shown in the Investigations that nothing is  intrinsically simple, but that whatever has the status of a simple, an indefinable, in one system of concepts, may have the status  of a complex thing, a definable thing, in another system of
concepts." On this view Malcolm wrote at length in his book on Wittgenstein, and http://faculty.fiu.edu/~hauptli/IntroductiontoWittgenstein'sPhilosophicalInvestigations.html Hauptli’s supplement to Philosophical Investigations quotes him as saying:


  "Paragraphs 47 through 49 present a tour de force in philosophical criticism.  What is attacked is the assumption of the Tractatus (and of much previous metaphysics) that the distinction between simple and complex has an absolute sense. In a variety of telling examples Wittgenstein shows very clearly that whether any particular thing is called a ‘simple’ thing or a ‘complex’ thing depends on accepted conventions, on decisions made for practical purposes, or on what comparisons are at issue".


There is some discussion of the simplicity objection in https://books.google.com/books?id=p8Z82g-sjaEC&pg=PA114&lpg=PA114&dq=leibniz+definition+of+perfection+malcolm&source=bl&ots=El_ieNjkfA&sig=6F2Md1bnrKfmEszb1z2fLxF1CYI&hl=en&sa=X&ved=0ahUKEwjJrJ3R3OfOAhWC7CYKHf_wCMYQ6AEITDAH#v=onepage&q=leibniz%20definition%20of%20perfection%20malcolm&f=false Adams's book on Leibniz, and https://www.jstor.org/stable/27901616 Scott in Scotus, Malcolm, and Anselm notes the following:


  "No doubt, Malcolm is taking demonstration in the sense of strict logical or  mathematical proof leading to certitude. All one can get, so Scotus claims, is a 'persuasive' or probable proof. In connection with this, if Malcolm is dissatisfied with Leibniz' definition of perfection, he might weigh Scotus' remark that the main aspect of viewing the nature of God is infinity, not the summum bonum of Anselm".


On Leibniz's perfection probably the most comprehensive source is Howe's thesis Existence as a Perfection: A Reconsideration of the Ontological Argument, which is referenced and discussed in http://philpapers.org/archive/SMIDOE.docx Smith's Doctrine of Existence as Perfection. More broadly, Leibniz's "modal" ontological argument and Malcolm's reconstruction of it are discussed in https://www.jstor.org/stable/27902177 Lomasky's Leibniz and the Modal Argument for God's Existence. Look discusses the concept in https://www.uky.edu/~look/essays/PPP.pdf Perfection, Power and the Passions in Spinoza and Leibniz, but not in relation to Malcolm's objections, he mentions that http://www.cambridge.org/us/academic/subjects/philosophy/history-philosophy/invention-autonomy-history-modern-moral-philosophy?format=PB Schneewind in The Invention of Autonomy,  gives a complementary discussion though.
I assume you use "weak omnipotence" for https://philosophy.stackexchange.com/a/29350 the fourth definition on the Wikipedia article, namely that a weakly omnipotent entity is one that can do anything that is logically possible. In that case I agree that it is not inconsistent that a weakly omnipotent entity can create another weakly omnipotent entity. But one must be careful; the definition of "weak omnipotence" must be based on global possibility. Having two weakly omnipotent entities is then possible because they are simultaneously constrained to be unable to together do something impossible, simply by definition. Thus one weakly omnipotent entity can make it so that there are two weakly omnipotent entities, again by definition.

That said, it is philosophically unsatisfying to have such a notion of weak omnipotence, when one also wishes to ascribe a conscious volition to a weakly omnipotent entity. How on earth can one such entity create another that has an independent conscious volition but yet with both constrained not to conflict? In other words, the issue lies not with weak omnipotence but in that we cannot have two entities that are both weakly omnipotent and have independent volition, unless you also affirm that the whole world (including all whatever omnipotent entities) is totally logically determined (so that there is only a single logical possibility). This does not imply that there cannot be one weakly omnipotent entity with volition in a world that is not totally logically determined, so it may be compatible with certain belief systems ascribing weak omnipotence to their respective God[s]. For example, it is not inconsistent to have two or more weakly omnipotent entities with a unique volition, though arguably that is essentially having a single being in the traditional sense, since they logically necessarily act as one.
As Price acknowledges in http://ndpr.nd.edu/news/46002-expressivism-pragmatism-and-representationalism Expressivism, Pragmatism and Representationalism, "expression" and "expressivism" are misnomers, simply used to label (multiple) alternatives to representationalism, "the assumption that the linguistic items in question 'stand for' or 'represent' something non-linguistic". This requires some sort of unmediated propositional access to said something, non-inferential cognitions through immediate sensations and/or intuitions. Descartes introduced the idea in modern times, and its criticism, along with the whole idea of "immediacy" in general, is usually traced back to Hegel. http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9191.2008.00317.x/abstract;jsessionid=BDFC8B81FF1AFEA2C1F99C699CC93195.f03t01?systemMessage=Wiley+Online+Library+will+be+unavailable+on+Saturday+3rd+September+2016+at+08.30+BST%2F+03%3A30+EDT%2F+15%3A30+SGT+for+5+hours+and+Sunday+4th+September+at+10%3A00+BST%2F+05%3A00+EST%2F+17%3A00+SGT+for+1+hour++for+essential+maintenance.+Apologies+for+the+inconvenience According to Miller, in Phenomenology of Spirit (§§90–110) Hegel argues that "any attempt to articulate, describe, or individuate the object of knowledge invariably makes use of either universals or contextually circumscribed indexicals (“this,” “here,” “now”) which necessarily require other items of knowledge, that is, they are epistemically mediated." 

In 19th century the argument was developed by Peirce, the founder of pragmatism, and through Lewis influenced Quine, Sellars and Davidson, possibly also Wittgenstein. On the continental side Hegel's argument was picked up by Heidegger, Merleau-Ponty and Adorno among others. Sellars elaborated it perhaps the most, and made its target famous under the name of the http://www.iep.utm.edu/sellars/#H3 Myth of the Given. He and Wittgenstein especially emphasized how the myth conflicts with holistic and social aspects of concept formation, and both, but especially Sellars, are Brandom's inspirations. 

The pragmatist alternative to the Myth usually takes the form of inferential semantics, an elaboration on "meaning is use". At this point, even prominent reprsentationalists, like Fodor and Lepore, acknowledge (very grudgingly and derisively) in http://ndpr.nd.edu/news/24555-reading-brandom-on-making-it-explicit Reading Brandom that "it’s hard not to be impressed by the extent to which Inferential Role Semantics is the consensus view, not just in philosophy but also in cognitive science... It must be nice to have so many people on your side, but you don’t win a war just by assembling an army; you also have to win a battle or two."

According to the argument, impressions are not of a kind with representations, so identifying them is a category error, and there is an explanatory gap as to how one transmorphs into the other. Moreover, a representationalist faces an unpleasant dilemma: either impressions (like pain, etc.) have to be learned, or representations (e.g. concepts) have to be innate, for the two to "fuse" in perception. 

Here is http://www.peirce.org/writings/p27.html Peirce from Four Incapacities (1868):


  Every thought, however artificial and complex, is, so far as it is immediately present, a mere sensation without parts, and therefore, in itself, without similarity to any other, but incomparable with any other and absolutely sui generis. Whatever is wholly incomparable with anything else is wholly inexplicable, because explanation consists in bringing things under general laws or under natural classes... Finally, no present actual thought (which is a mere feeling) has any meaning, any intellectual value; for this lies not in what is actually thought, but in what this thought may be connected with in representation by subsequent thoughts; so that the meaning of a thought is altogether something virtual.


Here is http://selfpace.uconn.edu/class/percep/SellarsEmpPhilMind.pdf Sellars from Empiricism and the Philosophy of Mind (1956):


  "The notorious "ing-ed" ambiguity of "experience" must be kept in mind. For
  although seeing that x, over there, is red is an experiencing -- indeed, a
  paradigm case of experiencing -- it does not follow that the descriptive
  content of this experiencing is itself an experiencing... Certainly, the fact that something looks red to me can itself be experienced. But it is not itself an experiencing... It implies that while the process of acquiring the concept of green may -- indeed does -- involve a long history of acquiring piecemeal habits of response to various objects in various circumstances, there is an important sense in which one has no concept pertaining to the observable properties of physical objects in Space and Time unless one has them all - and, indeed, as we shall see, a great deal more besides."

Argument:

(i) The hottest part of the solar system is the Sun.

(ii) The Sun is located at the centre of the solar system.

(iii) Therefore, the hottest part of the solar system is its centre. 

Using this reasoning, we assume it is true that:

(iv) The hottest part of any physical system is its centre

(v) The core is at the centre of a planet

(vi) Therefore, the core is the hottest part of the planet.

Similarly,

(1) The hottest part of any physical system is its centre.

(2) The glacier is at the centre of the lake.

(3) Therefore the glacier is the hottest part of the lake (which seems implausible)

The fallacy here is in the assumption that was derived from the Sun example.  It is a fallacy of division, when one reasons logically that something true for the whole (the solar system) must also be true of its parts (other physical systems in the solar system).
The objections Isaacson lists are important, but the canonical counterexamples are sacrifical dilemmas: Essentialy these scenarios present a situation in which killing a small amount of people can save a great amount of people from death. An examples for these scenarios are https://en.wikipedia.org/wiki/Trolley_problem trolley-cases.

Every Kantian has to deal with these kinds of problems and other than Isaacson suggests, most of them bite the bullet. E.g. in Germany, whose constitution is highly influenced by Kant, the suppreme court http://www.bundesverfassungsgericht.de/SharedDocs/Entscheidungen/DE/2006/02/rs20060215_1bvr035705.html ruled that it is illeagal to shoot down a passenger plane captured by terrorists, even if it would be clear that they want to destroy skyscrapers/ a stadium/ a nuclear power plant. 
You can see :


Walter Burkert, https://books.google.it/books?id=pSSRAAAAQBAJ&printsec=frontcover Greek Religion : Archaic and Classical (German ed, 1977)
Daniel Ogden (editor), https://books.google.it/books?id=yOQtHNJJU9UC&printsec=frontcover A Companion to Greek Religion (2010), Ch.25 : Greek Religion and Philosophy: The God of the Philosopher, by Fritz-Gregor Herrmann
Peter van Nuffelen, https://books.google.it/books?id=Ya-IZlJ6ZbUC&printsec=frontcover Rethinking the Gods : Philosophical Readings of Religion in the Post-Hellenistic Period (2012).

Mr. Jensen, the problem of universals is usually a heavily obfuscated issue. So, pardon me if my post gets too long because it, since the problem of universals cannot be encountered, without clearing up a few more issues.


  We have on one side the contradiction between e.g. the general or
  abstract “(being) yellow” vs “yellow things”. Most people would have
  difficulties recognizing the issue in everyday terms, contrary to
  other classical debates with obvious relation to our time (e.g. the
  motion of the Sun and the Earth).


First and foremost we must define what it means for something to be abstract in the sense in which philosophers talk of.

1) Non-spatio temporal, i.e. not in space-time.
2) Causally inefficacious.
3) Non-spatio temporal & causally inefficacous.
4) Incomplete objects.


  A murderer is led to the place of execution. For the common populace
  he is nothing but a murderer. Ladies perhaps remark that he is a
  strong, handsome, interesting man. The populace finds this remark
  terrible: What? A murderer handsome? How can one think so wickedly and
  call a murderer handsome . . . .
  
  This is abstract thinking: to see nothing in the murderer except the
  abstract fact that he is a murderer, and to annul all other human
  essence in him with this simple quality.


This last one is owed to, and is with the help of Hegel. A man is a lot of things. A husband, a father, a corporate owner, and a murderer. He is not just a murderer simpliciter. To reduce the man to either one of these things, is known as 'abstraction.' For the man is not just a murderer, but a concrete particular which instantiates all those qualities.

Now, the problem of universals can be approached in many ways. But this is the heart of it. Consider two atoms, they have the same spin and charge. When two things agree in attribute, we naturally ask the next question. How can something which is numerically one, run through numerically distinct entities? 

Philosophers use the term "numerically" in contrast with "qualitatively." I was given 5 bottles of coca-cola for the party. It won't make a difference if I use the first bottle, or the fourth one. With regard to the quality of it being a cola, at least, there's no problem, since the first bottle and all the other ones are qualitatively identical. By saying that they are the 'same' I mean to say that they are qualitatively the same. If I say that I want a different one, I'm saying I want a numerically different one. However, it won't make any difference whatsoever, with regard to the property of 'being cola.'

If two things are identical in all their respects, then it follows that they are the same (I am not defending the Principle of Constituent identity or Leibniz's Identity of indiscernibles). If two things are qualitatively identical, then it doesn't follow that they the two things are the same. The problem of universals, then, is to account for the pre-analytic datum of how two things agree with each other in attribute. It is in accounting how a numerically one entity runs through numerically distinct particulars.

Since this is such a complex issue, this issue cannot be reduced to any other issues and must be tackled head-on with as much clarity as needed, so trying to reframe the debate which doesn't capture the essence of what's said above will always miss the mark.

Realists believe that this datum can only be accounted by positing entities known as 'universals,' whereas Nominalists either deny such attribute-agreement obtaining and thus see now need to account for any such anomaly. Simply said, you need a theory of properties to solve the problem, and a realist is one who posits that universals obtain in the world, and the nominalist is one who says that they don't obtain in the world, but only in the mind, or some other sort. 

  [2.] The search for explanation thus does not point beyond itself;
  
  I do not understand 2. Does the author contradict herself: because per 1, does not the 'search for explanation' point toward our 'feel[ing] satisfied until we have adequate explanations'?


Yes, but the satisfaction is not external to the search. Therefore, when the search points to the satisfaction, it does not point beyond itself.

The feeling of satisfaction is, according to Aristotle, something that naturally accompanies the activity, the search for explanation, when it is done well. The satisfaction cannot be separated from the search. One could not get that satisfaction by other means (say, drugs) thus bypassing the satisfaction's natural cause, the search for explanation.

There are different kinds of satisfaction, which correspond to the different kinds of activity. As Aristotle says in the Ethics, regarding pleasures:


  As then the Workings are different so are their Pleasures; now Sight differs from Touch in purity, and Hearing and Smelling from Taste; therefore, in like manner, do their Pleasures; and again, Intellectual Pleasures from these Sensual, and the different kinds both of Intellectual and Sensual from one another. (Ethics Book X sec III)


And as for


  [3.] for Aristotle it would be beside the point, as well as foolish, for us to try to understand nature in order to exploit it for our own ends. [End of 3.]
  
  Why would Aristotle think 3? What if we did not 'exploit' nature, but rather tried to use it morally?


3 seems to me a mistaken reading of Aristotle's. Aristotle says that knowledge has an intrinsic value beside its practical value. So there is also the practical value, and hence a kind of use (or exploitation) of nature. Only of philosophy does Aristotle claim that it is done only for its own sake, without any practical value:


  But it is clear that this science [=philosophy] is not productive also from the early history of philosophy. For it was because of wonder that men both now and originally began to philosophize. . . So it is clear that we seek it for no other use but rather, as we say, as a free man is for himself and not for another, so is this science the only one of the sciences that is free. For it alone exists for its own sake. (Metaphysics Book Alpha Sec II)

The axioms of Peano arithmetic do not mention multiplication, but multiplication can be constructed in it from facts about addition, given complete induction.  Unfortunately Peano's axiom of induction is not fully reducible to a collection of first-order statements.

The issue is not about multiplication per se, or even about the combination of addition and multiplication.  The theory of Real Closed Fields has both, and is consistent and complete.  The issue is about the strength of induction.

The induction axioms in Presburger arithmetic are the first order approximation of the Peano axiom, and basically do not allow for establishing facts about other facts that have, themselves, to be established inductively.

You cannot get real recursion off the ground unless you have a second order theory of counting, that allows you to represent the sets of integers for with the results are already established.

So to get a first order theory to start doing Gödel's proof, you have to bring in either infinitely many facts about addition, which are needed to establish the relevant results about multiplication, or a few facts about multiplication, itself, as additional axioms.

  If what justifies how one ought to apply concepts is a matter of how the concept has socio-historically been used, then this leaves no room for justified change.


That seems to depend on the specific tradition in question. If the said tradition has internalized (or is willing to internalize) norms of conceptual change, then conceptual change is possible, to that extent. Nothing in Brandom's system prevents it. There is also always the possibility of starting or maintaining a new tradition-branch. Brandom's view requires a social structure, but it does not require a unified consensus.

Notice also that there is a kind of (intended) circularity about this idea that you look at previous uses of a concept, in order to judge its correct use in a novel case. Because what does it mean that the new case is novel, except that there are no precedents for it? That is, until one "re-interprets" past cases as precedents. By re-interpreting past cases as relevant precedents, one is not merely continuing the tradition. One is then actively participating in making the tradition.


  It is insofar as one takes the tradition to be rational . . . that one makes the tradition be, and have been, rational.
  
  Judgments that show up first as adventitious products of accidental circumstances . . . are exhibited as correct application of a conceptual norm, retrospectively discerned as already implicit in previous judgments. (emph. mine)


(Brandom, Tales of the Mighty Dead, Introduction p.14)


  But this leads to the paradox that even if Brandom is right about the use of the concept 'history', 'reason', etc., it would be wrong for someone who disagreed with him to change their minds and agree.


Brandom is not concerned with changes of mind. This is not a level that concerns Brandom.


  Another way of putting the problem is to say that Brandom can adequately account for how a concept-use binds an individual in a given tradition, but not how an individual is justified in becoming a member of a new tradition.
  
  Why should anyone wish to be a part of Brandom's tradition to begin with?


These questions are outside the scope of Brandom's system. He leaves open the (meta) questions related to choosing among traditions. He concerns himself only with how things work inside any tradition (that is, any tradition which has a specified "inferential" structure).
1. p => q         Premise
2.   | ~q         Assumption
3.      || p      Assumption    
4.      || ~q     Reiteration: 2
5.   | p => ~q    Implication Introduction: 3, 4
6.   | ~p         Negation Introduction: 1, 5
7. ~q => ~p       Implication Introduction: 2, 6

I think you may have in mind the problem of reconciling subject's productive role in the acquisition of knowledge, recognized since Kant, with having an input from reality to it. McDowell called reality's contribution to knowledge its "objective purport" in his book https://books.google.com/books?id=O4m7VtNHjY0C&source=gbs_navlinks_s Mind and World, which instigated the wide-ranging current debate on the issue. See also collection of essays http://ndpr.nd.edu/news/23295-reading-mcdowell-on-mind-and-world Reading McDowell, two chapters on him in Pippin's https://books.google.com/books?id=JQ_Vmpo6dgkC&source=gbs_navlinks_s Persistence of Subjectivity, and http://psc.sagepub.com/content/41/3/249.abstract Sachs's Ideology of Modernity and the Myth of the Given). McDowell frames the existing approaches as a philosophical oscillation between the Myth of the Given and "frictionless spinning in the void", the self-legislated Hegelian coherentism (although his coherentist protagonist is Davidson rather than Hegel). 

The http://www.iep.utm.edu/sellars/#H2 Myth of the Given is the traditional belief that the mind "receives" sense impressions (possibly also intellectual intuitions) from the "outside", and they then serve as the basis for more complex concepts and inferences. This belief turned out to be problematic for several reasons. First, to enter inferences impressions/intuitions would have to be judgements, which they are not (the difference between seeing red x and seeing x as red). Second, it is implausible that we have to learn the "impressions" of red or pain, while the colloquial use of "red" and "pain" is most certainly learned. And finally, mastering a concept requires mastering a web of other concepts, that relate to it, and such relating can not be grounded in atomic encounters with "impressions". 

In short, the reality simply can not perform the conceptual delivery services that the Myth of the Given asks of it, the conceptualized "objective reality" is a historical and developmental artifact, and one that developed holistically, not piece by piece. This does not mean that we can not or should not use these conceptualizations, indeed we can not do otherwise, but it does mean that we can not have a fundamental epistemological account that posits them, we have to perform a https://en.wikipedia.org/wiki/Bracketing_(phenomenology) "phenomenological reduction", to use Husserl's term. This applies to objectifying conceptualizations of the community, the "public world", as well. Although the above critique of "immediately given" can be traced to http://publishing.cdlib.org/ucpressebooks/view?docId=ft7d5nb4r8&chunk.id=d0e997&toc.depth=1&toc.id=d0e997&brand=ucpress Hegel's Phenomenology of Spirit (§§ 90-110), in the analytic philosophy its import came to be broadly accepted only after http://selfpace.uconn.edu/class/percep/SellarsEmpPhilMind.pdf Sellars's classic, Empiricism and Philosophy of Mind. 

But rejecting the Myth leads to an opposite conundrum: if impressions can not enter propositions of knowledge what possible role can the reality play in its generation? According to Davidson's coherentism, a remote descendant of Hegel's self-legislation, concepts can rationally relate only to other concepts, see https://www.academia.edu/7724787/Can_Perceptions_Justify_Beliefs_Peirces_Prescient_Reply_to_Davidsons_Argument Can Perceptions Justify Beliefs? by Atkins, who also discusses "Peirce’s prescient reply" to Davidson. The relation between concepts and reality is purely causal, reality simply causes us to have the concepts we have. There can be no reasoning from sensibility to understanding, the rational aspect only enters in maintaining the overall coherence of the conceptual web. This is what McDowell terms "frictionless spinning in the void", which leads to philosophical recoil back into the Myth of the Given, restarting the oscillation.

The general approach in pragmatism is to diagnose the root cause of the Myth of the Given as the representational theory of meaning, and to replace it with an instrumentalist one. There the basic notions are actional rather than representational: Peirce's "habit", the "ultimate interpretant", Ryle's knowledge-how, Wittgenstein's "custom" and "rule-following", etc. Then it becomes intelligible how reality can act as a constraint on our spontaneous productions without there being any reality intake, in the spirit of impressions and givens. Our actions, individual or social, meat a pushback, which leads to us adjusting them. In the special case of sense perception this process is so routine (in routine situations) that we conflate self-generated but multiply adjusted conceptual reports (which are seen more fundamentally as truncated action templates) with "impressions" that accompany them. There are variations in emphasis concerning action and adjustment, from more individualist Kantian versions, like McDowell's, to more social Hegelian ones, like Brandoms's. But even McDowell does not assign cognitive autonomy to a single individual (as perhaps Kant did), social norms and customs still exert their influence as internalized "second nature" (the term he borrows from Aristotle), an individual conceptual web would face serious http://plato.stanford.edu/entries/private-language/ "private language" problems. In the end one could say with Hegel that the  "self-legislating" spirit is social, and while it "comes to itself as a product of itself", it is not not as a sole result of itself.
There's perhaps something of hint of a meta-joke lurking in this demand for the original author of "otherness". Very generally speaking, the idea of the other (sometimes called alterity) is:

(a) phenomenologically disruptive of our self-assurance and authority to "legislate" our own words/writing (Derrida, Levinas), and 

(b) epistemologically confounding, through presenting us with fundamental un-knowability, at least as to the inner sense of the enjoyment/desire of the other (Lacan, Zizek, but Nietzsche belongs here too: what if nature/wisdom were a woman?)

Hence altogether then we have a map of a kind of onto-epistemic humility -- and the traces here of so-called negative theology can be detected. 

Heidegger and Levinas are perhaps close to an originary dialectical couplet here of the modern conception of alterity and otherness, who between them articulate alterity in its horror and intimacy. It is Levinas who recaptures a transcendental sense of phenomenological alterity in the infinity of the face-to-face encounter and the subsequent demand of the other upon us, which at its most fundamental is simply to let the other live: the most basic sense of alterity in this sense is an ethical injunction not to murder. 
Given that your goal is ⊢ ((AvB) -> C) -> (A -> C) , you have two different ways of getting there:

(A) Assume (AvB) -> C    assume the left side of  your conditional and get to your end point via CP

(B) Assume ~ ( ((AvB) -> C) -> (A -> C) )  negate the entire of your object then do RAA]

In this case, I think you've made the right choice:


| (AvB) -> C)  P


To get to A -> C we can again:

(A) assume the left side and CP  

(B) negate the entire expression and RAA

In this case, it's a lot easier to negate -- since we can use addition to show that the negation we make is invalid:


| | ~( A -> C)    P
| | | A           P
| | | A v B       Add 3
| | | C           MP 1,4
| | A -> C        CP 3-5
| A -> C          RAA 2-6
⊢ ((AvB) -> C) -> (A -> C)


(If your proof system requires it, you may need to:

(1) repeat the assumption at line 1 before line 5.

(2) add a conjunction after 7 of 4 and 7 to show the contradiction). 

  "Is this [the above] an accurate description of what Descartes said? "


No, it is not.

See http://plato.stanford.edu/entries/descartes-modal/#EteTru Descartes and The Eternal Truths :


  You say that you think it is ‘very hard’ to propose that there is anything immutable and eternal apart from God. You would be right to think this if I was talking about existing things, or if I was proposing something as immutable in the sense that its immutability was independent of God. But just as the poets suppose that the Fates were originally established by Jupiter, but that after they were established he bound himself to abide by them, so I do not think that the essences of things, and the mathematical truths which we can know concerning them, are independent of God. Nevertheless I do think that they are immutable and eternal, since the will and decree of God willed and decreed that they should be so. Whether you think this is hard or easy to accept, it is enough for me that it is true. (Fifth Replies [to Fifth Objections, by Pierre Gassendi, to the Meditations on First Philosophy], AT 7:380, CSM 2:261)

The fact that  Γ ∪ {¬P} is unsatisfiable, implies that Γ ⊨ P.

This is proved using the definition of the relation of logical consequence (  ⊨) :


  every truth assignement (or model) that satisfy the formulae in Γ will also satisfy P. 


To say that  Γ ∪ {¬P} is unsatisfiable means that there is no truth assignment that satisfy it; thus, every truth assignment that satisfy  Γ will not satisfy ¬P, i.e. will necessarily satisfy P.

And this in turn means : Γ ⊨ P.



Now we apply the tuth table for the conditional (→) :


  Q → P is true either when Q is false or P is true.


Thus : 


  every truth assignment that satisfy P will also satisfy Q → P,


and in conclusion :


  
    every truth assignment that satisfy Γ will also satisfy Q → P,
  


i.e. :


  Γ ⊨ Q → P.

See :


  http://plato.stanford.edu/entries/descartes/#Bib Note on references and abbreviations: References to Descartes' works as found herein use the pagination of the Adam and Tannery volumes (AT), Oeuvres de Descartes, 11 vols. The citations give volume and page numbers only (dropping the abbreviation “AT”). Where possible, the Cottingham, Stoothoff, Murdoch, and Kenny translation, The Philosophical Writings of Descartes, 3 vols., has been used; it shows the AT pagination in the margins. Where the translation has been emended, the citation is marked with an asterisk (*). The AT volume numbers provide a guide to which work is being cited in translation: vols. 1–5, correspondence; vol. 6, Discourse and essays (including the Dioptrics and Meteorology); vol. 7, Meditations; vol. 10, Rules; vol. 11:1–118, World, or Treatise on Light; vol. 11:119–222, Treatise on Man; vol. 11:301–488, Passions. Where there is no accessible translation for a citation from AT, the citation is shown in italics. Works that are broken into parts and/or articles are cited by abbreviated title, part, and article: Med. for the Meditations, Met. for the Meteorology, Princ. for the Principles, and Pass. for the Passions.


  Are people inherently good according to Plato?


This may be a delicate question. On the one hand, Plato's Socrates asserts, in the Phaedo, concerning the misanthropist (hater of people), that only few people are genuinely good or evil.


  Is it not obvious that such an one having to deal with other men, was clearly without any experience of human nature; for experience would have taught him the true state of the case, that few are the good and few the evil, and that the great majority are in the interval between them.


On the other hand, Socrates asserts in the Protagoras, that no person does evil except out of ignorance. So that no person is inherently evil:


  Then, I said, no man voluntarily pursues evil, or that which he thinks to be evil. To prefer evil to good is not in human nature; and when a man is compelled to choose one of two evils, no one will choose the greater when he may have the less.


Concerning the Gods, they have been doing a lot of mischief in the Greek mythology. Socrates and Plato, however, considered this preposterous. The Gods, by them, had to be virtuous. In the Republic, Plato's programme for an ideal state includes related censorship of Homer and other poets over this issue.


  Then we must not listen to Homer, or to any other poet ... And if any one asserts that the violation of oaths and treaties ... was brought about by Athene and Zeus, or that the strife and contention of the gods was instigated by Themis and Zeus, he shall not have our approval ... he must say that God did what was just and right.

The topic is somewhat vast due to the vagueness of "language" and "language use", so the claim can be construed to implicate most of the analytic philosophy. As https://books.google.com/books?id=lvsVFxK3BPcC&source=gbs_navlinks_s Dummet writes in The Logical Basis of Metaphysics


  "It has until recently been a basic tenet of analytical philosophy, in its various manifestations, that the philosophy of thought can be approached only through the philosophy of language. That is to say, there can be no account of what thought is, independently of its means of expression..."


Before that some specific suggestions as to what (broadly linguistic) means thinking "requires" were made by Aristotle (phantasma), Kant (schemata) and Peirce (diagrams). Empirical studies over the last century made any such specialized "vehicle of thought" highly implausible. Brandom's is not that kind of claim, and I will focus on his. He allows that rational thinking may employ non-linguistic means, but for it to develop in the first place requires participation in what Wittgenstein called language games. More precisely,  a particular type of language games, what Sellars called "giving and asking for reasons". Here is from https://books.google.com/books?id=BPIKaq80wmEC&source=gbs_navlinks_s Reason in Philosophy:


  "The game of giving and asking for reasons is not just one game among others one can play with language. It is the game in virtue of the playing of which what one has qualifies as language (or thought) at all. I am here disagreeing with Wittgenstein, when he claims that language has no downtown. On my view, it does, and that downtown (the region around which all the rest of discourse is arrayed as dependent suburbs) is the practices of giving and asking for reasons."


In other words, the rationality is "parasitic", as Brandom puts it elsewhere, on "giving and asking for reasons". Let me try to flash out Brandom's "syllogism".

1) Rational thought is about imparting and understanding meaning.

2) Understanding meaning requires making inferences, meanings are inferential roles.

3) Learning inference requires norm-governed (hence communal) linguistic practice, "giving and asking for reasons".

Ergo. Let's say that 1) is vague enough to be relatively uncontroversial. 2) is the thesis of semantic inferentialism, which Brandom credits to Hegel (ultimately), although his own version is more reminiscent of late Wittgenstein and Sellars. What goes for inferentialism is that its traditional alternative, representationalism, ran into some intractable difficulties in semantics and epistemology, see https://philosophy.stackexchange.com/questions/37574/what-is-the-difference-between-expressivism-and-representationalism-in-modern-ph/37582#37582 What is the difference between expressivism and representationalism in modern philosophy of language? The best known are perhaps Wittgenstein's rule-following regress, especially as laid out by http://krypton.mnsu.edu/~jp6372me Kripke in Wittgenstein on Rules and Private Language, and Sellars's argument against the Myth of the Given touched on in https://philosophy.stackexchange.com/questions/38447/how-is-the-conflict-between-created-by-reason-and-external-aspects-of-knowledge/38460#38460 How is the conflict between created by reason and external aspects of knowledge resolved? Brandom has a http://www.pitt.edu/~brandom/me-core/downloads/EPMGuide11496a.docx. study guide for http://www.pitt.edu/~brandom/me-core/downloads/EPMGuide11496a.docx. Sellars's Empiricism and Philosophy of Mind, where it was originally developed (some of its ideas were anticipated by Hegel, Peirce and Adorno, among others). Quine's https://en.wikipedia.org/wiki/Indeterminacy_of_translation indeterminacy of translation and Davidson's indeterminacy of interpretation also belong to this circle of arguments. http://www.yorku.ca/cverheg/documents/howsocial.pdf Verheggen in How Social Must Language Be? gives an insightful commentary on Davidson's arguments in comparison to Wittgenstein's.

3) is a major theme of Wittgenstein's Philosophical Investigations, although, unlike Sellars, he talks of language as a "motley", and does not single out giving and asking for reasons. Still, Wittgenstein's http://plato.stanford.edu/entries/private-language private language argument suggests (vastly oversimplifying) that signposts can only point if there is a custom of following them, and hence that normativity requires communal practice. A language may be privately used but not privately developed and established, that "requires something independent". The argument is discussed under https://philosophy.stackexchange.com/questions/34111/did-wittgenstein-consider-the-possibility-of-a-language-where-private-concepts-c/34157#34157 Did Wittgenstein consider the possibility of a private language with public content?

All three arguments are very complex and intricate, we can do them only so much justice in SE format. But I want to point out a peculiar feature. They are not so much arguments for Brandom's semantic pragmatism as against the existing alternatives. This is not accidental, and reflects a different approach to arguing a position, first championed by Peirce, see https://philosophy.stackexchange.com/questions/38433/do-all-epistemologies-suffer-from-the-regress-of-justifications-problem/38442#38442 Do all epistemologies suffer from the "regress of justifications" problem? It is unlike that of classical rationalists, Descartes, Kant, Fichte or Husserl, who tried establishing positive claims from imaginary "ground zero". If Brandom manages to recover traditional semantics in its confines (established disciplines with well conceptualized domains), and give an attractive account of new concept formation and acquisition, which evades realist semantics and epistemology, his position will have to be accepted without any (traditionally) positive argument for it, as a better alternative. He names as much as his task since Making It Explicit.
I'm going to presume from the way you've worded your question that you would like to frame your argument in ordinary language rather than in any particular form of Logic. To that effect, 2 and 3 could be conflated more neatly by simply asserting that the only two factors from which effects can arise are randomness and determinate cause. This would not be an unreasonable assumption and rules out in one premise the possibility that a combination of the two may give rise to a third form of effect as you have specified that no other factors can be involved. Here you have a relatively neat argument for determinism or compatibilism.

The problem arises when you reach the second part of your argument.

Your conclusion at 3 only results from your premises 1 and 2 if God is subject to the rules that you have just specified in the first part. If he is not, then he can simply "create" free will in defiance of these rules. You would need to start the argument with an additional premise that any God is subject to the rules outlined above, and I'm not sure that would allow your argument to be much used against the majority of religions (assuming that's the point).

In effect, you then do not need the first part of your argument at all. You could simply say that any God who, by exercise of any of his powers, limits free will is not a beneficent God and so not worthy of worship (as your second argument already includes the concept of worthiness we have not lost any certainty). Most religions already have their version of a refutation of this argument. Virmaior has provided a excellent outline of these https://philosophy.stackexchange.com/a/38575/22791 here for Christianity.

The trouble with using logic to argue against religion is that logic requires accurate premises in order to be useful which can only be obtained empirically from physical laws. Most religions consider their Gods to be above physical laws.

To paraphrase Wittgenstein, you cannot use rational argument to counter a view which was not arrived at rationally in the first place.
The perspective you are pointing at is https://en.wikipedia.org/wiki/Emergentism emergentism.  From that perspective, the problem is that the physical point of view simply lacks adequate context to express the notion of identity and will, not that it actually conflicts with the idea.

As you point out, physics proper does not handle notions like pressure very well.  It has even more trouble with notions like acidity.  Without the context of the 'bond' to identify which hydrogens are 'free' which can only be observed from a more complex POV than the laws of physics capture well, acidity is not a thing.  That does not in any way make us doubt that chemistry has reasonably defined acids.

But somehow, many of us are quite willing to look at the physical sciences together and assume that they should either correctly identify identity and will, or those things do not exist.  From a higher-level psychological point of view, it is obvious that identity and will exist, and philosophical takes on rational psychology and political theory do think about that.

From a point of view in one of those frameworks, say psychoanalysis, or Existentialism, you can reasonably say that if you have one of 'identity' and 'will', you get the other.  For instance, for Kleinian psychoanalysis will is what allows an identity to detect that it is different from its source, and a maturing will establishes and clarifies its identity in order to defend itself from merger back into that source.  From Sartre's perspective, 'will' is the illusion of freedom which we must maintain in order to have responsibility, and we insist upon having responsibility as a way of maintaining our identity.

But if these are properly emergent phenomena, the way chemistry is an emergent framing of physics (which 'supervenes on it', as such people say), then 'will' may still be determined (as the idea it is a necessary illusion points out).  More complexity does not necessarily reduce the ultimate nature of cause, it may just hide deterministic cause in the cover of mathematical chaos.  If there is not already indeterminacy at the lower level, it should not arise at the upper level.

There are all kinds of arguments that there is no 'free will' in randomness, and randomness and determinism together never result in choice.  But, to my mind, they are pasting the ideas together wrong.  One can easily say there is 'freedom' in randomness, but there is no 'will'.  But then there is no reason 'will' cannot result from an emergence from physics and get its 'free' nature from the underlying randomness.

As a parallel example, one can say there is no 'intention' in genes because there is no 'consciousness'.  But that does not mean there cannot be 'intention' in a being derived from those genes.  Consciousness arises as an emergent aspect of survival, as a way of keeping better track of one's environment.  Then, added to the goal of survival itself, this emergence easily explains how 'intention' is still possible.
The original German is 'der Wille zur Macht'

Re 'Wille':

I think the original interpretation is correct.

Re 'Macht':

Neitsche includes domination in his view of power, but he also includes influence and all other ways of affecting the world.  Power, is at root, 'potesse' -- being able, and not necessarily oppression.  In fact, he notes that oppression is too much directed at others to really be absolute power. In caring that you dominate, you give power to those dominated, whose responses actually determine your happiness.

His less didactic books, like 'The Gay Science' and even 'All too Human' have a focus on art as an aspect of life that makes no sense if one thinks of power as domination alone.  Artists do not dominate, they influence.

And in fact, in his critiques of Wagner, he points out how, when art dominates, it actually has less power, because it loses the ability to influence on a more detailed level.  Power aims to make the world exactly as one wishes it.  This cannot be accomplished any better with a maul than with a paintbrush if the essence of your vision has a great deal of detail.

Nietzsche also has a vision of the unity of opposites that strongly foretells psychoanalysis (thus the need for a focus that questions values, as captured in Beyond Good and Evil).  For instance, in The Gay Science, he admires the motive of domination so strong that it can be adequately served by forgiveness, being 'Drunk off' in imagination so deeply that it leaves one overly full, and calls for its opposite.  He points out that doing good for others is also a way of controlling their lives.  If you are powerful in a way that suits your nature, then, you might be magnanimous, or endlessly motherly, rather than dominant.

Re 'zur':

Here 'to' means 'for', 'toward' or 'unto'.  Although 'zu' is also used with infinitives, like the English 'to', given the article marker and the capitalization 'Macht' here is a noun and not an infinitive.  It is more often translated 'for' in such cases, to remove an ambiguity that exists in English and not in German. However, Schopenhauer's 'Wille zum Leben' had already consistenty been translated "Will to Live' rather than "Will for Life", and this naturally followed that compromised construction.
Well, in some ways Callicles comes close. One easily recognizes some of the key themes of http://www.kritike.org/journal/issue_8/urstad_december2010.pdf Nietzsche's master morality there: the strong dominate the weak by nature, laws protecting the weak are unfair to the strong, morality is not established by gods but by men with their own petty interests, etc. According to http://www.kritike.org/journal/issue_8/urstad_december2010.pdf Urstad's Nietzsche and Callicles on Happiness, Pleasure, and Power: 


  "Although  there  is  no  mention  of  him  in  his  published  works,  there  is little  doubt  that  some  of  Nietzsche’s  most  famous  doctrines  were inspired  by  the  views  expressed  by  the  character  Callicles  in  Plato’s Gorgias". 


However, we should be careful with transplanting concepts across centuries and philosophical systems, especially as heterogenous as Nietzsche’s and Plato's, or we will end up, like some commentators, with Plato's Republic as a Marxist manifesto. There is more rational "Realpolitik" in Callicles than Zarathustra's Dionysian passion and exaltation.

As for hedonism, that is cold, very. In Nietzsche's picture hedonism is a sign of decadence. "An overman as described by Zarathustra, the main character in Thus Spoke Zarathustra, is the one who is willing to risk all for the sake of enhancement of humanity. In contrast to the "last man" whose sole desire is his own comfort and who is incapable of creating anything beyond oneself in any form", see https://ccrma.stanford.edu/~pj97/Nietzsche.htm Nietzsche's Idea of an Overman and Life from His Point of View. If a hedonist is Nietzsche’s anything it would be the last man, not the Übermensch. Urstad concurs:


  "Nietzsche clearly rails against the pursuit of pleasure where pleasure is 
  understood  as  a  particular  sensation  marked  by  the  absence  of  any  pain  or discomfort.  He,  for  instance,  describes  Epicurus,  who  conceived  of  pleasure (ataraxia) as the absence of all physical and mental discomfort, as “representing a  state  in  which  one  is  neither  sick  nor  well,  neither  alive  nor  dead”... For Nietzsche, pleasure cannot be divorced from pain, rather, they are “twins”, in so far as one cannot have one  without  the  other.  He  states  that  pleasure  and  pain  are  “so  knotted together that whoever wants as much as possible of the one, must also have as much as possible of the other...”" 

Aristotle, http://www.perseus.tufts.edu/hopper/text?doc=Perseus:abo:tlg,0086,034:1451b Poetics, 1451b :


  The real difference is this, that one tells what happened and the other what might happen. For this reason poetry is something more scientific and serious than history, because poetry tends to give general truths while history gives particular facts.

Kant proves three rather different forms of the Categorical Imperative to be logically equivalent, given a grounding in his own theory of thought.  He realizes that different forms of the statement will appeal to people with different kinds of motivation.  But his own chosen motivations lie close to mathematics and physics, so he chooses to use the "Universal Will" formulation most often.  Solutions proceeding from it have a mathematical cleanliness that checks missteps driven by sentimentalization when one applies the other two formulations, which take third-person rather than first-person perspectives.

The 'https://en.wikipedia.org/wiki/Categorical_imperative#The_Second_Formulation:_The_Formula_of_Humanity Means-Ends' form of the Categorical Imperative, "A Being must be treated as an end-in-itself and never as mere means." does just what you ask.  Kant elaborates this in terms of 'autonomy', which is an abstract principle including both dignity and value as effects: an autonomous being chooses to exist as more than a mere extension of another, and thus needs his own value to be respected; and an autonomous being needs deference to exercise his autonomy, which is an assertion of his individual dignity.  He does consider autonomy to be intuitive to humans.
The model that Laplace was probably contemplating was Newtonian Mechanics; this theory is deterministic, so he was simply dramatising or even melo-dramatising via his demon the notion of determinism implicit in this theory.

As the character in this drama is a demon rather than an angel suggests that he supposes that there is something not quite right here, after all we experience the world as a mixture of neccessity and freedom. 
Cantor's is only one way of looking at sets and containment. And even it, from a point of view like https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Bernays%E2%80%93G%C3%B6del_set_theory Goedel-Bernays-VonNeuman set theory this result only declares that the class of all sets is not a set, not that it does not exist.  Variants of this solution provide models of mathematics that allow for a set of all sets (or at least a class of al classes, or a category of all categories), but they must sacrifice either some applications of negation or severely limit the degree to which self-reference makes sense in order to evade paradoxes like https://en.wikipedia.org/wiki/Russell's_paradox Russell's.

From the viewpoint of someone like https://en.wikipedia.org/wiki/Omnipotence_paradox#Types_of_omnipotence Descartes, contradictions do not controvert omniscience.  Instead, the fact that we cannot handle this apparent contradiction merely demonstrates the limitations imposed on our thinking by our nature as temporal, human animals -- including the very notion of contradiction.  Applying this notion to mathematics (though through a Kantian lens) http://plato.stanford.edu/entries/intuitionism/#Bro Brouwer decided negation is probably an aspect only of temporal thought, based entirely on our notion of before and after in time, and that we should not trust it completely: we should either limit it to finite cases or retain its temporal character. 
The inference from:


B


to


B v ~A


is valid.

We can prove this using a truth table,

For this truth table, we already know that B is true, so we just need to know that B v ~A is true in every instance to be able to add it.

B | A | ~A  | A v B 
T | T |  F  |   T
T | F |  T  |   T


As you can see, we can add anything with v in this way -- both A and not A work.
(The same is not true of other operators).

The only error I see is that you're referencing the wrong premise. You should reference line 4 (4. B) rather than 2 (2. ~D -> B)
Introduction

I think there are two points to consider:

1) The way philosophy worked these days, i.e. through poetry and

2) The problem of being "lost in translation".

I think most of us underestimate the wisdom of ancient Greek philosophy. I think that there may even be good reasons for expressing deep insights into the very fabric of Being and our place within it by appeal to Mysticism and in the form of poetry. And I want to illustrate this with a philosophical development that is a good 200 years old, not over 2.000 (references given at the end). In short, I want to make comprehensible what on first sight seems to be archaic and too far away to be rational.

Argumentation

After Kant elevated the transcendental ego to being the highest necessary condition for knowledge and (arguably) the noumenal self in form of the moral law as highest principle of the practical, philosophy was left with the task of finding a common ground for both of them.

After Reinhold as holding the chair for transcendental philosophy in Jena (THE intellectual center of philosophy these times, with Goethe and Schiller) tried and failed in finding it in the relation between subject, object and representation, Fichte (his successor) proposed his Wissenschaftslehre in his lectures of 1794/95.

There, he presented his view of the Tathandlung, i.e. the setting of an absolute self (expressed in I=I), that within itself then sets both the I and the non-I and their mutual limiting.

Hölderlin in April 1795 wrote the little fragment Judgement and Being, where he fundamentally criticises this view. He argues that the I in no sense can ever justify itself, as self and judgement presuppose the difference of subject and object. Therefore, there has to be a primeordinal Being that is undivided.

He will later argue (in letters and the Hyperion) that because every judgement (therefore knowledge) cannot account for this unity and therefore cannot account for world as it really is, but only for our subjective understanding of it. Therefore, he argues, philosophy has to use aesthetic means, i.e. poetry, in order to present truth that is not formulated in judgements and therefore able to convey true insight into Being.

Now we have come to a full circle: It may very well be that ancient Greek philosophers already came to the insight that perception and judgements can never express more than truth relative to our subjective restrains (an idea that can also be found in other pre-socratics, e.g. Heraclitus) and therefore deliberately chose poetry (or, as Heraclitus - and tellingly Nietzsche - Aphorisms) as both a mean to teach the common man (who cannot read at all or most certainly not long treatises) and convey a deeper truth. This idea is exactly what can be found in the Eldest System Programme of German Idealism, in which Hölderlin certainly contributed.

Teaching is for sure an important aspect in what has been written down and therefore known until today, so a way had to be found for it. Poetry basically was THE form of teaching in ancient Greece, and I think it to be doubtful that the philosophers really believed in all the myths they used to express their ideas. They are means to be understood by the adressee and arguably back in the times the only linguistic means for these ideas. Remember, Wittgenstein taught us that we have to play the same language game in order to understand each other. And our language and understanding may all too easy be alienated by what just seemed natural to them.

References

Regarding the intellectual developments in and after Kant, I propose reading The Twenty-Five Years of Philosophy by Eckart Förster (2012)

For a good setting and interpretation of Hölderlin (that is also rather short) Charles Larmore's Hölderlin and Novalis in The Cambridge Companion to German Idealism editioned by Karl Ameriks (2000).

For how philosophy at least for the last 200 years is stuck in some kind of a dialectics between kantian critical philosophy and the criticism of it (in other terms: Rationalism and Romanticism), see Meillassoux' After Finitude (2008).

For how pre-socratics link to the problem of critique of kantian critical philosophy, there are nice interpretations by Heidegger whose titles I cannot name off the top of my head, especially not in English.
The argument for the uniformity (or homogeneity, or self-sameness) doesn't follow from the boundedness of what is. Parmenides introduces both uniformity and the argument for uniformity in the passage you're citing. The argument is:


  [...] it cannot be greater or smaller in one place than in another.
  For there is no nothing that could keep it from reaching out equally,
  nor can aught that is be more here and less there than what is, since
  it is all inviolable.


The https://plato.stanford.edu/entries/parmenides/ Stanford Encyclopedia of Philosophy presents a paraphrasis of this argument when touching the modal interpretation of Parmenides' On Nature, but it's still general enough that it doesn't really lean towards any particular interpretation. Maybe it's a little bit clearer than Burnet's version:


  What must be must be free from any internal variation. Such variation
  would involve its being something or having a certain character in
  some place(s) while being something else or having another character
  in others, which is incompatible with the necessity of its (all) being
  what it is.

The question in the headline and at the end of the OP are different.  Since jobermark has already given a good answer to the latter, I'll tackle the former in reverse: What would it require for us to be able to judge God morally?

There would need to be an objective, sure, knowable and known standard of "good" that existed in the universe independent in some fashion of God (meaning it could have been created by God, but it couldn't be defined in reference to God).  Most people would agree that no such standard is currently known, so the question reduces to whether such a standard can be shown to NOT possibly exist.

Here you run into three difficulties: If the moral standard is not from God, where does it come from? If God created it, why wouldn't God abide by it?  If it is doesn't align with God, then in what sense is it good?  Clearly, the answers to those questions would depend on the characteristics of God and the good, so depending on your conception of those, you might come to quite divergent conclusions.
The philosopher Hans Reichenbach http://www.proginosko.com/docs/induction.html came up with this idea, which is called the "pragmatic justification for induction".


  Numerous criticisms can be levelled at Reichenbach’s answer to the problem. The fatal weakness with a pragmatic justification of induction, however, is just that it is a pragmatic justification and not an epistemic justification. That is, while it may motivate us to employ a certain strategy (to reason inductively), it gives us no indication of the actual likelihood of its success (i.e., whether the inductive principle is true). In this respect, it suffers from the same ailment as Pascal’s Wager (which may offer motivation for believing in God, but leaves us none the wiser as to whether He actually exists). A true solution to the problem of induction requires an epistemic justification — a reason for believing that induction is reliable — yet Reichenbach’s solution, for all its ingenuity, offers no such thing.


Laurence BonJour, In Defense of Pure Reason (Cambridge: Cambridge University Press, 1998), pp 192-6.
If I understand your question, it looks something like this:


God on the B-theory is outside of time.
To be outside of time is to be incapable of experiencing changes
To know something requires experiencing change.


Clearly, this set is contradictory. In fact, it's plainly so. The fact it's plainly so should be a hint that this is an incorrect reading of someone's philosophical position.

Simply put B-theorists about God's relationship to time reject claim 3. For them, to know something in the case of God is dissimilar to knowing in the human case.

For humans (and temporal beings), knowledge has a feature of coming to know, but there's no reason why this is necessary. For the B-theorist, God has instant knowledge of everything throughout eternity as if it were a single moment.

To give an analogy using a movie's physical film, temporal beings have an A-theory experience of time wherein each frame happens in sequence and there are frames before the current frame and after the current frame. There are things we come to know in future frames, etc. Similarly, we come into and out of the film and experience all sorts of states (sinus infections, births of children, etc). 

Conversely, a B-theory God sees every frame of the entire movie all at once as if in a single instant. This God doesn't experience any of this as passage. It all just is. In other words, that person Q has a sinus infection at moment 33331 is part of the knowledge for b-theory God but b-theory God has no moments and does not pass through time. For a person in time, the sinus infection begins at say moment 33330 and ends at 33338.

The basic idea is that God knows from eternity (here understood as neither before, during, nor after events) what happens at each moment of time regardless of whether we as temporal beings see these as "past", "present", or "future."

For more, you can read http://www.iep.utm.edu/god-time/#SH1b http://www.iep.utm.edu/god-time/#SH1b.



To simplify, if you find this account of B-theory knowledge (eternal knowledge or an eternal being behind it), then you probably would simply reject either that any God exists or that the existing God is a B-theory God.
Moral realists like Kant surely think so.

And from a more naturalized Kantian position, we can accept the basic argument in a modern framing -- we get something like Freud.  Humans have a certain fund of expectations which come down to us genetically and through the shared layer of culture that hold the species together and keep it functioning.  Respecting those and allowing them to do their work will be seen by most people as a reasonable definition of good.  The remainder are lying.

Something like the thoroughgoing empathy of Kant's Categorical Imperative is hard to see as evil, or even neutral.  One has to work very hard to make situations where one wishes to ignore it, and even then, there are always slightly more productive paths out of those staged dilemmas, which respect the rule.  We resent the degree to which such a notion would constrict our behavior, but we cannot really claim we do not expect the principle to be followed by at least the people most important to us.  We expect those we love to be fair, and although we play with contextual details, we do have an overall sense of what fairness is.

Any applied theory that works is still going to be negotiated on top of some shared base.  Its underlying notion of good is still ultimately going to trace back to shared opinions that arose over time out of these principles.  So disowning the idea that a few basic principles are not always good is just casuistic evasion.  If there were no basis to morality, different cultures could not make peace on a regular basis, which they simply do.

At the same time, we have a strong tendency to focus on only one side of human nature as good, the one that works longer term, and accept more basic competing drives as necessary evils.  But there is not really a place for that bias.  Conflicting drives that are productive and universal should be seen as competing good impulses to be reconciled, and not viewed in terms of good vs evil drives.

It is this intricate balancing act that makes morality seem baseless, because we are too firmly attached to the simplicity of negation.  Morality may not be, in and of itself, logically consistent.  That does not mean it does not exist or have structure.  The same can be said of all forms of taste, but overall, we have not seen the basic nature of things like food change in thousands of years.
I believe this impression is created by surveying the more "popular" part of the literature. http://quod.lib.umich.edu/cgi/p/pod/dod-idx/nietzsche-s-theory-of-the-will.pdf?c=phimp;idno=3521354.0007.007 Leiter in Nietzsche’s Theory of the Will describes the general approach as routine:


  "I am concerned with the notion of “will” familiar from general philosophy of action, both contemporary and historical, namely, the idea of a human faculty, whatever its precise character, that stands in some kind of necessary relationship with action. Such a faculty may itself be causally determined, or it may be autonomous of the antecedent causal order; its status may implicate questions of moral responsibility; and such a faculty may not exist at all. A theory of the will is one that sheds some light on these issues."


"Free will" is often used as an idiomatic label, which indicates selecting a particular aspect of the human action, namely self-determination and its relation to causal physical laws, often accompanied by implications for moral responsibility. This label, sometimes contracted to "freewill", is unsplittable and can be used even by those who believe that there is no will, free or otherwise. Philosophers (and psychologists and neuroscientists) who wish to focus on other aspects may use different terms, like "volition" (http://isites.harvard.edu/fs/docs/icb.topic889975.files/May%202nd/May%202nd%20papers%20to%20be%20presented/Roskies%202010.pdf Roskies, How Does Neuroscience Affect Our Conception of Volition?) or "antecedents to voluntary action" (https://www.ncbi.nlm.nih.gov/pubmed/24979469 Nachev and Hacker), etc. 

A recent trend in the philosophical literature, stimulated by experiments in neuroscience starting with Libet's, is to focus on another aspect: whether or not voluntary action is initiated consciously or unconsciously, regardless of whether it is "free". Correspondingly, the label is changed to "conscious will". But this still does not imply any "will" faculty, conscious or unconscious. https://mitpress.mit.edu/books/illusion-conscious-will Wegner's Illusion of Conscious Will is the book that launched what is now called http://www.3ammagazine.com/3am/questioning-willusionism "willusionism" into broad public consciousness. A systematic rebuttal of Wegner, https://books.google.com/books?id=h-oVDAAAQBAJ&source=gbs_navlinks_s Mele's Effective Intentions: The Power of Conscious Will, uses the same label. Some arguments for unconscious will are discussed under https://philosophy.stackexchange.com/questions/32189/what-counters-are-there-to-spinozas-argument-that-acts-of-free-will-create-infi/32206#32206 What counters are there to Spinoza's argument that acts of free will create infinite regress?

It may surprise some people, but Nietzsche was a forerunner of willusionism, and developed a powerful phenomenology undermining the folk notions about conscious "willing". All that without the measuring sophistication of Libet-type experiments. We do not experience our thoughts as "willed", argued Nietzsche, so if "willing" is causing, and our actions are caused by our thoughts, then they are not caused by "us" at all. In http://genius.com/Friedrich-nietzsche-twilight-of-the-idols-chap-5-annotated Twilight of the Idols he writes:


  "The “inner world” is full of phantoms and will-o'-the-wisps: the will is one of them. The will no longer moves anything, hence does not explain anything either — it merely accompanies events; it can also be absent. The so-called motive: another error. Merely a surface phenomenon of consciousness — something alongside the deed that is more likely to cover up the antecedents of the deeds than to represent them. …What follows from this? There are no mental causes at all." 


Compare this to Wegner's:


  "The initiation of the voluntary act appears to be an unconscious cerebral process. Clearly, free will or free choice of whether to act now could not be the initiating agent, contrary to one widely held view. This is of course also contrary to each individual’s own introspective feeling that he/she consciously initiates such voluntary acts".


Of course, Nietzsche and Wegner have quite different motivations for their views, the latter cites causal physics and Libet experiments, the former, while also being unduly impressed by deterministic physicalism of his time, has a deeper motive. No will - no moral responsibility:"the whole realm of morality and religion belongs under this concept of imaginary causes". One can find this aspect more recently developed by http://www.informationphilosopher.com/solutions/philosophers/strawsong/ Strawson in Impossibility of Moral Responsibility among other places. But there is one big difference between Nietzsche and determinists, like Wegner and Strawson, the Leiter points out:


  "it is precisely because Nietzsche is a radical empiricist skeptic about laws that he eschews the language of classical determinism. Nietzsche’s “official” view (strange as it may seem) is that ours is a world of token necessities, not lawful necessities..."

There can be different responses to your question, depending on which definition from the Oxford dictionary you go with. 



Based on the first definition:


  "The practice or principle of giving a group priority over each individual in it".


"Collectivism" isn't synonymous with "Communism" or "Socialism" nor is it antynomous with "Capitalism" - all of which are economic systems. On the other hand "Collectivism" would be a stance on human rights, ethics and social norms, and should be contrasted with "Libertarianism" or with "Individualism", not with the above mentioned economic systems. 

From this point of view both Soviet style communism, and excessive forms of capitalism where large corporate interest impose lifestyle and economic choices on hapless individuals are both collectivist - whether the entity doing the coercion is a government actor or a private corporate interest doesn't really matter.

In fact many leftists and socialist thinkers saw themselves as opposing the collectivism imposed by capitalism. 

Marx for example saw the division of labor as a limitation of freedom imposed by the capitalist mode of production: Capitalism force people to be either doctors, or bus drivers, or coal miners, or musicians, etc...whereas in a communist society people would be free to engage in whichever activities they please. In the https://www.marxists.org/archive/marx/works/1845/german-ideology/ch01a.htm The German Ideology (1845) he states that:


  ...while in communist society, where nobody has one exclusive sphere of activity but each can become accomplished in any branch he wishes, society regulates the general production and thus makes it possible for me to do one thing today and another tomorrow, to hunt in the morning, fish in the afternoon, rear cattle in the evening, criticise after dinner, just as I have a mind, without ever becoming hunter, fisherman, herdsman or critic.    


Similarly Adorno and Horkheimer, in https://en.wikipedia.org/wiki/Culture_industry The Culture Industry saw Capitalism as imposing a unified artistic aesthetic on society, a factory produced bland art that is used to deceive the masses, while legitimate "high" art needs to be free and creative to satisfy human psychological needs. 

I have also heard of capitalists who argued that collectivism is a good thing, but then went on a step further by claiming that capitalism is better at achieving collectivism than socialism is, by allowing any individuals to purchase shares in corporations through the stock market, and through things such as https://en.wikipedia.org/wiki/Employee_stock_ownership_plan employee stock ownership plans. I don't remember the reference for this, but it might have been mentioned in https://youtu.be/vm3euZS5nLo this interview with Herbert Marcuse. 

So the direct answer to your question is: Based on the first definition, there is no distinction between collectivism as it applies to communism or to capitalism. Whether collectivism is good or bad, it can be the result of both communism/socialism and of capitalism.  



Based on the second definition: 


  "The ownership of land and the means of production by the people or the state, as a political principle or system".


Based on this definition, it seems that superficially that both communism and capitalism where the rights of large corporations take precedence of the rights of individuals amount to forms of collectivism. 

A libertarian defender of (free-market) Capitalism, such as Robert Nozick or Ayn Rand, can argue that nonetheless, Capitalism does preserve individual freedom where socialism/communism don't in the following way:


In communist and socialist systems the workers don't have any choices. They are constantly coerced by the government and by restrictive labor laws and union rules (For example in many socialist countries, you are not allowed to just resign from your job, you have to have give several months notice, and your management has to approve your departure). In a capitalist system on the other hand, the worker is free at any time to leave the company if he doesn't like conditions he is working in (Of course he will likely starve to death, but he is doing so of his own free will).
In communist and socialist systems, the will of the individual is sacrificed to the "greater good". In capitalist systems, individual workers are sacrificed for the good of the shareholders who also happen to be themselves individuals, i.e. capitalism does focus on individual rights, it's just that is focused on the individual rights of shareholders not the individual rights of workers, and as mentioned above those workers freely entered into contractual agreements with their employers, nobody ever forced them into anything. 


So the libertarian will argue that the capitalist system is not collectivist insofar as it protects individual ownership and property rights, which are the only rights that really matter.   
Some references on the justification of logic: 

Quine's critique of the idea that logic can be derived from the concept of analyticity can be found in his papers "Truth by Convention", "Two Dogmas of Empiricism" and "Carnap and Logical Truth". These can be found in his collections The Ways of Paradox, and From a Logical Point of View. 

Putnam argues that we may have reason to accept that logic is empirical in his paper "Is Logic Empirical?" Boston Studies in the Philosophy of Science 5 (1968). 

Michael Dummett argues that the justification of deductive reasoning must be found in a theory of meaning, in "The Justification of Deduction" (1974, in his collection of papers Truth and Other Enigmas). 

Laurence BonJour defends the view that a priori knowledge of logic stems from rational insight, independently of experience in his book, In Defense of Pure Reason, Cambridge University Press (1998). 

Paul Boghossian attempts to restore the concept of analyticity as a source of a priori knowledge in "Knowledge of Logic" In Paul Boghossian and Christopher Peacocke (eds.), New Essays on the A Priori (2000). 

Other useful papers include: 

Crispin Wright, "Intuition, entitlement and the epistemology of logical laws"  Dialectica 58 (1):155–175 (2004) 

Sinan Dogramaci, "Knowledge of Validity". Noûs 44 (3):403-432 (2010).

Hartry Field, "Epistemological Nonfactualism and the A Prioricity of Logic". Philosophical Studies 92 (1/2):1-24 (1998)

Corine Besson, "Logical Knowledge and Ordinary Reasoning". Philosophical Studies 158 (1):59-82 (2012)

William Hanson. "Logic, the a Priori, and the Empirical". Theoria 18 (2):171-177 (2003)

Julien Murzi and Florian Steinberger. "Is Logical Knowledge Dispositional?" Philosophical Studies 166 (1):165-183 (2013)

Timothy Williamson. "Understanding and Inference". Aristotelian Society Supplementary Volume 77 (1):249–293 (2003)

Mark Jago, "The Content of Deduction". Journal of Philosophical Logic 42 (2):317-334 (2013)
This answer comes from the perspective of the Christian philosophy and theology of http://en.wikipedia.org/wiki/Emanuel_Swedenborg6) Emanuel Swedenborg (1688–1772).

Key point: The false premise is #2. God made humans for the purpose of ruling over His creation. This also falsifies premise #4.

Scripture does not say that God's purpose in creating humans is for them to rule over God's creation.

The idea that God created humans for the purpose of ruling over his creation is based especially on Bible passages such as:


  So God created humankind in his image, in the image of God he created them; male and female he created them. God blessed them, and God said to them, "Be fruitful and multiply, and fill the earth and subdue it; and have dominion over the fish of the sea and over the birds of the air and over every living thing that moves upon the earth." (Genesis 1:27–28, NRSV, emphasis added)


and:

What are human beings that you are mindful of them,
    mortals that you care for them?
Yet you have made them a little lower than God,
    and crowned them with glory and honor.
You have given them dominion over the works of your hands;
    you have put all things under their feet.
                                       (Psalm 8:4-6, NRSV)


However, neither of these passages states that ruling over God's creation is God's purpose in creating humans. They simply state that giving humans dominion over the remainder of creation is something God has done. It could just as well be said that God's purpose in creating humans is for them to "be fruitful and multiply," or to be "a little lower than God, and crowned with glory and honor"–which God is also said in these passages to do for human beings.

In short, what God does for humans is not necessarily God's purpose in creating humans.

Scripture suggests that God's purpose in creating humans is to be in relationship with them.

Taking any one or a few verses from Scripture in isolation and using them as the basis for major conclusions about God's actions and God's purposes is a fundamentally faulty way of reading Scripture. Especially considering that much of Scripture consists, not of philosophy and theology, but of a narrative, a better approach would be to look at the overall themes of Scripture for clues as to why God created humans.

And a key theme of Scripture overall is the concept of "covenant." In fact, this concept is so central to Scripture that Christians have actually named the two major divisions of their scriptures after the covenant between God and humanity: "The Old Testament" and "The New Testament." "Testament" is another word for "covenant."

Now, a covenant is a relationship between two parties–in this case, God and humanity. And if we follow the biblical narrative, we see that God is continually making and renewing covenants with humanity. For example (emphasis added in all cases):

God made a covenant with Noah:


  I will establish my covenant with you; and you shall come into the ark, you, your sons, your wife, and your sons' wives with you. (Genesis 6:18)


God made a covenant with Abram/Abraham:


  On that day the Lord made a covenant with Abram, saying, "To your descendants I give this land, from the river of Egypt to the great river, the river Euphrates, the land of the Kenites, the Kenizzites, the Kadmonites, the Hittites, the Perizzites, the Rephaim, the Amorites, the Canaanites, the Girgashites, and the Jebusites." (Genesis 15:18–21)


God made a covenant with the Israelite nation:


  Moses came and told the people all the words of the Lord and all the ordinances; and all the people answered with one voice, and said, "All the words that the Lord has spoken we will do." And Moses wrote down all the words of the Lord. He rose early in the morning, and built an altar at the foot of the mountain, and set up twelve pillars, corresponding to the twelve tribes of Israel. He sent young men of the people of Israel, who offered burnt offerings and sacrificed oxen as offerings of well-being to the Lord. Moses took half of the blood and put it in basins, and half of the blood he dashed against the altar. Then he took the book of the covenant, and read it in the hearing of the people; and they said, "All that the Lord has spoken we will do, and we will be obedient." Moses took the blood and dashed it on the people, and said, "See the blood of the covenant that the Lord has made with you in accordance with all these words." (Exodus 24:3–8)


And in the New Testament, Jesus, who is viewed by Christians as "God with us" (https://www.biblegateway.com/passage/?search=Matthew%201:23&version=NIV Matthew 1:23), renewed that blood covenant in symbolic fashion:


  When the hour came, he took his place at the table, and the apostles with him. He said to them, "I have eagerly desired to eat this Passover with you before I suffer; for I tell you, I will not eat it until it is fulfilled in the kingdom of God." Then he took a cup, and after giving thanks he said, "Take this and divide it among yourselves; for I tell you that from now on I will not drink of the fruit of the vine until the kingdom of God comes." Then he took a loaf of bread, and when he had given thanks, he broke it and gave it to them, saying, "This is my body, which is given for you. Do this in remembrance of me." And he did the same with the cup after supper, saying, "This cup that is poured out for you is the new covenant in my blood." (Luke 22:14–20)


These are just a few of many, many passages in the Christian Bible regarding the ongoing theme of the covenant between God and humanity.

This overarching theme of Scripture strongly suggests that in Christian philosophy and theology God's primary purpose in creating humans is not to give them dominion, but rather to establish a covenantal relationship with them.

Relationship is God's purpose in creating humanity.

Swedenborg picks up this theme of relationship as God's purpose in creating humanity in the most philosophical of his theological works, Divine Love and Wisdom:


  Divine love and wisdom cannot fail to be and to be manifested in others that it has created. The hallmark of love is not loving ourselves but loving others and being united to them through love. The hallmark of love is also being loved by others because this is how we are united. Truly, the essence of all love is to be found in union, in the life of love that we call joy, delight, pleasure, sweetness, blessedness, contentment, and happiness. 
  
  The essence of love is that what is ours should belong to someone else. Feeling the joy of someone else as joy within ourselves—that is loving. . . .
  
  Can anyone fail to see this who looks into the essential nature of love? What is loving ourselves alone, really, and not loving someone else who loves us in return? This is more fragmentation than union. Love's union depends on mutuality, and there is no mutuality within ourselves alone. If we think there is, it is because we are imagining some mutuality in others. 
  
  We can see from this that divine love cannot fail to be and to be manifested in others whom it loves and who love it. If this is characteristic of all love, it must be supremely characteristic, infinitely characteristic, of love itself.
  
  In regard to God, loving and being loved in return are not possible in the case of others who have some share of infinity or anything of the essence and life of intrinsic love or of Divinity. If there were within them any share of infinity or anything of the essence and life of intrinsic love—of Divinity, that is—it would not be others who would be loving God. He would be loving himself. What is infinite or divine is unique. If it were in others, it would still be itself; and it would be pure love for itself, of which there cannot be the slightest trace in God. This is absolutely opposite to the divine essence. For love to be mutual, then, it needs to be a love for others in whom there is nothing of intrinsic Divinity; and we will see below [55, 305] that it is a love for others who were created by Divinity. (Divine Love and Wisdom #47–49, emphasis in the original)


What Swedenborg is saying here, in brief, is that the nature of love itself, and especially of divine love, is that it must have others to love, and that love must be mutual, and that it was therefore necessary for God to create finite (non-God) beings whom God could love, and who could love God in return.

Another way Swedenborg formulates this, much more briefly, is found in Divine Providence, which forms a sequel to Divine Love and Wisdom:


  The ultimate purpose of creation is a heaven from the human race. (Divine Providence #324)


Heaven, in Swedenborg's conception of it, consists of people who have freely chosen to be in mutual, loving relationship with God and with one another. This is in line with Jesus' pithy distillation of the entire Scriptures into the two Great Commandments:


  One of them, an expert in the law, tested him with this question: "Teacher, which is the greatest commandment in the Law?"
  
  Jesus replied: "'Love the Lord your God with all your heart and with all your soul and with all your mind.' This is the first and greatest commandment. And the second is like it: 'Love your neighbor as yourself.' All the Law and the Prophets hang on these two commandments." (Matthew 22:35–40)


From the perspective of the Christian philosophy of Emanuel Swedenborg, then, God's purpose in creating humans is to have beings with whom God can be in a freely chosen and mutual loving relationship.

God's purpose in creating humans requires humans to have the ability to reject that relationship.

Finally, to take up the issue of whether or not God created humans "perfectly":

Obviously there is much evil and imperfection in human life, both individually and collectively. The issue of God's perfection, and perfect love, in the face of the existence of evil in God's creation, and particularly in the human element of God's creation, is a vast subject both in philosophy and theology, covered generally under the term "https://en.wikipedia.org/wiki/Theodicy theodicy." Though we cannot fully cover such a vast topic here, the basics, from the perspective of Swedenborg's philosophy, are these:

For a relationship to be truly loving and mutual, it must be freely chosen. If humans were created so that we could do nothing but love God (and one another), we would be mere robots, or mere extensions of God. Our love would be no more real or mutual than that of a computer programmed to display "I love you" on its screen.

For humans to be able to freely and mutually return God's love, then, we must also have the ability to reject God's love, and refuse a mutual, loving relationship with God.

And yet, if everything good is from God, and is God, as Swedenborg's philosophy states, then rejecting God also means rejecting what is good. And rejecting what is good means opting for evil over good.

Therefore in order to fulfill God's purpose of creating a human race with which God could be in mutual, loving relationship, God had to create humans with the ability to reject God, love, and goodness. God therefore had to create humans with the ability to choose, "create," and perpetrate evil instead of good.

This means that the existence of evil in human life and society is not an imperfection in God's creation. Rather, it was necessary for God to allow for it (not create it) in order for God to achieve God's primary purpose in creation of being in mutual, loving relationship with beings other than God's own self.

Conclusion

Based on the above reasoning:

Premise #2, "God made humans for the purpose of ruling over His creation," is false.

Premise #4, "Humans are not perfectly suited toward their purpose," is also false.

According to the Christian philosophy of Emanuel Swedenborg, humans are created perfectly by God to accomplish God's purpose for them. That perfection, however, requires human to have moral and spiritual freedom, so that we can reject God's goodness, and choose evil instead.

The fact that we humans are capable of rejecting God's purpose for us is essential to our very humanity, and to our ability to freely choose to fulfill God's purpose for us, which is to be in a mutually loving relationship with God and with our fellow human beings.
I'm not a nihilist but nihilism, at least the version I know of, is about the idea that there is no inherent meaning or value in life.  This allows you to create your own.  But that does not mean that only the nihilist's values are his own.  He is suggesting that this is the case with everyone.  So he is not at a disadvantage and if anything might consider himself the one awakened to the reality of life (which in Nietzsche's view is that God, religion is dead, for all practical purposes).  So why kill oneself then?  The nihilist enjoys her freedom of self-creation, and also the various pleasures of life.  

As for why each particular nihilist does or does not kill herself, that's a question you need to ask that person in particular.  She might say she values educating others about nihilism of life and so that's why.  Or whatever.  As for subconscious reasons (sorry, my background is in psychology and I know what people say and the actual reason for their actions are not necessarily the same), that would make an interesting study, to psychoanalyze nihilists. :)
Descartes actually addresses something quite close to your objection.

In Meditation 3 where Descartes makes this argument, he suggests that ideas can have three sources:


innate - we are born with
adventitious - come to us from outside (as for example our senses).
imagined - made by fusing different ideas together


Descartes deals specifically at one point with how we can handle animals that we have never seen. His answer is that we do so by taking adventitious ideas and mixing them together. In the case of a unicorn, we are mixing the idea of a horse with some other ideas we've got like horns.

In your question, you suggest, couldn't we have a perfect unicorn. To answer this, we need to think about what perfect means. In your question, I am not entirely sure I grasp its meaning, but I can imagine you mean one of two things:


Perfect-1 = most desirable to me.
Perfect-2 = best thing.


Perfect-1 isn't much of a useful criterion and does not at all seem to be what Descartes has in mind. Perfect-2 appears more useful as a criterion, but it fails to do any good work, because we just punt from "perfect" to "best".

Descartes has something else in mind by perfect than either of these in his "idea of perfection." He means roughly an idea that is unlimited and has what we call "all the perfections." But we actually don't need to completely solve what it is.

We can return to the three types of ideas that Descartes thinks we can have and how we can use these to understand things. Descartes suggests that we understand like this:


God from the idea of perfection
Angels from mixing our idea of God and our idea of ourselves
Humans from our experience of ourselves
Ourselves from our experience of ourselves
Animals from our experience of ourselves and our experience of things
Things from our experience of things


For all of these except God, Descartes thinks we can explain them by what we experience regularly. And that all of them are things we receive in flawed and imperfect ways. (This argument may seem quite dubious to us, but Descartes is less a pure product of modern foundationalism and more a product of medieval scholasticism).

What Descartes finds impressive and uses a proof for God is a type of cosmological proof built on the existence in him of an idea of perfection. This idea stands in contrast to the ideas of himself and animals and things that he can get from experience. First, it contrasts with them in that these ideas are all received imperfectly from the dubious senses. Second, it contrasts with them in having no flaws or gaps in terms of its object. I can have mistaken ideas about cows or myself (see Med. 1 and 2), but I can't on his view have a mistaken idea of perfection itself.

From this, he argues that this idea cannot have come from anything but perfection itself, ergo perfection itself exists.

Why can't this be the unicorn? Well, unicorns are pretty limited things. We see them as occupying a particular place and time and being, well, roughly like horses but different. And that means we can easily see how we combine several adventitious ideas. Descartes's specific example is a chimera (if memory serves) and how it mixes lion and another animal. The same would work here.
With a bit of googling the answer is, quite plausibly I think, https://en.wikipedia.org/wiki/Alfred_North_Whitehead A.N. Whitehead (1861-1947):


  The "one eminent modern thinker" that Copleston refers to is Alfred North Whitehead, who co-authored with Bertrand Russell their monumental work on logic, Principia Mathematica, 3 vols. (Cambridge: Cambridge Univ. Pr., 1925-27). Whitehead was well-known for his metaphysical defenses of belief in God. (Footnote 5 from https://books.google.co.il/books?id=1SBvAAAAQBAJ&pg=PA399&lpg=PA399&dq=coplestone%20russell%20%22modern%20thinker%22&source=bl&ots=nwQFXRnmMZ&sig=rANOhGCReX48YwHgJvdtIXrCtLM&hl=iw&sa=X&ved=0ahUKEwio3pXW4K_RAhUHAxoKHTwaDEEQ6AEIKjAC#v=onepage&q&f=false here.)

Sometimes it helps to read alternative translations.

The quote is from section 32, (part?) VII (p97 of the book 109 of the pdf) in https://ia801405.us.archive.org/12/items/timaeusofplato00platiala/timaeusofplato00platiala.pdf this copy of Plato's Timaeus translated by https://en.wikipedia.org/wiki/Richard_Dacre_Archer-Hind Richard Dacre Archer-Hind, 1888 - the first English edition.  


  "The best of bonds is that which makes itself and those which it binds as complete a unity as possible ; and the nature of proportion is to accomplish this most perfectly. For when of any three numbers, whether expressing three or two dimensions, one is a mean term, so that as the first is to the middle, so is the middle to the last ; and conversely as the last is to the middle, so is the middle to the first ; then since the middle becomes first and last, and the last and the first both become middle, of necessity all will come to be the same, and being the same with one another all will be a unity."


Also, it is from http://www.bard.edu/library/arendt/pdfs/Cornford-Plato'sCosmology.pdf section 32 in this 1937 book (page 44 - 28 in the pdf) by https://en.wikipedia.org/wiki/F._M._Cornford Francis MacDonald Cornford (which I think has a better translation as well as commentary by the author).


  (31 B) Now that which comes to be must be bodily, and so visible and tangible; and nothing can be visible without fire, or tangible without something solid, and nothing is solid without earth. Hence the god, when he began to put together the body of the universe, set about making it of fire and earth. But two things alone cannot be satisfactorily united (31 C) without a third; for there must be some bond between them drawing them together. And of all bonds the best is that which makes itself and the terms it connects a unity in the fullest sense; and it is of the nature of a continued geometrical proportion to effect this most perfectly. For whenever, of (32) three numbers, the middle one between any two that are either solids (cubes?) or squares is such that, as the first is to it, so is it to the last, and conversely as the last is to the middle, so is the middle to the first, then since the middle becomes first and last, and again the last and first become middle, in that way all will necessarily come to play the same part towards one another, and by so doing they will all make a unity."


According to https://en.wikipedia.org/wiki/Alfred_Edward_Taylor Professor A. E. Taylor in his "Commentary", "The formula for the physics and physiology of the dialogue is that it is an attempt to graft Empedoclean biology on the stock of Pythagorean mathematics" (p18). He continues in his distinction of what Plato himself thought and what the character Timaeus presents, 


  "It is in fact the main thesis of the present interpretation that the teaching of Timaeus can be shown to be in detail exactly what we should expect in a fifth-century Italian Pythagorean who was also a medical man, that it is, in fact, a deliberate attempt to amalgamate Pythagorean religion and mathematics with Empedoclean biology"


As for Timaeus's meaning, consider Thomas Taylor's translation of https://plato.stanford.edu/entries/proclus/ Proclus in "https://ia800306.us.archive.org/29/items/ProcluscommentaryOnTheTimaeusOfPlato/33700322-Proclus-Commentary-on-the-Timaeus-of-Plato-all-five-books.pdf Proclus on the Timaeus of Plato"


  32a "For when either in three numbers, or masses, or powers, as is the middle to the first so is the last to the middle; and again, as is the last to the middle, so is the middle to the first; then the middle becoming both first and last, and the last and the first becoming both of them middles, it will thus happen that all of them will necessarily be the same. But becoming the same with each other, they will be one."
  
  In the first place, it is requisite to explain what is here said mathematically; and in the next place, physically, as being that which is especially proposed to be effected. For it is not proper to separate the discussion from its appropriate theory. There are therefore some who think that Plato in these words defines the geometric middle, and among other things which they assert, they say that the geometric middle is properly exclusive of all the others analogy; but that the others may be justly called middles. Nicomachus also is of this opinion, and he speaks rightly. For geometric proportion is properly analogy; but it is requisite to call the others middle, as Plato also says further on in the generation of the soul. But the others are improperly called analogies. To others, however, these appear not to have apprehended the meaning of Plato properly.


and T. Taylor continues... 


  Plato clearly assumes the geometric middle. For it is the peculiarity of this proportion, that the first has the same ratio to the middle that the middle has to the third term. As, however, there are three middles, the  arithmetic, the geometric, and the harmonic, and these being such as we have shown them to be, Plato very properly assumes these three  subjects, numbers, masses, and powers. For the arithmetical middle is in numbers; the geometrical is in a greater degree conversant with continued [than with discrete] quantity; and the harmonical middle is in powers. For it is conversant with sharp and flat sounds. And after this manner you may speak, distinguishing the middles according to their predominance.

https://en.wikipedia.org/wiki/A._J._Ayer A. J. Ayer, a very famous twentieth century analytic philosopher, with the help of http://londonschoolofphilosophy.org/?page_id=8 Jane O'Grady published a book entitled http://rads.stackoverflow.com/amzn/click/0631194789 A Dictionary Of Philosophical Quotations which should provide you with exactly what you are looking for.

In addition, https://en.wikipedia.org/wiki/Bartlett's_Familiar_Quotations John Bartlett's book Bartlett's Familiar Quotations is one of the most famous collection of quotations in existence. Per its wikipedia entry: 


  Bartlett's Familiar Quotations, often simply called Bartlett's, is an American reference work that is the longest-lived and most widely distributed collection of quotations. The book was first issued in 1855 and is currently in its eighteenth edition, published in 2012.


The quotations range over many different subject matters, not just philosophy; however, you will likely find a lot of the quotations to be inspirational and or something worth reflecting on in a philosophical way. 
I confronted the same issue several years ago. It depends on how much you think you need to understand of this works. I read a nice paper(whose author and title I forgot) on Aristotle's works, and this author put it as this: view his works all taking a place in a circle, where no particular work is more important than the other; pick one, and you'll see that in it will be references, hints, and etchings to his other works; they all cross each other in no particular order. 

So no, you don't have to start with the Organon.

I would to start with his simpler works, such as Rhetoric or Nicomachean Ethics. Keep in mind that a lot of his science is disproven or excessively lengthy. This is, mind you, one of the men who thought atoms simply did not exist. Throughout his science works, however, you'll find charming little observations that, given a talented translator, will play on the mind like poetry. 

Although many of things are disproven or whatnot, they serve develop an understanding for the foundation of western knowledge, if you're looking to trace a genealogy of knowledge. But that doesn't mean everything he wrote is obsolete. There are many instances of Truths, just like there is in Plato. 

The great thing is that his works are still useful today, even in a practical sense. Kenneth Burke, a dramatist and must for all rhetoric students, developed his famous pentad from Aristotle's work; So here, we have the influence and shaping of ancient greek philosophy upon 20th century thinking(even though Aristotle was Macedonian). 

Another paper I read, again whose author and title escapes me, asks us to consider whose Aristotle are we reading, referring to the many translations that were done over the centuries. Still, there he provides us with a peephole of an era that was before the emergence of individualism and the cultural movement. 
Setting and provisional answer

As your quote is a note regarding a certain sentence, I will first quote this one for providing context:


  He who has the right to vote in this legislation is called a citizen (citoyen, 
  i.e., citizen of a state, not of a town, bourgeois). The quality requisite to this, 
  apart from the natural one (of not being a child or a woman), is only that of 
  being one's own master (sui iuris), hence having some property (and any art, 
  craft, fine art, or science can be counted as property) that supports him -
  that is, if he must acquire from others in order to live, he does so only by 
  alienating what is his [!here comes the note!] and not by giving others permission to make use of 
  his powers - and hence [the requisite quality is] that, in the strict sense of 
  the word, he serves no one other than the commonwealth. (On the Common Saying... 8:295)


Having both parts together now, we can analyze what this is all about: It is about requirements counting as a citizen. The main condition is according to him being sui iuris, i.e. independent or one's own master qua property.

The difference between a barber and a wigmaker therefore is that the barber indeed has property in sense of a craft just as the wigmaker, but he is not independent through it because he never really posesses it, he necessarily "alienates what is his"

Alienation vs. production of property

So what does it mean that he alienates his property, i.e. his craft? Well, Kant is quite explicit about it:


  ... the former [wood cutter] differs 
  from the latter [tailor], as a barber from a wigmaker (even if I have given him the hair for the wig) 
  and hence as a day laborer from an artist or craftsman, who makes a work that belongs to him 
  until he is paid for it). (emphasis mine)


The difference therefore lies in the point that the barber, even when executing his craft, does never own (the fruits of) his work, whereas the wigmaker does. A barber is dependent on hoping to get paid for what he did (= alienated from him - his labour power) without ever posessing actual property to trade, i.e. he does not own the product of his work.

He is in this sense a service provider (to translate it into a modern term) and closer to a day labourer - offering nothing more than his labour power - than an artist/craftsman. This is also coherent with the difference between a wood cutter and a tailor.

Keep in mind, though, that the last sentence of the note clearly states that this criterion is problematic, as it was hard to determine when someone really is one's own master, implying that there is some kind of a grey area. Ironically, this makes the criterion correct theoretically, but of no use in practice.

But....why?!

From today's perspective, this view must seem odd. But indeed, it is an improvement compared to the normal ancient view, like Hannah Arendt depicts it in The Human Condition (Arendt is very detailed and shows this point for e.g. Plato and Plutarch as well as Aristotle, her main focus; this is only a very short outtake!):


  What prevented the polis from violating the private lives of its citizens and made it hold sacred the boundaries of surrounding each property was not respect for private property, but the fact that without owning a house a man could not participate in the affairs of the world because he had no location in it which was properly his own. (29-30, 2nd edn.)


Here, property is the central concept as well. But instead of narrowing it to owning a house (and don't having to work for sustaining one's life at all!) as a necessary requirement for being a citizen, Kant allows for much more people to achieve the status of a citizen, i.e. a zoon politicon. That is a huge improvement! This reference could also be reflected in his distinguishing of citoyen [state and in reference to Rousseau] and bourgeois [polis].

The same thought of property grounding state and citizenship is found in Locke's Second Treatise of Government, coincidentally containing one of the few early bits of philosophy about the concept of work as well. I actually think this may be the main adressee here, although the section is supposed to be against Hobbes by its title. The big difference is that Locke simply assumes you make something your property through work, not even considering other cases.

The argument for revoking materially dependent persons the right to vote by many authors (e.g. Locke, Kant himself, and, very influential for Kant, Achenwall/Wolff in Germany and Abbe Sieyès in the wake of the French Republic) is that they are dependent. In fact, allowing them to vote would, so the argument says, result in them voting to please their masters or the persons they depend on. By that, those who own more would have more weight in the electorate than those who are independent as well, but own less. Or, to put it differently: Some citizens would effectively have more than one vote. So, given you want equal vote, you either disqualify some as active citizens (Kant's solution) or fight against material dependency as a whole (Marx' solution), see e.g. Vorländer, K. (1926). Kant Und Marx Ein Beitrag Zur Philosophie des Sozialismus.

One should keep in mind that voting by secret ballot in independent election was not exactly standard back then. Maliks (see below) quotes Allen Rosen writing:


  those who depend on others for their livelihood would either be too eager to please their masters or too susceptible to pressure, particularly in an open ballot system, for their votes to be truly their own (p.81)


There is also a formal reason: Kant uses the Hobbesian criterion from De Cive that "[the citizen] serves no one other than the commonwealth". As again Maliks writes:


  The reason is that women and the financially dependent are incapable of voting impartially because they answer to masters other than the state.


So e.g. civil servants are in some sense "dependent", but they are nevertheless "their own masters", as they serve no one other than the state. (p.108)

This view must seem odd in modern understanding, but was the practice of the time.

I would therefore argue that it must seem odd considering La Grande Révolution had happened already, the idea of fundamental equality etc. But especially regarding the philosophy of work, it is a considerable advance compared to everything that had been there before. Additionally, the development from Kant over Hegel to Marx' Theory of Alienation may be seen as presaged.

Further Reading and scholar's answer

Of course, the inner tension between moral theory and accounts of citizenship is widely discussed (and already had been in his times). For a historical view, see Maliks, Reidar (2014): Kant's Politics in Context, Oxford UP, Ch.3 (pp. 80ff). For two different contemporary approaches to this problem see James, David (2016): Independence and Property in Kant's Rechtslehre , British
Journal for the History of Philosophy, 24:2, 302-322 and especially Storey, Ian (2012): Kant's Dilemma and the Double Life of Citizenship, Contemporary Readings in Law and Social Justice, 4:2, pp. 65–88.

Maliks writes, referring to the argument laid out earlier (p.81):


  Most scholars agree that he [i.e. Kant] was convinced that the votes of the many who were economically dependent would distort the general will, given his doubts about their ability to make free and rational choices about public matters.


In this text, there are further sources to be found for that argument probably being what Kant had in mind there as well.

Aside

In German, the translation of sui iuris - selbständig - coincedentally can be understood both as independent and self-employed, which may be understood as the modern equivalent of what Kant describes here.
To me, it seems the professor's primary point was that her choice to break the law would put her family at "risk" or otherwise inconvenience them. Frankly, an Objectivist would not care about this, and would certainly not let it dictate their morality.

Furthermore, an Objectivist would reject such a law as immoral. In "What is Capitalism?", Capitalism: The Unknown Ideal, Ayn Rand writes (emphasis added):


  Capitalism is a social system based on the recognition of individual rights, including property rights, in which all property is privately owned. The recognition of individual rights entails the banishment of physical force from human relationships: basically, rights can be violated only by means of force. In a capitalist society, no man or group may initiate the use of physical force against others. The only function of government, in such a society, is the task of protecting man's rights, i.e., the task of protecting him from physical force; the government acts as the agent of man's right of self-defense, and may use force only in retaliation and only against those who initiate its use; thus the government is the means of placing the retaliatory use of force under objective control.


Objectivism advocates a sharply limited form of government, where the state has power only to take actions that are necessary to secure the rights and freedoms of the individual. This, it is held, is necessary in order to prevent excess governmental power from being turned against individual freedom and being used to restrict it.

Although an Objectivist would concede that the government needs to provide civil law (contracts, torts, etc.) as a positive service, this should be restricted by clear, objective standards. The laws must be based in "essential principles", by which is meant "grounded in the principles of individual rights." 

Thus, since government's only function is to protect rights, and the law that you describe does not protect rights—and moreover serves to restrict an individual's free exercise of rights—that law would be on face immoral and you could not possess a moral obligation to follow it.

I think you will find Rand's essay "Man's Rights" (reprinted in The Virtue of Selfishness, as well as other volumes of her work) most illuminating of these views. Here is a relevant excerpt; you can read https://campus.aynrand.org/works/1963/04/01/mans-rights/page1 the full text online here:


  “Rights” are a moral concept — the concept that provides a logical transition from the principles guiding an individual’s actions to the principles guiding his relationship with others — the concept that preserves and protects individual morality in a social context — the link between the moral code of a man and the legal code of a society, between ethics and politics. Individual rights are the means of subordinating society to moral law.
  
  The most profoundly revolutionary achievement of the United States of America [in contrast to previous "statist" and "altruist-collectivist" societies] was the subordination of society to moral law.
  
  The principle of man’s individual rights represented the extension of morality into the social system — as a limitation on the power of the state, as man’s protection against the brute force of the collective, as the subordination of might to right. The United States was the first moral society in history.
  
  All previous systems had regarded man as a sacrificial means to the ends of others, and society as an end in itself. The United States regarded man as an end in himself, and society as a means to the peaceful, orderly, voluntary coexistence of individuals. All previous systems had held that man’s life belongs to society, that society can dispose of him in any way it pleases, and that any freedom he enjoys is his only by favor, by the permission of society, which may be revoked at any time. The United States held that man’s life is his by right (which means: by moral principle and by his nature), that a right is the property of an individual, that society as such has no rights, and that the only moral purpose of a government is the protection of individual rights.
  
  A “right” is a moral principle defining and sanctioning a man’s freedom of action in a social context. There is only one fundamental right (all the others are its consequences or corollaries): a man’s right to his own life. Life is a process of self-sustaining and self-generated action; the right to life means the right to engage in self-sustaining and self-generated action — which means: the freedom to take all the actions required by the nature of a rational being for the support, the furtherance, the fulfillment and the enjoyment of his own life. (Such is the meaning of the right to life, liberty and the pursuit of happiness.)
  
  The concept of a “right” pertains only to action — specifically, to freedom of action. It means freedom from physical compulsion, coercion or interference by other men.
  
  Thus, for every individual, a right is the moral sanction of a positive — of his freedom to act on his own judgment, for his own goals, by his own voluntary, uncoerced choice. As to his neighbors, his rights impose no obligations on them except of a negative kind: to abstain from violating his rights.


That last paragraph in particular should really clench your understanding of why an Objectivist would take issue with a law like the one to which your professor alludes. It is inconsistent with the singular purpose of government, it is coercive to the individual in that it prevents her from exercising her own voluntary freedom of choice—to live her life as she sees fit. The state would be compelling the individual to act against her own judgment, and that would be intrinsically immoral. The government, even as it represents a collective of individuals, cannot thus force positive moral obligations upon its individual members.
My concept of God is that it is not meaningful to describe the omnipotent God as bound by any human constructs of logic or any other mortal rule.  Just doesn't make sense to say that "God must do this or God must do that or God cannot do this other thing."

I think that God chose to give people (as well as other creatures) free will and to make that will truly free.  Now just because I will the current occupant of the White House to be forcibly removed and tossed out to the street, doesn't mean that my will is realized in reality.  So my will is not omnipotent even if I choose that it is.  God's will is omnipotent but God can choose to cede power to mortal humans whose will may be to choose differently than what is the will of God.  Sometimes in Christian circles we differentiate this with semantics like "God's perfect will" and "God's permissive will.", but that is a human construct and I don't expect God to be bound by that.  But that differentiation between two different attributes of God's will (attributes cooked up by mortals so they might try to wrap their brains around this thing) is useful to me when I try to grok the Problem of Evil.

This response to the Problem of Evil appears to me to be compatible with https://en.wikipedia.org/wiki/Alvin_Plantinga's_free_will_defense Alvin Plantinga's thinking.

So while mortals may act in a manner contrary to the perfect will of God (but we don't have to, we can choose to act in a manner consistent with the perfect will of God), we mortals cannot act in a manner contrary to the permissive will of God.  Some evil is within the scope of God's permissive will (and some is not), but no evil is within the scope of God's perfect will.
I believe you have https://en.wikipedia.org/wiki/God_of_the_gaps "God of the gaps" fallacy in mind, it is a particular case of https://en.wikipedia.org/wiki/Argument_from_ignorance ad ignorantiam, appeal to ignorance, which in its turn is a case of a false dilemma.

The fallacy is to take the absence of contrary evidence for evidence to the contrary, in this case the lack of scientific explanation of a phenomenon as evidence for impossibility of such explanation, and therefore for the necessity of a supernatural explanation (theistic or not). In other words, the fallacy takes the lack of scientific explanation as the evidence for the supernatural. The false dilemma aspect of it is that scientific/supernatural are taken as the only options available, which overlooks the possibility of having insufficient information to decide between the two. Interestingly, the term  "God of the gaps" was invented not by critics of religion but by Christian theologians to point out the flaw in the https://en.wikipedia.org/wiki/Teleological_argument teleological arguments for God's existence.
I can only presume that the comment is metaphorical, meant to imply that at some point one has to take account of the failure of intellect in criminal responsibility. 

Such a situation of recursive states of "unawareness" obviously cannot really persist without very quickly reaching a point of such ignorance as to represent someone who is comatose. This is why such an argument does not, in fact, apply in law, but instead law takes a pragmatic position that unless proven otherwise, people are aware that their actions have consequences, and that the law requires them to foresee and mitigate those consequences to a certain extent. 

Thus, from a pragmatic point of view, only two states (i.e. the 1st 2 levels) are required to considered: the unawareness and the meta-unawareness. 

The 1st level is plausible: a person can be unaware of the exact consequences of her action.

The 2nd level is conscionable: She can be unaware that their action is the type of action whose consequences might need examining for possible illegality. 

But the 3rd is  to speculate a person who is unaware that there even exist actions whose consequences may need to be investigated for their illegality, and so is to speculate a person who is unaware of the law at all. Not only could this never be practically applied as it would make a virtually un-disprovable defence against any misdemeanour, but it is so unlikely that the law treats it a special case of diminished responsibility on the grounds of mental impairment.

A fourth level is where someone is unaware that there could be such a thing as awareness of the consequences of actions, but has not, to my knowledge, ever been encountered in a conscious human and so is irrelevant to any discussion of human law.
Friedrich Nietzsche, https://en.wikipedia.org/wiki/Thus_Spoke_Zarathustra Thus Spoke Zarathustra: A Book for All and None (German: Also sprach Zarathustra: Ein Buch für Alle und Keinen) (1883-91), https://books.google.it/books?id=sMHmCwAAQBAJ&pg=PA68 First part :


  "Alone I go now, my disciples! You too must go away, now, and alone. Thus I will it. 
  
  [...] Go away from me and guard yourselves against Zarathustra! And better still: be ashamed of him! Perhaps he has deceived you. [...]
  
  Now I bid you lose me and find yourselves; and only when you have all denied me will I return to you."

I think the argument remains valid, it is just staged in a way that assumes we would never get to this degree of mutual manipulation as a social process.  I would go with your second option, and then go farther.

Pornography is still a tease.  It pretends to portray something realistic, but it has carefully chosen to present individuals who are not accessible to most people.  It does not deliver sex, so it still only goes as far as presenting the possibility.  Clearly, you can masturbate without it, so it is adding something to your experience only in allowing you to imagine what you cannot attain.

If it did not create a need without satisfying it, since it lacks meaningful physical content it, it could not maintain its status as a commodity.

One could say that even of prostitution and recreational pharmaceuticals.  If the prostitute honestly satisfied the need for which they are sought, sex addiction would not be a real thing.  One can only to a certain bizarre degree want an endless supply of food or even human company, but one can easily want an endless supply of sex or drugs.  Examples like https://en.wikipedia.org/wiki/Rat_Park "rat-vanna" and the reasonable prevalence of successful marriage show that this is not an aspect of form, but of delivery.

To a certain degree, these theories originate in a theoretical psychological correction to explain the failure of the labor theory of value.  From this trans-Marxist point of view, only by being a partial satisfaction that ultimately fails, can any commodity have a value uncorrelated with its cost of production.  Unlike things like food or housing or other real services, media and services of socially reconstructed needs lack a correlation between their perceived value and production cost or real measures of quality.
There are many different ideological lines within Marxist thought and the analysis of the labor's movement problems is defined by these different perspectives. The question thus can be considered too broad to be answered in brief so I will focus to the issues raised in the question. 

In general Marxism analyzes the relations between economic classes, the peaks, the setbacks, the crisis of capitalism, of the labor movement, of the trade unions etc as a dense net of interrelationships, human history and progress of society passes through contradictions that determine the course of the subjects under examination. 

Capitalism is able through the use of various means to prolong and secure its existence but it can't override its inner contradictions, so the capitalistic crisis is here to stay. 

Some of the most obvious and commonly analyzed such means are imperialism, the destruction of productive forces, the ideological dominance of conservative forces via the control of mass culture, the division of the labor movement and the enforced confrontation of some parts of laborers towards other. 

Other reasons may be the ineffectiveness of forms of organization and struggle, the conservativisation of political forms of organization, the echo of the black pages of Stalinism and more.

When we analyze the political movements there is a risk of oversimplification, for example it can be seen that the organization of the labor movement at the international level is in decline but one can analyze this and vice versa. In practice we have the actual advent of a real internationalism, people are seeing through the subtle differences between nations, races, sexes and the contemporary crisis of capitalism makes this transparent.

On the last question it is obvious that a social system such as patriarchy which was prevalent for a wide historical period can not be reversed at a very fast pace but certainly the modern world is confronted with the traditional organization of patriarchy and women through their participation in capitalistic production, the evolution of our societies, etc are gradually equalized with men in the whole world. 
In The Great Disruption and in Trust, the conservative political philosopher https://en.wikipedia.org/wiki/Francis_Fukuyama Francis Fukayama gives an economic interpretation to 'social capital' looking at how liberal economics only works because assumptions based upon traditional principles can be taken for granted.

For example, where there is no underlying sense of honor, corruption prevents meritocracy no matter how much economic force arises to encourage it.  Without investing real capital to suppress corruption, instead of creating efficiency, the pressure demanding better use of resources instead leads instead to pretense, greater waste, and ultimately failure.

As a less traditional example, he indicates the ease with which Americans will simply get into another person's car, and still feel safe, in a way that some Europeans would be scared to do, and many Central Americans would be objectively stupid to do.  (It is not that the other American whose car you get into is actually less violent than his European or Central American counterpart, we have more crime that Europe, and less than Central America, to approximately equal degrees, and both of those cultures see this as equally weird.  It is particularly American ethical quirk that we extend the expectation that one should be gracious in one's own home, to our automobiles.)

This creates an opportunity for an economy of low-oversight taxi service, and ultimately Uber...

The fact it creates the opportunity for efficiencies makes this a form of capital, in certain terms.  Once it is lost, more genuine economic capital must be invested directly to offset the cultural drag that ethical assumptions used to counteract.
The philosopher https://en.wikipedia.org/wiki/J._L._Austin J. L. Austin, in his 1957 paper "https://sites.ualberta.ca/~francisp/NewPhil448/AustinPlea56.pdf A Plea for Excuses", makes a distinction between justifications and excuses. Contrasting these notions, he writes:


  In the one defence, briefly, we accept responsibility but deny that it was bad: in the other, we admit that it was bad but don't accept full, or even any, responsibility. (p. 2)


In one of his examples Austin considers killing:


  this may be on the ground that the killing was done in battle (justification) or on the ground that it was only accidental if reckless (excuse).


In other words, providing reasons is a way to argue that your action was right, or justified. Presumably, you would do it again under the same circumstances. Offering excuses, on the other hand, is a way to argue for not being held responsible, e.g. due to factors beyond your control.
Here is some historical context. In https://en.wikipedia.org/wiki/The_Foundations_of_Arithmetic Grundlagen der Arithmetik (1884) Frege introduced his ill-fated Axiom V, now known as the https://en.wikipedia.org/wiki/Axiom_schema_of_specification#Unrestricted_comprehension axiom of unrestricted comprehension: every predicate defines a class of objects that satisfy it, called its extension (Frege's own formulation is more technical). This led to the set of all sets and then to the Russell's paradox in 1901 (apparently discovered by Zermelo before Russell, see https://hsm.stackexchange.com/questions/5228/how-did-russell-arrive-at-the-paradox-demonstrating-the-inconsistency-of-naive-s/5234#5234 How did Russell arrive at the paradox demonstrating the inconsistency of naive set theory?). But already at the time of the writing Frege already knew that the full force of Axiom V was not needed for his proofs, or for deriving the philosophical consequences he wanted. A weaker claim sufficed, the so-called https://en.wikipedia.org/wiki/Hume%27s_principle Hume's principle (it was considered even before Hume, but adopted only after Cantor, see https://www.cambridge.org/core/journals/review-of-symbolic-logic/article/measuring-the-size-of-infinite-collections-of-natural-numbers-was-cantors-theory-of-infinite-number-inevitable/325464FFF1E318E3E51A80E652FA1C5B Mancosu's Measuring the Size of Infinite): 


  The number of Fs is the same as the number of Gs when there is a one-one correspondence between the Fs and the Gs. 


Of course it was harder to sell this as a "law of thought", and the whole point of Frege's logicism was to derive mathematics from logic, the laws of thought. But even after Russell pointed out the problem with the set of all sets not belonging to themselves Frege did not try to save his system by switching to the Hume's principle. He was apparently deterred by the "Julius Caesar problem" laid out as the "third doubt" in Grundlagen §66:


  "In the proposition [“the number of Fs is the same as the number of Gs”] [the number of Fs] plays the part of an object, and our definition affords us a means of recognizing this object as the same again, in case it should happen to crop up in some other guise, say as [the number of Gs]. But this means does not provide for all cases. It will not, for instance, decide for us whether [Julius Caesar] is the same as [the number zero] — if I may be forgiven an example which looks nonsensical. Naturally, no-one is going to confuse [Julius Caesar] with [the number zero]; but that is no thanks to our definition of [number]. That says nothing as to whether the proposition [“the number of Fs is identical with 
  q”] is to be affirmed or denied, except for the one case where q is given in the form of [“the number of Gs”]. What we lack is the concept of [number]; for if we had that, then we could lay it down that, if q is not a [number], our proposition is to be denied, while if it is a [number], our original definition will decide whether it is to be affirmed or denied." [boldface mine]


What Frege is saying here is that mere Hume's principle does not allow us to distinguish between numbers and non-numbers (like Julius Caesar), because the concept of number is lacking. We need a definition of numbers, not just a rule for establishing their equality in a special case. https://plato.stanford.edu/entries/frege/#AnaStaNum Axiom V provides for such a definition (for example, number zero is the extension of a concept under which nothing falls, i.e. the null set), while the Hume's principle does not. A good review of related issues is http://rgheck.frege.org/pdf/published/JuliusCaesarObjection.pdf Heck's The Julius Caesar Objection, who makes an interesting comment:


  "All of this having been said, the question arises why, upon receiving Russell’s famous letter, Frege did not simply drop Axiom V, install Hume’s Principle as an axiom, and claim himself to have established logicism anyway. The question is not only of historical interest. Though Frege did not himself adopt it, this position has seemed to some a worthy heir to Frege’s logicism: On one version of it, Hume’s Principle is thought of as embodying an explanation
   of the concept of number, whence, even though it is not a principle of logic, perhaps it has a similarly privileged epistemological position... The historical question is made pressing by the fact that, in a letter to Russell, Frege explicitly considers adopting Hume’s Principle as an axiom, remarking only that the “difficulties here” are not the same as those plaguing Axiom V."

Holism is an epistemological position, and externalism is a semantic one. Of course, some degree of interaction is to be expected, but not only is it possible to hold them together, it is not particularly challenging. The appearance of incompatibility comes from the misleading use of the word "meaning". In the holism, especially Quine's and Davidson's, "meaning" is an obscurity best left out of the vocabulary. There is no such "thing" as "meaning", sentences involving it rephrase facts about inference, relating concepts to one another, or acting based on them. Quine explicitly endorses Wittgenstein's "meaning is use", see https://uni.hi.is/opj/files/2011/02/OPJ-quine-kripke-wittgenstein.pdf Quine and Kripke’s Wittgenstein by Jónsson. It is not too far off to say that on Quine's (and Wittgenstein's) view the externalism/internalism distinction is altogether moot, there is no internal "there" (traditionally hypostatized as "meaning") there. The issue is pressing only for realists more robust than Quine.

In its turn, externalism explains how language user relates to her referents, not whether the reference is established atomistically or holistically. The chief opponents of externalists are not holists, but https://plato.stanford.edu/entries/content-causal theorists of content, like Dretske and Fodor, who advocate the computational theory of mind creed that "meaning" inheres in some sort of materially coded "information" in the brain, and then proceed to explain how this "information" relates to "reality" (the problem of intentionality). It is true that Kripke gravitates towards realism, even essentialism, this is needed to ground his modal logic in the face of Quine's objections to its interpretability. There are also disagreements over Kripke's metaphysics vs Quine's empiricism, intensionality vs extensionality, de re vs de dicto, etc., contingent a priori, necessary a posteriori are also related to this. https://philpapers.org/archive/TUBQAQ-3.pdf Tuboly's Quine and Quantified Modal Logic is a good review of these controversies from a historical perspective. It is even true that Putnam finds Quine's holism to be too much, and advocates the reality of natural kinds. 

But all these issues are separate from externalism. One can perfectly well hold that we pick up https://plato.stanford.edu/entries/meaning/#DavPro semantics semi-holistically a la Davidson (by applying charity to the totality of other users' linguistic behavior), but that what we pick up is still external-context-dependent, and so the "meanings" (i.e. conceptual and operational roles) are different on Earth and Twin Earth. I suppose one could argue that holism undermines realism (Quine's claims to be a "realist" notwithstanding), and hence the distinctions that externalists uphold. But even anti-realists have to take ontology at least as a temporary make believe reflecting the best of current science, and within it the question re-emerges in a more pragmatic way: is it more effective to represent "meaning" in our theories as an engram in the head, or as spread over the environment. I suspect that Quine's physicalism and behaviorism would tip him towards the latter. The https://en.wikipedia.org/wiki/Causal_theory_of_reference causal theory of reference, which is considered to imply externalism, has a distinct holistic flavor, reference is picked up opportunistically by imitating linguistic behavior of others.
it's an interesting question and one I struggled with when I started studying philosophy.  For me the answer really does depend on the writer, and even on the work.   For example Sartre's Being and Nothingness can be absurdly dense, but that is in part (at least I found) because it presupposes knowledge of Heidegger's work that proceeded it, whereas Existentialism and Humanism was written as a public lecture and is therefore much more accessible.

In my experience it is always better to engage with secondary sources where possible, particularly critical ones.  This will allow you to build a more robust understanding of any theory and you can benefit from the work of all these philosophers and avoid 'going it alone'.

My method usually begins with a primary source, depending on whether I can make any sense of it with my current knowledge.  If not I usually look for reader's guides, which can be really illuminating.  Otherwise I will read through the source, making notes and summarising much as you do.  I take notes, and after each chapter/section/paper I try to answer the following questions:

What assumptions are being made by the author in this text?

What is the main point/thesis of the text?

What are the authors objectives?

How is the text organised/structured?

How does the author support their argument?

Another thing to keep in mind is when you are reading, identify the parts that you think are clear and are not clear, try to discern what makes something more readable and understandable, and what obfuscates issues. This will set you in good stead for when you start your own academic writing.  

Edit:  I know that Sartre formed a lot of his views during the second world war.  Before French occupation Sartre worked as a meteorologist for the French army.  A leisurely job that involved sending up balloons and tracking their progress across the sky.  He was then captured and held as a prisoner of war, during which time he is said to have first read Heidegger.
I think it's going to depend on what you then plan to do with those views. Specifically, are you taking them as valid or invalid assumptions for doing ethics (i.e. will you knock them down or does your paper focus elsewhere and take them for granted?)

If my goal is to attack a common place view, then it really helps to have some evidence that the view is common place. If you can't get that, then


  In the Modern West, many people intuitively believe that ...


(bears some weakness on dubitability but ...)

OR


  It is commonly held that ... 


(Weakness of where? who?)



If you are going to grant these claims and focus elsewhere


  I will take it for granted that ...


(you can add the common place somewhere in there but it's not absolutely necessary).


  While argument can be made for and against, I will for the purposes of this paper work under the assumption that ...  


In this case, it's wise to pick assumptions that make your argument harder in which case you can add:


  I do so because if I can prove my claim under these conditions, it also obtains without these assumptions.


A good place to look is Peter Singer's "Famine, Affluence, and Morality" where he artfully uses views and positions that aren't his to highlight the effectiveness of his claim even outside his framework..



For the first category, famous citations and statistics help (I would suggest for instance Kant's views on animal suffering as a place to start). For the second category, you don't really need them. Depending on the scale of where you are trying to make these claims, this is not the most important thing to focus on. (If you are aiming for a journal, try to see if people in that journal generally concern themselves with (a) empirical surveys when they mention common views or (b) like famous figures or (c) gleefully say things like this without citing anyone).
The ethico-mathematical analogy is ancient, but it did gain some recent prominence among analytic philosophers. https://philpapers.org/rec/CLAMET Clarke-Doane's Moral Epistemology: The Mathematics Analogy, http://web.maths.unsw.edu.au/~jim/matheth.pdf Franklin's On the Parallel between Mathematics and Morals, https://www.jstor.org/stable/2253929 Lear's Ethics, Mathematics and Relativism all focus on the analogy. And all of them name book VII of Plato's Republic as its point of origin, where Plato outlines the work that the analogy is supposed to do: 


  "In mathematics, according to him, we come to perceive that which is universal, immutable and abstract: this is supposed to be relevantly similar to perception of the Good." [Lear] "Insight into the necessities of mathematics is apt for training the mind to love the necessities of ethics, and hence motivates the ruler to make this world conform to those necessities, to the degree that that is possible. The necessities of mathematics also make good models of absolute objectivity, for those seeking examples of truths independent of the arbitrary and subjective judgments of individuals and tribes." [Franklin]


It is the "self-evidence" of mathematical truths, despite the apparent lack of empirical input, and their peculiar "objective certainty", beyond that of any empirical surmise, that attracted many subsequent ethical rationalists to the analogy. If mathematics can credibly discover eternal truths, it went, so can ethics. This traditional use is rather problematic today.

Kant may still have been impressed by the mystiques of mathematical certainty and the moral law (https://plato.stanford.edu/entries/kant-development/#ChiStaSkyAboMeMorLawWitMe "Two things fill the mind with ever new and increasing admiration and awe, the more often and steadily we reflect upon them: the starry heavens above me and the moral law within me"), and reserved the same mode of justification for both, his synthetic a priori. But already Hume had doubts about both, which Kant chose to overlook, and in mathematics at least the mystique went by the way of logicist "laws of thought" that Frege and Russell never quite found. After the wrangling over Cantorian infinities and the axiom of choice, intuitionism, Gödel's incompleteness, Cohen's set-theoretic pluralism, Quine (mathematics as holistic completion of empirical theories), late Wittegenstein (mathematics as "grammar"), etc., it is hard to see how the analogy can do the justificatory work that rationalists expected of it. Moreover, Dostoevsky, Nietzsche, existentialists, and the two world wars, provided quite independent reasons to cast aside the ethical rationalism itself.

Still, it is perhaps of independent interest to explore to what extent the analogy holds, irrespective of the use rationalists and moral realists put it to. One obvious problem is that while mathematics, at least prima facie, is a corpus of truths, this is not exactly the case in ethics. Per Humean view, "murder is wrong" is the imperative "do not murder" rephrased, and imperatives are not eligible for having truth values. This of course is a version of https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem Hume's is-ought guillotine, "never the twain shall meet". Even if we get over non-declaratives having truth values somehow the next problem is the cultural and emotional neutrality of mathematics vs the opposite in ethics. Clarke-Doane creatively uses this wedge to argue that moral realism is more credible than platonism:


  "One obvious difference between mathematical disagreement and moral disagreement is that the latter tends to track with personal and religious investment in a way that the former does not. But this disanalogy only bolsters the suggestion that mathematical propositions have no better claim to being self-evident than moral propositions. Mathematical disagreement typically occurs among the intellectually virtuous and seems to be largely independent of personal and religious investment. Such disagreement raises doubts about the supposed self-evidence of the relevant propositions far more effectively than paradigmatic moral disagreement."


But this argument seems odd to me. It can just as easily be turned around to argue that the apparent scarcity of personal and cultural biases in mathematical controversies makes it more credible that their subject matter has at least some claim to objectivity. If http://www.rci.rutgers.edu/~stich/Publications/Papers/SemanticIntuitions.pdf cultural dependence of "linguistic intuitions" is taken to go against the objectivity of their substrate why should it be different for ethical ones? The same is confirmed by what even Clarke-Doane himself points out in another context:


  "Note that the puzzle in the mathematical case is not just that the relevant properties fail to participate in causal relata. The objects of which they are predicated fail to so participate as well. By contrast, moral truths are about objects that do participate in causal relata. For example, Osama Bin Laden, the Holocaust, and the Lincoln’s freeing of the slaves, all so participate."


But the self-evidence and objectivity of mathematics are arguably due to the abstract, non-empirical nature of its objects, which allows us fuller control over them. We do not see the definitional build-up in ethics on the same scale exactly because of its concreteness, nor do we see rigid logical arguments. One needs only to read the "proofs" in Spinoza's Ethics or https://en.wikipedia.org/wiki/A_Theory_of_Justice Rawls' Theory of Justice to see how loose they are, and these are the authors who explicitly adopted Euclid as the standard! "We should strive for a kind of moral geometry with all the rigor which this name connotes", Rawls tells us. But of necessity rooted in the subject matter, ethical arguments are only heuristic, and weighted heavily by definitional vagueness and said or unsaid ceteris paribus clauses.

Perhaps there is way to salvage some aspects the analogy in a creative way, by giving up traditional realism on both sides. Mathematics survived, and remained credible, through all the controversies, despite the lack of "apodictic certainty" and necessity that Plato and Kant sought. Perhaps the analogy tells us that we should settle for something more human in ethics as well. Lear argues for "sophisticated cognitivism" on both sides along the late Wittgensteinian lines:


  "Reality, truth, objectivity only make sense within the context of a form of life. If we wish to ground the objectivity of mathematics in something stronger, the sophisticated cognitivist argues, that could only be because we have not yet been cured of the desire to step outside our form of life and view it 'from sideways on', that is, from an external standpoint. If we sincerely abandon that desire, if the fever breaks, then we will no longer feel threatened by a collapse into natural history...
  
  This does not mean that we can convince anyone outside our moral outlook to adopt it: for we've already admitted that outside our moral outlook there is nothing to which we can appeal to commend it. We can only make various appeals to get him to see a situation as we do; if he is not so disposed there is nothing more that can be done... However, this doesn't threaten the objectivity of ethics, it only reveals him to be insensitive. The objectivity of mathematics does not totter every time a child cannot be taught to add."

This comment by https://www.academia.edu/621253/Nietzsche_and_the_New_Atheists?auto=download Jeremiah Bowden at the very least offers a curt explanation of its obscurity (page 10):


  Nietzsche is especially vehement in his denunciation of the Christian view of sex...
  
  Moreover, in his "Law Against Christianity", a piece that was eliminated from numerous editions of The Antichrist because of its virulence, Nietzsche proposes that, "The preacher of chastity is a public incitement to anti-nature. Contempt for sexuality, making it unclean with the concept of 'uncleanliness‘, these are the real sins against the holy spirit of life."


Fortunately the citation notes indicate which edition of "The Anti-Christ" the quote came from:

Friedrich https://youtu.be/MFUlXPX_-_E Nietzsche, “Law Against Christianity,” in The Anti-Christ, Ecce Homo, Twilight of the Idols, and Other Writings eds. Aaron Ridley and Judith Norman, trans. Judith Norman (New York: Cambridge University Press,2005), 67.  

And that edition I found here:  http://krishnamurti.abundanthope.org/index_htm_files/The-Anti-Christ-Ecce-Homo-Twilight-Of-The-Idols-And-Other-Writings-by-Nietzsche.pdf http://krishnamurti.abundanthope.org/index_htm_files/The-Anti-Christ-Ecce-Homo-Twilight-Of-The-Idols-And-Other-Writings-by-Nietzsche.pdf

In particular the article is on page 66-67.  


  Law against Christianity
  
  Given on the Day of Salvation, on the first day of the year one (-30 September 1888, according to the false calculation of time)
  
  War to the death against vice: the vice is Christianity
  
  First proposition. - Every type of anti-nature is a vice. The priest is the most vicious type of person: he teaches anti-nature. Priests are not to be reasoned with, they are to be locked up.
  
  Second proposition. - Any participation in church services is an attack on public morality. One should be harsher with Protestants than with Catholics, harsher with liberal Protestants than with orthodox ones. The criminality of being Christian increases with your proximity to science. The criminal of criminals is consequently the philosopher.
  
  Third proposition. - The execrable location where Christianity brooded over its basilisk eggs should be razed to the ground and, being the depraved spot on earth, it should be the horror of all posterity. Poisonous snakes should be bred on top of it.
  
  Fourth proposition. - The preacher of chastity is a public incitement to anti-nature. Contempt for sexuality, making it unclean with the concept of 'uncleanliness', these are the real sins against the holy spirit of life.
  
  Fifth proposition. - Eating at the same table as a priest ostracizes: you are excommunicated from honest society. The priest is our Chandala, - he should be ostracized, starved, driven into every type of desert.
  
  Sixth proposition. - The 'holy' history should be called by the name it deserves, the accursed history; the words 'God', 'saviour', 'redeemer', 'saint' should be used as terms of abuse, to signify criminals.
  
  Seventh proposition. - The rest follows from this.


Obviously tho, the work has been supressed for this:


  The criminal of criminals is consequently the philosopher.


;^)
https://plato.stanford.edu/entries/nothingness/ Nothingness is a key word for https://plato.stanford.edu/entries/existentialism/ Existentialism, a central philosophical movement in the post WW II in France; see at least https://plato.stanford.edu/entries/sartre/ Jean-Paul Sartre and https://plato.stanford.edu/entries/camus/ Albert Camus.

In Foucault's reading of the Enlightenment worldview, reason and truth are "being" and thus the key features of madness: unreason and hallucinations, "are nothingness, since they represent nothing".

See page 106:


  Inextricable unity of order and disorder, of the reasonable being of things and this nothingness of madness! For madness, if it is nothing, can manifest itself only by departing from itself, by assuming an appearance in the order of reason and thus becoming the contrary of itself. Which illuminates the paradoxes of the classical experience: madness is always absent, in a perpetual retreat where it is inaccessible, without phenomenal or positive character; and yet it is present and perfectly visible in the singular evidence of the madman.


And page 115:


  Confinement merely manifested what madness, in its essence, was: a manifestation of non-being; and by providing this manifestation, confinement thereby suppressed it, since it restored it to its truth as nothingness. Confinement is the practice which corresponds most exactly to madness experienced as unreason, that is, as the empty negativity of reason; by confinement, madness is acknowledged to be nothing.


https://plato.stanford.edu/entries/foucault/#4.1 Michel Foucault is also a  https://en.wikipedia.org/wiki/Structuralism post-structuralist and thus "he likes" oppositions: being-nothing, reason-unreason, pure-impure,..
We can see: Alfred North Whitehead & Bertrand Russell, https://books.google.it/books?id=ke9yGmFy24sC&pg=PA40 Principia Mathematica to #56, Cambridge UP (2nd ed, 1927), Introduction: Ch.II THE THEORY OF LOGICAL TYPES, page 39-40:


  When we say that "ϕx" ambiguously denotes ϕa, ϕb, ϕc, etc., we mean
  that "ϕx" means one of the objects ϕa, ϕb, ϕc, etc., though not a definite one, but an undetermined one. It follows that "ϕx" only has a well-defined meaning (well-defined, that is to say, except in so far as it is of its essence to be ambiguous) if the objects ϕa, ϕb, ϕc, etc., are well defined.
  
  It is necessary practically to distinguish the function itself from an
  undetermined value of the function.[...] If the undetermined value is written
  "ϕy," we will write the function itself "ϕŷ."
  
  We have seen that, in accordance with the vicious-circle principle, the
  values of a function cannot contain terms only definable in terms of the
  function. Now given a function ϕŷ, the values for the function [we shall speak  of "values for ϕŷ" and of "values of ϕy," meaning in each
  case the same thing, namely ϕa, ϕb, ϕc, etc.] are all propositions
  of the form ϕy. It follows that there must be no propositions, of the form ϕy, in which y has a value which involves ϕŷ. [...] Hence there must be no such thing as the value for ϕŷ with the argument ϕŷ, or with any argument which involves ϕŷ.


We have to be careful with the similar (but different) symbols:


  Socartes is a man 


is a proposition.

The (propositional) funcion is: ŷ is a man.

The expression y is a man stay for a "generic" value of the function ŷ is a man, i.e. for: Socartes is a man, Plato is a man, etc.

The vicious circle principle forbid to form a proposition of the form y is a man with some value of y that involves ŷ is a man. A fortiori, we cannot use ŷ is a man itself as value for y, i.e. we cannot write:


  (ŷ is a man) is a man.


What about y is a man ? It is a "generic" name for the (meaningful) expressions: Socartes is a man, etc.

So the question amounts to: why (Socartes is a man) is a man is forbidden by the vicious circle principle ?

It is not; it is forbidden by the (not so clearly stated) syntax rules.

ŷ is a man is a first-order functions [see page 51], i.e. a function that involves no variables except individuals.

Thus, the possible value for its argument must be (names of) individuals [the type of the argument of the function must be the "lowest" one], like Socrates, Plato, etc. and not (names of) propositions, like: Socrates is bald.

In conclusion, with an "abuse of terminology" with respect to PM, we have that (Socartes is a man) is a man is ill-formed with respect to the (not clearly stated) PM syntax rules, irrespective of the vicious circle principle.

Compare with https://books.google.it/books?id=v4tBTBlU05sC&pg=PA161 Mathematical logic as base on the theory of types (1908):


  every propositional function has a certain range of significance, within which lie the arguments for which the function has values. Whitin this range of arguments, the function is true or false.; outside this range it is nonsense.

Part 1: Why can Neigungen not be universal?

I think this comes down to lost in translation.

I refer to the CUP translation of the German-English edition by Timmermann and McGregor, quoting the important part, because it is much closer to the original style and meaning (4:428):


  All objects of inclinations have a conditional worth only; for if the
  inclinations, and the needs founded on them, did not exist, their object
  would be without worth. But the inclinations themselves, as sources of
  need, are so far from having an absolute worth - so as to make one wish
  for them as such - that to be entirely free from them must rather be the
  universal wish of every rational being. Therefore the worth of any object
  to be acquired by our action is always conditional. 


Now to begin with, my impression is that if we use inclinations [Neigungen] rather than mere preferences, it becomes clearer why it is hard to imagine them as necessary and general, i.e. lawful. It is quite clear that normally, people prefer not to suffer from unbearable pain. It is hard to think of this as an inclination, though.

In my understanding as native speaker and based on how he uses Neigung in the book, it means an intentional, actual longing for an object. That means that aquiring a certain object or state is the determining end of the action. I am not sure whether inclination is understood in the same way by a native speaker of English, but I think that is how it should be understood here.

Now, a universal inclination would mean that there is an object - i.e. a determined thing in the realm of experience - every single action of every single rational being would necessarily include as its end. And as absurd this is generally, for Kant it is even more absurd due to the fact that he very well allows for other rational beings to perceive the world completely different, i.e. they may not even understand our objects as objective or at all, as they represent things differently (he is agnostic towards this possibility, though):


  If one adds that, unless one wants to refuse the concept of morality
  all truth and reference to some possible object, one cannot deny that
  its law is so extensive in its significance that it must hold not merely
  for human beings but for all rational beings as such, not merely under
  contingent conditions and with exceptions, but with absolute necessity; then it is clear that no experience can give occasion to infer even
  just the possibility of such apodictic laws. For by what right can we
  bring what is perhaps valid only under the contingent conditions of
  humanity into unlimited respect, as a universal prescription for every
  rational nature, and how shall laws of the determination of our will
  be taken as laws of the determination of the will of a rational being
  as such and, only as such, for our will as well, if they were merely
  empirical, and did not originate completely a priori from pure but
  practical reason? (4:408)


He later explains this differently, i.e. that it is relative because I do only want the action because I want to achieve something different from the action. This means that the action itself does not have absolute worth:


  Whether the object determines the will by means of inclination, as with the principle of one's
  own happiness, or by means of reason directed to objects of our possible willing as such, in the case of the principle of perfection, the will
  never determines itself immediately, by the representation of the action,
  but only by an incentive that the anticipated effect of the action has on
  the will: I ought to do something because I want something else, and here yet
  another law must be made the foundation in my subject, according to
  which I necessarily will this something else, and this law in turn re-
  quires an imperative to limit this maxim. (4:444)


The trick with the Categorical Imperative is that it represents an objective end qua being rational, i.e. every rational being does have this end necessarily in every action. That is why it is universal. And the whole Groundwork, but especially the third section, basically tries to justify this claim.

Part 2: Why do we want to get rid of them, then?

The short answer is: Because we want to be moral and the very concept of what it means to judge morally means that we want it to be universal, i.e. that every rational being has to agree if they think it through.

This is indeed one of the stronger arguments of Kant and the basis of his whole analysis of moral judgements: We indeed, when judgeing morally, do not think of it as a subjective or relative judgement. We think that this is right. We feel that this is how it should be, even though we may err, and that every being in its right mind should agree. The Groundwork merely looks for the conditions under which this kind of judgement would indeed work without incoherences.

The long answer is veeeery long and takes about 20% of the Groundwork, all arguments considered. But the basic idea is that it is respect [Achtung] that makes us feel being of a higher order and transcending the shackles of our ordninary worldliness. Thinking about morality, we realise that we can try to be part of this higher order of absolute value by being rational, and therefore we long for being part of it and being up to what constitutes our dignity, even if we may never achieve it:


  Also, these actions [of moral worth, i.e. determined by the Categorical Imperative] need no recommendation from any subjective proclivity or taste to look upon them with immediate favour and delight,
  from any immediate propensity or feeling for them; they represent the
  will that performs them as the object of an immediate respect, for which
  nothing but reason is required to impose them upon the will, not to coax
  them out of it, which latter would be a contradiction in the case of duties anyway. This estimation thus lets us recognize the worth of such a
  way of thinking as dignity, and puts it inﬁnitely above any price, with
  which it cannot be balanced or compared at all without, as it were, violating its sanctity. (4:435)

Thanks for your answers, I think I have the answer. The problem was trying to find a relation of proportionality between entropy and any of the presented features.

But I realize now that entropy sustains the 2nd law, and viceversa. In simple words, there is some physically measurable quantity (entropy) that always increases (2nd law) on close systems evolving spontaneously. This, independent of order, enthalpy, and even probabilities. A system can get order, evolve towards a particular state out of the median states, or even concentrate its energy, while entropy reaches a maximum.
This is an interesting question, but ultimately the answer is "No, a non-linear view of time doesn't solve the paradox". Here's why: 

At the heart of the paradox is the fact of God's omniscience, which presumably includes knowledge of all future events (knowledge of Ghaib includes knowledge of the future). So God's perception of time is already non-linear, and in fact it is this very non-linearity which makes the problems of predestination and evil so paradoxical in the first place. 

I would argue the other way around, that to remove the paradoxes of predestination and the problem of evil, one has to weaken God's omniscience a little so that his knowledge of the future is limited, and his perception of time is more linear. Or maybe he himself deliberately chooses to limit his knowledge of the future - see https://en.wikipedia.org/wiki/Alvin_Plantinga%27s_free_will_defense Plantinga's freewill defense - because that is the only for there to be true good in the world. But down that path lies blasphemy....   
First of all, I agree on both points made by @MauroAllegranza (as I often do).

Regarding "Anti-Garve" and its origins

Timmermann in the introduction to his commentary on the Groundwork (2007, Cambridge UP) refers to a letter from Hamann to Scheffner (February 1784), where he describes the project as a counter critique ("Antikritik") against Garve's translation of Cicero's De officiis from 1783 and - more importantly - an indirect answer against the (complete) review of Garve as published in the Allgemeine Deutsche Bibliothek. 

It should be emphasised that this is from hearsay (the letter begins with "Einer Sage nach", which can be translated as "according to accounts received")!

I could not find a complete English translation of this letter, the German original can be found e.g. https://books.google.de/books?id=AUBcAwAAQBAJ&pg=PA257&lpg=PA257&dq=hamann+scheffner+1784&source=bl&ots=kQ8OLllG6B&sig=E9049VT7mHatgkLIWA4EEcB71x4&hl=de&sa=X&ved=0ahUKEwiK866audvTAhXQEVAKHSTRCoAQ6AEIKTAB#v=onepage&q=hamann%20scheffner%201784&f=false here.

The word of the "ever prolific" (xxvii) Hamann is not to be taken too seriously, though, as Timmermann himself acknowledges in his remark:


  It was again Hamann who, in a letter to Scheffner in February 1784, reported that Kant was working on a ‘Counter-Critique’ (Antikritik) of Garve’s ‘Cicero’ that was, as a matter of fact, intended as a retort against the unabridged review of the Critique (IV 626). It is difﬁcult to say whether Hamann’s testimony is credible.


In a letter to Herder two weeks earlier, he also says that "it is said that Kant works on" the Antikritik (see above link).

Interestingly, though, Hamann reports only about six weeks later to Herder, that his "counter-critique to Garve's Cicero" (own translation) would have transformed into a "prodrom of morals" [Prodromum der Moral] (https://books.google.de/books?id=AUBcAwAAQBAJ&pg=PA253&lpg=PA253&dq=hamann+prodromum+der+moral&source=bl&ots=kQ8OLnhA7I&sig=Gz1yunRIQO2ckPMpmXAIV5B7m3g&hl=de&sa=X&ved=0ahUKEwi8iuDR8tvTAhVJJFAKHduOAAoQ6AEIMjAD#v=onepage&q=hamann%20prodromum%20der%20moral&f=false German original letter), i.e. into a groundwork.

Regarding a comprehensible story and more sources

I think the most readable summary of how things were and the philosophical drive produced by the reviews is in Eckart Förster's The Twenty-Five Years of Philosophy (2012), pp.48-53.

It is a good compromise between length, readability and academic quality.

There, it is made clear that Feder essentially mutilated Garve's review and added a comparison to Berkeley, which Kant so bitterly adressed in the Prolegomena. He received Garve's original review by mail (on Aug 21st 1783, see below), and found valid criticism of his arguments about freedom and morality, as Förster argues:


  In the dialectic Kant had, on the one hand, shown that we cannot know anything about God and that theoretical cognition of supersensible objects must be ruled out as impossible in principle. On the other hand, he argues that certain propositions of practical reason cannot be true, or rather, cannot motivate action unless we can assume the existence of God and a future life. It is thus the validity and obligatory force of the moral law itself which reintroduces God into theoretical cognition, while at the same time it is the idea of God which serves to explain the bindingness and validity of the law . For “reason finds itself constrained to assume” the existence of God, Kant writes in the Critique, since “otherwise it would have to regard the moral laws as empty figments of the brain” (A811).
  
  Kant is thus guilty of a petitio principii which only becomes clear to him through Garve’s objection (for the published version [i.e. Göttinger Anzeigen] of the review had passed over this point as incomprehensible). His explanation presupposes the very thing it is supposed to explain. (The Twenty-Five Years of Philosophy, p.52)


Förster is one of the main proponents of reading the Groundwork as essentially an 'Anti-Garve', even down to its structure, btw.

Also, together with Timmermann's commentary, a lot of sources can be found for further reading on the discussion. 

For a different take with further sources, see Allison's commentary (Oxford UP, 2011), pp. 5-10 and 52ff. He takes a third stance, saying it is the challenge Garve's Cicero puts on "the very idea of a metaphysics of morals" (p. 6).

Good sources not mentioned in either of the commentaries, nor Förster (but only in German, just like the mentioned, excellent Schönecker, Beister, Reich, etc.): https://books.google.de/books?id=AUBcAwAAQBAJ&printsec=frontcover&hl=de#v=onepage&q&f=false Immanuel Kant in Rede und Gespräch by Rudolf Malter (ed.) and https://books.google.de/books?id=0Gsooqw8V9gC&printsec=frontcover&hl=de#v=onepage&q&f=false Kant und das Problem des metaphysischen Idealismus by Dietmar Hermann Heidemann

Regarding Kant's own perception of the difference between the two versions of the review

Kant did indeed, in a letter to a third person, clearly express the severe differences between the reviews as published in the Göttinger Anzeigen and the Allgemeine deutsche Bibliothek respectively (to Johann Schultz, Aug 22nd, 1783)


  I have the honor, dear sir, of transmitting for your evaluation the Garve review forwarded to me yesterday by Herr Oberconsistorialrat Spalding. I have only been able to skim it quickly, there being various other distracting tasks lying in the way; however, dispite his frequently mistaking my meaning, which is hardly avoidable, I found the review quite different and far more thought through than what is contained in the Göttinger Anzeige (which was supposed to be by him). (Ak. 10:349-50, translation taken from the Cambridge Edition Correspondence, p. 206)


Keep in mind that he writes this before he even had the time for an in-depth analysis of the arguments! Together with Förster's reasoning, it makes Timmermann's remark that "Kant still had little reason to be impressed" by the full review (xxvii) rather improbable.

As a counter-argument to that another letter from Hamann to Herder should be considered that deals with the Garve-review as well (from Dec 9th, 1783):


  Kant is not satisfied with it and complains of being treated like an imbecile. He won't answer it; but he will answer the Göttingen reviewer, if the latter dares to review the Prolegomena as well. (translation from Corr., p.201, fn.1)


This translation is not entirely correct, though. Hamann originally writes "Er soll nicht damit zufrieden seyn", i.e. "Kant is said not to be satisified". Again - heresay. He points out the sentence before that he did not have the heart to ask Kant personally when visiting him, although this was the original purpose of his visit. One might argue that the contents of his reports are generally quite accurate, though.

Regarding a translation of both reviews

In case it helps for research: a translation of both reviews, as referenced in the Correspondence translation by Arnulf Zweig (pp.206-7, fn.1), 


  may be found in the appendices to James C. Morrison's translation of Schultz's Exposition of Kant's Critique of Pure Reason (University of Ottawa Press, 1995).

The second appears to be the more literal translation, but the contrast that you point out is not a comparison between the same word. The original text does have the word "wisdom" [σοφία] and the first text is translating "by wisdom" as "are so clever that," which kind of captures the same idea, but it's definitely looser.

The word "pantomimic" translated in the first quote is translated as "to imitate all" [μιμεῖσθαι πάντα] in the second text.

Here's a rough breakdown of the first part of the sentence:


  ἄνδρα [a man] δή, ὡς ἔοικε, δυνάμενον [who is able] ὑπὸ σοφίας [by
  wisdom] παντοδαπὸν [of all sorts] γίγνεσθαι [to become] καὶ [and]
  μιμεῖσθαι [to imitate] πάντα [all] χρήματα [things]...

It depends on what exactly you want to get out of your reading. Due to the formatting of this question being pretty subjective, I'll offer an overview of what the different books cover and what you will gain from reading them and you can make the choice of which one to read yourself. 

The Story of Philosophy: The Lives and Opinions of the Greater Philosophers by Will Durant is a book that explores many of the major Western philosophers, putting their work into historical context and then elaborating on their main ideas. Russell's A History of Western Philosophy does much the same thing. However, one of the major differences between the two is their scope. Russell covers much more of the history of philosophy in his book, having sections that are completely omitted from Durant's work. These include a section on the Pre-Socratic philosophers as well as Greek philosophers that came after Aristotle. Durant only covers Plato and Aristotle's work. Durant also skips the Catholic Medieval philosophers and goes directly from Aristotle to Francis Bacon. It would be remiss to say that the scholastics had no influence on Western philosophy.

What Durant trades for in scope he makes up for in detail; while he does not cover as many philosophers as Russell does, Durant goes into much greater detail for most of the philosophers that he does cover. For example, Russell's section on Schopenhauer is around seven or eight pages while Durant's is around forty; Russell's section on Spinoza is around twelve pages while Durant's is around forty; etc. 

At their core, Russell's book is about the sequence of ideas and thinkers that ran throughout history leading to where we are now (well, to where we were a hundred years ago when he wrote the book) and Durant's work is about a few of the more major philosophers that participated in that process up until now (or, again, when the book was written). The titles of the books really do reveal what content is inside. The Story of Philosophy: The Lives and Opinions of the Greater Philosophers is about the lives and the opinions of some of the more important philosophers in Western philosophy while A History of Western Philosophy is a trace of its history. 

The Passion of the Western Mind: Understanding the Ideas That Have Shaped Our World View was saved for last because it is much unlike the other two books. The first two books are reviews or histories of the subject, while Tarnas' work is more like an actual piece of philosophy. He is not only trying to explain the sequence of ideas that lead to modernity and post modernity in Western culture, he is also trying to make arguments about this history of events and how they impacted the world we live in now. Tarnas is a psychologist/cultural historian and he makes his own arguments in his book. This is very different from Durant and Russell's books which for the most part detail and explain the ideas of other philosophers (although there is a small section at the end of A History of Western Philosophy that explains Russell's personal philosophy). Tarnas' book is a history of Western philosophy, but it is more so his argument for how that history is shaping the world today and how people should live accordingly.

If you want to read about the entire history of Western philosophy up to the 1920's you should read Russell. If you want to read a work that focuses more on specific, major philosophers and gives their arguments more detail then you should read Durant. If you want to read Tarnas' views about how the modern world is shaped by the history of philosophy and how our psyche should perceive the cosmos around us then you should read Tarnas. 
Outside of fitch, conceptually the answer is as follows:

1. | ¬(p ∨ ¬p)   A
2. | | p         A
3. | | p ∨ ¬p    vI 2
4. | | ¬(p ∨ ¬p) R 1
5. | ¬p          Contradiction Elim. 3,4 (2-4)
6. | p ∨ ¬p      v5
7. p ∨ ¬p        Contradiction Elim. 1,6 (1-6)


and there you go.

The hard part is that fitch lacks contradiction elimination. Instead, you need to use Negation Introduction, here's how you do that for the top half:

1. | ¬(p ∨ ¬p)   A
2. | | p         A
3. | | p ∨ ¬p    vI 2
4. | p -> (p ∨ ¬p) Imp. Introduction 2,3
5. | | p         A
6. | | ¬(p ∨ ¬p) R 1
7. | p -> ¬(p ∨ ¬p)  Imp. Introduction 5,6
8. | ¬p          Neg. Intro. 4,7


Then drop down an assumption by imp introduction:

9. ¬(p ∨ ¬p)  -> ¬p


repeat the same thing as above but with not ¬p yielding 

X. ¬(p ∨ ¬p)  -> ¬¬p
Y. ¬¬(p ∨ ¬p) Neg. Intro 8 + X
Z. p ∨ ¬p   DN Y


To explain it a little bit conceptually, Contradiction Elimination says "we have hit a contradiction in this sub proof so we reject its assumption." Negation Introduction says "if this antecedent were true, we would hit a contradiction because this antecedent implies contradictory outcomes, so the antecedent is false." In other words, it is a way of eliminating contradictions by denying the assumptions that go to them.  

In a sense, the "negation elimination" approach is more careful about handling the principle of explosion, but it's effect is the same in proving -- it's just more painful to write them out.
I'd tend to agree with the others that the problem is pretty similar to Sorites. I would also add that you seem to be getting at the idea of essentialism - that there is an essence of what it is to be a watermelon that is needed to say something is a watermelon. You (like the ancient Greeks) are trying to come up with necessary and sufficient criteria for watermelonhood. I think that this is a common philosophical muddle and let me outline why I think the problem dissolves if you consider the use of language. 

Instead of assuming that behind the word "watermelon" is some entity that must be common to all things we correctly call watermelon. Instead it could be helpful (in Wittgenstein style) to consider the meaning of "watermelon" as bound up in its use. So in answering the question "when does a watermelon cease to be a watermelon?" , we should consider the context. Consider the following examples:

It's your girlfriend's dad's birthday. She asks you to buy watermelon for the dessert because her dad loves watermelon. You are agreeable, and head to the shop, pick up the watermelon, and head back. On your way back you bump into your friend who suggests having a game of throwing/punting/kicking and you have no football so you suggest using the watermelon (you're an asshole). You kick it around a bit, leaving bits of melon all over the gravel, your clothes etc. After a while you realize you'll be in trouble so you scrape up the bits and pieces of the gravelly, mutilated watermelon into your shopping bag and head home. When you show your girlfriend the bag with red liquid in it, she shouts "What?!!  I told you to get a watermelon, that's not a watermelon!"

Is she wrong to say that? I don't think so.

Consider, on the other hand, a scientist working on watermelon cells. She has in her fridge slides with watermelon cells, slides with human cells, tomato cells, etc. She is looking through the microscope at a flea cell and calls her assistant, saying "Get me the watermelon". 

Is this use wrong? Again, I think not, despite the fact that, on a superficial view, the second is much less similar to the everyday watermelon. Context is everything. You need to ask, what are you doing with the word? That determines what your answer is. 

Consider one last example. Your friend is a watermelon connoisseur, and you want to impress him, bringing an expensive watermelon over for him to taste. Being a snob, he tries some, looks disparagingly at you combined with a smug grin, and says " listen dude, that's not watermelon", and gestures to his basket of premium watermelons on the table. 

Again, I think that it's perfectly clear what is meant in that case. 
I practice(d) zen for years.

The short answer  : No.

The long answer :  Zen as a non system that aims for nothing. No purpose no transformation or outbreak. Zen only reason to be and to be use is be here and now. When you try to use your mental trying to analyse why/IF/Should/analogies etc you are losing the interest of the Zen it self. Being here and now and Just act. 

but philosophy and logos are useful in they own way for others stuff.

On the quote on the "change", there is a misconception. Zen logic says one thing everything is here and now. Like a river your are in the flow. In fact nothing change, every moment "look" alike but in the same time every moment is unique.This is the contradiction of life everything is here but always moving, you never have the big movie, only each pictures at the time.
This really belongs in the stats stack exchange (a.k.a. cross validated). But I'll give you an answer here.

Before getting into any math, I'll just say that there's a problem of epistemology here. You can't ever know anything about the real world with perfect confidence. The only thing you can ever know with perfect confidence is whether the axioms imply the conclusion. This is what a "proof" always consists of. That is, you can prove that "if A then B", where A is the set of axioms and B is the conclusion. You are not 100% confident in A, but you are 100% confident that A -> B. Premise A, itself, may have been the result of another proof, which means that you are 100% confident that A is true if the premises that led to A are true. If you follow the chain backwards, you eventually get to the original axioms, which were either a claim about the real world (which you cannot be 100% confident in) or a definition (usually in math). So any conclusion you make from a chain of proofs is either one in which you're only as confident in as the original set of axioms, or it's tautologically true. For example, if I posit C as an axiom of which I'm 70% true, and I prove that C -> D then, assuming this is a valid proof, we are 100% confident that if C then D. However, because we are only 70% confident in C, we are consequently 70% confident in D. However, instead of a true proof, I might have made a probabilistic claim. That is, C -> D with 90% confidence. In this case we are 63% confident in D, because 90% of 70% is 63%. 

We can always form hypotheses and conduct experiments that are true tests of the hypothesis. This procedure can be used to increase our confidence in a claim, even push it to near-certainty. But it will never be certain.

The consequence of this fact is that we are not certain about anything, even our best scientific theories. We merely get to a point that a certain claim is so negligibly unlikely to be wrong given the set of data we currently have testing the claim, that our best bet is to accept it. If you google "most accurate theory", you will find resounding results that it is QED (Quantum Electrodynamics). But how can there be a "most accurate theory" if we can know that certain theories are true? Well, we cannot. However, QED makes certain statistical claims on what you would observe in a particle collider, were it true. From there, you can calculate the probability of observing the things it claim, were it not true (by random chance.) In QED's case, the probabilities of its claims across the board were generated by chance, by non-QED hypotheses, are so dramatically low that not believing in QED is as bad an epistemological bet as you can make. But it's not guaranteed to be wrong with 100% certainty. 

You can apply this to anything involving probability. So, for example, we might come up with a probability that the sun will rise tomorrow, given the set of historical observations. A frequentist would predict 100%, and a Bayesian would predict something so close to 100% that the difference is negligible. But we cannot know for sure. Assuming we have not yet discovered celestial mechanics, we can make inferences on the probability of the sun rising given previous events.

Now for a more grounded example, to help cement this concept. Suppose we take a coin. We can assume it's a "fair coin" (i.e. 1/2 chance of landing on each side) but we don't know that for sure. (In fact, it's probably not exactly true for any coin because there are subtle imperfections that make it not a perfect thin cylinder.) However, its probability of landing on heads is a purely empirical claim. We can do something like a hypothesis test, which is similar to what I described in QED, but much simpler.

To give you an idea of how a hypothesis test works, consider this. Suppose we start with a coin, and ask "is this a fair coin?" (i.e. 50% chance to land on either side.) One thing we can do is flip it n times and ask "what is the probability that a fair coin would have been at least this deviant from the expected result?" The expected result of n flips of a fair coin is n/2 heads, but we know that it can deviate from that. There's nothing abnormal about that. When I say "at least this deviant", what I mean is that the number of heads is at least as far from the expected result as we have observed. So suppose, for example, that we flip it 100 times, and we get 55 heads. To be "at least this deviant" simply means outside of the range of 4 heads away from the expected result of 50. That is, below 46 or above 54. 

Suppose we flipped it four times, and it landed on heads only once. The probability of being "at least this deviant" is the sum of the probability of landing 0 heads, 1 heads, 3 heads or 4 heads. It turns out that the probability is 62.5%. That is, a fair coin would have a 62.5% chance of being at least one off the expected result of two heads. That's pretty high. So is this grounds to reject the "fair coin" hypothesis? No. But that doesn't mean we should blindly accept it. We have to keep going.

So now we flip it 10 times, and we get 2 heads. This deviates from the expected result by three. What is the probability of deviating from the expected result of 10 flips by at least 3? The answer is ~10.9%. That's not very low; things of that probability happen all the time in our daily lives. Should we reject the fair coin hypothesis on this basis? It would be a weird standard if we did.

Now let's say we flip it 100 times and get 30 heads. We have deviated 20 from the expected value. The chances of deviating at least that much is ~0.003%. That is, a fair coin has roughly a 3 in ten thousand chance of it's "head-count" in 100 rolls to deviate by at least 20 from the "fair coin" expected value of 50. But this coin did. This should constitute "strong evidence" that this is not a fair coin. Now, does that mean it definitely isn't? Well, I mean, the chance of a fair coin landing like that is not 0. So it's still possible that it's a fair coin. But given the result we just observed, it would be a fairly bad epistemological bet to conclude that it's fair. Some people say "we should reject the hypothesis" because the result was so low. I, personally, don't take such a binary view, but I would say that I'm so confident that it's not a fair coin that I will act as though I'm certain (even though I'm not). After all, that's how we treat epistemology in many aspects of every day life. Just keep in mind that, with more rolls, we can become even more confident in our claims. But never 100% confident.

Then the question is, what do we conclude about the coin's probability of landing on heads? Well here's the tricky thing about adjusting our views based on evidence. It's far easier to make a negative claim than a positive claim. That is, if we take a theory (e.g. "this coin is a fair coin with a 50% probability of landing on heads"), the best we can do with that is formulate an experiment to see if the claim of this theory holds up. If it does, we haven't exactly confirmed the theory (other theories could make the same claim) but we failed to reject it. However, if the claim appears to be unequivocally false, we can easily reject the theory. So the question of "after the coin experiment, what do we choose to believe is the true probability of landing on heads?" is far harder to answer than "is the probability of landing on heads an a priori given value?" 

There are several ways of addressing this problem. Bayesian statistics is one such novel way. Instead of claiming "the probability of landing on heads is x", we instead have a probability distribution for the value in question. Then, as we obtain evidence from new experiments, we adjust that distribution. In the coin example, we might say "given no knowledge, we'll assume that the probability of landing on heads is equally likely to be anywhere between 0 and 1". That's our probability distribution. Then we conduct an experiment by flipping the coin. Every time the coin is flipped, our distribution shifts slightly. After, say, 100 flips, if we have 30 heads, our distribution would be somewhere centered around 0.3, but it's not fixed at that value. The more times we conduct this "experiment" the more confident we become in our assessment, and the narrower this distribution becomes. (Recall that flipping 2 out of 10 heads wasn't enough for us to reject the fair coin hypothesis, but flipping 30 heads out of 100 was more than enough.)

This goes to something called the "Law of Large Numbers", on which we're relying to pan out to the truest answer in the limit of many experiments. You can look it up, but loosely speaking, it claims that if an event is drawn from a probability distribution, as the number of times we generate this event approaches infinity, the distribution of the outcome of this event approaches the true probability distribution. So, if we perform the experiment a few times, there's no guarantee that its distribution will look anything like the true distribution. But we expect it to look more and more like that distribution as the number of experiments grow. In the coin example, we would often expect a fair coin to give something like 2 out of 10 heads, but we would almost never expect it to give 30 out of 100.

Going back to the casino discussion. If we take a casino game of pure chance, involving dice or coins, once we learn the parameters of that game we can easily prove that the game favors the house using simple math. However, as I mentioned in my first paragraph, that proof has axioms. So we're only as confident in the conclusion of that proof as we are in the axioms. Most of the time, those axioms are that the tools of the game are fair tools. (Fair dice, fair coins, etc.) 
This is really just an example of an appeal to authority, a classical logical fallacy. His connection to authority is more direct, due to his having spent more time with the source of information.

Authorities become authorities by being likely to be right, but likely is never enough. An argument must also have logical content and be convincing.

A native speaker can easily spend 40 hours a week teaching English, and still not know how to use all of it correctly. He is an authority, but his individual decisions are not proof of anything.
Under presentism there is only one now. From B's point of view the future in which A will receive the card does not yet exist. B relies on his observations of events which happened in the past but no longer exist to infer things which will happen in the future but which do not yet exist, such as A receiving the card. At the time of A's receiving of the card, the B that was sending the card at the time of its sending does not exist any more, since it was in the past. When the now was at the time that B sent the card both A and B existed, but A was not at that time receiving the card. At the time A receives the card, A and B both exist, but B was not at that time sending the card. If you have more than one now, I don't think you're talking about presentism any more.
Physicists have actually considered this question.  Some would say no, due to the https://en.wikipedia.org/wiki/CPT_symmetry symmetry of our physics  The law that requires an increase in entropy over time is the only place our accepted physics loses its reversibility.  And it is basically taken as an axiom.  

But theories about https://en.wikipedia.org/wiki/Tachyon tachyons and antimatter suggest it may be possible to accumulate information and even have configurations of matter travelling in the opposite direction (or at any angle relative to our notion of forward) in time.  Richard Feynman pointed out that these are not daft imaginings, and made the point by suggesting that all the electrons and positrons in the universe could be a single entity, which has simply reversed trajectory in time, charge and or 'spin' many, many times, as far as our current physics can tell.

If these make sense, our linkage of entropy to information may only be an observation, and not a fact.  The observation would be what we see only because our memory is an exothermic chemical process.  An 'endothermic' being is conceivable.

If the universe is already continuously going both ways, then forward or backward it is the same world.  But if tachyons and antimatter are deeply intertwined, different aspects of it may never be able interact.

So the next step:  If time goes both ways, is there some other direction relative to which it actually reverses?

http://www.hawking.org.uk/the-beginning-of-time.html Hawking has suggested that time should be measured as a complex number.  This would mean that it has two dimensions, to a limited degree (the real and the imaginary axes).  Then real time would be able to reverse relative to the imaginary time axis, explaining how time can be a continuous function and still begin.  What would an extra dimension of time look like?
These are not really exclusive terms that either do or do not apply to a given word.  'Water' is a singular substance in chemistry, but a general noun in ordinary life.  Singular vs general is useful only to clarify which of the meanings you intend in given logical context, not to classify vocabulary.  (Almost every noun is both: There can be a Springfield in every state.)

As with other nouns, most ideological labels are both at once, often depending upon your distance from them.  

Christianity can be seen as a singular thing, from the POV of an atheist opponent, or a member of an exclusive sect that claims to be the one true faith.

But from the POV of and ordinary moderate Christian, Christianity has multiple acceptable forms, making it a general noun.

Feminism and Marxism, in particular, are so often singular nouns for their opponents, and general nouns for their adherents that proponents purposely say 'feminisms' or 'Marxisms' to capture the latter perspective.

You are best off, in my personal opinion, always seeing them as general nouns so that you are not tricked into perceiving them as coherent targets.  At both extremes, both atheists and rigid sectarians often ascribe to Christianity generally aspects that are true only of individual sects.  This undercuts their understanding and leads them into misleading arguments.
You say "probability is seen as a mathematical theory that we use to describe the physical world". I would say rather that probability and statistics are tools we use to help us test scientific hypotheses. To understand this let's go back a few steps and ask why we use probabilities. 

Philosophers commonly distinguish between physical (or metaphysical) possibilities and epistemic possibilities. The first are concerned with what events happen or might happen and these are directly related to properties of the world. The latter are concerned with what we might reasonably believe to be true given our current knowledge. The dual of physical possibility is determinism; the dual of epistemic possibility is certainty. Probability can be thought of as a quantitative measure on possibility - a degree of possibility. Physical probability might then be thought of as the amount of possibility of some event happening, while epistemic probability represents the degree of credibility of some proposition given our available information. 

To see that these are quite different, recall that probability theory was invented in the 17th century at a time when deterministic newtonian mechanics was believed to hold true of the whole universe. The fact that there are no physical possibilities in newtonian mechanics does not preclude us describing our state of information probabilistically. People playing a game of 'chance' can still talk of probabilities. We can even coherently bet on events in the past: for example, if there was a football match last week and neither you nor I know the result, we could have a bet on the outcome, even though this outcome is already physically determined. The odds that we agree upon reflect our assessment of the epistemic probability of the outcome given our current information. 

If there are genuinely indeterministic 'stochastic' processes in the physical universe then there are physical possibilities as well as epistemic ones. Quantum mechanics is often understood to be indeterministic, because of the way the Born rule interprets the wave function probabilistically, though it is worth pointing out that some physicists do not accept the Born rule and consider QM to be a deterministic description of a multiverse. But whether or not there are physical possibilities, there are always epistemic possibilities: there are always propositions of which we are nearly certain, others less so, and others hardly at all, depending on what information is available to us. 

In ordinary everyday usage we use epistemic probabilities all the time, though usually without much rigour. We may judge that it is highly probable that the defendent is guilty given that his fingerprints were on the murder weapon, the victim's blood is on his shirt, a security camera shows him fleeing the scene, and witnesses heard him threatening to kill the victim. We may judge it highly improbable that Johnny really did his homework considering that he has used the "a dog ate it" excuse many times, his clothes show evidence of him playing football, and there are no dogs in the neighbourhood. 

The harder question to answer is, in the context of scientific method, is it helpful to use the concept of epistemic probability to describe how credible some scientific statements are versus others? Here we get disagreement. At one extreme we have Popper who in "Logic of Scientific Discovery" maintains that we cannot speak of the probability of a theory or hypothesis being correct - that a theory would always have probability zero, though in his later writings he allows that we can reason probabilistically about hypotheses, but such reasoning is still deductive and not inductive. At the other end we have Edwin Jaynes who in his book "Probability Theory: the Logic of Science" argues that we can understand scientific inference as an application of Bayesian probability theory. I suspect most scientific practice lies somewhere in between. We use probabilitistic and statistical methods to help test hypotheses, but we do not usually speak of the probability of a theory being true. 

Your question, "is probability a product of the scientific method, or is it a part of it?" suggests a false dichotomy. Probability is a tool that has evolved to help us address problems in scientific inference. As such it is both the product of scientific progress and a part of it. 
If you stop before the last point, it's called progressive evolution:


  Progressive creationism (see for comparison intelligent design) is the pseudoscientific belief that God created new forms of life gradually over a period of hundreds of millions of years.
  https://en.wikipedia.org/wiki/Progressive_creationism - wikipedia


If you include the last point, it's the more generic theistic evolution:


  Theistic evolution, theistic evolutionism, or evolutionary creationism are views that regard religious teachings about God as compatible with modern scientific understanding about biological evolution.
  https://en.wikipedia.org/wiki/Theistic_evolution - wikipedia




As an aside: although sometimes lumped together with what's called https://en.wikipedia.org/wiki/Creation_science creation science, theistic evolution (as well as progressive evolution) are derided by proponents of both naturalistic evolution and what's known as young-earth creation:


[Dawkins] dismissed ... theistic evolution as a superfluous attempt to "smuggle God in by the back door."
https://books.google.com.au/books?id=drk3zykoEy4C&pg=PA13&lpg=PA13&dq=dawkins%20smuggle%20backdoor&source=bl&ots=FEMThPLgth&sig=TGMl-kVb3eQ9ViQeJ6mtr931P_c&hl=en&sa=X&ved=0ahUKEwjS1caw1dvUAhWFipQKHTL0BesQ6AEIPTAE#v=onepage&q=dawkins%20smuggle%20backdoor&f=false - pp 12-13, Ronald L Numbers, "Darwinism Comes to America"
In rejecting God’s right to lay down objective moral standards and by appealing to evolution, you are left with an unsolvable problem of evil. Theistic evolution is intellectually unsustainable.
http://creation.com/theistic-evolution - Joel Tay, creation.com



Many would are argue that you are right, the demon is still successful in his deception. 

DesCartes claims in the cogito that he has proven the existence of an "I", since for there to be deception, there has to be thinking, and for there to be thinking there has to be an "I" that does the thinking. Hence "I think, therefore I am". 

Several philosophers, notably many empiricists like Locke and Hume, pointed to a major flaw in DesCartes argument, which is that all that DesCartes proves is that "thinking occurs", not that "I am thinking". Later on, Russell in his essay http://www.gutenberg.org/files/2529/2529-h/2529-h.htm "Analysis of Mind", makes the analogy with rain: when we say "it rains", there's no need for a "rainer" to do the raining. Similarly, when thinking occurs, there's no need for there to be a thinker doing the thinking, the thoughts just occur.  

From David Hume's perspective: When we try to observe an "I" that is doing the thinking, we can't find anything. All we observe is the thoughts and emotions themselves - what we think of as the "I" is just the collection of thoughts and impressions that we have. This is known as the https://en.wikipedia.org/wiki/Personal_identity#The_bundle_theory_of_the_self Bundle Theory of Self. See https://philosophy.stackexchange.com/a/37683/13808 this post  for a more detailed explanation. 

To recast the argument in Cartesian demonic terms: The demon is fooling you (and this "you" is just an illusion) by making you think that an "I" is necessary to do the thinking, when in fact thoughts can occur perfectly well on their own. 



One can try to save DesCartes argument by replacing thinking with observation. Thinking might not require a thinker, but observation by definition requires an observer. If we prove that observation is occurring, then there must be an observer: "I observe therefore I am". 

Thinking is not so much of a challenge, after all computers think all the time, but conscious, first-person perspective is. This is the basis for https://en.wikipedia.org/wiki/Philosophical_zombie philosophical Zombie arguments. 

The bundle theorist can still refute this version of the argument, but they have to do a lot more work do to so. How do we explain first-person perspective and consciousness, if all there is, is thoughts, no selves? 

Here, the bundle theorist has to resort to https://plato.stanford.edu/entries/consciousness-higher/ Higher-Order and https://plato.stanford.edu/entries/consciousness-representational/ Self-Representational Theories of Consciousness: Consciousness and first-person perspective are just thoughts about other thoughts or thoughts that are about themselves. https://philosophy.stackexchange.com/a/39535/13808 See this post for details.   
I am not sure how to prove a negative, it is unlikely that we will have it in Hegel's own words that he did not live at the end times. But the idea that Hegel saw his time as "the end of history" is not supported by modern scholarship. http://www.iwm.at/publications/5-junior-visiting-fellows-conferences/vol-xxi/eric-michael-dale/#_ftn11 Dale in Hegel, Evil, and the End of History traces the fable back to none other than Nietzsche, namely to his Untimely Meditations:


  “History understood in [the] Hegelian manner has been mockingly called God’s sojourn on earth, though the god referred to has been created only by history. This god, however, became transparent and comprehensible to himself inside Hegelian craniums and has already ascended all the dialectically possible steps of his evolution to this self-revelation: so that for Hegel the climax and terminus of the world-process coincided with his own Berlin existence... 
  
  Indeed, [Hegel] ought to have said that everything that came after him was properly to be considered merely as a musical coda to the world-historical rondo or, even more properly, as superfluous... instead he implanted into the generation thoroughly leavened by him that admiration for the ‘power of history’ which in practice transforms every moment into a naked admiration for success and leads to an idolatry of the factual.” [emphasis added by Dale]


According to Dale, Nietzsche’s “idolatry of the factual” alludes to “was vernünftig ist, das ist wirklich; und was wirklich ist, das ist vernünftig” in the Philosophy of Right, from which the Owl of Minerva also flies. But in fairness, Nietzsche explicitly describes Hegel as not saying what he "ought to have said", and even faults him for it.

As if Nietzsche’s scorn was not enough, the fable got additional boost after the Second World War. This part is traced in https://books.google.com/books?id=vHp4HltpEO4C&source=gbs_navlinks_s The Hegel Myths and Legends, a collection of essays edited by the above mentioned Jon Stewart, which has three,  by Grier, Maurer and Harris, on "the end of history" specifically. The last two are well-known Hegel scholars, and Maurer even wrote a whole book https://www.amazon.de/Hegel-Geschichte-Reinhart-Klemens-Maurer/dp/B0000BGN8Y Hegel und das Ende der Geschichte analyzing various meanings of "the end of history" and their applicability to Hegel. 


  "In France the lectures at the Sorbonne in the 1930s delivered by the Russian emigre https://en.wikipedia.org/wiki/Alexandre_Koj%C3%A8ve Alexandre Kojève represent without a doubt the key event in French Hegel studies. Kojève’s provocative, yet at times fully misguided, interpretation was the main source of information about Hegel’s philosophy for the entire postwar generation of French intellectuals. The key figures of French phenomenology, existentialism, and Marxism, such as Raymond Aron, Maurice Merleau-Ponty, Georges Bataille, and Jacques Lacan, were all present at Kojève’s lectures and later developed the interpretation of Hegel that they received there in various directions in accordance with their own research programs...
  
  Kojève seems to have borrowed heavily from the work of his fellow emigre, Alexandre Koyré, primarily with respect to the latter’s emphasis on Hegel’s purported claims about the end of history. These claims found clear affinities in the teleology of Marxist theory, where Kojève was most at home. The view that Hegel saw the end of history in his own time or with his own philosophical system has had its most widespread acceptance in France due to the influence of these two men. Although in the literature these problematic views have long since been corrected and revised by more thorough French Hegel scholars such as Hyppolite and Labarriére, nonetheless in the popular mind they are still quite pervasive."


Of course, the most recent burst of Owl's popularity is due to Fukuyama's https://en.wikipedia.org/wiki/The_End_of_History_and_the_Last_Man The End of History and the Last Man, to which David Brooks, whose mention of the Owl prompted Pogge's answer, is likely indebted. And which in turn is traceable to... Kojève and Koyré, as Grier argues. If indeed Hegel had hopes of historical finality they were shaken by the French July revolution of 1830. On December 13 he wrote to his pupil Goeschel: 


  "At present the enormous interest of politics has swallowed up all others – a crisis in which everything previously dependable seems to become
  problematic. So little can philosophy stand up to the uncertainty, violence, and evil passions of this great unrest, I hardly think that it can penetrate into those circles which rest so easily..." [quoted from http://www.bard.edu/library/arendt/pdfs/Lowith-19thCenturyThought.pdf Löwith's From Hegel to Nietzsche, p.28]


Not unlike https://www.washingtonpost.com/news/worldviews/wp/2017/02/09/the-man-who-declared-the-end-of-history-fears-for-democracys-future/?utm_term=.1f801278f5c7 Fukuyama's change of heart. Löwith has a long discussion of Hegel's "eschatology" and its historical context.
The Great Beethoven fallacy, based on the referred article, is that, if we kill a fetus, we are killing a genius who will come to be in the future. You ask what kind of fallacy would subsume the Beethoven fallacy. I offer the counterfactual fallacy as an answer. That is,  the  Beethoven fallacy is a counterfactual fallacy applied to a pro-life argument.

The counterfactual fallacy occurs  when one treats a hypothetical (or counterfactual) situation as if it  is a fact, and then draws a conclusion about the future or the past based on the counterfactual situation, but the evidence for the conclusion is almost none. Of course, not all counterfactual inferences are fallacious, as is shown in the following case: "If this coin had not landed on the head side, it would have landed on the tail side." This  counterfactual inference is not fallacious because of the well established fact that a coin toss results in a binary case (assuming that the coin is unbiased and landing on the side is impossible). 

An appeal to a counterfactual situation  commits a fallacy if it lacks well established facts relating to the situation.  The circumstance of the pregnant woman in the above case is such that the probability is almost zero that the future person will become a Beethoven. The apple never falls far from the tree! It is more likely than not that, had the fetus been born, it would have lived an unfulfilling life. This is why the pro-life argument based on conterfactual situation is fallacious.
The Kantian criterion of ethical is whether one would wish such behavior to become generally practiced (there are delicate differences between "wish" and "will", which I leave out). 


  "There is ... only a single categorical imperative and it is this: Act only on that maxim through which you can at the same time will that it should become a universal law."


So disobeying a law, in and of itself, is not immoral, it could even be immoral not to do so, if it is particularly unjust (probably not in this case). But also conversely, if the law is ethically sound the fact that it is not legally binding in one's country does not make breaking it ethical. 

On whether copyright violations becoming a general practice is a good thing opinions differ, some argue that abolishing, or at least scaling back, copyright would on balance be beneficial. Your circumstances might be particularly favorable to such arguments: if we restrict the practice to individuals who have no alternative access to the books through no fault of their own the case for making it universal becomes stronger ("universal" does not exclude qualifiers, as long as they can be generally applied).

Since Kant wrote an essay titled Of the Injustice of Counterfeiting Books (1785) he may not concur. However, Kant did reject the notion of intellectual property, his defense of copyright is based on different considerations, see Pievatolo's http://eprints.rclis.org/3892 Freedom, ownership and copyright: why does Kant reject the concept of intellectual property?:


  "As most scholars, in the field of humanities, take intellectual property for granted, the representation of Kant like an intellectual property forerunner is still a dangerously mistaken commonplace. According to Kant's Architectonic of Pure Reason the philosopher is closer to a lawgiver than to an artificer, if philosophy is considered in its Weltbegriff or cosmopolitan concept (AA.03: 542.23-30). Because such a lawgiving is based upon that reason with which every human being is endowed, the laws of reason should be thought as public laws and not as individual, private creations.
  
  How could a public law be consistently viewed as an object of private intellectual property? Kant avoids such a contradiction because his justification of authors' right does not rely on intellectual property, but on the meaning and the function of both authors and publishers in the world of the public use of reason. Therefore, Kant's theory of copyright is compatible with the Weltbegriff of philosophy."


Kant did not address poverty, etc., specifically, but given his justification of copyright in terms of public use of reason one can imagine a Kantian defense of the practice when it is a precondition for including individuals into this use. One could perhaps even invoke Kant's "formula of humanity", a second formulation of the categorical imperative:


  "Act in such a way that you treat humanity, whether in your own person or in the person of any other, never merely as a means to an end, but always at the same time as an end."


See also http://eprints.lse.ac.uk/37521/1/Kant_Copyright_and_Communicative_Freedom_%28lsero%29.pdf Barron's Kant, Copyright and Communicative Freedom on Kantian subordination of authors' rights to the "public sphere":


  "For Kant,  progress  towards  a  fully  emancipated  (i.e.  a ‘mature’  or  enlightened’)  culture can only   be   achieved   through   the   critical   intellectual   activity   that   public communication  demands:  individual  expressive  freedom  is  only  a  condition,  not constitutive, of this ‘freedom o make public use  of one’s  reason in all matters’. The main thesis defended in  his article is that when  Kant's  writings on publicity (critical public  debate)  are  read  in  relation  to  his  writings  on  the  legal  organization  of publishing, a necessary connection emerges between authors' rights – as distinct from copyrights  –  and  what  Jürgen  Habermas  and  others  have  named  the  "public  sphere"."

This is called ∀-introduction or generalisation. It is not related to the conditional in the body of the quantifier (i.e., you can also apply it to ∀x:P(x)). If you can prove that P(x) for arbitrary x, then it must be true for all x.

When proving a conditional P(x) → Q(x) you assume P(x), because the case that ¬P(x) is trivially true (since a conditional with false antecedent is always true). So the assumption that P(x) is not really a restriction on the arbitrarily chosen x, it is rather the next step in the proof.

If it helps, you don't have to assume P(x) to prove P(x) → Q(x). You can also use the law of excluded middle:


  For arbitrary x, either P(x) or ¬P(x).
  (a) If P(x), then ... so Q(x). Hence, P(x) → Q(x).
  (b) If ¬P(x), then P(x) → Q(x) is trivially true.
  Therefore, P(x) → Q(x).


If you want to prove the universal, you can continue with:


  Since P(x) → Q(x) for arbitrary x, we can conclude ∀x: P(x) → Q(x).

It depends on the kind of possibilities you're talking about. If you're talking about logical possibilities this is clearly not true. There are conceivable states of affairs that did not occur. 

I guess you're talking about possibilities that are not merely "in the head". If you're talking about nomological possibilities (what is possible given laws of nature) this is still not true if you assume "the initial state of the universe could have been different"is true. There are counterfactual possibilities corresponding to different possible universes with different initial conditions.

Now you could assume necessity of the past. Then your statement is true, by definition: if determinism is true, laws of nature determine the future state of the universe and so there's only one possible way the world could evolve.

Finally you could talk about metaphysical possibilities. Many authors since Kripke believe that they are distinct from nomological and logical necessities, in particular because laws of nature "could have been different"metaphysically speaking. In that case, your statement is false because there are metaphysical possibilities corresponding to alternative laws of nature even if the world follows strict laws of nature. But others think that metaphysical possibilities are the same as nomological possibilities (in particular, dispositional essentialists) and others that they are closer to logical or conceptual possibilities.

As to how long people have been thinking that, well, since there are different understanding of possibilities it's hard to say, but questions about necessity and determinism go back to the Greeks.
This writing strike me as it could answer https://plato.stanford.edu/entries/concept-evil/ https://plato.stanford.edu/entries/concept-evil/
It suggest that what you are asking is the answer.

I would correct your statement (if we would be talking about this say 20 years ago) then I would claim most people would say "Good or Bad" (not evil) and as @Canyon suggested word VERY bad or even Very, Very bad... however it could still not be enough and for these occasions we would have use word EVIL. 

I know you can't go back to the past, where word EVIL would be used for the most horrific things that could happen to you in life, nowadays word evil is used everywhere (not so often in news, probably due to its religious connections but in other poplar media, movies and everyday talk). 
But EVIL is the very very very very bad.. 
You said "With these two comments in mind, could we infer that Socrates fears Euthyphro?"

By just taking two comments from such a large conversation, you are going to conclude somethings which may be true (based on just these 2 comments) but pointless/worthless.

By the way, I have the conversation in ancient Greeks language (https://repository.edulll.gr/edulll/retrieve/6990/1761_euthyphro.pdf https://repository.edulll.gr/edulll/retrieve/6990/1761_euthyphro.pdf) and your posted translated dialogue has a different meaning (compared to the actual conversation)!

Please note that the "revered friend" is just a common greek expression. It has no particular meaning in the sentence.
Roughly, the text means we have to put some faith into our sense-data. I'll translate what I take to be the best reading into plainer terms.


  As we seek to understand more deeply our common conception of rationality, we can make some interesting observations.


Self-explanatory.


  First, our beliefs can't be irrational, or nonrational, or else the concept of rationality has no application at all.


We shouldn't hold irrational or nonrational beliefs. This is a requirement of rationality. If rationality did not forbid irrationality, it wouldn't do anything at all.


  The concept of rationality derives its usefulness from its ability to demarcate some beliefs off from others, separating the sheep from the goats, or the wheat from the chaff.


This is evidence for the previous sentence; rationality needs to be able to discriminate between good and bad beliefs.


  But how could any of our beliefs be rational unless it's rational for us to assume that the sources or mechanisms through which we received them are sometimes reliable?


Let's go out on a limb and say, hypothetically, that we have some rational beliefs. A rational belief is a belief held for rational reasons, that is, a well-justified belief. A belief couldn't be justified if there were no way to even occasionally acquire justified beliefs.


  It must then be rational to hold that our basic belief-forming mechanisms---sense experience, memory, and the testimony of others, for example---are sometimes reliable.


Of course we do have some rational beliefs, so we have to put some trust in the mechanisms by which we acquire beliefs. But of course we also have some irrational beliefs, so we shouldn't just trust in our ability to form beliefs blindly. In fact, we can be certain that our belief-forming mechanisms are sometimes unreliable, or else we would never have wrong beliefs.


  And if this rationality does not consist in our having a proof, or even any good evidence, for the truth of the proposition believed... then there must be some other road to rationality, other than proof and evidence.


This sentence is unclear and iffy. I'm not sure why the beliefs formed by the already-mentioned mechanisms wouldn't be supported by evidence. The testimony of others, our senses, and our memories all seem to me to be evidence that a belief is accurate. But I suppose we'll have to wait for Chapter 5 to really understand what the author is talking about.
The key to understanding the italicized part of your question is “in itself”. If the first state of matter is the cause in itself (and does not become the cause as a result of something else at a certain point in time), it means that all the effects or subsequent changes in states of matter start following immediately as soon as this first cause exists, without any delays, without any exceptions, with strict necessity. Cause “in itself” cannot be “inactive”, cannot exist without causing the following effect - it would be a violation of a law of nature. Thus, the period of time between that first state of matter and the current moment will always be limited, finite, with a beginning (the first cause in itself) and an end (the current moment). No matter how long this finite period of time is or can be, it will be always shorter than the infinite time in the past. If we imagine such first causal state of matter, we would have to move it into past infinity and thus all following states of matter, including the current moment, would also be in the infinite past, or as Schopenhauer says, “they must have existed from all eternity”.  

Schopenhauer is consistent and insistent in his ideas and arguments. So, when we are not sure that we fully understand his thoughts or ideas, further reading of his works can reassure us if we interpreted his ideas correctly. For example, here is how Schopenhauer «answers» your question directly: «But now, in the case of the honestly expressed cosmological proof through the assumption of a first cause, and consequently of a first beginning in a time absolutely without beginning, this beginning is moved up higher and higher by the question: Why not earlier? In fact, it is moved so high that we never reach down from it to the present, but must marvel that this present did not itself exist already millions of years ago». (WWRII, chapter IV, p.43-44 in Dover Publications, Inc. Ed.)

And furthermore: Schopenhauer explains why any cause in itself cannot be in a state of «inactivity» by pointing to the connection of the law of causality and eternal forces of nature. «…the law of causality finds complete application, and admits of no exception, to all things in the world, in accordance with their form of course, to the variation of these forms, and hence to their changes. … if we try to comprehend it [the law of causality] in a purely objective way, then fundamentally and ultimately it rests on the fact that every operative or causative thing acts by virtue of its original, and thus eternal, i.e. timeless, power [force of nature]. … Completely different from the cause, this force is nevertheless what imparts to every cause its causality, in other words, the possibility of acting. … Therefore its present effect would necessarily have appeared infinitely earlier, and so prior to any conceivable time, if the temporal condition for this had not been lacking. This condition is the occasion, i.e., the cause, by virtue of which alone the effect appears only now, but now with necessity; the cause assigns it its place in time.» (WWRII, chapter IV)
I'm not sure what angle you'd like this question answered from, but presuming that, being a site about the study of philosophy, you're asking about the epistemic value of peer review as part of the wider "scientific method", then I think pretty categorically, no, "peer review" is not a guarantee of scientific quality.

Many people outside of academia misunderstand what peer review actually is, conflating it generally with "what other scientists think of the work". Peer review, as far as journal publication is concerned, is a very specific process involving a very small number of "peers" (usually three, only two of whom are independent of the publishing house), all of whom will have been appointed/selected by the editor of the journal, who in turn will have been appointed by the publisher, of which there are basically five (yes five), in the whole world. Thus five CEO's effectively exert their influence on the whole of academic research. More shocking is that the entire system was basically https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science set up by Robert Maxwell as a money making enterprise.

The failure of this system to identify flaws in papers has been well documented by https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1182327/ Ioannidis, http://www.physics.nyu.edu/sokal/transgress_v2/transgress_v2_singlefile.html Sokal, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1420798/ Smith, http://www.sciencemag.org/content/342/6154/60.full Bohannon. 

Even the editors themselves have at time admitted the failure of the system, as Richard Horton of the Lancet put it


  "The mistake, of course, is to have thought that peer review was any more than a crude means of discovering the acceptability—not the validity—of a new finding…We portray peer review to the public as a quasi-sacred process that helps to make science our most objective truth teller. But we know that the system of peer review is biased, unjust, unaccountable, incomplete, easily fixed, often insulting, usually ignorant, occasionally foolish, and frequently wrong."


Ex-editor of the NEJM Dr. Marcia Angell


  "It is simply no longer possible to believe much of the clinical research that is published, or to rely on the judgment of trusted physicians or authoritative medical guidelines."


There is evidence of bias in terms of https://www.ncbi.nlm.nih.gov/pubmed/9163412/ gender, race and institutional prestige have been found (8 out of 9 paper that journals had already published from prestigious institutions were rejected when researcher re-typed them and submitted them again with different institution names.

As a side note (nothing to do with the epistemic value of peer-reviewed knowledge claims), the power of peer-review does not stop at just what papers are read, but in England, it actually effects research funding via the government's RAE assessments (I think there's a new system now, but I've not been involved for quite some time), by which peer reviews of department performance on some very spurious criteria (like "impact") actually determines research grants to those departments.

As Nikolaus Kriegeskorte said in his submission to the Parliamentary review of the peer review system


  "A scientific publication system needs to provide two basic services: access and evaluation. Access means we
  can read anything, evaluation means we don't have to read everything. The traditional publication system
  restricts the access to papers by requiring payment, and it restricts the evaluation of papers by relying on
  just 2‐4 pre‐publication peer reviews and by keeping the reviews secret."


He goes on to describe how Open-Access publications and the advances of modern technology can facilitate a more open and robust system which could actually further knowledge rather than restricts it. This was in 2011, to my knowledge absolutely none of the recommendations from any of the witnesses in that review have been adopted to date.
The quote describes what Brouwer calls the first act of intuitionism, the splitting off of discrete from the comprehensive intuition of which discrete and continuous are idealized poles. 

Here is some quick background. The basis of Brouwer's philosophizing is the non-linguistic "primordial intuition of mathematics", of a continuum without qualitative characteristics or changes, where continuity and discreteness are fused, and where any in-between is inexhaustible. This is his fluid continuum of intuition. But even this primordial intuition is not free from idealization and abstraction, it is the abstraction from qualities that makes this continuum suitable for doing mathematics. The first act of intuitionism calls for tracing the emergence of the discrete from the fluid continuum non-discursively. Its foundation is the "two-ity", the "falling apart of moments of life into two qualitatively different parts". Here is some further commentary on this process from http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.553.6849&rep=rep1&type=pdf van Atten, van Dalen and Tieszen's Brouwer and Weyl: The phenomenology and
mathematics of the intuitive continuum:


  "Brouwer says that this first act separates mathematics from mathematical
  language and recognizes that intuitionist mathematics is a languageless activity
  of the mind having its origin in the perception of a move of time, i.e., of the
  falling apart of a life moment into two distinct things, one of which gives way
  to the other, but is retained by memory. This ‘two-ity’, divested of all quality, is the empty form of the common substratum of all two-ities. In this common substratum, this empty form of all two-ities, lies the basis of the discrete aspect of the primordial intuition of mathematics. It successively generates each natural number and arbitrary finite sequences. It is natural to suppose that it lies at the basis of the finite combinatorial objects that could be generated from the natural numbers.
  
  Brouwer gives precedence to ‘two-ity’ in his account of the natural numbers. It is not good enough to merely start with a unit to obtain the natural numbers. Once we become aware of a sensation passing into another sensation, for example, we have the foundation for the abstract two-ity out of which the natural numbers are generated. Suppose we were to mark this awareness as ( | ) | to indicate the retention in memory of what was sensed earlier. This ‘two-ity’ can then be an element of a new two-ity: (( | ) | ) |, and so on... Brouwer emphasizes how
  in this successive, sequential structure with its ordering of ‘before’ and ‘after’ the ‘before-after’ or ‘first-second’ are held together in consciousness so that we have unity in multitude."


For more on Brouwer's and Weyl's fluid continuum see https://philosophy.stackexchange.com/a/30188/9148 Is Aristotle's resolution of Zeno's paradoxes vindicated by motion in the intuitionistic continuum? The linked paper also gives an interpretation of Brouwer's first act in terms of Husserlian phenomenology of intentional acts and temporal retentions/protentions:


  "At later (successor) stages of intuition the earlier stages sink back in time but are retained in an appropriately modified manner, indicating the importance of the role of memory in our constructions. To be more specific, as the construction begins and continues earlier parts of it sink into the past and out of our immediate awareness even though they are retained and remain active in processing present parts of the construction... The retentions are
  continuously modified as they sink back into the less immediate part of our
  present experience. Along the horizontal axis we have a multiplicity of successors but the vertical axis at each stage indicates how they are all held together or unified in one consciousness at that stage... 
  
  While the construction is in process there will also be some more or less
  determinate protentions (which are similar to expectations—but only roughly,
  see below) at any stage about how it will unfold and about its completion. In
  the case at hand this is completely determinate. It is clear that this will be a
  lawlike or rule-governed becoming. The future course of experience is fixed: it
  is simply the iteration of successor."


Moving from rule-governed to "lawless", free choice, construction, which creates the mathematical continuum, is the "second act of intuitionism".
As Isaacson points out, Kant's moral system is very complex and, as such, focusing on a few aspects can lead us to lose sight of some other important aspects of his system. But your questions themselves can be answered straightforwardly.  

Your first question is how Kant can be consistent when he says that morality requires free will yet morally worthy act is an act performed out of the sense of duty. Your complaint can be legitimate from a common sense perspective: acting out of duty means acting without choice, that is, acting without free will. But for Kant acting otherwise (out of self-interest) is acting without free will. To Kant, your statement, I do not think that it's tenable to say we do things outside of an egoism actually proves his point that, without free will, we could be the slave of egoism (self-interest, pleasure, personal values and projects). The difference between you and Kant is that to you free will is to promote self-interest, but to Kant free will is to overcome the egoistic compulsion. Once we exercise free will and employ reasoning capacity, we can arrive at the deontic morality, according to Kant. Thus holds the Kantian equation: rationality + free will = moral prescription

Your second question is how an act done out of the sense of duty can be properly moral since such an act sounds rather robotic, merely following a prescribed moral algorithm. Your question (complaint, precisely) is legitimate indeed as Bernard Williams made his career out of criticizing this algorithmic aspect of the Kantian (and utilitarian) morality, and a new paradigm of morality called particularism that rejects any universal moral algorithm was born.    
Genesis, in fact, contains (at least) two creation stories. The first ranges over Gen 1:1–2:4a; the second over Gen 2:4bff. The exact boundaries are debated. See e.g. Zevit, 2013, What Really Happened in the Garden of Eden?, esp. pp. 76–77:


  Originally, the Hebrew Bible did not have chapter divisions. It was written as a continuous text with breaks approximating paragraph divisions where narrative scenes or topics under discussion changed. Chapter divisions and verse numbers were first inserted into biblical texts during the Middle Ages by Christian scholars as a way of dividing the text for ease of reference. (...)
  
  One consequence of this medieval misdivision has been uncertainty
  as to where the seven-day creation story ends and the Garden story begins. Although many scholars consider Genesis 2:3 to be the end of the Cosmic Creation story, others propose that it ends with the summarizing statement of Genesis 2:4a. If so, then the Garden story proper begins only at Genesis 2:4b.
  
  Arguments in support of the second position follow a twofold line of reasoning. On the one hand, verse 4a seems an appropriate summary of the creation narrative; on the other, if verse 4a were the first line of the Garden story, verse 4b would be unnecessary because it repeats the same information.


So, Philo doesn't really skip part of the story, he just considers a different story. In Legum Allegoriae, Philo writes how https://en.wikipedia.org/wiki/Philo%27s_works#Allegorical_commentary "the history of primal man is (...) considered as a symbol of the religious and moral development of the human soul." For this, the Garden story is much more relevant than the cosmological account of creation. However, not having access to the current knowledge that the Eden story only starts around 2:4, he also deals with vv. 1-3. This is described in the analytical introduction to book I (pp. 140–145 of your PDF):


  In 1-18 Philo deals with Gen. ii. 1-3, which tells first of the completion of Heaven and Earth.


Philo does consider Genesis 1 in De Opificio Mundi. As a book of laws, that is "fitly prefaced by a Cosmogony" (analytical introduction to On the Creation, p. 2):


  26 Then [Moses] says that "in the beginning God made the heaven and the earth," taking "beginning" not, as some think, in a chronological sense, for time there was not before there was a world. (http://biblehub.com/genesis/1-1.htm Gen 1:1)
  
  29 First, then, the Maker made an incorporeal heaven, and an invisible earth, and the essential form of air and void. (http://biblehub.com/genesis/1-1.htm Gen 1:1)
  
  30 Special distinction is ac­corded by Moses to life-breath and to light. The one he entitles the "breath" of God, because breath is most life-giving, and of life God is the author, while of light he says that it is beautiful pre-eminently: (http://biblehub.com/genesis/1-2.htm Gen 1:2,http://biblehub.com/genesis/1-3.htm 3)
  
  ...
  
  69 After all the rest, as I have said, Moses tells us that man was created after the image of God and after His likeness (http://biblehub.com/genesis/1-26.htm Gen 1:26)


Also helpful is the analytical introduction to De Opificio Mundi on pp. 2–5 and the list of biblical references on pp. xxviii ff. of the PDF you linked (Op for De Opificio Mundi; L.A. for Legum Allegoriae).
I'm not sure about Plato, but the interpretive principle that is described in the question has been discussed in modern analytic philosophy, and has been nicknamed https://en.wikipedia.org/wiki/Principle_of_charity the principle of charity.


  In philosophy and rhetoric, the principle of charity requires interpreting a speaker's statements to be rational and, in the case of any argument, considering its best, strongest possible interpretation.


The philosopher that has been mostly associated with the principle of charity is https://en.wikipedia.org/wiki/Donald_Davidson_(philosopher) Donald Davidson. That is because the principle of charity plays a central role in Davidson's philosophical system.

What your friend said expresses well why the principle of charity is important for everyone.


  If I can't see what is substantial and noble in a viewpoint I oppose - whether ethical, political, or religious - there's a good chance I haven't understood it, and/or that my own view is grounded in passion more than reason.


To stress the point a bit: the principle of charity in interpretation, despite its nickname, is not a matter of charity. It is not a matter of generosity, or of good will. It is not, that is, optional, but necessary. If you are not invoking it, towards opinions that you hear, and towards texts that you read, you are practically guaranteed to misunderstand what you hear and read.
I think (and I broadly agree here with Eckart Förster, whose book The Twenty-Five Years of Philosophy will be quoted here for reference) that Hegel roughly follows Kant's understanding of science. Therefore, clarifying what Kant wrote about science may help to elucidate how this intertwines with the idea of a single principle.

Kant himself on science

Kant thought that science is, as opposed to a modern understanding, a set of constructible, certain sentences. Certain, however, they can only be if the way they are obtained itself is certain, which for him means by and from principles that are themselves certain. Förster draws on these two main aspects:


  First, according to Kant science is not merely a rhapsodic collection of propositions, but a totality of knowledge ordered according to principles and hence systematic. Systematicity is only a necessary condition for science, however, not a sufficient condition. For if those principles are merely empirical in nature, what we have is a systematic doctrine, but not a science in the proper sense. Secondly, therefore, the principles must be associated with a “consciousness of their necessity” (4:468). Hence they cannot be principles discovered on the basis of induction, mere generalizations from experience; they must be capable of being known a priori. “All proper natural science therefore requires a pure part, on which the apodictic certainty that reason seeks therein can be based” (4:469). (Förster, 2012:67, bolded mine)


Science proper here only consists in the pure part. That is why in his introduction to the Anthropology, he dismisses psychology as not being a science proper in any way, missing this pure part.

Kant on philosophy as science

It is the  main point of the whole critical endevour of Kant to bring metaphysics (or philosophy as such) back on the "secure course of a science":


  Metaphysics - a wholly isolated speculative cognition of reason that
  elevates itself entirely above all instruction from experience, and that
  through mere concepts (not, like mathematics, through the application
  of concepts to intuition), where reason thus is supposed to be its own
  pupil - has up to now not been so favored by fate as to have been able
  to enter upon the secure course of a science, even though it is older than
  all other sciences, and would remain even if all the others were swallowed up by an all-consuming barbarism. (Kant, CPR, B xiv)


And:


  Now the concern of this critique of pure speculative reason consists
  in that attempt to transform the accepted procedure of metaphysics, undertaking an entire revolution according to the example of the geometers and natural scientists. It is a treatise on the method, not a system of
  the science itself; but it catalogs the entire outline of the science of
  metaphysics, both in respect of its boundaries and in respect of its entire internal structure. (Kant, CPR, B xxii)


From Kant to Hegel

Förster has some four chapters on that, and I cannot refer to all the content discussed. The main core points of Kant prevailed, and it had been a major criticism that he presented several principles (for each faculty of knowledge one), trying to show how these can stand side by side without contradiction. 

Most critics argued that there has to be a single, unifying principle. Basically, the idea why a systematic Wissenschaft has to be derived from a single principle is easy: Say we have two a priori certain principles, to take the easiest case. Now, if we want to apply them, they are either materially identical (single principle), or we will have to decide which principle is to be applied. For deciding that, we would need to have a third principle, which would need a justification of its own. The main idea of this dilemma can be found in my answer https://philosophy.stackexchange.com/questions/8216/is-it-possible-to-know-anything-with-certainty/42465#42465 here as well.

This lead to various attempts of finding a single principle. Förster writes on Fichte:


  For Fichte characterized his philosophy, which he now referred to as Wissenschaftslehre, as the discipline which philosophically grounds the possibility of every other science. Since every science must have a systematic 
  form, and since such form can only be derived from a first principle, the 
  Wissenschaftslehre must at the same time establish principles for every other science. Those principles must, if they are truly to be principles, be incapable of further proof: “All those propositions which serve as first principles of the various particular sciences are, at the same time, propositions indigenous to the Wissenschaftslehre. Thus one and the same proposition has to be considered from two points of view” (GA I,2:128; W 1:56) (Förster, 2012:175).


This "one and the same proposition" was A=A, the proposition of identity. This has led to criticism by e.g. Hölderlin, who was highly influential on Hegel, his former fellow student in Tübingen and very good friend (they met 1797 in Heidelberg and discussed these things a lot).

Hegel himself

I will quote secondary literature here, as this is easier than carving it out of Hegel's text and give interpretation and context. Hegel saw philosophy as a science:


  For Hegel, it is the “scientific” in the
  sense of the theoretical whole [he links Hegel's understanding of science with 'totality' just before] that determines not the empirical but the 
  ontological truth of a sentence. He knew very well the difference between
  physics and philosophy, for example, although he often opened himself to
  ridicule by attempting to express the philosophical significance of physics.
  But this was precisely his intention: to provide a philosophical explanation
  of philosophy as an expression of the totality of the human spirit. Hegel
  accepts the scientific nature of philosophy, but he distinguishes philosophical
  from natural science. (Stanley Rosen, *The Idea of Hegel's "Science of Logic", pp. 5-6)


Rosen is quite explicit about that Hegel is looking for something like a fist principle:


  Like Hegel, Fichte is obsessed with the need to arrive
  at a presuppositionless beginning, in order to transform philosophy into a
  deductive or systematic science. He begins his search for the “first, strictly
  unconditioned principle” with a distinction between thinking as activity and the principle as an expression of that activity (Stanley Rosen, *The Idea of Hegel's "Science of Logic", p.196)


Regarding the nature of this single principle, this case is clear to some extent if you know Hegel, but hard to track down in a single quote: It is (Absolute) Geist, the all-encompassing conscience. The closest I could find to verify that is the following, effectively describing Geist as ultimate condition of the unity of object and subject, which can only be grasped by looking at the whole of history:


  It is
  Hegel’s goal to bring together understanding and reason in such a way as
  to show that the ideals of the latter are achieved or fully manifested in the
  structure of the former. This in turn depends upon the transformation of
  the synthetic unity of apperception from a logical condition of consciousness
  to a principle of subjectivity, namely, the principle that underlies the
  unity of subject and object (Stanley Rosen, *The Idea of Hegel's "Science of Logic", p.22, emphasis mine)


Summary

The understanding of what it means to be Wissenschaft, i.e. something that through its methods literally translated creates knowledge [Wissen = knowledge; schaffen = to create], had been quite different. Hume's skepticism led to the understanding that all phenomenal, empirical data is not reliable enough to constitute knowledge in this very peculiar sense. 

And what Hegel thought to have accomplished is to present a method that, through its application, is able to get rid of empirical illusions, leading to an understanding of how reality actually is, i.e. to knowledge. Therefore, in this sense, it is Wissenschaft. And it is Wissenschaft der Logik as the knowledge is gained through a very specific methodology he calls logic, although this may differ a lot from contemporary understandings.

Long story short: If terms in historical philosophy do not make any sense, try to look up their historical and, in philosophy, often times technical meaning.
I got to read Ramberg's essay and Rorty's response, so I'll try an answer.

This issue requires subtle but sharp distinctions. Ramberg's essay is very cautious. What he attempts, and impressively succeeds in, is to recocile central philosophical views of Rorty's and of Davidson's. Ramberg tries hard throughout his essay to remain faithful both to Davidson and to Rorty.

Ramberg did get Rorty to accept the phrase, and the idea of truth as "getting things right". It is crucial to notice, however, that there is not, either in Ramberg's suggestions or in Rorty's concession, the slightest hint about conceiving truth as "representation" or "correspondence to reality". The whole exchange, including the "getting it right" bit, is entirely embedded in the pragmatist notions of "coping", "tools" and "norms".

(Indeed, where could Ramberg import relations of representation or correspondence from, when what he does is to defend Davidson? There are no such relations in Davidson's philosophy)

Roughly speaking, the change that Ramberg caused in Rorty's views is this: Before the change Rorty was a kind of social relativist, which he also identified as a kind of pragmatism. He believed that the community determined truth and falsehood, although an individual could sometimes choose to alter the community. After the change, Rorty accepted Davidson's "triangulation" view: the self (epistemology), the community (normativity) and the world (causality) jointly and inseperably determine truth and falsehood. Agents are related by linguistic communication, the world is related causally. By contrast, truth as representation and correspondence is not involved.

In terms of ongoing debates, again roughly speaking, after the concession Rorty no longer had any substantial disagreements with Davidson. By contrast, he continued to disagree with any philosophers that held to any degree of truth as "correspondence with" or "opening to" the world. This includes McDowell and Putnam.

In his response to Ramberg, Rorty seems well aware that his concessions to Ramberg about some views raise questions about the consequences for Rorty's other views. He subsequently lists four of his views that are unaffected by his concessions to Ramberg:


  How many of my previous positions - positions criticized by McDowell, Dennett and others in this volume - am I now forced to give up? Not many. Here are some doctrines which remain unaffected:
  
  1 No area of culture, and no period of history, gets Reality more right than any other. The differences betewen areas and epochs is their relative efficiency at accomplishing various purposes ...
  
  2 Pace McDowell, there is no second norm given us by the facts, in addition to the norms given us by our peers. Still, McDowell would be right to point out that I should not speak of "norms set by our peers." It was a mistake to locate the norms at one corner of the triangle ...
  
  3 To say that we get snow mostly right is not to say that we represent snow with reasonable accuracy. Talk of representing goes along with talk about sentences being made true by facts, and with talk of "structural isomorphism" between mind and world (such as Dennett's "real patterns"). The holism of intentional ascription forbids any such talk ...
  
  4 My militant anti-authoritarianism, exhibited in my response to Williams and critically discussed by McDowell, remains unchanged. For I can still maintain that there is no such thing as the search for truth, as distinct from the search for happiness. There is no authority called Reality before whom we need bow down ...


  The problem is that all positions on the table have the same probability. That means the probability for the ashtray to hit any position on the table is zero.


Not quite. The probability for the ashtray to hit any given position on the table is zero. But as you have observed, you can most certainly lay the arrow on the table and get a new position.


  Nevertheless, obviously it is possible to place an ashtray on a table. So, in spite of a zero possibility, one position is chosen anyway. This cannot be!


Since you are not targetting a given position, there is no paradox. There is zero probability that you will pick up the ashtray and put it back down at the exact same given location, but you can certainly put down the ashtray and get a new position, just like you did the first time.
If you are working from Sam Harris's version of morality, then you are dealing with something more like Ethical Naturalism which is a type of Utilitarianism, but distinct from many other forms of Utilitarianism. Harris contends that there are moral rights and wrongs that can be objectively stated based on the fact that people stating their preferences are stating facts about the world and as such facts can be objectively assessed. Whilst the traditional Utilitarianism of Mill might be concerned with maximising utility via any means, Harris asserts that such means can be deduced by scientific investigation.

Traditional Utilitarianism is not so concerned with the 'intention' of the person as it is with the outcome, so, in your scenarios both of the seemingly moral actions (because of their good intentions), would be morally wrong because of their outcome. This may seem unfair, but the hard Utilitarians take the position that it would be irrational to want any outcome other than the maximal happiness of humanity (or all concious beings) and so to advise (by moral judgement) the taking of any other course would be  wrong.

Ethical naturalism differs slightly in taking into account the consequences of the cultivation of virtue. Phillipa Foot argues that virtues are tools that a person can use to cause well-being. As such your scenarios cannot be taken out of context. So in your first example one might say that the world has suffered an immediate reduction in well-being as a consequence of your actions, but in the long term your cultivation of the practice of 'honesty where it seems appropriate' that will have been furthered by this one exercise, may be logically assessed, using facts about people's preferences, to be something which is likely to bring about an increase in welfare overall, and is therefore moral.

The difficultly with such an approach is that of any consequentialist ethic as Anscombe argues, is that one still has the problem of not being able to see all ends. In both of your examples the consequences are somewhat unpredictable, and so one could argue that judging the rightness of a moral choice on the basis of it's long-term consequences (as Foot would have us do), is even more prone to the unforseeability of the consequences as standard utilitarianism. The counter-argument to this for Harris is from evolution (both biological and cultural). We have, he argues, carried out such experiments thousands of times and so we do indeed have a relatively sure knowledge of the long-term consequences of certain virtues, enough to declare some action objectively wrong.

Opponents of Ethical Naturalism (or any consequentialist ethic really) often use scenarios like the ones you've given to illustrate their opposition, but really, if you examine the reality of the situation carefully, the moral wrong often becomes obvious. Is the admission of your indiscretion morally wrong because of it's consequence, or is it your failure to support the person's emotional needs afterwards? Is it the seeking of a vaccine that's wrong because of it's consequences, or is it, in fact, the failure to put in place adequate bio-security measures? Ethical Naturalists generally argue that for most circumstances we are actually quite good at estimating the long-term consequences of our behavioural strategies and as such general statements about what is morally right based on the cultivation of virtues (a specific form of 'intention') are perfectly objective.
Well Heidegger would say the primary way we deal with our environment would be the ready to hand, and he gives his famous example of hammering to show his point. We don't have to analyze too closely, we just cope. We hammer without overthinking it. We see the same thing with driving and many other things we do.  However, I should mention that this mode of coping "on automatic" can be potentially dangerous. We can imagine the Buddhists cautioning us to be mindful!  

What Heidegger was keen to do was to draw a distinction between ready to hand and present to hand, and the
latter would harken back primarily to Aristotle and what followed from him. Typical Western categorization, analysis and so on (perhaps "analysis paralysis"), representational/ correspondence theories of truth would come in here too. Though Heidegger does not deny the importance of the present to hand, nevertheless I think he wants to show that our primary way of coping (or being) would be the ready to hand. 

So Heidegger is trying to balance the Western tradition. In my opinion, and I think this is a fairly common opinion, Heidegger was a Romantic character (I refer here to the romantic era). He was suspicious of modern technology. The people of the countryside knew how to cope too without all the analysis and categorization demanded by our new scientific technological world which philosophers like Aristotle etc. had made possible. You know Heidegger had his hut up in the mountains and so on.   He wrote more about his concerns with technology in his later works. I am familiar with Brandom from the internet (YouTube interviews etc) and I know he is well regarded, but since I have not read any of his his work, I can't comment on him. 

As far as Heidegger ever thinking in terms of any sort of praxis or pragmatism. He did not have a high opinion of America/ Americans in general, and on that basis alone I doubt he would use the word "pragmatism". To the extent that "praxis" may be associated with the Marxists, he might have avoided that word too. I can't read German, so I don't know. I did read somewhere he was open to some sort of socialism, but I don't have a source to be able to judge how serious he might have been, or what his mature position was. 

De facto, however, it could be argued that the ready to hand is a kind of practice. And the whole idea of coping with our world would be amenable to the pragmatists. But I should hasten to add that certainly the later Heidegger would be highly opposed to the instrumentalism associated with some forms of pragmatism. 

In the end,  he was concerned with the dangers of technology for its own sake, technology "let loose", and the contribution that typical Western philosophy had made toward this phenomenon. 
Xunzi famously argued that the human nature is evil, and thus for human beings to live in peace and harmony, they need to learn from sages (masters) 禮, and live according to the teachings of 禮 (禮 is pronounced in Korean 'ye,' meaning manners or rite or rituals; I do not know the Chinese pronunciation). Examples of 禮 are being an obedient son and wife, and performing sacrifice for the dead ancestors. This is an example of the Korean sacrifice.

https://i.stack.imgur.com/04XVb.png 

Practicing 禮, according to Xunzi, is the way to transform our nature: from the innate evil tendency to the acquired, good characters. 

The question is, "Where does the first master come from?", or more precisely, "How the person discovered 禮, given that there were no other masters to teach him 禮 and that he himself should have been innately evil?"

Xunzi almost answered this question with his famous metaphor of crossing a treacherous river. To cross the river, someone should have placed marks to indicate where is safe to step on. To Xunzi, the person who puts the marks is a master, marks are 禮, and the treacherous river is the innate human nature.   When we follow the marks in the river, we will safely cross the river. Likewise, when we practice 禮, we will live peacefully and harmoniously together. Xunzi maintains:  


  Rituals provide the footing upon which people walk. If you lose this
  footing, you will certainly stumble and fall, sink and
  drawn." (I borrow the English translation from Effortless Action: Wu-wei As Conceptual Metaphor and Spiritual
  Ideal in Early China: Edward Slingerland, p.241)


Once we understand that the masters are markers for a safe cross, it is pretty common sensical how the first master could have been made, as explained in http://www.iep.utm.edu/xunzi/#SH3d http://www.iep.utm.edu/xunzi/#SH3d.  The first master is like the person who first started to mark the fords. Nobody was born to know where the fords are.  It would have been most likely a matter of trial and error, perseverance, talent, luck and vision. Likewise, the 禮 that worked for a given society would have been a collective, generational process of crafting.   
There's several reasons to believe Kant would not


include a duty to prevent another person's unethical actions


OR


consider preventing the action of another person in general moral


First let's start with the distinction between these categories. Type 1 is whether this would fall under the required duties that arise out of the categorical imperative. While Kant supplies several formulations, the important point here is the distinction between  perfect duties and imperfect duties (see https://plato.stanford.edu/entries/kant-moral/ https://plato.stanford.edu/entries/kant-moral/ and also Marcia Baron, Kantian Ethics almost without Apology). For Kant, perfect duties arise from either 


considering what is universally required 
OR
identifying what is necessary to respect rational beings as ends.


Imperfect duties, in contrast, arise for human rational beings because they at times need things. Thus, we have an imperfect duty to assist others and to develop our talents, because we have at times needed others to act according to maxims that accord with this but not at all times.

To this, we need to join an odd and often over-looked feature of Kant's ethics: that Kant believes we are to assume that humans and other rational creatures act rationally. This is a major motive for his views on lying (prior to the sense in which he thinks it violates a duty to one's self in Metaphysics of Morals). 

It's also a mirror image of the Kantian idea that you can do the "right" action but not from the right maxim and thus not have acted morally (Groundwork Section 1 -- discussion of the shopkeeper; n.b. that doesn't mean the shopkeeper acts immorally).

Returning to the question of whether we can have a duty to actively prevent another's unethical actions, we can first ask whether we have a perfect duty to do so. The answer on the Kantian picture is no, because it would make no sense for any rational to have a moral maxim of harming others, so there's no way to have an perfect duty to prevent others from harming since this would never rationally arise.

I want to briefly skip over the potential for an imperfect duty to prevent others from causing harm to state that for Kant, in general, the prevention of the expression of another's will is immoral, because others are assumed to be acting rationally and worthy of respect in our treatment of their wills. This is a strong motive for Kant's view "On a Supposed Right to Lie" in response to a killer where he rejects lying as an option (contra many of his contemporary followers).

At best, I think you could argue we have an imperfect duty -- meaning a duty we can do some of the time -- to prevent others from causing harm. But this would have to be severely qualified. First, it would have to be qualified in the sense that we are not acting to prevent the will of a rational creature, because on Kant's view we should assume a rational creature is trying to act morally. In other words, it would have to be narrowly restricted to obvious wrongs like murder (for which Kant believes there can be no moral maxim).
I do not know of any philosophers who argue that time has a beginning but a slight adjustment to your idea would lead you to Kant and the Perennial philosophy for which time is not metaphysically-real.  

This is a different idea but has many of the same consequences. What you seem to be suggesting is that the time is only ever 'Now' and the past and future are only ever theoretical, and this allows your speculation to work. I think you're probably right about this but pretty much on your own among philosophers. To me the Upanishadic or Buddhist explanation of time seems a lot more plausible and it has widespread support and an extensive literature. 

It may also be relevant that the consistent-histories interpretation of QM allows for history to be re-written in every moment, but I'm not enough of a physicist to explain this.        
The question deals with ⊨ i.e. with https://en.wikipedia.org/wiki/Logical_consequence Logical consequence: 


  A formula A is a logical consequence within some formal system of a set of statements S if and only if there is no model in which all members of S are true and A is false.


We can apply the definition above: by assumption, we have that every truth valuation that satisfy a will also satisfy c and every valuation that satisfy b will also satisfy c.

But a valuation that satisfy a ∨ b must satisfy either a or b.
As a parent, I was often presented with similar arguments from my kids. I can see at least two fallacies in the scenario, depending on interpretations: equivocation and denying the antecedent.

Equivocation

The argument is based on the ambiguous construal of the content of choice.
For the parents, the content of choice is this: "Clean your room or else (some sort of punishment would ensue)!" The child however construes the choice as follows: "I clean my room ( = I get $50: To her, cleaning implies a monetary compensation as she believes that all unvoluntary labors must be compensated) or I do not clean my room (= I exercise my free will)." 

Since the child understands the content of her choice in this way, she rightfully complains that she is in dilemma:  "Either I clean my room (in this case, her cleaning action lacks free will since her work without the remuneration is forced) or I do not clean my room (in this case, her exercising her free will will be construed as disobedience).

If the parents explain what is the content of the choice for the child, she would realize that she does have a choice after all.  

Denying the antecedent

Upon hearing "Clean your room," the child permissibly translates the sentence into a disjunctive form. "Either I don't get $50 or I clean the room." (disjunction introduction). The disjunctive form is equivalent to the following conditional: "If I get $50, then I clean the room." The child did not get $50. Thus the child concludes that she does not clean the room. The child's reasoning however commits the fallacy of denying the antecedent. 
Your step 7 is wrong. 

See https://en.wikipedia.org/wiki/Contraposition Contraposition: (∼W ⊃ ∼G) is equivalent to (G ⊃ W).

From (∼W ⊃ ∼G) and G we cannot validly infer ∼W. Consider the case when G and W are both TRUE: in this case the premises (∼W ⊃ ∼G) and G are TRUE but the conclusion ∼W is FALSE. 
You cannot that way; after step 3), you need ∨-Elimination (i.e. Proof by Caes).

You have to start two subproofs: one from assumption Pc and the second one from Qa and in both cases derive (∀y)Py ∨ (∃x)Qx.
The problem with this line of reasoning is that your refutations are not refuting the initial arguments.

For the first argument, unless you're arguing that these groups do not have less social privilege, you're not affecting the view that that discrepancy can be ameliorated by positive discrimination. 

At best, your argument means that there are other groups e.g. poor, white males who suffer from a similar lack of social privilege, possibly for similar underlying reasons, that aren't being helped. 

This may well be true (I'd be very surprised if it isn't) but it doesn't mean that positive discrimination would not help the specific groups. It may open up a charge of unfairness but that's not a refutation.

And your refutations do not at all address the second argument i.e. that diversity helps an organisation's performance. If it can be shown that that statement is empirically true, then it becomes a secondary consideration as to why it's true. 

Now, I'm reasonably familiar with this field and, to my knowledge, the only diversity metric that has been shown to have a material performance effect is male/female gender ratio. That's not to say the others don't but the academic backing is light.

Having said all that, I happen to agree that there are deeper societal issues. Or to put it another way, it's not explicit discrimination at a company level that is the cause of the discrepancy so cannot be the driving solution. 

However, economic status is, I believe, a factor as is visible opportunity. As such, my view is these measures can help, and should be employed, but are by no means sufficient to resolve the underlying issues.

Edit:
Category Mistake

To the question of whether the arguments are category mistakes.

For the first argument, I would say no. These identity group do exhibit a lack of social privilege and that positive discrimination, at a hiring level, can alleviate some of the symptoms of that lack. 

For the second argument, I will have to hedge. It is not a category mistake for male/female gender diversity as that is well established to have a bearing on performance. I am not aware of research that concluded a positive impact of other identity diversity on team performance. So there may be a mistake there.

Finally, in reference to a number of comments, it is very possible that the idea of identity selection, at an organisational level, does not significantly resolve the underlying causes of social privilege difference. Nor is it necessarily the most effective or just mechanism. As such, it may well be a category mistake to presume such. 
The Wikipedia article on https://en.wikipedia.org/wiki/Free_will Free Will calls it “hard incompatibilism”.  

Here is the graph showing the taxonomy: https://en.wikipedia.org/wiki/Free_will#/media/File:FreeWillTaxonomy4.svg https://en.wikipedia.org/wiki/Free_will#/media/File:FreeWillTaxonomy4.svg
As I understand it, there are 3 parts to your question.
1) The only limitations are those imposed by the physical storage system/medium.
2) To answer the second part, one must distinguish between "internal" (individual) knowledge, and "external" knowledge (information).
All externalized knowledge (information) can be binary encoded, and therefore, can be stored in a binary system.
3) Any "internal" (individual) knowledge can not be accessed, therefore, can not be encoded or stored in a binary system. 
I agree with @PeterJ's comment to a point, but believe NO "meaningful" theories stand up to analysis. Given the justification for any "meaningful" theory, I believe one or both of the following must be true:


The justification contains a logical fallacy
You can show the theory is logically equivalent to statements that "reasonable" people would reject


More specifically, a "meaningful" theory is one that addresses real-life issues, not pure abstraction.

"Reasonable" people reject statements such as "it's OK to kill innocent babies for no reason".

A fun application of my belief is arguing with people on social media: you can show that all arguments either contain logical fallacies or, when logically extended, are equivalent to statements that the arguer abhors.
Facts includes the existence of all things, but also all provable properties and behaviors of all things.

Imagine a universe made up of only a teacup and a hammer.

Things:


Teacup,
Hammer,
Universe


Facts:
The existence of things are facts. *at this point the two views are identical


There is a teacup 
There is a hammer 
There is a universe


But then we have facts ABOUT things


The teacup is near the hammer
The teacup and hammer are moving toward each other
The teacup and hammer will continue to move toward each other


And facts about facts!


Anything that is moving will continue moving unless something stops it 


*at this point, we're transcending things entirely and starting to talk about general facts.  If we only cared about the objects in the universe, this would not be 'part of the universe'

Wittgenstein also is talks a lot about hypothetical facts


The teacup could have been larger than the hammer
There could have been two teacups
There could have been a bowl of petunias


etc. etc.
It is one of Hume's central claims that we have no experience of necessity and cannot appeal to it in the explanation of anything. When we consider, say, the determination of an effect by a cause, we infer the existence of a 'necessary connexion' between them. Given the cause, the effect cannot but occur. This is a common way of thinking. But it has a purely psychological explanation due, Hume says, to the 'constant conjunction' of two types of event. We say that A causes B because and only because in our experience A-type events have invariably been followed by B-type events. 

Hume backs up this claim with his basic position that ideas or concepts, such as that of necessity, require experience at some point in their derivation. But we have no experience of necessity. We do not experience one event causing another; we experience one event following another under conditions that Hume spells out.  If the experience is missing then either we cannot form the idea in the first place or, if we do as in the case of necessity, it is a fabrication or fiction unjustified by experience. It is the product in Hume's language of the association of ideas. 

This is all easily to be found in Hume : Treatise of Human Nature, I, III, 14, 'Of the idea of necessary connexion'. Don't be misled by the earlier I, III, 2, 'Why a cause is always necessary'. The heading is ironic and does not vindicate the necessity in causation at all.
acts are public already so there is no privacy breach there

Equating an event that happened in public to having a recording of an event is a false equivalence.

An event in public can be witnessed live by people who happen to be there.  By contrast, a recording is an artifact that grants its possessor the ability to control to whom, whether or not, and when the event is witnessed.  Possessing a recording creates a power imbalance not present when merely witnessing an event.  This alone makes having a recording drastically different from merely being a live witness.  (There are other differences in degree as well, such as that live witnesses can only collect information if they happen to attend to it, but recordings can be played back repetitively and scrutinized).

the main problem here is the bullying by other people regarding their sexual orientation or even simple things like gastronomic taste which could be protected exactly by the surveillance people who engage bullying

This possibly creates another false equivalence, though it's a bit ambiguous.

If you're arguing that it's okay to bully a homosexual/mock an employee's eating habits, if you could in addition catch the bully/mocker, then I'm curious what sort of ethical system you're employing.  I don't see how catching the bully/mocker with the same technology erases the harm to the homosexual/employee.  Surely not having harm done in the first place is different, and preferable, at least to the affected party who should for that reason have some say.

If you're arguing that nobody who is recorded would want to bully a homosexual, or mock an employee, then you're living on a different planet from me.  The notion that the bully would suppress his behavior while being recorded but the homosexual should be unaffected (i.e., free to show affection) while being recorded is extremely naive.  It also misses the point; this is a risk assessment issue.  Whereas you're not the one facing the potential harm in this scenario, it's not up to you to assess the risk on behalf of the potentially harmed party.

In the other hand I noticed that a number of people that I know who are strongly against public recording often engage in socially unacceptable behavior like cheating their partners or vandalism.

That observation is meaningless.  For whatever reason, a large number of people cheat.  If you actually used the fact that a large number of people who are against public recording cheat to conclude something, then you're doing something wrong.  To just establish a correlation between cheaters and anti-public recorders, you need to have a comparative analysis across all groups (including pro-public recorders); i.e., you cannot ignore the https://en.wikipedia.org/wiki/Base_rate_fallacy base rates.

This personal observation lead me to think that people who don’t want to be recorded probably have a guilty mind of something wrong they did or still do in public space and they don’t want this to be known to the public.

Let A be that a person cheats.  Let B be that the person is against public recording.  Then so far, you had been arguing that A=>B.  But here, you're concluding from this that if B, then A.  In other words, you are arguing:

A=>B, B, therefore A.

That is https://en.wikipedia.org/wiki/Affirming_the_consequent affirming the consequent.

As it turns out, the most general concern here isn't merely being exposed for doing something wrong.  It's any situation where the revelation of information to some particular party can cause a harm.  We're not just talking about people being guilty, we're talking about preventing your friend's abusive ex from learning where your friend lives; keeping despotic anti-butter governments from learning where the butter factories are; keeping mobs of butter-on-the-other-side folk from attacking a butter-on-the-same-side proponent.  Keeping a thief from learning mothers' maiden names.

Or perhaps, being exposed to a bully for being homosexual, or to rude coworkers for your culinary habits?
From 'The Dionysiac World View', which is a kind of commentary on BN it appears that Greek tragedy on Nietzsche's view arose from the conjunction, the fusing in creative conflict, of the Apollonian and the Dionysiac. Both mentalities had existed separately but 'at the moment when the Hellenic "Will" blossomed' and this conjunction occurred, tragedy was born. It is not clear that Nietzsche offers any other source or origin for tragedy except this conjunction. It is a fair inference that both the Apollonian and the Dionysian had existed separately before the birth of tragedy - but co-existed and not fused in the art of tragedy.  

Quotation is from Nietzsche, 'The Birth of Tragedy and Other Writings', ed. R. Guess & R. Speirs, Cambridge, 2000, 119. 
It is fair to say that the concepts are "equivalent" in the modern mathematical practice. However, they have different histories and different overtones of meaning. The notion of natural or counting numbers goes back (officially) to Pythagoreans and unofficially to prehistoric times, https://en.wikipedia.org/wiki/Ishango_bone Ishango bone, a counting artifact, is 20,000 years old. We are dealing with a loose concept imported to mathematics from natural language after centuries of practical and then more abstract use. While in one sense cardinals generalize natural numbers, in another sense they are a much more narrow, technical, and context bound notion.

The notion of "cardinal number" or "cardinality" (even finite) is much more recent, it is one way to make the everyday concept more precise for mathematical use, the one favored by the current formalization of mathematics. The notion was https://www.etymonline.com/search?q=cardinal+number introduced by grammarians in 1590-s to distinguish between counting numerals (one, two, three) and order numerals (first, second, third), so-called https://en.wikipedia.org/wiki/Ordinal_number ordinals. But their modern mathematical life begins at the end of 19th century in Cantor's set theory, which imported the distinction and made it even more technical. Cantor replaced the elementary concept of a number with a derived and abstract one based on sets (for what it is worth, the informal counting conception is closer to his ordinals than to his cardinals, the notions are equivalent in scope in the finite case but diverge dramatically for infinities). Two sets are equipollent if they can be put into a bijective correspondence (this is now called https://en.wikipedia.org/wiki/Hume%27s_principle Hume's principle), and the cardinal number of a set is something like the equivalence class of all sets equipollent to it, or so Cantor wanted to say. This turned out to have technical problems, and now more "concrete" definitions are preferred, ones that identify it with one of very specially generated sets like ∅,{∅},{{∅}},... or ∅,{∅},{∅,{∅}},... , see https://en.wikipedia.org/wiki/Set-theoretic_definition_of_natural_numbers Set-theoretic definition of natural numbers.

This multiple realizability is already a problem for philosophers, we would like to think that there is a unique concept of "two", expressed as 2 or {{∅}} or {∅,{∅}}, but set theory can only provide us with an arbitrarily chosen token for it. This leads to popularity of http://www.iep.utm.edu/m-struct mathematical structuralism, the philosophical position that it is not what it is that makes 2 a 2 but only its place in a structure, in this case the structure of the counting number series described by the Peano axioms. Peano arithmetic already shows that natural numbers, unlike cardinals, can be lifted off of set theory since it does not depend on it. Neither does category theory, which has its own versions of natural numbers. Even within set theory the notion of "finite cardinal" can come apart from that of a natural number if we play around with the axioms. For instance, Dedekind defined "finite cardinals" as equipollents of those sets that can not be put into bijective correspondence with their proper subsets. Well, Russell and Whitehead showed in 1912 that https://en.wikipedia.org/wiki/Dedekind-infinite_set#History Dedekind finite cardinals can be infinite (on the usual conception) in set theory without the axiom of choice, so-called ZF, or other alternative set theories. Intuitively, this is because those models of set theory do not have enough bijections to "detect" infinity Dedekind's way.

Cantor's set theory, and even Hume's principle it is based on, were historically controversial and not without alternatives, see https://www.cambridge.org/core/journals/review-of-symbolic-logic/article/measuring-the-size-of-infinite-collections-of-natural-numbers-was-cantors-theory-of-infinite-number-inevitable/325464FFF1E318E3E51A80E652FA1C5B Measuring the size of infinite collections of natural numbers: Was Cantor's theory of infinite number inevitable? by Mancosu. If mathematicians decide one day that they prefer categorical or some other formalization of mathematics to the set-theoretic one the notion of cardinal number may go away, but we can be sure that the natural numbers will still be around.
If you take a really silly literal view of the sentence the statement is a https://en.wikipedia.org/wiki/Performative_contradiction performative contradiction but not equivalent to the liar's paradox.

Let's say being intolerant of something is along the lines of forbidding it. This is plausible. So saying


  I am intolerant of intolerance


means


  Forbidding things is forbidden!


If we agree that forbidding things is forbidden, we have to ask---how are we forbidden from forbidding things?

The problem stems from an unstated context. In all likelihood the sentence really means something like


  Forbidding things on the basis of ethnicity, gender, sexuality, religion, etc, is forbidden!


But of course nobody would have to spell that out; we all know what you mean when you say "intolerance" and "intolerant of intolerance" is just a fun phrase.

Finally, the statement isn't equivalent to the liar's paradox. If we affirm the liar's paradox we deny it, and if we deny the liar's paradox we affirm it. But if we deny "I am intolerant of intolerance" all we have is


  I am tolerant of intolerance


or


  Forbidding things is not forbidden!


which is clearly not a contradiction. This is because the sentence is not self-referential, https://en.wikipedia.org/wiki/List_of_paradoxes#Self%E2%80%93reference unlike the liar's paradox.



A small note on the rest of the tweet: I find it incomprehensible. The liar's paradox is not the https://en.wikipedia.org/wiki/Halting_problem halting problem, and neither of them have anything to do with the https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation map-territory distinction. Perhaps the writer means the concepts got at by language are different than the surface-level grammar, which is exactly right. But the first part of the tweet is just babble.
It depends what you mean by "set theory". ZF is not the only way to formalise set theory (though it is, of course, the most widely accepted). Cf. this excerpt from https://en.wikipedia.org/wiki/Axiom_of_choice#In_constructive_mathematics the Wikipedia entry on the AoC, in the context of constructive mathematics:


  In constructive set theory, however, Diaconescu's theorem shows that the axiom of choice implies the law of excluded middle (unlike in Martin-Löf type theory, where it does not). Thus the axiom of choice is not generally available in constructive set theory. A cause for this difference is that the axiom of choice in type theory does not have the extensionality properties that the axiom of choice in constructive set theory does.
  
  Some results in constructive set theory use the axiom of countable choice or the axiom of dependent choice, which do not imply the law of the excluded middle in constructive set theory. Although the axiom of countable choice in particular is commonly used in constructive mathematics, its use has also been questioned.


You might also be interested in reading the "https://ncatlab.org/nlab/show/axiom+of+choice#Variants Variants" section of the nLab page on the AoC, and this quote from https://ncatlab.org/nlab/show/topos the nLab page on 'topos':


  The internal logic of toposes is intuitionistic higher order logic. This means that, while the law of excluded middle and the axiom of choice may fail, apart from that, every logical statement not depending on these does hold internal to every topos.


So in addition to @celtschk's comment that the answer "depends on what you think set theory describes", it also depends on the specific set theory in which one is working.

  It is impossible for us to know a specific truth or order of universe
  with only finite observations; instead, we can only verify them. For
  instance, scientific knowledge are tentative and are subjected to new
  evidances. It is always a cycle of hypothesis and confirmation of the
  theory until it is proven to be false. We may assume it is true once
  it is verified.


You're mixing up verificationism and falisificationism here. I believe you hint at the idea of Popper. We only have finite observations. In order to circumvent induction we have to formulate hypotheses and try, with all our might, to falsify them. When there not yet falsified then they are our best explanation. If they get falsified we have to drop them. I'll just note that there are arguments against that views in philosophy of science.

But this isn't even that important for your question. It's more about whether the results we get out of scientific processes are to be believed or if they are only functional but can't result in truths. The former would be scientific realism, the latter would be scientific antirealism. There is, however, a position inbetween called "scientific structuralism" which seems to be quite defensible. The SEP can provide articles about the issue.

https://plato.stanford.edu/entries/scientific-realism/ https://plato.stanford.edu/entries/scientific-realism/

https://plato.stanford.edu/entries/structural-realism/ https://plato.stanford.edu/entries/structural-realism/

So your position seems to hold scientific realism at least possible, as you say that we can't tell the trueness of a theory. More on that later. These positions then come into play with the problem of scientific progress: whether science progresses and how we should think about it in terms of truth.

More here:

https://plato.stanford.edu/entries/scientific-progress/#ReaIns https://plato.stanford.edu/entries/scientific-progress/#ReaIns


  However, as said before, we can never tell the trueness of the theory
  as a form of knowledge.


So this is not a default position. But, assuming you can argue for it, if we go from here we could find value in two ways. Firstly, while they might still be wrong, they could be closer to truth. Popper argues in that way. You'll find a bit more in the third article. Secondly, even if they might be completely wrong, they could still have instrumental value.

You asked:


  Is it reasonable to distrust any knowledge we know?


No, in general it isn't. But it depends on whether we think there is some acceptable theory of justification and also what we think truth is. This is a huge field. But let's take one example.

If we think that knowledge is justified true belief (that can deal with Gettier cases... I'll rather add that before someone lynches me) then your position would have to commit to the idea that we are justified in doubting justification in general because, often times, it has turned out wrong. This seems contradictory. Does it look different if we just apply it to science? Well not really. Just because theories before have turned out to be wrong this does not undermine our justification to accept current theories. (If "accept" means that we should believe that they show something true is a different matter connect to all sorts of issues, as I've tried to show beforehand.) After all, this sceptical approach has no justification itself. 

I'll leave you with a bit of Wittgenstein. In On Certainty he writes: "If you tried to doubt everything you would not get as far as doubting anything. The game of doubting itself presupposes certainty.". I believe this is really important. The word "knowledge" does not require complete certainty. Hence it's fine to say that we know something even if there's a chance it can turn out to be wrong.
While there is an argument for this around the concept of fate, it's also a serious question for AI research as well. The science and mathematics behind this question is not that complicated, but it does tend to fly in the face of our own empirical observations and the experience we have of being human. Let's start with the science.

Since Einstein, our concept of the universe revolves around a 4 dimensional space-time, in which time is merely another dimension of our universe. This becomes important because when discussing symmetry (a very important concept in physics which shows that we can predict what will happen in one place, orientation or time based on observations of the same phenomena in a different place, orientation or time) we see that time is as much bound to the laws of physics as any other direction.

With the single exception of the second law of thermodynamics (entropy, we'll get to that) all the laws of motion we understand work in both directions of time. If all these laws work in both directions, then it becomes clear that it's possible to predict the future by observing the past and extrapolating. If these laws hold perfectly in both directions of time and we are bound by them also, then the universe is algorithmic in nature, and that means 3 things;

1) We are algorithmic in nature also
2) It's possible for a computer to be aware because it's algorithmic
3) Free will (by definition) has to be an illusion because an algorithmic universe means that the future can be accurately predicted with enough information and (by extension) no choice we can make is able to change that future.

So, how does entropy apply? Well, entropy has been described in many different ways but the important point to note is that in a closed system (the universe), order degrades over time. For our purposes, this explains why we can only remember in one direction of time; the brain lays down memories (increased local order) through the release of heat (decreased global order) in the temporal direction set by entropy. That means that even if space-time is a static object, we appear to remember it through a lineal sequence because of the ways our memories are set down.

Lots of implications here, but let's get to the meat of it for the purposes of this question; if space time is deterministic (algorithmic) in nature, free will must be an illusion. If space time is non-algorithmic in nature, then algorithmic behaviour can still exist (it's a subset of non-algorithmic possibilities) but it's now possible that the human mind is non-algorithmic in nature meaning that it's possible that free will exists for us.

Even if that's the case, it means that computers cannot ever achieve human awareness because they are algorithmic in nature, and therefore at best could only simulate a subset of the functions of the brain and therefore could not achieve free will.

There's another scary thought here. The vast majority of science (physics in particular) is based on the idea that the universe is deterministic in nature, or that in other words we know how the universe works because we've seen how it works in the past. In order for us to have free will, it would mean that the universe can't be fully deterministic. Sure, the vast majority of it could still function according to algorithmic principles, but our own free will implies that at least part of the rest of the universe may not.

If that is the case, then all that we know about the universe must in some way be called into question. We cannot be certain of the past, or the future. In fairness, no scientist would ever say they were certain about concepts like the Big Bang, relativity, quantum mechanics, etc. But, if we could ever prove that free will did actually exist, we would have to be less sure of these things than we are today.

Is it possible that the organic brain is the only aspect of the universe that operates outside deterministic principles? Sure, it's possible. But, it's not very likely. So, that leaves us with one provable theory and two possibilities;

1) Computers can never have free will as they operate on deterministic principles.

a) If humans also operate on deterministic principles, our free will is a lie
b) If not, then free will may not be a lie, but proving that would force a re-think of all modern scientific principles to date.

Either way it would be both a thrilling and terrifying discovery. 
Since you say you are just starting to learn logic, it is likely that you are being taught about the conditionals known as material implications. These are usually the first conditionals that you are taught when studying logic, though there are many others. Material implication only works well when used with simple propositions and leads to apparently paradoxical examples when stretched to fit less simple ones. If the conditional in your example is interpreted as a material implication, it is "if Jackie is not hungry then Jackie eats sweets". The negation of a material implication is the antecedent conjoined with the negation of the consequent, so its negation would be "Jackie is not hungry and Jackie does not eat sweets". The answer you have been given: "Jackie ate sweets though she was not hungry" is not correct.

If we were doing some slightly more advanced logic, we might observe that "Jackie eats sweets, if she is not hungry" is better represented as a quantified sentence, along the lines of "on all occasions when Jackie is not hungry she eats sweets". The negation of this might be "sometimes Jackie is not hungry and does not eat sweets". 

Human existence does not as such harm the environment. Suppose there were only ten humans in the world. 
It is not the current level of population that harms the environment but the way in which we currently live. We do indeed cause harm to the environment at considerable risk to our own present and future well-being. But an environmentally-friendly economy and way of life could minimise if not remove the harm. It's how we live that harms the environment, not the size of the earth's population. 
It is not clear how much population growth the earth could sustain if we switched to an environmentally-friendly economy and way of life. 


What the realistic chances are that we will adopt an enviromnmentally-friendly way of life, I don't know - I am not optimistic. But the three points above still apply. 
See https://plato.stanford.edu/entries/brentano/ Franz Brentano's http://www.univpgri-palembang.ac.id/perpus-fkip/Perpustakaan/Filsafat/Ontologi/Franz%20Brentano-PSYCHOLOGY%20FROM%20AN.pdf Psychologie vom empirischen Standpunkt (1874), Preface to the English edition, page xxi:


  “Vorstellung” is sometimes translated as “presentation,” and sometimes as “idea,”
  or “thought.” The corresponding verb “vorstellen,” is translated variously as “to think of,” “to have before the mind,” and as “to have a presentation of.”


And see page 60:


  Every idea or presentation [Vorstellung] which we acquire either through sense perception or imagination is an example of a mental phenomenon. By presentation I do not mean that which is presented, but rather the act of presentation. Thus, hearing a sound, seeing a colored object, feeling warmth or cold, as well as similar states of imagination are examples of what I mean by this term. I also mean by it the thinking of a general concept, provided such a thing actually does occur. Furthermore, every judgement, every recollection, every expectation, every inference, every conviction or opinion, every doubt, is a mental phenomenon. 


See also https://plato.stanford.edu/entries/intentionality/ Intentionality.



But we have here also an issue regarding translation:
Russell use "presentation" for the German Vorstellung that is also transalted as representation (see Schopenhauer's https://en.wikipedia.org/wiki/The_World_as_Will_and_Representation The World as Will and Representation (German: Die Welt als Wille und Vorstellung)).
The logic is sound, and reflects my personal thinking on the matter. I don't know if I have free will or not, but by choosing the best option I can with the information available (even if I only think I'm doing that) has to be the better option for the reasons you state above.

The problem however comes with the injection of the subjective; what really is a good decision?

You mention ethics, but that is only a part of the equation, and one that some people don't care about. A sense of ethics implies that to you, good means good for the community as a whole, rather than good for you personally. This is a very subjective word that will mean different things to different people, and will often look different with additional perspective.

If I shoot someone and kill him, is that a bad thing?

If I shoot someone coming at me with a knife and murder in his eye, and I kill him, is that a good thing?

If I shoot someone coming at me with a knife and murder in his eye, and I kill him, is that a bad thing given he was after the murderer behind me that I didn't see?

The list goes on.

There's a reason they say context is for Kings; ultimately if there is an afterlife or some form of judgement that decides how well we lived in whatever form, it would be grossly unfair for us to be judged if there is no free will. If there IS free will, then we can only be judged by what we knew at the time and what our goals were. The context behind our decision at the time is probably dwarfed by the context of our world and the knowledge of the impacts a decision had.

Take (for example) Adolph Hitler. Decorated war hero, Tee-totaler vegetarian with a good grasp of economics. He clearly believed in his country and wanted to make it great. Did his intention (a strong Germany, able to protect itself not only from the Treaty of Versailles but from militarily strong European neighbors) justify his choices or actions? Does it justify the results?

Everyone I can imagine would universally say No. The thing is, Hitler didn't wake up one morning and say 'I think I'll start a global conflict today and try to wipe out an entire ethnic group' even if that's what he ultimately did. One could also say that he didn't even do what was best for himself; he did what he thought was best for his country. That it ended up leaving his country in an even worse state than he found it proves that his choices were poor, but from his perspectives, at the time, they were good decisions insofar as he believed they would lead to a strong Germany.

Ultimately though, the events of WWII can be argued to have changed the way we reason on matters of ethnic cleansing. The very comparison to Hitler has swayed many leaders from a hard line on matters such as refugee crises, how to deal with ethnic minorities and the like. On a longer scale than we've considered in the past, Hitler's choices and actions have created a morality tale that has shaped the way we consider matters of social reform, ultimately for the better.

So; while the logic works, the fallacy here is an appeal to emotion. What constitutes GOOD and when should the decision as a result of free will be judged? At the time it's taken or at the time that the true consequences are understood? Even then, on what timescale?

I personally continue to act as if I have free will for the reasons set out in (as you've coined it) Blomstrom's Wager. That said, I'm not naive enough to believe that all my decisions will work out for the best or even that the consequences will align with my original intent. I do the best with the information I have at hand and hope that it's enough to leave the world a better place than I found it. If I'm ultimately judged for this (and that's a big if) then at least I can say that I did my best with what I knew at the time.
We want to frame the world in terms of law vs chaos and reason vs emotion, but those are false dichotomies we have inherited from the nature of our politics.

You are starting from an extremely biased interpretation of art.  Many artists have been well-balanced people.  Passion is not a mental disease, and mental diseases do not constitute genuine passion.  The art done in Jungian Art Therapy is not high art that speaks to the world, unless it already would be with all the mental torture absent.

We want to see those who would alter the dominant order as alternately 'creative' and 'crazy', because we both honor and resent our domination by social convention. So we create an imaginary correlation between the two.  But history just does not bear it out.  We have great crazy innovators, and we have great sane innovators.  We have a lot of totally uncreative mentally ill people, and a lot of totally uncreative sane ones.

Being a visionary may be hard on one's emotions, but it does not necessarily affect your mental health.  And seriously imagining that the world could be different does not make you crazy by default.  These are just two narratives that forgive massive hypocrisy involved in a highly structured society that both wants and hates change.
For the sake of other readers, here's the passage with some additional context:

Most people will be inclined to agree with St. Augustine: "What, then, is time?  If no one asks of me, I know: if I wish to explain to him who asks, I know not."  Philosophers, of course, have learned to be glib about time, but the rest of mankind, although the subject feels familiar, are apt to be aware that a few questions can reduce them to hopeless confusion.  "Does the past exist?  No.  Does the future exist?  No.  Then only the present exists?  Yes.  But within the present there is no lapse in time?  Quite so.  Then time does not exist?  Oh I wish you wouldn't be so tiresome."  Any philosopher can elicit this dialog by a suitable choice of interlocuter.

There's not much to this.  From the perspective of a hypothetical representative of the "rest of mankind", here's an outline of the hypothetical "argument" that time does not exist.


The past does not exist (it may have existed in the past, but it's now gone)
The future does not exist (it may at some point, but it doesn't now)
The present, however, does exist.
The present is just an instant; it has no duration.  (Just rephrasing "within the present there is no lapse in time?").
By 1, 2, 3, and 4, the only thing that exists is this present instant.  That implies that time (i.e., "the passage of time") does not really exist (because there's no room in "the only thing that exists", that being an instant of time, to have such things as "flow of time").


The argument above isn't meant to be taken seriously (see the passage); it's simply an example of how "a few questions" can reduce "the rest of mankind" into "hopeless confusion".
I just wanted to close this question, so thanks to @LuísHenrique I realized I mistakenly translated the word from Hebrew (פנטומטי) to pantomathic instead of phantomatic (a weird word to use nonetheless). That way those lines are much clearer. 
Probably the best complete translation of Plato is : 

J. Cooper and D.S. Hutchinson (edd.), Plato: Complete Works. Indianapolis:
Hackett Publishing Company, 1997. Pp. xxx + 1848.

This is better - slightly more scholarly and definitely more up to date - than :

E. Hamilton and H. Cairns (edd.), Plato : The Complete Dialogues, New Jersey : Princeton University Press, 1961. 

On the Timaeus : Plato, Timaeus by H. D. P. Lee (1966) - Penguin - is pretty reliable. A good and more recent translation is : Plato’s Timaeus. Translated by Peter Kalkavage. (Focus Philosophical Library.). Newburyport, Mass.: Focus Publishing, 2001. I also endorse Zeyl. 

As to page numbers, all editions of Plato use the Stephanus pagination - e.g. 26b. So whatever translation you use will easy cross-reference to any other. 

You would do well to avoid the much earlier work of AE Taylor. He was a notable scholar but in this area inclined to eccentric views. 
If examinations can be justified, I doubt if it is terms of some single aim. I have myself set more examination papers (in philosophy) than I care to remember. I can't avoid the platitudinous : the aims of my exams were to test accuracy of knowledge, to assess judgement (so I looked for fairness and balance in an answer) and, least important, expression. 

These three criteria don't sit in easy harmony with one another. What to do with the answer that shows truly impressive accuracy of knowledge yet is one-sided, not balanced, but brilliant ? 

If these criteria - perhaps others have better - define the aims of examinations, those aims are only imperfectly served by any actual examination system. 

1 The examiner can only hope to assess a cross-section of what a student might know. No examination paper can cover the whole syllabus or module. It is a matter of no small chance whether for a particular student the 'right' questions come up. I have myself sat both lucky and unlucky exams - exams where I got the questions I had prepared for and others where I didn't. Say, two 'good' questions and several horrors on a single paper. There is always this element of unpredictability and (good or bad) luck. 

2 The examinee quite often faces the worry whether s/he has understood the question. (In one exam I realised half-way through my answer that I had completely misunderstood the question. I cancelled everything and started again, just managing to organise my material in time.)

3 Then there is the worry whether the examiner will read the answer as intended, understand the exact point the student is making. 

4 Finally - at least here - there's the worry whether memory will work fast enough, or whether you are answering questions in the most 'efficient' order (don't tackle your weakest questions first, they will or may well undermine your morale), and the sheer worry whether you can sort out the essential from the less relevant or irrelevant in time. Time is a dimension of terror in any exam.

Because of these imperfections in any exam system, I think the golden age of the exam is over. Increasingly exams are supplemented (if not replaced) by course work. But this, though a good idea, brings its own dangers of undetected plagiarism and undue help from fellow students or even, it must be admitted, instructors. 

So, to wrap it all up, exams are not pointless. They serve the three purposes I outlined at the start. But points 1 - 3 can well induce scepticism. I know : I've been there. 
Induction is about the probability of something. Abduction is an assumption as to what is the most likely answer - it's a judgement call.

ABDUCTION #1: The bones of 3 llamas were found in Cave X; therefore the vertebrae found in Cave X are likely from a llama. (since we already found 3 llamas, it's likely that the bones found are also llamas)

ABDUCTION #2: Object A orbits around the Earth. Object A is probably a moon. (it could be a satellite, but judging by the conversation about planets and stars, it makes more sense to assume it's a moon).

Deduction is something that always appears to be so. Induction is something that sometimes appears to be so. Abduction is the best assumption about something. 

So for instance: 

Deduction: Rain is water. Water makes things wet. Therefore, when it rains, the grass becomes wet.

Induction: It's 90 % chance of showers tomorrow afternoon: therefore, it will probably rain tomorrow afternoon and the grass will be wet. 

Abduction: The grass is wet in the afternoon; it probably rained. vs. The grass is wet in the morning, it is probably wet because of dew, not rain. (the best explanation for/an intelligent explanation).
The problem with scientism is that it's generally philosophically incoherent.  Examine your own statements of scientistic dogma:


  Isn't empirical truth the only one we can be sure about? If there is any absolute truth at all, isn't it to be uncovered through the scientific method?


Laying aside the thin veil of casting these as rhetorical questions, neither statement is an empirical truth, nor has been uncovered through the scientific method (if you disagree, describe to me the experiment that confirms them).  They are therefore self-undermining statements of belief.  You could have instead said "The only truths I accept are the ones that have been empirically confirmed," or "The scientific method has been the most valuable method of intellectual inquiry for the human race," but those statements rescue themselves from self-negation only at the price of making their value judgments more explicit. 

There isn't necessarily anything demonstrably wrong with affirming science as your own personal belief system, as long as you understand that is what you're doing.  But the belief that science itself confirms scientism, or is even capable, structurally, of confirming scientism is incorrect.  That's not the kind of thing it was designed to do --those are exactly the kinds of pronouncements it withholds.
Perhaps you could establish your body as a sovereign nation, yes, but where would the resources come from that are needed to sustain your body? You would have to barter with other nations (the place you live in) to gather resources, something which you already do through taxes and trading.

Furthermore, while it is your body to decide its fate, you are still in another nation with its own laws and customs, and the state has the authority to use violence because it has majority control over the violence. You would better be off declaring an actual nation rather that pointlessly break the social contract imposed upon you by being in a nation.
See e.g. https://link.springer.com/article/10.1007%2FBF02198233 Ontology and Ideology (1951):


  The ontology to which an (interpreted) theory is committed comprises all and only the objects over which the bound variables of the theory have to be construed as ranging in order that the statements affirmed in the theory be true. 


Thus, applying this criteria to e.g. first-order set theory, we conclude that the "universe" of sets is composed by all and only the sets whose exisence is needed in order to satisfy the axioms and theorems of the theory.
Check out Aristotles Physics where there is a discussion of this and which I found quite clear. The monists did not believe in the void they believed in a single thing/being the world could be reduced to - so monist. If I recall rightly, Russell points out Thales as the first monist for thinking everything is made of water.  

But Parmenides pointed out that if being is actual this means that there could be no change. This pushed the atomists to invent the notion of the void and atoms but Aristotle argues against the void and posits his notion of potentiality/actuality as the explanation of motion. Heisenberg used this notion of Aristotle to interpret QM. This returns as Thales: when you see a body of water water what do you see? Waves. So waves of potentiality and actuality in the body of being. 
From what I read in the license, such actions are explicitly intended to be taken.  The contributors accept that when they license their software under MPL.  Of course, the product must include the license in Exhibit A to even be legal (presumably you are not interested in the ethics of illegally renaming the product).  That exhibit is:

"The contents of this file are subject to the Mozilla Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
https://www.mozilla.org/MPL/

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is ______________________________________.

The Initial Developer of the Original Code is ________________________.
Portions created by ______________________ are Copyright (C) ______
_______________________. All Rights Reserved.

Contributor(s): ______________________________________.

Alternatively, the contents of this file may be used under the terms
of the _____ license (the  "[___] License"), in which case the
provisions of [______] License are applicable instead of those
above. If you wish to allow use of your version of this file only
under the terms of the [____] License and not to allow others to use
your version of this file under the MPL, indicate your decision by
deleting the provisions above and replace them with the notice and
other provisions required by the [___] License. If you do not delete
the provisions above, a recipient may use your version of this file
under either the MPL or the [___] License."


It also states that "You must include such notice in a location (such as a relevant directory) where a user would be likely to look for such a notice."  If superdb.com does this, then it does exactly what the contributors expected it to do.  By doing so, the original contributors get the credit they expected from the license.

Now perhaps this particular open-source database software was unaware of what their license choice meant, in which case such actions might be preying on the ignorant.  But if we assume they knew what they were doing, they picked this particular license out of the dozens of similar licenses which draw the line slightly differently.  There was intent to support this action.  Thus, to argue that such an act is unethical is to argue that the act the contributors intended you to do is unethical.  While you could argue that there are sufficient negative consequences to make it unethical, doing so with the contributors expressed intent is a difficult argument to make.  You would likely have to argue that the contributor's choice of license was also unethical, because it provided too much freedom and not enough guidance.

(assuming this action is actually legal.  The way I read the license, it's legal, but a lawyer may know better than I)
I find it useful to approach this question from the bottom up.  You made a philosophical argument:


  My argument is that there is no way to deny the sure success of the sciences (like Physics, Chemistry, Medicine, etc).


One of the things I love about philosophy is once you take a stand like this, there's always a line of questioning which can unsettle your position.  I find it's useful to unsettle it first, and then use that uncertainty to explore the other interesting parts of the question.  So that being said, I will not deny the sure success of the sciences.

Instead, I will question it.

I'm not going to say that the sciences haven't had sure success, I'm simply not going to immediately accept that the sciences have been a sure success.  I'm going to ask you to convince me.  How sure are we?  You will almost certainly point to the wide acceptance of science.  Science is everywhere in our society!  To which I will reply that bacteria are everywhere as well.  Does that mean bacteria are a success?  Is it really good if something succeeds, simply because "succeeds" is the word we used?

Are we happy because of science?

Do we have meaning, because of science?

Are we better people because of science?

These are harder questions.  There are a lot of very strong arguments suggesting that science and technology have actually made us less happy, and further from meaning.  After all, that's the general pattern which drives people to become monks, and monasteries are alive and well today.  They're "succeeding" too.

Now I, myself, tend to find the science arguments compelling.  I'm choosing to be the person questioning science here, but I understand where you're coming from.  What I'm really picking at is


  I think the scientific method must be assumed as an axiom/premise in Philosophy


(Emphasis mine).  Such wording is a very powerful claim when speaking in the philosophical world.  And, generally speaking, powerful claims are very hard to justify in philosophy.  And, in fact, you will find that the scientific method actually does not always appear in every philosophy.  I once attended a great lecture on what Traditional Chinese Medicine is, and the speaker explained a difference in how their tradition is developed as compared to Western medicine:


Western medicine tears the body apart into components, develops
hypotheses about these components, then builds them up. At each step,
it develops testable hypotheses, and tests them. From there, it finds
things which may provide results, and tests those.
TCM starts with the body as a whole, finds things that cause good results, then develops testable theories about why the results
occurred.


There's clearly a difference in methodology.  Many would claim that TCM does not follow the scientific method.  But TCM is deeply steeped in Chinese philsophy, so a claim that philosophy must assume the scientific method as a premise invalidates 4000 years of Chinese philosophy, declaring it to "not be philosophy because it doesn't assume the scientific method."  You can understand why such a claim is not popular.

Or you might claim that TCM has the scientific method hiding in it.  As it turns out, there is no one "The Scientific Method."  We talk about it as though there is only one, but there isn't.  It's actually a rather large class of approaches ranging from the very precise definitions that are used at the LHC when making observations of subatomic particles all the way out to a very broad "guess and check" mentality.  You could choose to define the scientific method to be broad enough to admit Chinese philosophy, thus making it easier for others to accept your claim.

But there's a catch.  The weaker you elect to define the scientific method, the harder it is to have absolute confidence that it must be a good thing and a successful thing.  It's actually a really fun exploration, which digs at the heart of what it means to be "science."

This is the Philosophy of Science, and the point where I can segue to answer your original question.  The philsophy of science is considered to be a subdiscipline of empiricism.  Empiricism is the study of that which we can "know" with our senses, i.e. empirical observation.  There are other subdisciplines of empiricism as well besides science.  Empiricism, itself, is a subdiscipline of epistomology, which is the study of what we can "know."  Knowing is an incredibly complex and nuanced thing in philosophy because it has to actually address questions along the lines of "How do we know that we know something?  How do we know that we know that we know something?" and so on and so forth.

Epsitomology, itself, can be contrasted to ontology.  Ontology is the study of what is real.  Most of us assume that we know what "reality" is, but ontologists really question it.  It turns out to be a tremendously interesting topic, but it's almost completely divorced from science.

Which is interesting.  We often have the opinion that science is a tool which leads us to the truth of reality, but when you dig far enough down into philosophy, you start to see that that isn't quite what it does.  In fact, some even argue that it does the opposite: instead of leading us to the truth, it tries to lead the truth to us.

But that's just one argument.  The point being, that philosophy explores a class of questions and their answers which reach far broader than science does.  And that's a good thing.  Diversity is good.  Science is great at what it does (that is to say, science is great at being scientific).  Philosophy is great at what it does (that is to say.... whatever philosophy does.  It's actually a rather funny exercise to try to pin down precisely what philosophy does).  Both are valuable in this world, and neither should really replace the other.

Now I have pointed out how much separation there is between science and philosophy.  But there is a very important connection between them: philosophers are people.  Their ideas mingle with the ideas of the population around them.  While there is no explicit connection between science and ontology, you will find that many ontological philosophers strive to develop their research to fit nicely with the ontological claims that science sometimes makes (when they technically can't make such claims, being empirical).  Other philosophers will explicitly strive to make their work conflict with science's claims, just to explore that "what if the world isn't the way we think it is" sort of question.  Their philosophy will naturally reject the claims that the scientific method must be assumed, because the point of their work is to see what happens when you reject it.

So science absolutely influences all of philosophy, though often in a very indirect way.  Likewise, philosophy forms the cornerstone of what science, itself, is.  But many find it's digging and questioning to be a bit of a bore, so we often ignore this connection to philosophy.
Gauss in http://epsaleph.tripod.com/sitebuildercontent/sitebuilderfiles/disquisitionesarithmeticae.pdf Disquisitiones Arithmeticae (1799) does indeed express something close to what is now called mathematical formalism and structuralism. He writes: 


  "What is calculated (in the sense of things already counted) are not substances (thinkable objects for themselves), but relations between two objects counted two by two... The mathematician abstracts totally from the nature of the objects and the content of their relations; he is concerned solely with the counting and the comparison of the relations among themselves".


But it is hard to ascribe similar opinions to Kant, in fact his view was just the opposite, that concepts without intuitions are empty, and that (pure) intuitions for mathematical concepts are supplied by imaginative construction according to a priori schemata of space and time. In other words, relations are constructed only along with their intuitive objects. This led Kant to claim the a priori certainty for Euclidean geometry, something https://anewdifferentworld.wordpress.com/2015/07/16/gauss-kastner-and-kant Gauss explicitly criticized him for:"Precisely the impossibility of deciding a priori between [Euclidean and non-Euclidean space] gives the clearest proof that Kant was not justified in asserting that space is just the form of our perception." Indeed, relationalization and formalization of mathematics in 19-th century went hand in hand with rejecting (notably by Frege and Hilbert) Kant's intuitive conception of it (which was retained more by Poincare and intuitionists).

Gauss had plenty of earlier sources to build on though. The abstractization of mathematics can be traced back to Vieta's Isagoge (1591). Bos writes in https://books.google.com/books?id=ApbfBwAAQBAJ&source=gbs_navlinks_s Redefining Geometrical Exactness, Ch.8:


  "It was Viète who first introduced and promoted the idea that algebra was proper method for analysis of problems both in geometry, and in the theory of numbers... Viète usually reserved the term specious logistics for that part of his new algebra that dealt with abstract magnitude and in which therefore no assumptions coud be made about the actual effectuation of algebraic operations... Viète did not see algebra as a technique concerning numbers... but as a method of symbolic calculation concerning abstract magnitudes." 


For more see https://philosophy.stackexchange.com/questions/49451/gauss-and-the-defense-of-abstract-mathematics Esteve's The Role of Symbolic Language in the transformation of Mathematics. The next thinker to advance relational/abstract view of mathematics, and Kant's chosen foil, was Leibniz. He is the one who called imaginary numbers and infinitesimals "useful fictions" and promoted the so-called http://www.jstor.org/stable/41134263 "generality of algebra" (the term was coined by Cauchy), treating algebraic idenities as purely formal rules that apply regardless of the nature of the quantities involved. Peckhaus describes in https://pdfs.semanticscholar.org/4d36/5e07c3104dd1bc5780620424ecdafa89979a.pdf Calculus Ratiocinator vs. Characteristica
Universalis:


  "‘Abbreviating’ means that as soon as a characteristic sign has been established for a complex object, memory can be relieved of the burden of retaining all the characteristic elements of this object. Natural languages are not sufficient for this job of designating objects unambiguously. Only in the language of arithmetic and algebra has this idea been partially realized. All reasoning in these branches consists in using characters. Errors in reasoning prove to be miscalculations... He uses arbitrarily chosen letters according to the model of mathematics. This notation allows ‘calculating with concepts’ according to sets of rules, each of them forming a calculus ratiocinator."


Frege specifically names Leibniz's calculus ratiocinator as inspiration for his concept-script (predicate calculus). Generality of algebra was later extensively used by Euler, Lagrange, and Gauss himself, in "algebraic analysis" that preceded modern Weierstrassian one, see http://www.jstor.org/stable/41134263 The Foundational Aspects of Gauss's Work by Ferraro:


  "Finally, eighteenth-century functions were characterised in an essential way by the use of a formal methodology that it made it possible to operate upon analytical expressions, independently of their meaning. This formal methodology was based upon two closely connected analogical principles, the generality of algebra and the extension of rules and procedures from the finite to the infinite. The generality of algebra consisted of the following assumption: (GA) if an analytical formula was derived by using the rules of algebra, then it was thought to be valid in general"."


Peacock later renamed this into https://hsm.stackexchange.com/questions/606/why-does-the-principle-of-permanence-have-two-different-definitions Principle of Permanence of Form in his Symbolical Algebra (1831):"Whatever form is Algebraically equivalent to another, when expressed in general symbols, must be true, whatever those symbols denote." The abstractization of algebra was further promoted, before Hilbert, by Hankel and Dedekind.
The explicit purpose of a state is to inhibit agency.  A state is the opposite of anarchy - anarchy is the scenario where all individuals have absolute agency over themselves and their environment, which is often detrimental to most if not all of those individuals.  As such, the very nature of the state is an entity which limits ones agency in exchange for similarly limiting the agency of others.  Therefore to seek a state which does not infringe on the agency of its citizens is somewhat contradictory.

There are very few, if any, things a state does which do not constitute an infringement on agency.  You must pay taxes, you must pull over or get out of the way when you see flashing lights on the highway - you must follow the highway at all, you must respect other's property rights and you must not lie under oath, just to name a few.  These are fundamental functions of the state, to propose a state lacking these (sort of) functions is to propose nothing at all.

As such, it isn't useful to compare the actions of the state to the actions of individuals.  It is perfectly alright for the state to mandate you get out of the way when emergency vehicles need to get through on the highway, for instance.  It would be counterproductive, not to mention silly and inefficient, if anyone could do that whenever they pleased.

And so, to address your question, as it is a necessary part of the state's role to infringe on agency, it seems highly unlikely to me that there is any way for the state to properly punish those who inhibit others' agency without in turn limiting the criminal's agency.

Not to mention that the very word punishment could be defined as "infringing on another individual's agency in response to a previous action on their part", which would render your question the paradoxical "how can the state infringe on individuals' agency without infringing on their agency?"

A related question that perhaps could be explored further might be "When is it wrong for the state to infringe on the agency of its citizens?" and this question has been, at least to American standards, been answered by The Deceleration of Independence, The US Constitution, and the Bill of Rights.  This question is, I think, the fundamental underlying question of any state which professes a duty to its citizens - that is to say any state which agrees with your "supposition that we want to allow humans Agency".
I think the fact that the list of adjectives fails to determine if the character is lawful or chaotic speaks not to a problem with the system, but instead simply to the fact that ones alignment is not determined by their adjectives.  I feel like those adjectives could just as well be applied to an evil person as to a good person, and that you could construct a character who fits all those adjectives and has any of the nine alignments you chose.

To your question about philosophical mappings, I think the very point of the alignment system is to map philosophies to easy to remember terms, and I suspect one could go through the http://en.wikipedia.org/wiki/Normative_ethics Normative Ethics and associate each alignment with a more technical term.

One interesting note regarding the disconnect between the adjectives (effectively, values) and the alignment (effectively, philosophy) is this speaks to part of the problem in modern politics.  A group of people can get together and agree freedom, personal happiness, low crime rates and good education are all important, and yet still bicker endlessly on how to actually attain those things.
As you hinted, many of the 'paradoxes' about the idea of God's being omnipotent and omniscient are really just the use of language to describe logical impossibilities.  "Can God create a rock so heavy that he himself cannot lift it?" is a nonsensical proposition, like "Can God create dark brightness?" or "Can God kill the unkillable?"  There is an answers to such questions - no.  However, the 'no' is not a comment on said God's lack of omnipotence, but rather a statement that a logical impossibility is impossible.

It would indeed be the case that if a God could 'violate the laws of nature', the laws of nature should simply change to include the fact that they apply except when God violates them.  That way, they can easily be defined and be consistent with God's intervention.  In this way it is impossible to violate the laws of nature because they are simply a definition of how nature is, whether or not God is causing the behaviour.

So, the idea of God is not, I believe, logically impossible.  It is certainly possible that a God could exist that is omnipotent and omniscient, and logically impossible statements don't change that.  What can be said for sure, though. is that if such a God exists, it is an extremely nasty God (by human standards).  It is a God that has the power to end suffering, yet does not.  It is a God that has the power to give every human an equal opportunity to discover it, yet it does not; in fact, it gives some humans a one-way ticket to heaven (the ones born into a strong culture of indoctrination into belief in the God), and other humans a one-way ticket to hell (the ones born into a strong culture of indoctrination into beliefs in another God/Gods).  Would one even wish to worship such a God even if one knew of its nature?  That's for the reader to decide.

Concerning the https://secure.wikimedia.org/wikipedia/en/wiki/Coherentism#The_regress_argument regress argument, a coherentist would deny the premise that some proposition P must be given a single justification P`, which must be given a justification P``, etc. Rather, a coherentist might suggest that various beliefs constitute a complicated and interdependent web of justification. This answer avoids question begging, an infinite regress of justification, and foundationalism. Also note that Plantinga's proper functionalist account of properly basic beliefs is not open only to theism. For instance, Plantinga grants that various sense perceptions are also properly basic, just as belief in God is. Finally, for an account of knowledge that blocks sceptical scenarios like the Cartesian demon and the infinite regress, I suggest investigating Timothy Williamson's position in Knowledge and Its Limits.
Maybe you shouldn't care about sceptical scenarios too much. It's important to distinguish knowing some proposition P from knowing that you know some proposition P. The fact that you know that you're not being deceived by an evil demon does not imply that you can know that you know that you're not being so deceived. Basically, you can have first-order knowledge without even bothering about the second-order knowledge.
At least in Plantinga's flavor of "reformed epistemology", what counts as a "properly basic belief" is mostly determined by the proper functioning of your brain according to a "design plan". Basically, if you are functioning as you were designed to, you should know which of your beliefs are "properly basic". It's an externalist account, so you shouldn't expect to be able to tell infallibly "from the inside" which of your beliefs are basic. You might not know that you have a brain lesion, for instance. It's worth noting that the foundation is determined by the design plan that went into making you, and not merely "written into the rules".

The problem with this approach is that it fails to distinguish between two completely different types of consequences. First, there are consequences that involve intrinsic goods, such as telling the truth and not killing. Second, there are more indirect consequences in which we might say that the ends justify the means – such as stealing a loaf of bread to feed one’s starving family. True morality should focus on intrinsic goods, without attempting to counterbalance these against the second and more indirect type of consequences.

At the close of World War II, President Harry Truman used consequentialist reasoning when deciding to drop atomic bombs on the Japanese civilians. On one side of the balance, Truman placed the negative consequence of killing tens of thousands of innocent Japanese civilians. On the other side of the balance, Truman considered that the bombs would bring a quick end to the war, and thus serve as a useful means to an end. Believing that the latter reasoning was more weighty, he decided to drop the bombs – a murderous decision. 

Thus, consequentialism is not only flawed but even hazardous when applied to decisions like this.
There is not a single "philosophical angle" on this topic.  There is a branch of philosophy called http://en.wikipedia.org/wiki/Political_philosophy Political Philosophy that deals with this subject, and http://en.wikipedia.org/wiki/Political_philosophy#Influential_political_philosophers many philosophers with greatly dissenting views who have written on it.

Some views that may be of particular interest:


Nicolò Machiavelli wrote http://www.constitution.org/mac/prince00.htm The Prince.  He is famous for advocating the contention that "the ends justify the means".  His work would suggest that the government can do whatever they have to if it will help to accomplish their goals.
Thomas Hobbes, John Locke and Jean-Jacques Rosseau advocated http://www.iep.utm.edu/soc-cont/ Social Contract theory.  Although they had somewhat diverging views on what the limitations of the contract were, they all agreed that "a persons’ moral and/or political obligations are dependent upon a contract or agreement among them to form the society in which they live" (IEP).  Locke, in particular, argued that if the government infringed upon the natural rights of its people, the people are obligated to revolt.
David Hume was a critic of social contract theory and believed that a government had no justification for its sovereignty other than that which was granted by force.  However, he "expressed suspicion of attempts to reform society in ways that departed from long-established custom, and he counselled peoples not to resist their governments except in cases of the most egregious tyranny" (http://en.wikipedia.org/wiki/David_Hume#Political_theory Wikipedia).
Thomas Paine wrote http://en.wikipedia.org/wiki/The_Rights_of_Man Rights of Man which "posits that popular political revolution is permissible when a government does not safeguard its people, their natural rights, and their national interests" (Wikipedia).  Paine is most famous for his inspirational role in the American revolution.


Historically, people with a political agenda tend to select the "philosophical angle" of the thinker whose work is most sympathetic to their objectives and social conditioning.  The list I have provided is meant as a starting point and is by no means exhaustive.  Hopefully, these will help you to find the "philosophical angle" that works for you.
Would it be useful to begin where Marx begins, with the idea that each commodity has a http://en.wikipedia.org/wiki/Use-value Use-Value, an http://en.wikipedia.org/wiki/Exchange_value Exchange-Value, a http://en.wikipedia.org/wiki/Value_%28economics%29 Value and a http://en.wikipedia.org/wiki/Real_prices_and_ideal_prices Price?

I realize that Marx may not be the best authority to bring in from a tactical perspective, but I think that he gets at the heart of the value problem.
Because living forever, or at least much longer than we do now, is something who's impact would unfold predominantly in the future, consideration of its consequences have to take into account the nature of the future. Of course, we all the know the problems associated with predicting the future. The subject of future resource availability is something that many people have studied closely, yet there is still, of course, substantial disagreement. Thus, I would say, the consequences are unpredictable.

Personally, I subscribe to the idea that a http://en.wikipedia.org/wiki/Technological_singularity technological singularity will likely occur within the next 10-50 years. Thus, to me, immortality does not seem to pose much of a danger. Notably, many people who today endorse life-extension research and/or the pursuit of immortality also anticipate the advent of a near-term singularity. The most notable such person would be http://en.wikipedia.org/wiki/Ray_Kurzweil Ray Kurzweil. Also, I believe that Aubrey de Gray is http://www.youtube.com/watch?v=yxBPrMrCfPs&feature=related a board member of the http://en.wikipedia.org/wiki/Singularity_Institute singularity institute.
It would seem they must; there is still a functioning http://www.sophiaperennis.com/ Traditionalist publishing house, which is http://www.facebook.com/sperennispress active on Facebook and has more than 500 "friends", so it would definitely appear that there are new publications and active readers.
There are a large number of good books about Buddhism (and, more to the point of this site, Buddhist philosophy), but you seem to be looking for practical advice-- i.e., putting the teachings into practice-- which leads me to suggest that you visit a Buddhist center of some sort in person.  Trying to learn Buddhist practice from a book is something like trying to learn to swim from a book; it may be possible, but it is far from the optimal method.

Note, by the way, that there is something called "the paradox of desire"; in order to be free of desires, you must first have the desire to be free of desires.

Note: if you really want book suggestions, I'll add them, but I really would recommend visiting a center first.
It doesn't flip the left-right axis or the up-down axis. It flips the front-back axis, which is special because your front is closer to the mirror than your back.

You think it flips the left-right axis because you imagine yourself superimposed on your mirror image by walking into the mirror and then turning around. But it is this imagined turning around that reverses your left-right axis.

If you imagine yourself simply walking into the mirror, the reversal will be front-back only. If you imagine yourself superimposed on your mirror image by diving into the mirror such that your head lands where the mirror image's feet are, your left hand will superimpose on the mirror iamge's left hand, and vice-versa for right. Except now the image will be reverse on the up-down axis.

So, it's because human beings have left-right symmetry and are easily imagined turning around but not so easily imagined diving onto their heads that a mirror appears to reverse a human being left-right. It is actually front-back.
You should read http://www.zpub.com/notes/idle.html In Praise of Idleness, an essay by Bertrand Russell which examines your question.


  If the ordinary wage-earner worked four hours a day, there would be enough for everybody and no unemployment -- assuming a certain very moderate amount of sensible organization.


This is the gist of Russell's argument. Indeed, he argues that "individual human beings" would be capable of adjusting to such a system. (I can't recall what he has to say regarding the " feasibility of implementing such a system")
You may find in recent philosophical letters (e.g., http://www.urbanomic.com/ Collapse, in particular http://www.urbanomic.com/pub_collapse4.php vol. 4) a pronounced focus on horror, to the point sometimes where it is even presented as a kind of ontological principle. Many of the works which I might identify as participating in this turn will offer readings of "Weird" literature, like Lovecraft or Mieville.

In terms of philosophers to investigate, I might suggest a few potential jumping-off points. 

Reza Negarestani may merit some attention with respect to this problem. The work I would point you to would be http://rads.stackoverflow.com/amzn/click/0980544009 Cyclonopedia. To my mind he most directly answers to the terms of your question.

Kierkegaard's Fear and Trembling may be of some interest in this context as well.

More broadly, I might suggest that Deleuze and Guattari, as well as philosophers like Nietzsche and Spinoza, might have a lot to offer here given their concern with psychology and emotions.

In passing, note that Freud has a lot to say about fear and anxiety, but the presentation is decidedly more 'enclosed' than those of the aforementioned writers.
This is classic "http://en.wikipedia.org/wiki/Nature_versus_nurture Nature versus Nurture" debate, and if you study psychology you'll never hear enough of this. The ultimate answer is that it is not one way or another, but rather a dynamic mix of both.

Tabula rasa vs. innate knowledge

The problem is first and foremost of definitions: how do you define knowledge? Proponents of http://en.wikipedia.org/wiki/Tabula_rasa tabula rasa suggest that we are all born with a "blank slate", a mind empty of all knowledge. But does that mean it's completely empty? Given our understanding of the mind today, the notion of tabula rasa is really only true if you put the emphasis on slate rather than blank—"blank slate" thus referring not to an "empty" state of mind but rather to a default state of mind. For example, the reason we are really good at learning languages is because our brain is shaped in a such a way at birth that makes it really easy for us to pick up words. Some people would argue that this innate ("default") skill at learning languages counts as knowledge, and as such the notion of tabula rasa would be false. But if you accept that an innate ability acquire language, for example, doesn't count as innate knowledge (perhaps because it is not factual knowledge), then tabula rasa is true.  It should be noted that in the brain, skill knowledge is stored in a different location than factual knowledge (skill knowledge falls under http://en.wikipedia.org/wiki/Procedural_memory procedural memory [dorsolateral striatum/basal ganglia] whereas factual knowledge falls under http://en.wikipedia.org/wiki/Semantic_memory semantic memory [medial temporal lobes/hippocampus]). The procedural memory system is actually a lot better in many regards than the semantic system, which is why it's a lot harder to forget how to ride a bicycle than it is to forget the http://en.wikipedia.org/wiki/Quadratic_equation#Quadratic_formula quadratic formula. Tabula rasa thus might be defined to only refer to factual knowledge (semantic memory) rather than skill memory, and as such it would fit with the prevailing scientific theory of mind.

Is the stuff we're born with the same as stuff we learn?

On the same note as above, we're really good at learning the world around us when we're very little. Few people realize the extent of the things we learn as newborn infants and how amazingly fast we learn it, completely unaided by anyone. For example, we are able to discern a notion of "space" and "distance" (that we live in a 3D world and things can be nearer or further from us, not merely bigger or smaller), of object occlusion and solidity (that http://en.wikipedia.org/wiki/Object_permanence objects don't simply disappear when they leave sight, that two solid objects cannot occupy the same space at the same time). Very early on, infants also develop a rudimentary understanding of logic, they that other people have minds that are different from there own, and that http://en.wikipedia.org/wiki/Sally-Anne_test others can believe things which are false. The point is, we're good at these things because we're born with innate faculties which make it much easier for us. (Apologies, I would cite more of this but my child psychology books are at my parent's house. All of this stuff is heavily researched though, so you can easily find it online).

Okay... so what?

My point here is that humans are born with innate abilities to learn certain things easier and perform certain tasks better. The special thing about genes is that—outside of twins—everyone's are different. It is in fact very true that some people are born with better faculty for certain tasks than others. For example, I don't think too many people would dispute that some peoples of the world tend to—on average—be born with better genetic disposition to become great long distance runners than others (say, Kenyans). Just like some families have a lot of big people, others have a lot of small people, these kind of genetic predispositions which exist in the physical body also exist in the physical brain. Research heavily concurs that intelligence, for example, has http://en.wikipedia.org/wiki/Heritability_of_IQ a strong genetic component, but other aspects of the human mind do as well such as personality characteristics and even tendencies for things like alcoholism or depression.

So are some people born with better innate ability to draw or play music than others? Absolutely, in the sense that some people's brain structures are better suited to acquire and perform certain skills than others.

But no one is born already knowing how to draw perfectly. There is much experience that is needed, and training which helps develop the skill. The difference between a person with a genetic predisposition for drawing and someone without is that someone with the disposition would learn faster than someone without, and at more advanced levels may reach a level of proficiency that others cannot.

Great training and opportunity can often bridge the gap between innate ability and learned ability (although not always). But do not be misled into thinking that anyone of great skill automatically has great genes suited for the task. It may very well be the case, for example, that Beethoven worked long hours and studied extra hard to compose the music he did; he could very well have had poor genetic predisposition but practiced extra hard to be as good as he was.
You are starting from the assumption of a divine creator. A big assumption.

You are then stating there must be some justification for humanity having intelligence. "God was bored" does not seem like a suitable answer to you here. That means that there must be some sort of "divine plan" that human intelligence aided. "God was running an experiment" does not seem like an acceptable answer. 

Your argument seems to boil down to "God created humans special, ergo there must be a specific purpose for which God created humans with these special qualities." This argument has issues with God, creation, divine purpose/values, creationism, predestination, ect. 

So, your claim that there must be a real purpose to our being? nope.

Also, this isn't really a question in the sense of "I need to know something."
We stop the slide on step 1.


  Children are taught that different cultures have different values and that no one culture (even our own) has any higher claim to knowing right from wrong. Right and wrong must be made in the context of a particular system of belief.


Actually, children aren't taught this.  They are taught that different cultures have different values, and that it is important to be understanding and tolerant of those values, and that right and wrong is always made in the context of a particular system of belief.  But, at the same time, they are also taught that there are some universally held values (such as those encoded in the UN's Declaration of Human Rights).  

So, when it comes to matters of whether or not it is permissible to drink alcohol, or eat pork or beef, etc., it is prudent to defer to local customs.  This does not mean, however, that we need to look the other way in cases of torture or genocide.

EDIT:

I want to flesh out this answer a bit more, as I coincidentally came across some passages in some unrelated work I was doing that seems germane to the point.  The passages are in reference to skepticism and epistemology, but I think that the notions transfer (ceteris paribus) to the ethical domain in a straightforward fashion. 

First, let us begin with a quote from Myles Burnyeat:


  Nowadays, if a philosopher finds he cannot answer the philosophical question "What is time?" or "Is time real?," he applies for a research grant to work on the problem during next year's sabbatical.  He does not suppose that the arrival of next year is actually in doubt... [In this way,] he insulates his ordinary first order judgments from the effects of his philosophizing. (Burnyeat 1997:92)


Burnyeat goes on to say:


  So, we reach the idea that there are two ways of understanding a statement like 'The stove is warm,' the plain way and the philosophical way, and it is only the philosophical claim to an absolute knowledge that the skeptic wants to question.  [However,] this skeptic has no historical reality.  It is a construction of the modern philosophical imagination....[Skepticism] becomes the name of something internal to the philosopher's own thinking, his alter ego as it were, with whom he wrestles in a debate which is now a philosophical debate in the modern sense. (Burnyeat 1997:122)


Now, I would argue that the strong variant of MMR is precisely analogous to the skeptical position in this regard; you are not going to find people actually supporting this position, but rather, raising the position in order to argue against it.  There are no actual proponents in the wild.

Now, this does not necessarily mean, however, that everyone is a moral absolutist. Here we need to be careful to distinguish between the various moral codes in play (i.e., is it permissible to murder, or drink alcohol on Sunday) and the various means of meta-ethical justification.  All cultures agree that murder is bad, but there are a whole slew of ways that this dictum can be justified-- divine decree, the categorical imperative, utilitarianism, virtue ethics, etc.  And, it is quite possible that for many people (and cultures) the justification is nothing more than so much hand-waving, and is merely accepted on pragmatic grounds, much as we accept that the stove is warm without grappling with Descartes's evil genius or solipsism or any of the other challenges to the philosophical claims of absolute knowledge.  And it is this flexibility which allows the weak forms of moral relativism to flourish, whereby we defer to alternate moral codes (and justificatory schema) as long as a certain core of basic ethical strictures are maintained (roughly, again, we can point to the UN Charter on Human Rights as an example.)

References:

Myles Burnyeat, "The Sceptic in His Place and Time", in Burnyeat and Frede, eds., The Original Sceptics: A Controversy, 1997 Indianapolis:Hacking

quoted in 

Dan Arnold, Buddhists, Brahmins, and Belief: Epistemology in South Asian Philosophy of Religion, 2005 New York: Columbia University Press, pp133-134
First, a small point: I don't know of any "West Asian" antecedents to the Eternal Return; if you have a citation, please pass it along, as it would be interesting to find out about.

Second, it is not by any means clear that Nietzsche would have had to have been "a fool" to believe in the Eternal Return, and there are certainly passages which would indicate that he did believe it (more than as a thought experiment). It's far from a foolish position-- if you accept a materialist universe, in fact, it is a likely side effect; if we posit (like modern physicists) that the universe began with a Big Bang, one would presume that whenever the necessary conditions for such an event arises, another Big Bang occurs, which would play out deterministically in exactly the same fashion, etc.  Nietzsche makes this reasoning clear in some of his notebooks (minus the reference to the Big Bang, of course).

Now, as to the consequences of the thought experiment: you'll find almost as many varying interpretations as there are readers of Nietzsche, but he makes explicit that he is aiming at a notion of amor fati, that one should live one's life as if each moment were holding the force of eternity; a nice literary examination of this "heaviness" is found in Milan Kundera's The Unbearable Lightness of Being, where the weight of the Eternal Return is contrasted to the lightness of believing that every ephemeral moment only occurs the once.
Giorgio Agamben has written fairly extensively on this expression. A systematic reading of the phrase occurs in an essay of his entitled "Friendship," apparently written after discussions with Derrida during the period of time he would have been working on the text you mention (i.e., the one that would eventually be called The Politics of Friendship).

Agamben takes it upon himself to "trace" this expression back through Montaigne and Nietzsche to Diogenes Laertius, where as you mention it originally appears. He shows there that, as you indicate -- perhaps through a transcription error -- a one letter distortion had crept in at some point in the history of this phrase. Like you describe, the original actually might have been translated as:


  He who has [many] friends, has no friend.


Derrida, for his own part as you show, does seem aware of this distortion. He certainly concedes that the version of the phrase he analyzes might indeed have resulted from a copyists' error or bias.

Note that Agamben is mentioned among the friends Derrida thanks in the text.

I found this essay (Giorgio Agamben's "Friendship") published in the tiny volume, http://books.google.com/books/about/What_is_an_apparatus.html?id=xklY7uSplVkC What is an Apparatus?; you can read more about the Agamben-Derrida connection on this issue in Durantaye's http://books.google.com/books/about/Giorgio_Agamben.html?id=I-_1RefOOvUC Giorgio Agamben: A Critical Introduction (in the notes to the main work, pp. 418-419).

(In passing, Deleuze and Guattari speak extensively about the relationship between friendship and philosophy towards the beginning of What is Philosophy?; in particular, I might note that they indicate Maurice Blanchot as being "one of the rare thinkers to consider the notion of friend in philosophy". I cannot speak directly to the point but I thought it might be helpful nevertheless.)

  why can't all words mean an exact thing?


The most concise answer you are going to find is in http://www-csli.stanford.edu/~paulsko/Wittgenstein293.html Section 293: the famous "beetle in a box" thought experiment.


  If I say of myself that it is only from my own case that I know what the word "pain" means - must I not say the same of other people too? And how can I generalize the one case so irresponsibly?
  
  Now someone tells me that he knows what pain is only from his own case! --Suppose everyone had a box with something in it: we call it a "beetle". No one can look into anyone else's box, and everyone says he knows what a beetle is only by looking at his beetle. --Here it would be quite possible for everyone to have something different in his box. One might even imagine such a thing constantly changing. --But suppose the word "beetle" had a use in these people's language? --If so it would not be used as the name of a thing. The thing in the box has no place in the language-game at all; not even as a something: for the box might even be empty. --No, one can 'divide through' by the thing in the box; it cancels out, whatever it is.
  
  That is to say: if we construe the grammar of the expression of sensation on the model of 'object and designation' the object drops out of consideration as irrelevant.


As for the example of mathematics specifically, you'll want to look at the argument that begins in section 143, and goes on right up to the Beetle Box argument mentioned above.  In short, mathematics is based upon "rule following", and as Wittgenstein shows (in Section 201), "No course of action could be determined by a rule, because every course of action can be made out to accord with the rule."
Yes, many philosophers have discussed the question of free will vs determinism.  Too many to mention here, in fact.

The notion of "randomness" (and the associated concepts of "choice" and "chance") are suprisingly difficult to pin down.

Jacques Derrida has a fascinating essay on the subject ("My Chances/Mes Chances"), but judging from the manner your question is posed, I imagine you are too unfamiliar with the underlying literature to glean much from it; I suggest instead you turn to some encyclopedias of philosophy to do some preliminary research on the subject.
The literature on identity is enormous, so it would be easier to answer your question if you narrowed your wishes down a bit.

If you are a beginner to the field, a good starting point is the Stanford Encyclopedia of Philosophy article on http://plato.stanford.edu/entries/identity/ Identity, which contains a reasonable bibliography, but is slanted towards the analytic tradition.

If you are interested in the Continental side of things, two classic texts are Heidegger's http://rads.stackoverflow.com/amzn/click/0226323781 Identity and Difference and Deleuze's http://rads.stackoverflow.com/amzn/click/0231081596 Difference and Repetition-- although you should be forewarned, both are difficult going.

Finally, if you are looking for some thought experiments to explore on your own, I'd suggest beginning with the http://en.wikipedia.org/wiki/Ship_of_Theseus Ship of Theseus.
I will have to defer to classicists and Plato scholars for secondary literature on the theme in the Platonic oeuvre. Note the bibliography for http://en.m.wikipedia.org/wiki/Daemon_%28classical_mythology%29 Wikipedia's entry on "daemons" in classical mythology cites M. Joyal's "To Daimonion and the Socratic Problem" (from Apeiron, vol. 38 no. 2, 2005); I can't speak to the text but it sounds like it may be worth a look.

For the perhaps more general problem of demons from a philosophical or psychoanalytic perspective, I might suggest looking at Reza Negarestani's Cyclonopedia for serious discussions of demons and demonology. Nick Land's work may also offer some insight into the problem; I might suggest Fanged Noumena, a collection of his essays.

Finally note that pleateau/chapter 10 of A Thousand Plateaus, "Becoming-Intense, Becoming-Animal", explicitly delves into the problem of  demons -- "It can be said that becoming-animal is an affair of sorcery because (1) It implies an initial relation of alliance with a demon..." (p. 272)

  But there's a critical conflict buried here; namely, that the state is actively restricting the freedom/liberty of its citizens (at least temporally) in the name of security and expanded freedom in the future.


That's not a conflict; that's the state's raison d'etre.

With the exception of a few libertarian anarchists, all philosophers operate from the premise that the state is going to "actively restrict the freedom/liberty of its citzens (at least temporarily)."

As for the details of how much liberty can be restricted for what purpose, and by what ethical justification, there are as many different answers as their are political philosophers.  You're going to have to narrow the question down quite a bit in order to get a more detailed reply.
I think you are intentionally misquoting the section about PAC learning of Aaronson's paper, in order to ask a question about that nicely written paper.

The intention of the quoted section is not to prove Occam's razor, but to explain how Valiant's theory of PAC learning can help with clarifying the following questions regarding Occam's razor:


  (1) What do we mean by “simpler”?
  
  (2) Why are simple explanations likely to be correct? Or, less ambitiously: what properties must reality have for Occam’s Razor to “work”?
  
  (3) How much data must we collect before we can find a “simple hypothesis” that will probably predict future data?    How do we go about finding such a hypothesis?


The drawback related to the i.i.d. assumption is sufficiently highlighted in the same section:


  The third drawback of Theorem 2 is the assumption that the distribution D from which the learner is tested is the same as the distribution from which the sample points were drawn.   To me, this is the most serious drawback, since it tells us that PAC-learning models the “learning” performed by an undergraduate cramming for an exam by solving last year’s problems, or an employer using a regression model to identify the characteristics of successful hires, or a cryptanalyst breaking a code from a collection of plaintexts and ciphertexts.


Even so I only read that paper in order to be entitled to answer this question, I think the paper is really worth reading even if you don't want to answer any question. It's easy to read, covers much ground, and even sketches the proofs for some non-obvious theorems. But is it relevant to philosophy? Well, it is an honest attempt to address an audience of philosophers and tries to reduce (or show how it might be possible to reduce) the gap between theory and reality in certain areas.
It's not clear how much you've read, but consider that you reading a small handful of papers doesn't exactly give you a good perspective on the field. I studied both perception in philosophy as well as perception in psychology, and in my readings (philosophy was after the psych course), I do not recall the philosopher's theories conflicting with the science I had learned prior to any great extent. In fact in most cases it wouldn't have mattered at all what the science was. Whether rods or cones are stimulated, for example, or what kind of action potential is fired when light is detected in the retina, is largely irrelevant to philosophers because they are looking at a higher level abstraction of perception. The most fundamental thought experiments of perception demonstrate very quickly why the scientific position is of little use to philosophy.

You write:


  For example, if someone asked me what it meant to see a table, I would
  say that perceiving the table means that light reflects off the table
  and hits light receptors in the retina, activating certain parts of
  the brain. A neuroscientist or biologist could of course make this
  story much more precise.


But how do you know that your perception of the table is actually based off the real world and not some evil demon tricking your mind? How do you know that you simply aren't in a really vivid dream? How do you know that you aren't hallucinating? These basic questions show how scientific explanations are unreliable and give us no certainty. Most philosophers ignore them not because they have historically known little about the eye, but because that kind of data can't take them beyond the classic problems outlined above.
Wikipedia has a http://en.wikipedia.org/wiki/List_of_unsolved_problems_in_philosophy list that can get you started.

I don't know of any textbooks that are set out in this manner, but there might be some.
The general behavior would be described as selflessness or altruism. But you're talking specifically about being selfless or altruistic to the extent that one's own needs suffer. In that case, the behavior would be a negative one. And in clinical psychology, that is often denoted by the use of the word "pathological". That indicates that such behavior has become a pathology, or in other words, that it has become chronic to the extent that it resembles a mental condition/disorder. So I'd probably call this pathological selflessness, or pathological altruism. There is indeed http://www.oup.com/us/catalog/general/subject/Psychology/Social/?view=usa&ci=9780199738571 some corroboration to either of those terms in the literature, but not anything that emerges as a clear winner.

Better yet, this is commonly known in philosophical circles as self-denial, self-abnegation, self-sacrifice, and/or self-effacement. But again, those terms don't necessarily connote (and certainly don't denote) this as negative behavior, or one who does so pathologically, so you'll still need to clarify.

I would also say that this type of behavior is just a special case of self-destructive behavior, which is used extensively throughout the applicable literature, so perhaps that's what you should call it generically, and then explain the specific type of self-destructive behavior where necessary.
If your action forces other players to behave the same way, you are not playing a real game. you are playing a one-player game, a decision problem. The game theoretic fallacy Hofstadter makes is not new. An extensive discussion of the "symmetry fallacy" can be found in Ken Binmore's Game Theory and the Social Contract, Vol. 1: Playing Fair in Chapter 3.
Which brand is hardest to refute is going to depend on what epistemological standpoint one is arguing from, but I imagine that Pyrrho and Sextus Empiricus represent two of the most enduring proponents of skepticism; certainly, anyone attempting to "refute" skepticism would have to grapple with http://en.wikipedia.org/wiki/Agrippa%27s_Trilemma Agrippa's Trilemma.

EDIT: Just to flesh out the link a bit--

Agrippa's Trilemma argues that all attempts at justification resolve to one of three cases: an infinite regression (e.g., we justify A by B, which is in turn justified by C, etc., with no end); a circular argument (e.g., we justify A by B, which is in turn justified by C, which is justified by A); or a set of unjustified axioms (we justify A by B, which is taken as axiomatic.)

In other words: if treated skeptically, nothing can be satisfactorily justified; all attempts at foundation are ultimately either assumed, circular, or deferred.

  The description here offered suggests that God Himself can not change His will. Isn't this account contradictory with His nature?


Not really.  What could cause an omniscient, omnipotent being to change its mind?  Surely there can be no new information or surprises to respond to; the passage of time would be irrelevant.


  Also, regardless of this apparent contradiction, doesn't His omnipotence allow for contradictions?


There are some, myself included, who argue that the notion of omnipotence is necessarily contradictory, and therefore not a useful concept.  Others believe that a non-contradictory notion of omnipotence is possible, and offer arguments to dismiss said contradictions.  In other words, it's contested.


  It seems a number of Philosophers, in their discussion of God, have assumed, hitherto, that His nature must be describable in a manner which does not invoke contradictions. Isn't this requirement extraneous? Or, even detrimental to such an endeavor?


This is not limited to the discussion of God, but is global across philosophical discourse.  A concept that is contradictory is not compatible with classical logic; if one wants to proceed with philosophical discourse beyond this point, one must either proffer a non-classical logic (such as dialetheism) or limit oneself to apophatic statements. In either case, one has reached the limits of rationality.
The first form of language is concept-formation from perceptions, the second is concept-exchange verbally. He cannot teach them, because they cannot understand his concepts as they have not formed them perceptually and consciously like he has.

To quote my second favorite philosopher, Leonard Peikoff:


  According to Objectivism, concepts “represent classifications of observed existents according to their relationships to other observed existents.” (Ayn Rand, Introduction to Objectivist Epistemology; all further quotations in this section, unless otherwise identified, are from this work.) To form a concept, one mentally isolates a group of concretes (of distinct perceptual units), on the basis of observed similarities which distinguish them from all other known concretes (similarity is “the relationship between two or more existents which possess the same characteristic(s), but in different measure or degree”); then, by a process of omitting the particular measurements of these concretes, one integrates them into a single new mental unit: the concept, which subsumes all concretes of this kind (a potentially unlimited number). The integration is completed and retained by the selection of a perceptual symbol (a word) to designate it. “A concept is a mental integration of two or more units possessing the same distinguishing characteristic(s), with their particular measurements omitted.”


I hope that provides more clarity about concept formation.
I am fairly certain that 'grammatischen Witz' is not a technical term in Wittgenstein's writings. I cannot recall another instance where he uses it either. Nor, I believe, is it a common German expression, referring to something that is lost in translation when one renders it as 'grammatical joke'.

As for what he means by depth in §111, I have no time to write now because I'm at the airport, but I will post this answer to save it and will edit later with a full answer.
If we use your own definitions,


  By actual possibility I mean the possibility which is implied by ability or power.
  By logical possibility I mean whether concepts of reality contradict each other or not.


then I would say that yes, it is straightforward to have something which is logically impossible but actually possible. The reason for this is that you do not specify which concepts — or models — of reality you are concerned with.

For a half-serious example, consider the dramatic revelation in Star Wars: Episode V (The Empire Strikes Back). Luke's reaction to the revelation that Darth Vader is his father is disbelief: that it is impossible. Whatever emotions drove this reaction, it is likely that this was his reaction to the fact that the assertion contradicted his mental model of Darth Vader and Anakin Skywalker being seperate individuals, one of whom literally killed the other, as Ben Kenobi described in Episode IV. Relative to this model of reality, it was logically impossible for Darth Vader to be Anakin Skywalker, because it violated an assumption used in constructing the model. But if we accept what is asserted or demonstrated by the later Star Wars films, it was in fact actually possible, and indeed true.

More seriously, discovering things which are actually possible but which are logically (more accurately, theoretically) impossible, is a good approximation to how science works according to Popper: by falsification. If a theory predicts that something should not happen (or is impossible to make happen), but which subsequently does happen, this invalidates the theory. For this reason, I would prefer to call this "theoretical", rather than "logical", impossibility, because it places the fault clearly where the failure of the model can more easily be remedied — by improving or replacing the theory.

In modern science, where we accept that probability may be an unavoidable feature of physical theories, we are presented with a more complicated situation. When a theory predicts one probability distribution, but experiment produces another, has the theory been falsified even if we assume that the experiment was "executed perfectly"? With probabilities, there is always of course a non-zero chance of freak occurrances in which events drawn from one distribution resemble another. This is of course less likely, the more random samples you take, but in most cases you cannot actually rule out the possibility that one distribution will in practise, with a finite number of samples, produce the curve of another. We then move from impossibility to improbability — where we might ask whether something is actually probable while being theoretically (or logically) improbable. This is a somewhat more nuanced, but still essentially Popperian notion of falsifiability: we accept that there can be such events, and that when they arise they indicate a failure of the theory.
According to at least one source, it seems that the Asharites didn't believe in space or time as physical constructs. They only exist in the mind of the one who perceives them:


  The Aristotelian categories of thought were subjected by the Ash'arites to a searching criticism. Only two of those categories, substance and quality, were retained by them. The other categories, quality, place, time, etc., are nothing but relative characteristics (i'tibarat) that exist subjectively in the mind of the knower, having no corresponding objective reality.
  http://www.muslimphilosophy.com/hmp/14.htm Source: MuslimPhilosophy.com


This quote does state "quality" in both that they retained and that they didn't, but I assume one of them is meant to be "quantity".
After a quick scan of Kratzer's paper, I can't actually see a logical difference between the modal and implicational forms of any of the examples.  It seems to me only a different way to feel about the statement if you want to not offend your notions of causality.

As detailed on the Wikipedia page, the raven paradox isn't paradoxical at all (just surprising); in fact, by examining a non-raven you do gain information about whether all ravens are black because you can only verify that statement by checking every extant object and independently assessing both whether it is a raven and whether it is black.

If you recast the raven statement modally as [Always: x is a raven] x is black, then to test the truth of it you still need to check everything, and you end up with the same "paradox" that observing a green apple tells you something (namely, that this green apple part of the universe is not a counter example to the blackness of ravens, in this case because you do not fall into the "is a raven" category).  Since you have asserted that you're testing the raven-ness first, the greenness of the apple is irrelevant, but there's no logical reason why you have to test the mode first to find a counterexample; if [condition]: p and p is true for all conditions, you don't need to check whether you're in the right condition to rule this out as a counterexample.

  Any help would be appreciated.


I have some help for you, but it's probably not the help you are looking for.

My advice is this: stop thinking of your problem as a philosophical one.  It has nothing at all to do with ontology or metaphysics-- it is a problem of applied computer programming.  The fact that certain groups within CS have adopted the terminology of a philosophical tradition is unfortunate, because it leads to confusions of this type.

Objects in an object-oriented system are just containers for behaviors (methods) and system state (properties).  They have very little to do with ontology. and reading Heidegger or Husserl isn't going to help.

Take your problem to StackOverflow, and describe the actual problem in detail-- not the abstractions, but the concrete problem you are trying to solve.  I'm sure they will be able to help you out.

I tell you this as one who has both an academic background in philosophy and more than 20 years of professional experience in software development.

EDIT: As the questioner has complained that I have not properly engaged with the philosophical content of the question, I will attempt here to recast the question in a philosophical light, and answer in that form.  I apologize in advance for the length of this.


  Products, let's say consumer electronics, are represented by classes which describe different properties or groups of properties. Some classes can be same as categories, e.g. "smartphones".


Already, we are in a bit of trouble here. "Category" is a philosophical term, dating back to Aristotle, and "smartphone" is not a category in this sense.  "Class" used in this manner is not; it is a software engineering term.  Since we are speaking of groups of properties, let us propose "entity" as a philosophical replacement.  


  Now let's say we have "Samsung Galaxy S II" as one of the items under "smartphones" class. This item, although it exists in physical world, is still abstract to our users - they can't touch it, they don't own it.


This is a mistake.  The fact that the item is outside of the reach of our users does not make it abstract.  The Eiffel Tower is real, even though I cannot (at present) lay my hands on it.


  It exists somewhere in a store or a warehouse. And it really doesn't matter that it exists at all unless it exists in user's posession.


Again, this is a mistake from a philosophical perspective.  Whether or not an item exists matters.  Whether or not a particular individual can touch it, by and large, doesn't.


  So, "Samsung Galaxy S II" is a representation of real actual physical Galaxies II.


It is not clear what you are after here.  Are you pointing out the commonplace notion that the words "Samsung Galaxy S II" represent an actual Samsung Galaxy S II? 


  And finally there's Jill, a user, and she owns a "Samsung Galaxy S II".


OK, now I'm confused.  A minute ago we said that the phrase "Samsung Galaxy S II" was just a representation of an actual Samsung Galaxy S II.  does she own a Samsung Galaxy S II, or a "Samsung Galaxy S II"?  


  I want to represent her Galaxy II as an object inheriting attributes of the class "Samsung Galaxy S II" and from another class, which has attributes that make this an actual thing that exists somewhere and may be in someone's possession.


This is purely a software engineering concept.  We don't speak of object inheritance in this manner in the philosophical context.  We can say that Jill's Samsung Galaxy S II partakes of the Platonic Ideal of a Samsung Galaxy S II, and thus has certain essential qualities that constitute its Samsung Galaxy S II-ness; and we can also stipulate that it has certain accidental qualities, such as a serial number, that are purely aleatory or contingent, and are thus time-dependent.  Is that what you are after?


  All attributes I can think of are these:
  
  Geolocation (the thing has specific coordinates)


From a philosophical perspective, we would say "Location"-- but yes, every physical object exists at a particular location at a particular point in time.


  Condition (in most cases, once the thing has been purchased, it's become used)
  We can certainly stipulate such a quality, of "degree-of-usedness" which changes over time.
  
  Posessor (although products in a warehouse or on Amazon.com also technically have an owner, this is not something we people have intuition about - to us they are still abstract products)


They are not abstract products, as we have seen; they are actual.  We can definitely stipulate a "posessor", and talk about which person (or corporate entity) "possesses" the phone at any point in time.


  I also considered the following attributes:
  
  Existence - but that's incorrect as once manufactured, products exist somewhere


Most philosophers will tell you that existence is not a property, but there are large bodies of philosophical debate on this point.  In any event, as you point out, it is not useful here as we are only dealing with phones that actually exist.


  Related events - but even non-existing things can have related events


I can't even begin to fathom what this would mean.  How can a non-existing thing partake of an event?  And how are we to conceptualize an event as a quality?


  Any help would be appreciated.


And here's the crux of the problem: we still don't know, from a philosophical perspective, what you are trying to do?  I mean, it's clear from a software engineering perspective what you are after, but in philosophical terms, your project is not clear.  Are you attempting to catalog all of the accidental and contingent properties that could possibly be applied to a Samsung Galaxy S II (or a "Samsung Galaxy S II")?

If so, I'd suggest you take a look at the famous http://www.multicians.org/thvv/borges-animals.html description of Borges's Chinese Encyclopedia, and see if you can figure out the problem you face.

To summarize: your problem is a practical one, not a philosophical one.  Ontology is not of any help to you.
No, not really (practically speaking.)

The "validity" of a statement like this depends entirely on the assumptions and definitions (of "omnipotent", "omniscient", etc.) that are being used -  both by the person making the statement, and by the audience.

Many read this statement and think Richard Dawkins has successfully refuted the Christian God*, but he has really only succeeded in refuting his own idea of God.

Christians* do not use the word "omnipotent" in the same way that Richard Dawkins uses the word.


Dawkins' assumes that if God "can't change his mind about his intervention, [then] he is not omnipotent"  This claim comes from the belief that God must, by definition, be capable of doing anything (even changing His mind.)
When a Christian* claims that "God is omnipotent", their meaning is that God has the power to do whatever He wants to do.  (https://christianity.stackexchange.com/a/8262/1548 See here.)  This omnipotence does not necessitate the capacity for changing His mind, and does not preclude Him from knowing what He wants to do (and is going to do) "ahead of time".


So the outcome is:


Using Dawkins definitions, his claim is true
Using the Christian* definitions, Dawkins' claim is not true
Thus, Dawkins has not succeeded in refuting the Christian God*, but has succeeded in refuting his own idea of God (which is of very questionable value)
As a result, if a person were to use Dawkins' reasoning to try to refute the Christian idea of God, the reasoning would amount to a "strawman argument".  Since the whole intent of such a claim is to refute the idea of God (including the Christian God*), and it falls short of doing so, the reasoning is not sound.


**NOTE: I am using Christianity and the Christian God as an example to illustrate the importance of defining terms and understanding a claim within the framework in which it is made.  I understand Dawkins was not speaking solely in reference to the Christian God.*
Isn't an epiphenomenon a thing?  Is it really useful to say that--forgive the overly-used example--"air pressure doesn't exist" because it is an epiphenomenon of the statistical properties of air molecules?  Indeed, if you follow this sort of logic to its most reductionistic extremes, you start to conclude that nothing is a thing except for those very most fundamental forces and logical constructs, the former of which, at least, we probably haven't fully discovered yet.  In order to avoid a complete inability to converse, you then have to invent a new word for "thing" (entity, object, whatever) that means basically what the old "thing" meant before you destroyed it.  This is perhaps an interesting exercise, but ultimately an unproductive one.

You could ask instead: is there a difference in kind, in some important way, between grammar and the otherwise undirected interplay of syntax and semantics?  Considerable difficulty in answering this question arises because grammar is not something that we defined mathematically and then sought to understand, but rather is something that we observed people using.  One way to proceed is to ask whether our brains are specialized for grammar in a way that is separable from syntax and semantics.  If yes, then in some sense it is at least an interesting enough epiphenomenon to be worth talking about in its own right.

And, in fact, there is moderately good evidence that this is the case.  Damage to http://en.wikipedia.org/wiki/Wernicke%27s_area Wernicke's area causes syntactically and grammatically mostly-correct production of semantic nonsense.  Thus, our brains compute semantics separately from syntax and grammar.  In contrast, modest damage to http://en.wikipedia.org/wiki/Broca%27s_area Broca's area can cause retention many elements of correct syntax, but with muddled grammar--strange choices of word order, http://en.wikipedia.org/wiki/Aphasiology difficulty in understanding certain grammatically valid word orders, and so on.  Although this is less clear than the result for Wernicke's area (severe damage can result in the loss of the ability to speak, or the retention of the ability to only speak a handful of words, and the distinction between syntax and grammar is not all that crisply defined anyway), we can provisionally say that there are grammar specializations distinct from rudimentary syntax and the full richness of semantics.

Thus, yes, grammar is a thing.  Our brains think so, at least.
Your specific question (about abortion) has been discussed a fair bit. In general, people seem to agree that when the mother's life is threatened it's OK:


  This presumption [that abortion is immoral] may be rebutted when the agent’s reasons for abortion have to do with such things as physical risks of pregnancy... abortion is morally problematic, but often permissible - http://onlinelibrary.wiley.com/doi/10.1111/j.1933-1592.2007.00117.x/full Animality and Agency: A Kantian Approach to Abortion


You can read the full paper for her exact reasoning, but it roughly has to do with considering all the various duties one has and weighing them against each other. (i.e. certain duties are more "important" than others.) This is a very common way to approach it.

Another way, frequently discussed with regards to euthanasia, is the http://plato.stanford.edu/entries/double-effect/ doctrine of double effect:


  It is claimed that sometimes it is permissible to cause such a harm as a side effect (or “double effect”) of bringing about a good result even though it would not be permissible to cause such a harm as a means to bringing about the same good end. 


So, roughly, killing the fetus is "side effect" of saving your wife and therefore you aren't using it as a "means to an end." How exactly one defines a "side effect" versus a "means" is difficult, of course.

As to what Kant would say: who knows? You're right that in the inquiring murderer case he held fast to his guns and claimed that you shouldn't lie, but if more extreme examples were brought to his attention would he have changed his mind? I guess we'll never know.

  My question is, is there any utilitarian thinker which has taken into
  account this two (or any combination of both) non-equivalent ways of
  maximizing collective utility?


In John von Neumann and Oskar Morgenstern's classic, the http://archive.org/details/theoryofgamesand030098mbp Theory Of Games And Economic Behavior (1944), both http://en.wikipedia.org/wiki/Non-cooperative_game non-cooperative and http://en.wikipedia.org/wiki/Cooperative_game cooperative game theory are introduced and explored.

The full text is available online.

  Why did Aristotle place the earth at the centre of an infinite universe?


He didn't.

He placed the earth at the center of a finite universe.  For Aristotle, the universe is decidedly not infinite; he argued that there were potential infinities, but not actual infinities.
Žižek actually has touched this subject a couple of times. Basically, he sees his popularity and entertainer status as a potential attempt to reduce the serious undertones of his work.

Here is his quote from http://beanhu.wordpress.com/2009/12/07/zizek/ Zizek! transcript:


  There is a clownish aspect to me, like they
  put it in “New York Times,”Marx Brother, or whatever.
  
  All that, I maybe flirt with it. But nonetheless, I’m getting tired of
  it,because I notice that there is, as it were, when there are some
  stupid reports on me, reactions to me, a kind of a terrible urge,
  comparison, to make me appear as a kind of a funny man. And the true
  question would be, where does this urge come from? Why is there this
  necessity to portray me as somebody who can only thrive through jokes?
  And even my publishers buy it. You know that my Lenin book…
  introduction of Lenin’s… was almost turned down by Verso? Why? First,
  they always, at Verso, gave kinks at me… Oh, you are just making
  jokes, then I told them, “Okay, now you have a book, Lenin’s text,”
  Their reproach was, So, you know, much more than it may appear is
  going on here. It’s quite a complex phenomenon. I’m almost tempted to
  say that making me popular is a resistance against taking me serious.
  And I think it’s my duty, for this reason, to do a kind of a public
  suicide of myself as a popular comedian or whatever.


This is in line with some of his other ideas he often talks about, namely ideological masking of the reality in ways that appear paradoxical. Examples:


In Kubrick's Full Metal Jacket, private Joker is a cynical soldier who doesn't take many aspects of the army too seriously. He is not some "kill-them-all" mindless drone. Yet underneath this, he functions perfectly as a highly effective killer. His cynism can be seen as something that merely neutralizes the moral and political context of his situation, so that he can operate exactly as expected. Similarly, in many other modern war movies, you will find soldiers who are depicted as very "humane" - e.g. they cry and suffer together, they are nice to children etc. - and somehow this is supposed to e.g. make the big-picture context of their actions (participating in a war etc.) irrelevant.
Some CEOs, managers, bosses etc. dress casually and act as other employees (their subordinates); they (your boss) joke with you, they act as your buddies and equals. In reality, you must do as they say and the power structures are very real despite the superficial permissive equality.

The theory of the continuum is central in Brouwer's intuitionism. See for example the excerpts in http://rads.stackoverflow.com/amzn/click/0195096320 Mancosu (ed.), From Brouwer To Hilbert: The Debate on the Foundations of Mathematics in the 1920s. From my review of this book: A flavour of Brouwer's theory of the continuum is conveyed by its most conspicuous theorem: all functions are uniformly continuous (p. 39). The simplest classical counterexample is a function with y=0 if x<0 and y=1 otherwise. There are several good arguments for why the intuitionistic theorem is in better accord with intuition. First, the classical counterexample relies on "magical language" since, constructively, the function cannot be evaluated; for example, there are numbers that are "neither equal to 0 nor distinct from 0" (p. 51). Second, the theorem implies that the continuum cannot be split, in accordance with intuition (whereas it is split in the classical counterexample). "Indeed, Democritus argues with good reason that if I can break a stick, then it was from the outset not a whole. Strictest atomism is the inescapable conclusion of this." (Weyl, p. 135; see p. 124).
You ask why A is considered better than B. This assigns properties to A and B that can be measured so that the results can be evaluated w.r.t. some value system.


  How is Shakespeare's work superior to Twilight? How is a Van Gogh better than what is termed 'kitsch'."


Imho, this is a subjective evaluation of art that is created according to and measured versus the current values of society. I guess, as a rule of thumb, the more you can emotionally connect to or "understand" art, the higher its value.


  How is String Theory superior to some random dude's "theory of everything"? 


This can be scientifically explained.
If you were to create physical experiment to measure what is explained by String Theory (ST) and Random Dude's "Theory of Everything" (RD), then ST is more likely to predict the correct results than RD.
No, but it leads to things like http://plato.stanford.edu/entries/justep-coherence/ Coherentist Epistemology, for example.
If I had to say it was anything i'd comment that your difficulty is really an extension of you thinking that Deleuze's thought somehow has to be accountable to a positivistic conception of facts and states of affairs. I think Delanda presents a fairly orthodox interpretation of Deleuze. Graham Harman describes this perspective well by noting Deleuze's formulation of truth or fact goes by way of


  his critique of the false alternative between formless chaos and
  supreme individuation, the distinction between singularities and
  individuals, the role of irreducible inequalities in the actualization
  of beings, the idea of the individual as a product or result,
  resonance between divergent series, and so on.


this is fairly uncontroversial interpretation of Deleuze, and is close to Delanda's, and does amount to a departure from a mode of thinking which has Aristotle at its beginning. 

I'm not sure how one could explain this 


  (useing facts and an objective method


also in saying


  I hold the fact value distinction is primordially fixed in a kind of
  wonderful factual ground


what do you mean? Like Platonism? 
I think it is usually an act of homage, or a tribute. Schopenhauer wrote clearly as he was influenced through his knowledge of English, their clear writing style conditioned by their love of the empirical. 

Plato wrote his philosophy in the form of plays as presumably theatre & the dramatic art was seen as the highest form of artistic achievement. 

Ancient mathematicians wrote their puzzles in the form of verse as Poetry is usually seen to be the most important art-form in traditional societies. (And I'm not talking about the poetry that is written down. But that which can be performed). 

Spinozas style is Euclidian. Woolhouse in Descarte, Leibniz & Spinoza: Substance in 17C Metaphysics has Leibniz saying he wasn't overly troubled by this


  ‘demonstration in the geometrical order’ 


and refers to it as


  ‘an empty pretentious device’


But most probably react as Bergson did, who said:


  that complication of machinery, that power to crush which causes the beginner in the presence of the Ethics to be struck with admiration and terror as though he were before a battleship of the Dreadnaught Class


Is this but the schoolboys terror of the quadratic equation? The American beat poet Kenneth Rexroth in his essay http://www.bopsecrets.org/rexroth/sfe/1960/11.htm#Mathematical Mathematical Elegance and Classic Fiction wrote:


  People have written to ask what I meant by the five greatest works of prose fiction. They are there on the shelf, too, but first I would like to talk about the books that stand at the head of the row, and that, as a matter of fact, I have been reading now. They are Thomas Heath’s History of Greek Mathematics, his three-volume Commentary on Euclid, his Works of Archimedes, and Apollonius on Conic Sections...I discovered them when I was a boy of 19. Few books have influenced me more. I got them one by one from the library and read them in a kind of exaltation. 
  
  Like Homer and the tragedians, and in a sense, like the other books, too, they are great works of art.
  
  In the first instance, however, the great mathematicians have always been artists...The mathematical term for beauty and perfection in the work is “elegance". In this term are embodied a group of moral qualities — the human mind’s confidence in its own order, nobility and discipline, and the realization that the order of the universe, beyond the narrow confines of the human mind, is also of the same kind. 
  
  Any fool can chatter about nobility and magnanimity and courage. It is another thing to embody these virtues.


Spinoza's Ethics by embodying Euclidean marble grace is also embodying the moral and artistic qualities Rexroth describes. Colebrook in her book on Gilles Deleuze says:


  Style, for Deleuze [who is an admirer of Spinoza], is not something that ornaments voice or content. Voice, meaning, or what the text says is at one with its style.    


And perhaps Bergson is saying of his  admiring/terrified vision of a Dreadnaught on being confronted with Ethics  what Rilke said in his http://poetryintranslation.com/PITBR/German/Rilke.htm#_Toc509812215 First Elegy:


  ... For beauty is nothing but
  
  the beginning of terror, that we are still able to bear,
  
  and we revere it so, because it calmly disdains
  
  to destroy us.

You have a number of incongruities in your question, I think:


If S is made up of infinite strokes, as you presented your question, its cardinality is ℵ0  
So, the set S is countably infinite
This also means that the set ℘(S) is not countable since |℘(S)| = 2ℵ0 which, assuming continuum hypothesis, is equivalent to ℵ1  
Ergo, all possible subsets of S (otherwise known as ℘(S)) are not countable; keep in mind that 2ℵ0 > ℵ0 which is the same thing as ℵ1 > ℵ0  


Also, when looking at a power set ℘(S) of a set S, there is only one element in ℘(S) that's simply S.

Consider L = {a, b, c}
Then ℘(L) = {Ø, {a}, {b}, {c}, {a, b}, {a, c}, {b, c}, {a, b, c}}

L is only equivalent to the last discrete element in ℘(L), so I guess one could axiomize α ∈ ℘(α) since the same holds for countably infinite sets (and I think uncountably infinite sets, as well but I could be wrong).

I don't think there needs to be any distinguishing between L and (in our case) the last element of ℘(L) as they represent the same "thing" - in one case L is a set made up of discrete "things" and in the second, L itself is a "thing" inside a larger set. I don't think this breaks Bell's discreteness (or Set Theory, for that matter).

If your question was about breaking set identity (which Bell argues is simply the number of elements - also known as cardinality) when using the power set, worry not! Directly from Wikipedia:


  Cantor's diagonal argument shows that the power set of a set (whether
  infinite or not) always has strictly higher cardinality than the set
  itself (informally the power set must be larger than the original set).


So there is never any ambiguity. Or maybe I missed the entire point of the question.



@ThomasBenjamin, to answer your comment:


I have the set of all natural numbers N
I have the set of all even natural numbers, lets call this Ne
I have the set of all odd natural numbers, lets call this No


Set theory says that |N| = |Ne| = |No| - that is, the cardinality of the set of natural evens is equivalent to that of the set of natural odds and to that of the set of all naturals. This can be confusing because Ne and No are subsets of N.

However, that doesn't really seem to be a problem for Bell. In a sense, you're right to worry about |N| = |Ne| = |No|. How can we say that the even numbers are the same thing as the odd numbers?

Well, it looks like Bell argues that all sets of cardinality ℵ0 or greater are abstract sets (as opposed to concrete sets like L = {a, b, c}). So you could say L possesses the attribute a, but you could not say Ne possesses the attribute 2. So then how can we know that 2 is in Ne? Well, Bell, at the bottom of pg. 10, shows us how to create a relation between two abstract sets. In our case, it would maybe be f: n → 2n.

So, going back to your question (and comment), there is no way to distinguish between two sets if they have the same cardinality unless we map them. So until we specify that the set of all even naturals maps to n → 2n and the set of all odd naturals maps to n → 2n + 1, the two are identical.
The following answers are informed by my background in the mathematical sciences. Hidden in the distinctions above are questions of certainty, epistemology, and expertise.


  an ordered sequence of actions chosen to economically and efficiently achieve a desired end


— In my background, this would come with the connotation that there are some theoretical guarantees as to its success: that is, that success is in principle guaranteed, or that the probability of success (if the procedure is not itself entirely deterministic) is substantial. Thus the words


algorithm, procedure, formalism, recipe, method


all fit quite well here in English. When the procedure does not guarantee success but seems to work anyway, for reasons which are poorly understood, the word "heuristic" fits better.


  a set of methods chosen for the purpose of achieving a common end or related ends (e.g. the cluster of methods used in molecular biology)


— An emphasis on a set of methods has the interesting side-effect that one must determine when any one particular method will be effective. Thus while the methods may be recognized as useful, there is no longer necessarily an algorithm for applying them to a novel circumstance, and we enter the domain of strategy, craft, and art. Thus I would apply the words


technique or techniques, tools or toolbox [figurative].


One sometimes hears "bag of tricks" as well, for a less thoroughly developed 'toolbox' in a discipline which people are trying to come to grips with. "Programme" (as opposed to program, which is effectively a synonym for algorithm) is related in that it is usually a directed effort to produce a comprehensive toolbox or set of effective techniques, informed by some basic principles.


  the science whose proper objects of study are the previous two


Wikipedia informs me that this is the proper subject matter of methodology. When restricted to a particular domain of knowledge, it may be a theory (as in "group theory", "set theory", "information theory").
I would argue that Nietzsche certainly had a purpose in choosing "genealogy" over "history."

Let's examine the meaning of each word (from Google):


  History: the study of past events, particularly in human affairs; the past considered as a whole; etc.
  
  Genealogy: The study and tracing of lines of descent or development


We can see from this is that history deals with events, while genealogy deals with lines of development (it would be reasonable to claim from this that genealogy is a branch of history). This carries the corollary that history does not have to assert any connection between what it talks about, while genealogy by definition seeks to make some sort of developmental or evolutionary claim regarding how certain things are related. 

The latter is precisely what Nietzsche does in the Genealogy of Morals. He isn't simply listing off a bunch of facts about what morality was here and what it happened to be there. Rather, he's making a claim that he can trace a line through the development of morality itself. 

He begins with his idea of "Good vs. Bad" as it manifested itself in the society of nobility and common people. He then argues for how this evolved into "Good vs. Evil" through the "priestly" people (he credits the Jewish people) and their daring "inversion of morals."

He also makes claims, often using his linguistic expertise, on how guilt developed in the debtor-creditor relationship and how this ultimately grew - and was inverted to - guilt in the prime creditor (God) toward the debtors (man). 

This is the sort of thing Nietzsche talks about in the Genealogy: lines marking the development of human morality through the course of civilization. It's because he argues that this is a decidedly causal and evolutionary process that he chooses to call it a "genealogy" and not simply a "history," which is much less specific in its meaning.
Mathematics is not "infinitely regressive"


  Its commonly taken that mathematics is axiomatic. However just as mathematicians can build ever more elaborate structures, they can painstakingly dig-down into foundations.
  
  Does this mean that mathematics is actually infinitely regressive, it's just that the diggig is a bit slow?


Mathematics is not infinitely regressive, because the establishment of a set of axioms from which all interesting theorems follow has been in fact not only finite, but realizable. Specifically a set of axioms cannot be further analyzed if all the axioms are independent.

An axiom P is independent if there are no other axioms Q such that Q implies P.


The analysis of http://en.wikipedia.org/wiki/Axiom_independence axiom independence has been a very important search in establishing axiomatic systems and today's axiomatic systems are independent in this sense.



In case you wonder: The fact that it is possible to find different "foundations" for previously established mathematical results (i.e multiple groups of axioms for a given set of theorems) is a matter concerning the pluralism of foundational systems, not their being infinitely regressive.
Your question refers to the domain of http://en.wikipedia.org/wiki/Rational_Choice_Theory rational choice theory (RCT). Many leading figures in economics, e.g. the neoclassical school of Milton Friedman, advocated the use of unrealistic assumptions in economic theory. But there's also a lot of opposition within economics.

However, as far as I can see, what is under discussion is not the unrealistic status of these assumptions, but their role and their necessity. None of the participants in the dispute question that unrealistic assumptions are, in fact, unrealistic.

An interesting historical case study is Roy Harrod's formulation of the http://en.wikipedia.org/wiki/Harrod-Domar_model first modern model of economic growth (1939)
and subsequent criticism by http://en.wikipedia.org/wiki/Robert_Solow Robert Solow (1956) and http://en.wikipedia.org/wiki/Joan_Robinson Joan Robinson (1956). Harrod's model contains some interesting unrealistic assumptions, among them its aggregate production function, which was criticized as "unrealistic" by Robinson. In turn, the discussion between Robinson and Solow also concerned the need of unrealistic assumptions and is known today as the http://en.wikipedia.org/wiki/Cambridge_capital_controversy Cambridge capital controvery.

In the social sciences, http://en.wikipedia.org/wiki/Pierre_Bourdieu#Bourdieu.E2.80.99s_theory_of_power_and_practice Pierre Bourdieu's critique of RCT's homo oeconomicus has had some impact.



More generally, the underlying point of your question is the role unrealistic assumptions and false models play in science and the in social sciences.

Here are some links to continue 


Unrealistic assumptions in economics


http://en.wikipedia.org/wiki/Economic_model#Restrictive.2C_unrealistic_assumptions WP: Restrictive unrealistic assumptions

Unrealistic/False models


http://pos.sagepub.com/content/38/3/334.abstract Hindriks: "False models as explanatory engines", 2008 (economics)
http://mechanism.ucsd.edu/teaching/models/Wimsatt.falsemodels.pdf Wimsatt: "False Models as Means to Truer Theories", 2006 (biology)
http://plato.stanford.edu/entries/models-science/ SEP: Models in science (A good read)

Related: Toy models


http://en.wikipedia.org/wiki/Toy_model WP: Toy model


If we allow the "anthro" in "anthropocentric" to not mean human but rather "intelligent consciousness capable of communicating philosophical idea", then I see no way to avoid either anthropocentrism in some sense or asserting some sort of Platonic Idea.

The argument is perhaps a little tired, but the fact is that all conceptual articulations and observations and deductions and inductions have an implicit asterisk that means "or so it appears in my consciousness apparati." Those relationships which the concepts codify may have an objective reality, but the articulation--and thus the concept--itself cannot be reductively removed from the communicating, conscious entity (i.e., the philosopher) without asserting that there are objective Concepts floating in the aether and it is ours to access them.

It is different in the sense that posterity is a set of members related by the notion of 'successor' to another member. Or in other words the notion of successor is used in the definition of posterity, but they are not the same thing.
Russell defines hereditary as meaning the set where if x is a member then x + 1 is a member, that is its immediate successor. With relations, if S means 'immediate successor' then xSy means x is the immediate successor of y, i.e. informally x = y + 1. So the hereditary set with relation to S would mean for any x that is a member, then y such that xSy is a member, that is that if 5 is a member then 4 is a member. This is going the wrong way for what is required in the posterity set, the idea is to have the posterity set of x contain x and all it's successors, which is achieved by using the relation 'immediate predecessor' instead.
0 is not a member of every hereditary class containing 5, as you have shown in your example sets, all the numbers below 5 are not in every hereditary set containing 5, only 5 and the numbers greater than 5 are in all of these sets.


The word 'every' being the part of the definition of posterity I think you overlooked.
An appeal is, in basic terms, an argument of last resort. In philosophy, ideally, there is no appeal. Either the logic of your premises read out your conclusion or it does not.

In a more etymological sense, an appeal is a call out for assistance from a higher power. The word comes from the the Latin appelltus, meaning to entreat. In a very basic sense, we can understand this to mean that an appeal is intended to offload the burden of proof for some argument to some external object.

For instance, in the appeal to authority, the appellant (probably the wrong usage there) says, in essence, "if you can prove authority A wrong, then I am wrong."

Or in an argument to pity, the appellant says, "to disprove my argument, you must reconcile it with my circumstances."

So, in the wider world of rhetoric, an appeal is an argument which attempts to reverse the burden of proof by introducing a factor external to the debate, rather than relying on the logic of the premises.
The difference would be difficult to quantify from any point of view other than the individual acting.  That is, the one choosing to do a thing, be it out of free will or imagined obligation.  In the example given I would surmise that it is unlikely that the individual donating his wallet is doing so of free will.  That said, it is impossible for me to know as an outsider.  If I were the individual I may not even know what drives me to action. 

A more common and direct example would be that between individuals and family members.  In these cases however, the imagined obligation would often be so ingrained that the individual would think of it as free will.  In fact free will its self has been subverted by conditioning during the individual's upbringing.

To bring this to an end, the difference between free will and imaginary obligation is a matter of source at best.  At worst, it begs the question, "is there free will?"  We will assume that free will exists, a broad assumption, for now.  The source is what we should then discuss.  What is the source or motivation of the individuals decision making process?
    If it is fear or some derivative, it is imaginary obligation.  If it is not, it is free will.

That is a simple statement but true none the less.  If the individual fears something (anything) and that makes him decide on a course of action, it is from imaginary obligation.  It is only when we have no fear, of reprisal, or other's views, of our own judgement etc... that we can truly exercise free will.
Oren Tsur, Dmitry Davidov and Ari Rappoport, computer scientists at The Hebrew University in Jerusalem, devised an algorithm to recognise sarcasm in lengthy texts "by analysing patterns of phrases and punctuation often used to indicate irony". First the researchers trained them with 5,500 sentences consisting of either sarcastic or non-sarcastic type of comments and when tested on other subjects resulted in an accuracy of of "77 per cent of cases". For more you can read http://www.telegraph.co.uk/technology/news/7740955/Scientists-devise-algorithm-to-detect-sarcasm.html the The Telegraph article itself here.

  "You can trust that academics know the truth because they have tenure and are free to think for themselves."


I presume that statement was preceded by a certain claim made by an academic, which was then said to be credible simply because an academic said so. 

If this is the case: this form of fallacy is an https://en.wikipedia.org/wiki/Argument_from_authority Argument from Authority. 

It generally goes as follows:


A is an expert in domain D 
A claims C
C is a question within domain D
Therefore, C is true


Now, of course, it can be assumed that it is more likely that an expert (within his domain of expertise) is right than a random person. It just does not logically follow that this is the case. You have to evaluate the actual argument, not who made the claim.


  Question: What percentage actually have tenure?


Quote from http://en.wikipedia.org/wiki/Tenure_%28academic%29#From_1972_to_the_present wikipedia:
The period since 1972 has seen a steady decline in the percentage of college and university teaching positions in the US that are either tenured or tenure-track. United States Department of Education statistics put the combined tenured/tenure-track rate at 56% for 1975, 46.8% for 1989, and 31.9% for 2005. That is to say, by the year 2005, 68.1% of US college teachers were neither tenured nor eligible for tenure; a full 48% of teachers that year were part-time employees.

So the claim that anyone in academia has tenure is simply false.


  Does having tenure mean you're right about everything?


No, obviously not. 
There are people with tenure who have conflicting views. Just to give a notorious example: Leonard Susskind and Stephen Hawking (who both have (or did have)) tenure have been in a fierce debate on http://en.wikipedia.org/wiki/Black_hole_information_paradox information in black holes being completely lost or not. They disagree fundamentally, yet they are two of the world's top experts in their domain. And there are tons of examples of similar (yet not as famous) cases. 
The reference is to Plato's Sophist, to which Deleuze refers with some frequency, albeit, at times, quite obliquely. This is a text where the key question is often "How?" and perhaps more importantly "What is it?" Moreover, it articulates a concept of "simulacrum" and provides a rejoinder avant le lettre to the Neo-Platonic reading of Parmenides (and hence Deleuze's differentiation between Platonism and Plotinism).

I can think of three reasons that this might be referred to as the "last dialectic":


Some supposed ordering of textual composition
Sophist is the dialogue where Socrates steps aside and gives way to the stranger
Deleuze's discussions of Sophist tend to link it with the Phaedrus and the Statesman. The order of these last two changes, but Sophist stands at the end of the series, and indicates the point where Platonism begins to reverse itself.


Relevant sections of Deleuze (from the books that happen to be in front of me at the moment) include the first appendix to Logic of Sense, as Joseph suggested, as well as the section of "Difference In Itself" in Difference and Repetition that begins "La tâche de la philosophie moderne a été définie: renversement du platonisme." ("The task of modern philosophy has been defined: the reversal of Platonism" --- This is marked as a separate section in the French text, though Patton's translation omits these sections. The "Antilogos" section of Proust and Signs also offers an interpretation of Plato in the same spirit as the bit of Deleuze you quoted, though without explicit reference to Sophist.
Its language being used metaphorically; here its being used as a synonym for ideology. Grand narrative=big story. But there is a bit more to it than that. An ideology, say for example Marxism has a start point: Marxs theories, these then develop and change over time. In this sense ideology has a narrative. But there is more, by reducing their truth value to a narrative, to a story, one questions their truth, in a sense placing them of all equal value. This is where post-modernism starts. 
I'm afraid I don't know of any papers that discuss indispensability and impure set theory directly. In a sense there's a reason to think that impure set theory is nice to have for physics. As you know, it's natural to represent functions in set theory as sets of ordered pairs, hence if you want to talk about functions that map spacetime points to other spacetime points, you'll need impure sets (if those functions don't float your boat, pick your favourite physical objects that you want to talk about functions from/to).

However, to say that impure set theory is indispensable is a much stronger claim. It's also going to be tough to establish, given (as I'm sure you're aware) that the universe(s) of pure sets is pretty big, far bigger than the physical universe (on any plausible theory of the physical universe; the biggest I think you can reasonably get it is if you allow mereological sums of spacetime points then you might be able to argue for the universe having cardinality $2^{2^{\aleph_0}}$, which is diddly squat in set theoretic terms). Given then the sheer abundance of sets, we can always represent new an interesting physical phenomena by pure sets, in such a way that the impure set theory is dispensable.

However, one should be mindful of the dialectic into which an indispensability argument is often inserted. Usually there is some sort of Quinean holism in the background providing the necessary oomph to think that indispensability to science matters. Given this, one's question really should not be "what is indispensable to science?", but rather, "what is indispensable to our best theory of the world?".

If the latter is the question, and if one thinks that categoricity is important for a mathematical theory (say for worries about first-order theories being unable to pin down their intended model up to isomorphism), one might be interested in the following paper by McGee:

McGee, Vann; `How We Learn Mathematical Language', The Philosophical Review Vol. 106, No. 1 (Jan., 1997), pp. 35-68

There he gives a full categoricity proof for $ZFC$ (on the assumption of unrestricted first-order quantification), by first adding urelemente and proving the categoricity of the pure sets from the impure universe. Thus if it turned out that urelemente were indispensable for this task, one might think that that impure set theory is an indispensable part of our best theory of the world after all.

[As a footnote, it should be noted that there are plenty of other ways to get categoricity given unrestricted first-order quantification. See, for example:

Martin, Donald A. (2001). Multiple universes of sets and indeterminate truth values. Topoi 20 (1)

who argues that any two universes of sets (satisfying certain criteria) can be combined,

and

McGee, Vann (1992) Two Problems with Tarski's Theory of Consequence Proceedings of the Aristotelian Society New Series, Vol. 92, (1992), pp. 273-292

where he argues for categoricity through the introduction of a satisfaction predicate.]
One reason is to preserve certain intuitive relationships that we would like. All children like icecream implies Some child likes icecream only if the set of children is never empty. The assumption that universal quantification is a strengthening of existential quantification only holds if the domain is not empty. See http://math.andrej.com/2012/12/25/free-variables-are-not-implicitly-universally-quantified/ this blog post for a discussion of this use within mathematics.
As a person, who studied anarchism a bit, i can assure you there's nothing wrong to start from Wikipedia page on https://en.wikipedia.org/wiki/Individualist_anarchism individualist anarchism.

The early individual anarchists were https://en.wikipedia.org/wiki/Max_Stirner Max Stirner and https://en.wikipedia.org/wiki/Benjamin_R._Tucker Benjamin Tucker. I recommend Stirner's https://en.wikipedia.org/wiki/The_Ego_and_Its_Own The Ego and Its Own, it's an easy read and proved way more interesting than Nietzsche or Ayn Rand. https://en.wikipedia.org/wiki/Pierre-Joseph_Proudhon Proudhon is also a major inspiration for individualist anarchism for his accounts on market economy.

For the full view you may also look at Marx's critique of Stirner in http://www.marxists.org/archive/marx/works/1845/german-ideology/index.htm The German Ideology (part III: Saint Max) and communist anarchists' view on individualist anarchism on http://anarchism.pageabode.com/afaq/secGcon.html An Anarchist FAQ.

Today individualist anarchists arguably developed into 3 currents: Neo-mutualism (advocated by the likes of https://en.wikipedia.org/wiki/Kevin_Carson Kevin Carson), https://en.wikipedia.org/wiki/Agorism agorism and so-called https://en.wikipedia.org/wiki/Anarcho-capitalism anarcho-capitalism. Communist anarchists http://anarchism.pageabode.com/afaq/SecFcon.html reject the last branch, and Konkin also http://www.anthonyflood.com/konkinreplytorothbard.htm critiqued Rothbard.

Sites, where individualist anarchists hang out include http://praxeology.net/all-left.htm Alliance of the Libertarian Left and http://c4ss.org/ Center for a Stateless Society. Check out also Reddit sections http://www.reddit.com/r/Agorism Agorism and http://www.reddit.com/r/MarketAnarchism MarketAnarchism.
Not a specialist in Ethics, but it looks to me like the fundamental issue here is whether everyone has rights only over himself (the classical liberal position) or whether some people have rights over others (Rawls's position). Rawls has to be saying that some people have rights over others because the strategically rational set of principles of justice that we would agree to in the original position should involve redistribution of income and other similar schemes of social welfare. Consequently, this means that I have a right over other people insofar as I have a claim upon putting the money they earn by their time and talent to use in funding such schemes. 

I don't know that that's Nozick's criticism of Rawls, actually. But it is a fair characterization of Rawl's position.
I'm reading 'Residence on Earth' by Pablo Neruda. He's a South American poet who spent five years in the far east as a consul, and he wrote this during that period. 

They speak essentially of his spiritual isolation and alienation. His poetry I imagine was a response to this suffering. 

His famous youthful song was called 'twenty love poems and a song of despair'. Despair for him then was a minor note, in 'residence' it becomes a kind of existential crisis. Later, he repudiated the work as it for him was a song of death. He'd moved beyond that singular point (so in a sense that point was not singular).

Rilke often spoke as silence and aloneness as a condition for his poetry. Whereas for Neruda it was put upon him. It's not enough of course to have these feelings in a deep way, plenty of people have them without becoming artists, one must also have the talent and opportunity to learn to express it.

If art is the response to suffering, then it is not surprising that madness, and so called schizophrenia is associated with it. They're the outward form in the personality of an inward singularity. 

Having said this, Susan Sontag (literary critic) said that there is a certain fetishisation in european culture that asks its artists to suffer as a sign of authenticity. Could this be connected to the suffering christ? Just because europe has desacrilised over the last century or so, does not mean that the inner form of its spirit is dead. John Gray (philosopher) wrote of both communism & capitalism as being forms of christianity on the level of ideology. What is true on a political level could also be true on an inward level. 

Tagore, an Indian poet, rebuked his fellow poets for embracing European modernity, as a contracting movement rather than an expanding one. One should note that modernity was born after European-wide civil warfare. One could suppose that modernity was a reaction to this, certainly Dada, Surrealism and Primitivism was. Although there are notes of melancholy, there are moments of transcendence, joy, hope and enjoyment of sensuality in Tagores poems.  

There is also a romantic ideology which elevated sensibility against an increasingly materialistic & industrialised European society.

I'm not sure one could characterise Rilke as being incredibly productive, he wrote little and slowly (the duino elegies took ten years), but what he wrote was of lasting significance and read still today. He is essentially a religous poet, a poet of the sacred.
Note: Whether this is actually an answer as opposed to an extended comment is debatable. I write it not as an answer (because I don't actually believe your question has an answer), but as "the closest one can get" to an answer. At any rate, I've turned it into a community wiki so I don't get reputation for it.

The crossroad you have come to is common, and you should be proud you picked up on it: It's a telling sign that you actually understand determinism; a concept which — even after many students of philosophy graduate with their degrees — I can assure you many never fully grasp.

You should note that there are dozens of different versions of compatibilism, each sometimes as radically different from each other as they are from https://en.wikipedia.org/wiki/Determinism hard determinism or https://en.wikipedia.org/wiki/Libertarianism_%28metaphysics%29 libertarianism. I reckon some of the early versions were designed as a sort of "easing theory", published in philosophical journals as a "middle ground" to "ease" the academic community into this concept of determinism without seeming too radical. At any rate I have yet to read a convincing compatibilist argument myself, usually they just convolute terms like "freedom" and "determined" by redefining them in slightly different ways that supposedly don't conflict with (hard) determinism. Why do they do this? Because humans are not good at giving up things they are used to, or that they cherish. One of these things is the notion of moral responsibility, and determinism destroys this notion. Determinism also destroys the notion of praise (how can you praise someone for an action they took that was entirely inevitable, that wasn't of their own choosing?). This, in my opinion, is the real source of compatibilism: it is merely an unwillingness to accept that we may very well be automata, peering out the window of a robotic body, so to speak.

I suggest you take a look at http://plato.stanford.edu/entries/compatibilism/ the SEP article on compatibilism and see if any arguments are convincing to you, and if not, no fear — simply cast them aside. I also recommend (one of my personal favorites) Daniel Dennet's Elbow Room. He claims to be a compatibilist himself, but his writing all but screams hard determinism. His work helped me formulate my own position, which I write briefly about in https://philosophy.stackexchange.com/questions/966/what-are-the-necessary-conditions-for-an-action-to-be-regarded-as-a-free-choice my answer to this question.

Lastly, here's https://philosophy.stackexchange.com/questions/849/to-what-extent-do-we-choose-our-beliefs/ another question you might find interesting regarding choice.
I assume you know this, but I would recommend using much caution when reading any "encyclopaedic overviews" of philosophers or their ideas.(In reading Russell's History of Western Philosophy, you'll find many mischaracterizations of philosophers and their ideas; and, Russell has little concern for showing his distaste for many of them.) Not only that, but it is quite easy to think that, well, "even if this thinker didn't use 'this word, etc.,' he still meant the same thing."

The last link you provided is an example of the sort of problem I'm talking about: it uses interpretative, modern phrases and notions--many of which were written hundreds to thousands of years before the characterizations had sense. 
The following is from page 77 of Wittgenstein's Notebooks: 1914-1916: 


  21.7.16.
  
  What really is the situation of the human will? I will call "will" first and foremost the bearer of good and evil. 
  
  But can we conceive a being that isn't capable of Will at all, but only of Idea (of seeing for example)? In some sense this seems impossible. But if it were possible then there could also be a world without ethics.
  
  24.7.16.
  
  The World and Life are one. [5.621.] 
  
  Physiological life is of course not "Life". And neither is psychological life. Life is the world. 
  
  Ethics does not treat of the world. Ethics must be a condition of the world, like logic. 
  
  ￼￼Ethics and aesthetics are one. [See 6.421.]


The "discussion" of ethics, here, continues for fifteen or so pages, and I would suggest looking into there for more incite into your question.
I also remember, from Ray Monk's Duty of Genius, which is a highly recommended intellectual biography of Wittgenstein, that Wittgenstein was seldom silent about the topics he claimed we shouldn't speak about. (I believe the person who made the comment was Keynes or Russell or someone in the Cambridge Apostles.) 

Anyway, I believe that the "Lecture on Ethics" and the full text from the Notebooks are the only two (relatively) sustained discussions on ethics in all of Wittgenstein's writings. I would, however, take his claim that "[e]thics and aesthetics are one" seriously--a claim that, I believe, Later-Wittgenstein would still hold, or at least, not disagree with greatly. So, if I were you, I'd look to see what he says about aesthetics––something he has more to say about.  
As stated, this is not any different from the original problem: you've just added irrelevant stuff (that happens to be coin flips) as a premise in addition to the flip that actually determines whether she's awoken once or twice.  Events that have no bearing on the outcome also have no bearing on the logic of the situation: adding irrelevant coin flips is no different than adding that she saw a pair of pigeons fly past the window after she woke up.

You might stop believing the Self-Sampling Assumption if it made you conclude otherwise, however.

Let me actually answer the Sleeping Beauty problem also, since writings on it seem confused, and there are apparently two different philosophical camps that each in their own Wikipedia summary fail to grasp the essence of the situation.

The situation is as follows (made to sound more like the fable): Sleeping Beauty goes to sleep; a coin is flipped.  If it comes up heads, the Prince kisses her on the lips, she wakes up, and stays awake.  If it comes up tails, the Prince kisses her, she wakes up; then the Prince pricks her finger again and she falls back asleep; and then he kisses her and she wakes up again, unaware that she was previously awake for a while.  Immediately when she wakes up, in any case, we ask her: Heads or Tails!  What should she say?

She should say, "Why are you bothering me with this question?!"

So, okay, Sleeping Beauty has recognized that if you want to maximize your score in a game, you need to know what the rules for scoring are.  You don't need to know where the pigeons are flying or if other people are playing the same game as you, as long as the pigeons and other players do not affect your game.  It does matter if the structure of the game introduces correlations in an otherwise random process.

Let's try some rules, then.


You get a point every time you get the answer right.  (In the tails case, you can win 2 points; in heads, only 1.)  Solution: guess tails.  50% of the time you will get 0 points, 50% of the time you'll get 2, for a net payoff of 1 point.  (If you guess heads, your expected payoff is 1/2.)
You get a point if you are consistently right; half a point if you're right half the time; no points if you are never right.  Solution: it doesn't matter what you guess.  Expected payoff is 1/2 regardless of what you say.


So, if Sleeping Beauty wants to maximize number of questions answered correctly, she'll choose tails, while if she wants to maintain accurate thought for the maximal duration, she's free to choose randomly until she gets information.  If you ask her to calculate probabilities instead of give a single answer, then it matters what exactly you ask.

If SIA vs. SSA boils down to anything other than asking different questions / scoring your rewards differently, then making that assumption is unjustified.
It was Nicholas of Cusa who famously challenged the notion of divine omnipotence and this move becomes the basis of F.W.J. Schelling's Philosophical Investigations into the Essence of Human Freedom (1809).  Each argue from their peculiar standpoints about the weaknesses confiding in such a God, which is ironic.  Cusa did not make the distinction between appearance and reality, which has been a philosophical and religious mainstay since Plato.  Rather, there is a distinction between relative and absolute knowledge.  Only God can possess the latter, while we as creatures are subject to a relative viewpoint.  Cusa identified this difference empirically, claiming that at any time humans consider their viewpoint there is always something closed off, as for instance, right now depending on your seating you can only see the front or back of another’s head or since we don’t have eyes in the back of our head we can’t navigate behind us.  Whereas our knowledge is limited, God sees everything in its full transparency constituting all-knowingness.    

Cusa tries to overcome the difficulty by allowing for the movement of becoming within the divine nature, which allows for things to be known as they are revealed.  Quite controversially, Cusa dismissed the notion God would create creatures without them revealing anything to Him truly.  If God knows everything in advance by means of universals that can be applied to all particulars, then what does creation really have to do?  How did God create out of love ex nihilo if He will not let the Other (creation) truly be in itself?  And obviously the slam dunk question is, how are we free or responsible for our actions if we are simply fake acting according to the design of providence or the mechanical pre-established harmony of cause and effect?  These are the questions Cusa thought were the most crucial but it was the former who sought to really move outside the dogma.  On Cusa’s explanation God is still all-knowing, but it’s not foreknowledge!  Not at least in the sense of classical theism.  Rather, foreknowledge here means to see everything not in advance, but to see ineluctably everything that is “before-hand.”  Creation reveals things to God on the spot by which only He can see and understand.  One need not be all-powerful to appreciate 
the breadth and width of the manifold of relations intricate to the divine life.

In order to allow for human freedom in the fullest sense, which stems from God’s grace unblemished, Cusa gives up the “omnis.”  How severe is Cusa’s sacrifice for our own theological convictions, especially since divine sovereignty must be preserved at all costs?  I suggest that Cusa is seeking to think divine necessity and perfection more dynamically, whereas the reformers (scholastics included) have merely a static view of sovereignty and freedom.  After all, how can we love God while realizing that forced love is a logical contradiction and a sham?

Schelling cuts right to the chase and asks:  suppose God had things to do and becomes preoccupied with the other-worldly for a day, year, or whatever.  When or if God comes back then what was missed?  NOTHING AT ALL.  If one assumes divine foreknowledge in the traditional sense then why does God need me or the world?  Especially when he knows everything perfectly?  Why does God need us to run some DVR re-run of life on the ground to confirm what is already known?  It is not a shock then to hear talk about divine boredom or the death of God under such conditions.    

In an effort to emphasize the importance of love and freedom these thinkers challenge the view that God has OCD or is a control-freak.  They leave us justified in re-considering and re-working what power means for any semblance of the Godhead.  From Cusa's and Schelling's speculations, God is more of a companion or fellow-feeler than a despot or dead-beat dad!                         
Good question, sorry for bad English!
I can't answer by all means but here are two points.  


It is well known that children, that grow up without a language,
get a fatal lack of human consciousness.
Buddhists assert that adult human beigns may (and should) spend a long time without
words and estimations and this even improve their minds.
I practise Vipassana more than 15 years (being high-educated in theoretical physics)
and just confirm it.

Why would you link to my comment?

I didn't say they wouldn't give it back to you, I explained Animuson's comment regarding that he has never heard of an award being given manually.

You are avoiding the real-world cost/ROI equation for something that has zero intrinsic value.

Would it be nice to have your badge back? Sure. Is it worth it? Different question, and different people will answer it differently. We understand your answer. You'll have to wait for their answer, and no answer is an answer–but you're assuming short turnaround on something that isn't of critical importance.

Ethical actions have trade-offs: it sucks to kill, but would you to save a room of kids? Where do you draw the line between the action and the action's cost to you, and to others? Let's say it took an SE employee an hour to fix your badge issue: is your worthless gold badge worth $50? $100? $150? To who? To you? To SE?

Is it worth the cost of sounding like you're whining across multiple sites, posts, and comments? Who pays that cost? Not us–you do, in your public image, ephemeral as it is.

  What is the purpose of natural and social sciences, respectively?


The purpose of science, in general, is to gain more knowledge about the world. This, in turn, leads to the possibility of improving our lives. The purpose of natural sciences is to find out more, as the name implies, about the natural world, while the purpose of social sciences is to find out more about social phenomena. I think, if you asked a whole bunch of scientists, they will say their primary purpose is to gain knowledge. If it can improve the quality of our lives, great, if it can't, it's still worth finding out.

There is, however, a debate about whether the main goal of science is to improve the quality of our lives or to gain knowledge. In other words, if research on a certain topic will not directly or indirectly lead to an improvement of our lives (medicine, technology,...), should we spend money on it? To give a very concrete example - there are tons of examples; I'm just giving one, take a look at http://youtu.be/MlyTq-xVkQE?t=6m55s this Numberphile video. Mathematicians found out whether 17 clues is the absolute minimum to solve a sudoku in only one way. This seems fairly pointless -in the sense that it won't improve technology, society,..., and at the end of the video, they immediately try to "give an excuse" by stating that the methods used to solve this problem can be used to solve more important questions. Also, in space missions, they often stress that it can improve our lives in some way if they face criticism regarding the high costs. My opinion on this, and I'm stressing this is just opinion, is that every scientific question is a good one and that even if there is no direct or indirect usage of some new knowledge, it often will someday. 


  What's the point of science in general and do we need it?


It's hard to say what you mean by "need". If you mean by it "need to survive", then the answer is obviously no; Homo Sapiens has survived for thousands of years without science. The rest is a matter of opinion; some would say it has improved our lives, some would say it hasn't or has even made our lives worse. 

I would argue, and again, this is just my opinion - which is all I can give to this kind of question, that science has dramatically improved our lives. 

Science (see also http://undsci.berkeley.edu/article/whathassciencedone_01 this article):


has helped us get rid of a lot of superstition (witch hunts,...)
has enabled global, fast and almost free communication (and applications like this forum)
has increased our lifespan dramatically
has drastically improved medicine (and also got rid of many non-working and even dangerous 'medical treatments')
has provided us withfast and safe travel
has drastically improved agriculture


An example of an author who would disagree with me is Jean-Jaques Rousseau. In his http://records.viu.ca/~johnstoi/rousseau/firstdiscourse.htm Discourse on Science and the Arts (also called the First Discourse), he argues that the arts and sciences are not beneficial to society, but rather add more dependencies and cover up our enslaved state. He was a critic of luxury (which science and the arts make possible), which lead to more inequality, and even argued that it contributed to the corruption of man and moral deterioration. An example of this moral deterioration is that people, who see a scientist, a philosopher, or any other educated man, will try to be like him. In other words, they'll try to be like someone who they are not. They are being dishonest, Rousseau says. The further we push science and the arts, the further we get from who we naturally would be.
The answer to the main question asked is trivially yes; Russell was well aware of Kant's views on mathematics and was influenced by them.  Kant, Frege and many others were forerunners to Russell's views on mathematics in a very general sense.

The answer to the more interesting question in the body of the text - whether Russell's conception of mathematics is analytic - is definitely no.  Russell held that mathematics and logic are both synthetic.  Kant on the other hand held that logic is separate from mathematics; logic is analytic and mathematics is synthetic.  As Russell says:


  Kant never doubted for a moment that the propositions of logic are
  analytic, whereas he rightly perceived that those of mathematics are
  synthetic. It has since appeared that logic is as synthetic as all
  other kinds of truth...


The Principles of Mathematics, section 434

I would add that when you say Kant 'showed' mathematics is synthetic a priori, you seem to imply this was definitively done, but Kant's, Frege's and Russell's conceptions of mathematics and logic have been disputed by Quine, Wittgenstein and others.
Haha- yeah, I'm pretty sure the term you want is "ignorance".

This was not a serious answer since I believe you were asking if there were an "official" philosophical term for it and "ignorance" obviously is not it. However, lest this post be considered a waste of good bytes, I will state that I don't believe there actually IS an official term for it because it would not actually be considered a logical fallacy in itself, but rather as someone else said, more like an argument of ignorance. Logical fallacies are where arguments are made which may even appear valid yet are logically unsound. "Nothing about the ancient Greeks is relevant to the modern world." is not in any way, shape or form an actual ARGUMENT as is simply makes a statement of, I suppose we could say, opinion. An argument would have stated some form of reasoning, however unsound it might or might not be. "Nothing about the ancient Greeks is relevant to the modern world BECAUSE..." "...the people of the past were too different from us today for it to relate." or "...because they were truly democratic while America is a republic" or "...anyone who chose to wear togas and believed in diplomacy over warfare is naive."

What you are talking about, when a person is able to make a statement that they believe to be true due to their ignorance of the invalidity of their statement we would call that simply "ignorance". If a person makes that statement and is then made aware of information that is not logically compatible with their statement's validity, yet are of such a strong opinion that they willfully ignore it or discount it... in your example, the "fallacy" only appears once our ignorant opponent of modern Grecian relevance makes the statement that he has likely not heard of  "square" and "square root" because they are too archaic to be of use today. He is falsely assuming that 1) the terms are not in common use because he has not personally heard of them and 2) that these terms are not in common usage today because they are so ARCHAIC. The first assumption is not a fallacy, but rather just general stupidity and ignorance... one could even make the argument that since everything we know was once something we were at one time unaware and that since his argument begins by assuming his being unaware of it means it does not exist then his argument is inherently invalid no matter what it ends up being, as things that he is aware of are valid and those he is not are not, yet everything he is aware of is something which he was once unaware of.

The second assumption is the logical fallacy, where he takes a (supposedly) true statement, that these things are not in use today (HOWEVER he got to that) and states that is because they are so archaic... which, I actually just noticed, is what your hypothetical "hard-head" is actually giving as his argument for the Greeks modern irrelevance- that that which is "archaic" is inherently worthless today. Fallacies everywhere; supporting an argument with itself, relating unconnected things in such a way to appear to support ones argument... but sorry, I don't think there's a new one here. Holding onto ones views as being logically sound after having been shown their invalidity is something which one cannot do and BE INVOLVED in a logical discourse at that point. It is not a logical fallacy; in fact it eschews logic altogether.

Hope this helps.
Please note that cunning (unless particularly duplicitous) isn't illegal, but rather an important aspect of microeconomics.

I think the Wikipedia entry on the https://en.wikipedia.org/wiki/Black_economy black market is quite insightful. 

Unless a black market is completely* closed off, of course it forms an inseparable part of the total economy, and, if significantly so, then can't be ignored. I should think there's plenty research (even theoretical) on the effects on the regular economy of, e.g., https://en.wikipedia.org/wiki/Money_laundering money laundering and https://en.wikipedia.org/wiki/Smuggling#Economics_of_smuggling smuggling.

*I can't think of examples of closed-off black markets that are not particularly unsavoury. Such markets probably wouldn't even use legal currency, but more likely rather be https://en.wikipedia.org/wiki/Barter barter economies. And the "goods" exchanged wouldn't have substitutes in the regular market.

  Or is this an indication that there are in fact more than one Set Theory in the same way that denying the parallel postulate in non-euclidean geometry resulted in several different geometries: elliptic and spherical with the euclidean geometry occupying a special place because it is flat


Yes, something like that: there are many set theories being studied, and each depends on what you want the "set" to be.

The problem with sets is that we use them in so many different contexts. So the question is: is the given set theory T appropriate for the given context? What we call "set" in one occasion might not have (almost) anything in common with the use in another occasion. Now, mathematics is about building systems that are (hopefully) internally consistent, without having to make external sense or correspond to any actual part of the nature (universe). 

But as philosophers, we might ask ourselves: if this thing called set here and that thing called set there have so much in common (containing elements and such), might they be the same thing? If you're a Platonist (or at least math Platonist), then by Occam's razor, it seems reasonable to assume that this "set" thing is the one and the same. There might be some issues with talking about sets (the logics that we know of are full of problems, like second-order logic's incompleteness, and all our theories are based on those logics), but the idea you mentioned - representing of the same thing through different views - comes to rescue (different views give different ideas, perhaps sometimes even "untrue", but the essence is reflected in all views).

Personally, I'm not Platonist, and I don't think that sets exist in any form independent of us, and I do believe that in different contexts, "set" means different things, and I think there can hardly be any connection between those usages.
Assuming that by "God" you mean an omnipotent, benificent and all-knowing supernatural entity, this question boils down to a rephrasing of the classic problem of "evil". And I think it was argued by Epicur quite sufficently thousand of years ago:


  Is God willing to prevent evil, but not able?
  Then he is not omnipotent.
  Is he able, but not willing?
  Then he is malevolent.
  Is he both able and willing?
  Then whence cometh evil?
  Is he neither able nor willing?
  Then why call him God?


[Source: http://en.wikipedia.org/wiki/Epicurus#Pleasure_as_absence_of_suffering Wikipedia]

So in order to get out of this dilemma while still upholding such a god concept, one has to rationalize evil differently.

You can ad hoc rationalize why man is to blame quite easily: Simply invent "sins" committed by man, so that blame can be attributed "correctly". Just watch the news of any natural disaster, you surly will find some theologian claiming that the wicked way of man made that event a just and rightful punishment.

Problem is, the concept of "sin" only works a theological framework that allows for "free will". https://philosophy.stackexchange.com/a/2171/1140 Not only is "free will" incompatible with the physical world, it also conflicts with the all-knowing attribute. Surly such a god would know how his creation would choose.

The whole "sin" concept has also troubles with the disconnect between what humans think to be good and a god as origin of "goodness". As in the end, whatever god wants to be "good" would be good. Even murdering millions of people. This is why you could even turn this whole argument upside down by arguing that a god was there the whole time during the holocaust as it very much wanted the holocaust to happen to punish the Jews!

How benevolent such a god would be is debatable. For me, it would be a malevolent one, but I am not the standard here. If God would want it, it would be "correct". Anyone else would have gotten it "wrong".

Nazis did not consider themselves doing evil acts. They did what they thought to be right. In their twisted world view, Jews were parasites, and it was their duty to destroy them. "Gott mit uns" aka "God with us" was one of their mottos.

And as cruel as that may seem, there still are many irrational http://en.wikipedia.org/wiki/List_of_conspiracy_theories#Antisemitic_conspiracy_theories conspirational theories attributed to the Jews, and to this very day some people think it is their holy duty to purge the Jews from this planet. And not because they consider themselves evil, no, but because they think they are the good guys as strange as that may seem.

Or as Voiltaire once said: People believing absurdities will commit atrocities.

In the end, I would claim there is no sufficient enough argument that would support the concept of a benevolent god and the event of the holocaust. Playing devil's advocate (Pun very much intended) is a fool's errand here.
We must first distinguish between what is physically possible — what it is possible to actually occur — and what is imaginable, or logically possible under certain premisses.

Remarks about the logically possible

Initial approaches

Logic itself — which I will take to mean classical propositional logic — has very little to say about time, or about infinite chains of consequences, either extending forwards or backwards. Indeed, it has nothing at all to say. Logic is merely a tool which we use to investigate topics, but anything it has to say on the subject are from premisses which we supply. So what is logically possible depends on the premisses we adopt.

Obviously, if we assume that there cannot be infinite regresses, we will conclude that infinite regresses are impossible; and if we assume that everything must have a cause, then infinite regress is necessary. Boldly asserting our assumptions is not a form of logical deduction, however. So we must try to avoid doing so if we wish to consider logical possibility or necessity.

We can observe that the two statements — everything must have a cause, and that there cannot be an infinite regress of causes — are in apparent conflict with one another. There is one possible resolution: a cycle of causes, where A ⇒ B ⇒ C ⇒ A, and the like, including potentially complicated networks of mutual-causation. If you find this just as dissatisfying as an infinite regress of causes or an uncaused event, then you may which to assume that such cycles cannot exist: but then you should remain aware that this is an assumption on your part.

There is absolutely no proposition A that we know of, which "causes" another proposition B to hold — that is, where A ⇒ B — which prevents us from considering yet another proposition Z such that Z ⇒ A, and where we may regard A as true because Z is true. So every proposition can be concieved of as being caused by another. But there is nothing which forces us to formulate such a proposition Z, either. We must move beyond mere sentential logic if we wish to plumb this idea further.

Infinite regresses in mathematics

We may consider what ideas come from mathematics to inform our ideas about whether logical causal chains are possible: mathematics is in effect our most intense testing grounds for logical consistency of ideas. Indeed, in modern mathematics, infinite forward-moving causal chains are common. The simplest example is http://en.wikipedia.org/wiki/Mathematical_induction Mathematical Induction, in which one proves that if some property P holds for 0, and if P(0) ⇒ P(1), and if P(1) ⇒ P(2), and so forth ad infinitum, then P holds of all whole numbers: one essentially completes an infinite chain of implications in one swoop. It is similarly common to build "upward towers" of containments: for example, sets A ∈ B ∈ C ∈ D ∈ ... However, it is unusual to consider chains of conditionals which reach "infinitely backwards", where ... ⇒ Q(3) ⇒ Q(2) ⇒ Q(1) ⇒ Q(0); and in most formulations of set theory, chains of the form ...∈ D ∈ C ∈ B ∈ A are expressly forbidden. We must not mistake this for logical impossibility, however. The axioms of set-theory that we have today were explicitly formulated to avoid confusions of definitions of sets, but they are not the only such formulation: there is a study of so-called https://mathoverflow.net/questions/14133/is-there-a-category-of-non-well-founded-sets/14135#14135 non-well-founded set theories in which such "infinitely descending chains" are possible. As to infinite chains of consequences, for any predicate P for which we have an infinite ascending chain P(0) ⇒ P(1) ⇒ P(2) ⇒... of entailments, the predicate Q(n) ≡ ¬P(n) has an infinite descending chain ... ⇒ Q(2) ⇒ Q(1) ⇒ Q(0) by contraposition. So if you admit infinite chains of "logical effects", you must also allow infinite chains of "logical causes" as well, or very carefully re-examine your foundations of logic.

Infinite descent is very common in mathematics, of course, if you consider the set of the integers ... < -3 < -2 < -1 < 0 < 1 < 2 < 3 < ..., or similarly if you consider the rational or real numbers ... < 1/16 < 1/8 < 1/4 < 1/2 < 1. Arguing for the fact that these are defined in terms of the whole numbers starting from 0 neglects the fact that we have chosen that starting point for reasons which may be described as simply traditional; the fact that we feel compelled to consider number systems which allow these infinite backward regresses is also a counterpoint.

So much, then, for inspiration through mathematics.

What are the permissible assumptions to use?

It is difficult to see how to proceed without entering the domain of physics (which I will touch on momentarily).


The Principle of Sufficient Cause is very much in sympathy with determinism; but of course assuming that the world is deterministic does not prevent us from entertaining the idea of a further cause to any particular cause that we might like to imagine — so more physical assumptions beyond mere determinism would be necessary to make the notion of determinism useful.
Consider an  "actual infinity" of regress — that is, where one may not only posit a preceding cause for any cause, but actually entertain a completed chain of causes. One might try to argue that an actual infinity of anything (logical causes or otherwise) is absurd; and while this was an active debate in philosophy of mathematics in the late 19th and early 20th centuries, the consensus is heavily in favour of actual infinities; a simple rejection of actual infinities is not likely to be convincing to others. But even if you only admit potential infinities of causes, you still have a potentially-infinite-regress, where the only reason why you don't entertain a cause for some early event is because you get caught up in doing something else instead. (The tendancy for us to do so is a possible reason why the idea of a first cause is so popular in the first place.)
The fact that there may, or may not be, a largest infinity which describes an infinite regress, is more ambivalent. Few people are terribly concerned about the subject so far as I can tell. However, the fact that one could always posit "a larger infinity", a la Cantor, is no rebuttal against an actual infinity of causes (despite the fact that this is in effect what Aristotle does for his Prime Mover): there is also nothing preventing someone from positing a cause for what otherwise would appear to be a Prime Mover. Whether one prefers a system of reason in which largest possible cardinalities exist, or do not, is a matter of taste; this is an impasse for the debate.
If you are of a religious persuasion — and in particular, a creationist — then it will seem quite natural to posit that there is a first cause. Suffice it to say that https://philosophy.stackexchange.com/questions/1233/is-it-possible-for-something-to-have-no-cause there are many people who will find your arguments unconvincing, if for no other reason than the fact that they do not agree to the assumptions included in your religious background.


I am unaware of any particularly compelling ideas — or for that matter, any particularly interesting ideas — which would decide in favour either of infinite regress, or in favour of the impossibility of infinite regress, as logical necessities. As far as I can tell, both the notion of a first cause and the notion of an infinite causal regress are logically coherent — except if you in essence assume that one of them is false.

It would seem that there is nothing left but to get out of the arm-chair, so to speak, and actually look at the outside world to see what is more likely to be the case.

Remarks about the physically possible

Because this is not https://physics.stackexchange.com/questions the Physics StackExchange forum, we should not pretend to answer definitively what is "actually" possible, which is the domain of physics (or science more generally). However, we may make some observations from what is broadly known in the physics community.

For physical quantities or qualities, such as mass and energy, physicists tend to be skeptical of the idea of infinite quantities, if for no other reason than the fact that some object of infinite magnitude should presumably be easy to spot (if it didn't destroy the universe first). However, things like "age" aren't physical quantities or qualities; the universe may have processes which we can use as reliable time-keeping devices, but time is not written into matter itself, so far as we know.

Remarks on cosmology

Of course, the Big Bang theory is a physical theory, and it posits that our universe has a beginning only a finite amount of time ago. So this supports the idea that the universe does not have infinite causal regresses. But this is an observation, not a theoretical proof: our universe happens to be finitely old, and only so far as we can tell. (As if we could do better than the best of our observations.) When Einstein formulated General Relativity, he postulated a cosmological constant precisely because he thought the universe was in an infinitely old steady state: this is a move he later described as http://en.wikipedia.org/wiki/History_of_general_relativity#The_development_of_the_Einstein_field_equations the biggest mistake of his life, but only because his prejudices prevented him from making one of the most astonishing anticipations in the history of science — modern theoretical grounds for a finite age to the universe based on a theory of gravity (which would have been an unanticipated event on the order of magnitude as Dirac's prediction of antimatter). These days, people feel more forgiving of Einstein's mistake, because it would seem that there is a non-zero cosmological constant, just as Einstein thought — only it has the opposite sign to what he thought, so that the universe is not only expanding, but faster than it had before.

The continuity of time

Of course, if time is continuous, there actually are infinite causal chains, but more of a Zeno-like flavour: between every cause and effect which happen at different times, there are intermediate effects and causes, and ones between those, ad infinitum. In the limit of infinite division of causal chains, you can obtain a continuum of intermediate events. Alternatively, between a cause at time t=0 and at time t=1 you may contemplate intermediate events at t=1/2, t=3/4, and so on for all times t=1-2-n for all positive integers n, still giving rise to an infinite chain of events which lead up to the event at time t=1. This is only prevented if there is discrete time; but there's no particular evidence that time is finite. (There is indeed research into such discrete models of time, and although this research sometimes looks interesting and promising, there isn't anything particularly strongly suggestive.)

On determinism and causation

It is possible that we might be able to undermine the Principle of Sufficient Reason, if for instance there are random events. Do they have causes, and if not, can the whole universe (or some powerful entity within it) perhaps be uncaused? Of course, many events which seem random can in principle be predicted if we have enough information about the initial conditions in which the die was rolled. Chaos theory may predict that it is impossible to pin down initial conditions sufficient to predict for all subsequent times, and quantum mechanics suggests that perhaps there is no perfectly defined initial conditions in the way that we would require e.g. in Newtonian mechanics. But so persuasive is the idea that the world acts according to deterministic and causal mechanisms that it is difficult to abandon the idea that everything happens for a reason, and so there are researchers such as those who work on http://en.wikipedia.org/wiki/De_Broglie%E2%80%93Bohm_theory de Broglie-Bohm theory who seek to give a deterministic interpolation of quantum mechanics (as opposed to "an interpretation", speaking here against the common manner of speaking of de Broglie-Bohm theory).

Of course, here too there is an impasse: just because one of our more practical theories can be formulated efficiently as a probabilistic theory, does that mean that therefore there is randomness inherent to nature? But this is just a particular instance of the problems of epistemology: if nature is sufficiently subtle, it can fool us into classifying it differently than we might if we were somehow more perceptive or less biased. As with everything in science, the jury is still out.

In summary

But the state of the art in theoretical physics is that there's no theoretical grounds for ruling out infinite causal chains, even ones which extend into the infinite past: the best we can do is to say that observation suggests. 
This is ultimately what matters anyway; what is, rather than what might otherwise be. 

What observation — and our interpretation of these observations — has thus far suggested that our universe is finitely old, and that it is reasonable to suppose that there are events which are not completely characterized by what came before. However, by the very fact that we have a useable theory of random behaviour in quantum mechanics, no event seems to be "completely uncaused"; and it also assumes a continuous evolution in time, so that there are at least Zeno-like infinite chains of cause and effect.
Well, then we get other logical systems with possibly interesting properties and applications.


Giving up (a) is tough, I'm not aware of any logic where this doesn't hold. (But I wouldn't be surprised if there is one.) 
(b) does not hold in intuitionistic logics and also not in partial logics. Many logicians consider a failure of (b) to be desirable.
(c) is given up in paraconsistent logics, e.g. in a logic with with 4 truth values you can interpret the values as {}, {T}, {F}, {T, F} where the latter is the case A & not A is true - dialethists do this to "deal" with semantic paradoxes.

You are operating within the laws of classical logic. If God is all-powerful he'll can possibly change the laws of logic itself to allow what you suggested is for him impossible. I say possibly as this is to a large extent speculation on my part. However note that there are http://plato.stanford.edu/entries/logic-paraconsistent/ paraconsistent logics in the Western philosophical tradition within which allow inconsistencies and http://plato.stanford.edu/entries/logic-intuitionistic/ intuitionistic logic which drops the excluded middle; the Eastern philosophical tradition has the http://en.wikipedia.org/wiki/Catu%E1%B9%A3ko%E1%B9%ADi catuskoti one of which allows the possibilities of contradiction.

Of course this itself a little anthropomorphic - for him to change the laws of logic. One could say alternatively that there are no laws of logic for him - since he is the ground of all laws. Though I'm not sure quite this means in practise.
an opportunity to get out my battered old copy of Grundlagen, woo.

So the introduction is where Frege is establishing the point of the book: when you're writing an entire book to establish what people think they already know, you need to make a good case that they're wrong. So that's what he does; he takes on the current state of philosophical thinking about mathematics and bitchily tears it up.

"Aggregative" means "put together", basically. "Aggregative mechanical thought" is Fischer's idea that numbers are what happen when we start from 1 and just keep adding things together in our head. Frege points out that this is nonsense; thoughts aren't things that can be put together, and numbers don't work by some special kind of reasoning of their own but are just features of the same reasoning we use for everything else.

If you're reading to learn about Frege's ideas, though, I wouldn't worry too much about the specifics of this; he moves on to jucier targets (gets really bitchy about Mill on page 9) and actually starts to talk about his own ideas eventually. I had a look at the Fischer (it had never occurred to me to just Google it before), but my German isn't quite up to translating it properly; basically he's talking about calculation just being counting number in a mechanical way.
I think there's an ambiguity on the word "work". 

Sense 1: work is how much gets accomplished. 
Sense 2: how many hours of labor a person has to do in a day. 

Technology has increased the amount of work that we do in sense 1. An individual can accomplish far more, in some sense, in any given 24 hour period today than would have been possible 100 years ago. I can communicate with people all over the globe, I can transport myself or some goods several thousands of miles if I want. And so on. 

On the other hand, this increased amount accomplished hasn't lessened the daily burdens placed upon us. But this isn't because technology has failed, it's because people's standards have risen--you might be able to live in a dirt-floored shack only working an hour a day today, but you wouldn't want to. You want to live in a nice modern house with plumbing, and heat that is fire resistant and will last for a long time, etc. Your house is a lot nicer than the houses a hundred years ago, probably, which means that more work-in-the-first-sense was required to produce it. hence you still have to do a lot of work-in-the-second-sense to afford it. 
In Judaism, there is a very interesting approach to prayer. 
According to one of the principles of Judaism, god does not change his mind.
It is then difficult to understand how one can ask god for anything!
The answer Judaism gives to this question is that when one prays to god and asks him for something, the person himself changes, and therefore god is judging a new person altogether. Therefore, god does not change his mind, but since he sees a completely different person, he judges him by his new character.
Similarly, perhaps when one is asking for something, he becomes more humble and thus becomes deserving of what he asking for. 
The term leads back to pneuma, a central concept in stoic metaphysics:


  In Stoic philosophy, pneuma (πνεῦμα) is the concept of the "breath of life," a mixture of the elements air (in motion) and fire (as warmth). Originating among Greek medical writers who locate human vitality in the breath, pneuma for the Stoics is the active, generative principle that organizes both the individual and the cosmos. In its highest form, the pneuma constitutes the human soul (psychê), which is a fragment of the pneuma that is the soul of God (Zeus). As a force that structures matter, it exists even in inanimate objects.


More information to get started at the http://en.wikipedia.org/wiki/Pneuma_%28Stoic%29 relevant WP page.

The frequentist interpretation also allows for some frequency with which the observed frequencies differ from the ideal. In particular, you should expect in N trials of a "perfectly unbiased" coin to observe a variance of up to N/2 (a standard deviation of sqrt(N/2), equivalently) from the norm for a collection of N samples, with some probability — and a variance of more than this also with some probability. This is to say: you cannot be certain that the norm of the sample will even be particularly near to the idealised mean, though it is likely to be so on average.
Probability theory is just a model; or perhaps more accurately a meta-model. By abstracting away details which we think have a negligeable impact on outcomes — such as the effect of the position of Jupiter on your coin-flip — we arrive at a model which is practically useful, although perhaps not as comprehensive as possible. Its success comes from the fact that such fine details do not seem to play any significant role in outcomes. As such, probability theory is a success story of applied mathematics, which is to say a success story of quantitative epistomology.

I honestly cannot understand what this has to do with free will.

Free will is hard to define, but roughly the philosophical definition is independence from external physical influences. If we have free will, then we are by default independent from these influences. Then, if we are told that certain actions will incur punishment, which is an external physical influence, nothing changes at all.

Suppose you get a glass of water and want to drink it. If you have free will, then it is your independent decision to drink it. Then, suppose I tell you than though the water will quench your thirst, I put something in it to make it taste very bad. If you had free will before I told you about this "punishment", you will still have it afterward: it is still completely your decision. Knowledge of punishment is merely a factor in this decision - if you have free will from other influences, then this one too will not determine your choice in any way. There's nothing special about punishment that makes it more physically determinant than everything else in the world.

Thus, whether God punishes us has nothing to do with free will. We either have it or we don't, and in either case punishment plays no role in determining our freedom.
Fundamentally, no; but it is a moment of change.

Humans have always had to deal with information: their social environment - gossip, rumour etc; and formal knowledge - schooling and so on.

One learns who and what to trust. It is institutions that verify & validate this. Newspapers, journals & universities. 

The internet obviously multiplies this hugely - by making information readily and globally available. A large proportion of the information on the net is not new but simply transferred from print media. Google though very powerful is simply an indexing service.

But similar institutions have & will arise. For example, the SEP. Online newspapers.

One can argue we have moved from oral, to print, to online. But that misses the subtle point that older forms are not superseded but added to. Online may be new but it still uses writing. And writing of course uses the same language as the oral mode does. 

Marshall McLuhan said - the media is the message. He is simply emphasising that a new means of communication brings change which is tied to its form as a form of communication. But I would argue against it being a fundamental change. Instead its a new harmonic added onto the fundamental tone to use a musical analogy.
We do not perceive time, of course. What we do perceive, albeit indirectly, is change: we see one situation, form a memory of it (or retain it in our short-term memory of what's happening), and then perceive another situation which differs from it. The notion of time is prompted by the notion of change; and the notion of a regular "flow" of time comes from a large array of cyclic changes — days, phases of the moon, seasons, planetary motions — which together suggest a steady rate at which things change.

If everything were to stop moving, time would have no significance that we know of. Time is only significant to us inasmuch as it is a framework for describing change. Indeed, philosophers of science such as http://en.wikipedia.org/wiki/Julian_Barbour Barbour have proposed that time is indeed an "illusion" which is suggested by change, or more precisely by a collection of distinct configurations of matter which we somehow perceive as (i) related to one another, as in being distinct states of a single system, and (ii) being ordered in time:


  [Barbour's book] The End of Time advances timeless physics: the controversial view that time, as we perceive it, does not exist as anything other than an illusion [...] He argues that we have no evidence of the past other than our memory of it, and no evidence of the future other than our belief in it. "Change merely creates an illusion of time, with each individual moment existing in its own right, complete and whole." He calls these moments "Nows". It is all an illusion: there is no motion and no change. He argues that the illusion of time is what we interpret through what he calls "time capsules," which are "any fixed pattern that creates or encodes the appearance of motion, change or history."
  
  Barbour's theory goes further in scepticism than the block universe theory, since it denies not only the passage of time, but the existence of an external dimension of time. Physics orders "Nows" by their inherent similarity to each other. That ordering is what we conventionally call a time ordering, but does not come about from "Nows" occurring at specific times, since they do not occur, nor does it come about from their existing unchangingly along the time-axis of a block universe, but it is rather derived from their actual content.


To distill this into a quick metaphor: you are meant to think of the universe not as a motion picture, nor even a static piece of film, but as a scattered and disorderly collection of frames from a film. They all exist simultaneously, and if we (as characters in the movie) perceive an ordering of time, this is because the similarity of adjacent frames induces an order on the frames.

However, does this mean that time is an illusion? While Barbour's ideas are treated with some seriousness, I find difficulty in understanding how an ordering obtained from similarity of co-existing "nows" differs from the block-universe picture of general relativity, which is essentially nothing more than the "nows" being explicitly ordered rather than implicitly; nor do I understand how the division of the world into "nows" comes about, nor why we should experience the echos of some "nows" as memories in other "nows". The simple reason is perhaps that some "nows" encode physical states of the brain which represent information about other "nows", and if one supposes that the universe is enormous and random, there will surely be systems which have such encodings — but why we should experience them is a mystery.

So Barbour has perhaps succeeded in reducing the notion of time to the hard problem of consciousness, provided a hypothesis about the universe being large and random enough to give rise to enough "nows" that there is a plausible sense of continuity. Even if we grant this: does this mean that time is an illusion? Provided that Barbour could explain why we experience anything if the universe consists of a static ensemble of "nows", this would rather be a mechanism (or rather construction) for the emergence of temporal change as an experience. Regardless of what underlies it, I am unable to avoid the simple fact that I experience change; therefore it does not really seem justifiable to dismiss time as a phenomenon (or a way of describing a phenomenon).

Time may not be a spatial dimension, and it may have subtle physical origins, but this does not mean that it does not 'exist'. One might as well say that matter is an illusion because our physical sensation of touch is based on electromagnetic fields propogating across small distances of "empty" space. The fact is that matter is not an illusion — our experiences are still described well by the notion of matter — it is simply that matter is not what our naïve impressions might suggest it is. The same may be true for time, and for time nevertheless to be 'real'.
The sentence in the Wikipedia article prior to the one you cited gives a rough idea of how Foucault moves towards to structuralism.


  it is an examination of the evolving meaning of madness in European culture, law, politics, philosophy and medicine from the Middle Ages to the end of the eighteenth century, and a critique of historical method and the idea of history.


Foucault has clearly moved away from a phenomenological perspective if he now concerns himself with the meaning of a sign or a fact such as madness, and how that sign is defined by cultural and political agendas, rather than possessing an objective definition. Concurrently Foucault addresses the impossibility of an objective definition for such a term that is not intrinsically biased.
There is always some special arrangement of the neurons that makes the difference between a brain and a mass of neurons. We can even say we associate words to shapes in an innate (culturally independent) way, as the http://en.wikipedia.org/wiki/Bouba/kiki_effect Bouba/kiki effect demonstrates. But from that substrate there are many things that we learn.

To measure how much we learn we can take a look at children, as in the https://philosophy.stackexchange.com/questions/7019/what-does-it-mean-to-have-a-sense-of-geometry-innate-to-us-if-that-is-in-fact/7871#7871 answer from cartomancer, or we can consider people that have different culture, capabilities, etc.

For instance we can consider blind people. Blind people are in general are more used to a three-dimensional world where two dimensional objects do not make so much sense. [They are still normal for them (more than 4D objects) as a wire can take any of those shapes, for instance.] The point is that our experience and perception shapes our understanding and comparing with http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3386238/ haptic perception helps to understand where do our prototypes and concepts for shapes come from.

There are many notable http://www.ams.org/notices/200210/comm-morin.pdf blind mathematicians specialized in geometry allegedly due to this difference in perception of the world, shapes and geometry, that at the same time influences a difference in the understanding of geometry. I would personally say that a posteriori influence is what makes a difference in the a priori substrate.

To finish up I'd like to call the attention over a specific paragraph in the original question:


  This means that although there are such geometries, because as human
  beings we have only our immediate environment to purvey, that is, our
  spatial knowledge is local, what is a straight line or circle in the
  standard sense remains effective. It does not have to be acquired, but
  can be innate.


The point about innate as being more effective does not make much sense. The same can be said about colors, for instance, however colors mean nothing to blind people and are perceived in different ways depending on color-blindness. That point suggests an intelligent design that creates people in ways that are efficient, however that is not the way evolution works and to the best of our knowledge that [efficiency] is not a good reason to think humans are in one way or another. We should be very careful about assumptions that are introduced inadvertently in such ways.

PD: Actually evolution pushes human beings to have the least amount of innate knowledge, the brain is not mature at the moment of birth due to limitations to enable birth in a bipedal species like humans. 

Also, it may be interesting to consider spiders, and probably other animals. Spiders can make webs that can be perceived as complex to the human eye. We can debate about whether that is innate knowledge or knowledge at all. Spiders sure don't have an explicit knowledge that they can transfer to any other being, or reason about. Probably it is just a feeling, about what feels right at a given time making a web, and that feeling is http://scienceblogs.com/startswithabang/2013/07/06/weekend-diversion-spider-webs-on-drugs/ altered by drugs. In this case I'd say there is a substrate and an emerging pattern through some kind of "spider feelings", but the spider never knew anything in an explicit way.
According to Kant, space is not definitely "out there." We have no way of perceiving the things as they are in themselves (the noumena), because all perception is mediated by the mind and our senses. Therefore to say that space is out there is to make an assumption that we have no way to verify. Space and time, according to Kant, are the forms of intuition, the way that our perceptions may be determined. So rather than thinking of space as something out there, it is the way our mental equipment represents the things we perceive (the phenomena):

"Thus, if I take away from our representation of a body all that the understanding thinks as belonging to it, as substance, force, divisibility, etc., and also whatever belongs to sensation, as impenetrability, hardness, colour, etc.; yet there is still something left us from this empirical intuition, namely, extension and shape. These belong to pure intuition, which exists a priori in the mind, as a mere form of sensibility, and without any real object of the senses or any sensation." (A21/B35)

"Space is nothing else than the form of all phenomena of the external sense, that is, the subjective condition of the sensibility, under which alone external intuition is possible." (A26/B41)

Kant specifically denies that space is a property or relation of things as they are in themselves:

"Space does not represent any property of objects as things in themselves, nor does it represent them in their relations to each other; in other words, space does not represent to us any determination of objects such as attaches to the objects themselves, and would remain, even though all subjective conditions of the intuition were abstracted." (A26/B41)

Secondly, a priori knowledge could in no way come from experience, not even as an inheritance from our ancestors. Otherwise, Kant's Critique would have been a total failure, because his whole purpose was to find justification for metaphysical principles such that they could be known with necessary certainty. If a priori knowledge did have its origin in experience, it could never rise above the level of contingency, because experience could at some point provide evidence to disprove it. John Locke made the mistake of thinking that he could derive such principles from experience:

"... we have to thank the celebrated Locke for having first opened the way for this inquiry. But a deduction of the pure a priori conceptions of course never can be made in this way, seeing that, in regard to their future employment, which must be entirely independent of experience, they must have a far different certificate of birth to show from that of a descent from experience." (A85/B118)

David Hume, on the other hand, didn't fall into the same error. However, even though he recognized that such principles had to originate in the understanding independently from experience, he failed to see how such principles could be applied to experience:

"David Hume perceived that, to render this possible, it was necessary that the conceptions should have an a priori origin. But as he could not explain how it was possible that conceptions which are not connected with each other in the understanding must nevertheless be thought as necessarily connected in the object..." (A93/B125)

So to answer your question specifically, there is no evolutionary argument for the problem, because it would still be rooted in the contingent uncertainty of possible experience. The most experience can do is provide us with undetermined intuitions. Concepts, on the other hand, are abstractions from raw intuitions. In order to understand Kant, it's essential to understand that intuitions don't abstract themselves. There's nothing in intuitions that suggests the possibility of concepts or knowledge. It's the difference between seeing a mix of colored paint on a canvas and seeing what the painting is depicting. It's difficult to explain, because we tend to take too much for granted. Understanding these things requires some careful reflection.

Take Descartes, for instance, when he said "I think, therefore I am." In that affirmation, he found the kind of certainty that experience can't provide, and from that he had something to build upon to develop his philosophy about the world. Kant also took the same starting point, but he went in the opposite direction. Instead of simply regarding it as foundational, he sought to understand what foundation such certainty has: 

"But this representation, 'I think,' is an act of spontaneity; that is to say, it cannot be regarded as belonging to mere sensibility. I call it pure apperception, in order to distinguish it from empirical; or primitive apperception, because it is self-consciousness which, whilst it gives birth to the representation 'I think,' must necessarily be capable of accompanying all our representations." (B131)

"For the manifold representations... must conform to the condition under which alone they can exist together in a common self-consciousness, because otherwise they would not all without exception belong to me." (B131)

Notice that he's saying here that representations could not exist in a common self-consciousness, i.e., the "I think" wouldn't be possible, unless certain conditions are met. To discover those foundational conditions, he had to treat "I think" as a conclusion to be derived from principles that are even more fundamental. In other words, he was digging deeper than Descartes in order to discover the conditions that make thinking possible; when you do this, then  what you find is: you can never get past the foundational elements of knowledge, such as concepts, to discover some basis in experience, as if raw intuition could themselves provide the possibility of knowledge. Multiplicity, for example, doesn't itself suggest the idea of possible unity. A whole doesn't suggest the possibility of parts. Those are abstract concepts which presuppose the ability to abstract. For that reason, Kant concluded that a priori knowledge is rooted in the understanding itself:

"[T]he concepts met with in metaphysics are not to be sought in the senses but in the very nature of the pure understanding, and that not as innate concepts but as concepts abstracted from the laws inherent in the mind (by attending to its actions on the occasion of experience), and therefore as acquired concepts. To this genus belong possibility, existence, necessity, substance, cause, etc., together with their opposites or correlates. Such concepts never enter into any sensory representations as parts, and thus they could not be abstracted from such a representation in anyway at all." (Inaugural Dissertation, sec. 8)
RE: Should philosophers be concerned about the political implications of the theories of other philosophers (as well as their own)?
Answer: Yes! Yes! A thousand times yes! Ideas (theories) have the ability to make life (standards of living, rise and fall of a nation) amazing and beautiful, or horrific and evil. Hitler's philosophies of killing all the Jews and enslaving the World into his 1000 year Reich resulted in the slaughter of (estimated) 50-80 MILLION PEOPLE. Even today it is illegal in Germany to make a Nazi salute - this is how IMPORTANT or dangerous theories can be. After WW 2, many of the Japanese and German soldiers were interviewed to find out why they so savagely tortured and abused the prisoners of war. The American and British soldiers were shocked at how horrific the prisoners were treated. They treated human beings like animals. Upon exhaustive questioning, it was discovered that the philosophy of evolution was the foundation for their actions. Germany was the most educated nation on the planet before WW2. It makes perfect sense when the philosophy of evolution is broken down. If you are taught humans can evolve, then it makes perfect sense to believe that your race can be "more evolved" than other races. The Germans and Japanese actually had a list they distributed and taught. At the top of the "most evolved" list were the Aryan races. As you went down their evil list,  (supposedly in order of the "lesser evolved" human species), at the bottom you would find blacks Jews, gypsies and other "undesirables". Stalin, Lenin, Mao, and Pol Pot were all radical adherents to the PHILOSOPHY of atheism/communism. MAO KILLED between 49 and 78 MILLION people! Stalin 20 million. Lenin 4 million. Pol Pot 1.7 million. It is extremely important for the survival of the human race (politically and physically) that the implications of belief (philosophies) are critically  examined to their final destination. One young man learned in high school about evolution and this prompted him to attempt to murder his father with a hammer. 
See Youtube Testimony
https://www.youtube.com/watch?v=kS8aUSygJM0 https://www.youtube.com/watch?v=kS8aUSygJM0
On a positive note, the philosophy of Martin Luther King JR resulted in freedom from oppression in the political arena for millions of black people and resulted in the laws of the nation to reflect these truths.  
Simplicity actually depends mostly on the point of view. In physics, this becomes obvious when choosing coordinate system which are most suitable to the problem at hand, or simplifying equations by introducing suitable notations. Before people in Europe started to write numbers with arabic decimal digits, division was its own subject in university education. Today, it is taught in primary schools, because we found a more useful notation...

The other component of simplifying the world is abstraction: disregarding any information which is not seen as important at the moment.

So: there are simple laws of physics, if you find the right way to look at the world, and disregard everything that would make it too complicated for your taste...
Answer to your question: No - they do not have to lead to infinite regress.

Explanation:


To cope with world-1, evolution equipped behaving animals with the possibility to sense the world.
Smart interaction with this world-1 (aka behavior) requires to map a high dimensional sensory input space to a low dimensional motor output space. This mapping requires generalization and abstraction which are implemented as cognitive processes. E.g. a animal has to realize that an apple is an apple independent of the light conditions, its exact shape and a variety of different colors,... i.e. the animal has a notion of an apple. 
Smart social behavior is an evolutionary advantage but it requires a possibility to exchange such internal generalized notions. This exchange is achieved through the communication of symbolic representations. E.g. an animal warns other animals through a distinct call (symbol for predator)
The evolution of such symbolic representations led to the human language and highly sophisticated models of the world-1 (the set of these models is what you call world-2). Part of these models is a set of rules that allows to treat symbols in a consistent fashion aka. mathematics. If we apply mathematics to symbols which originate from abstractions of the world aka science, we can predict reactions in the world aka explain it. It is important to note that a sentence on the world-2 can be proven (e.g. logic/mathematics) by checking whether it is consistent with a set of other sentences in world-2. This is not possible for sentences on the world-1 (science) since our access to the world-1 is restricted through our senses, cognitive processes and our limited possibilities to manipulate the world. So the only thing we can do to have good models of world-1 is to reject the contradictory ones i.e. the ones that predict wrong observations.
Even tough we can describe the regularities in the world-1 we cannot explain them. The regularities of world-1 are a necessity for any description - from the cognitive process to the symbolic representation and the communication. So if we would come up with an explanation of the regularities, it would not be falsifiable. 
The creation of world-2 depends on the regularities in world-1 and therefore the regularities in world-2 are deduced from the ones in world-1 as everything in world-2. 
The sentence on the regularities in world-2 (point 6) might be considered a sentence of world-3 because it is a statement on the nature of world-2 but this is not true because the cognitive processes of animals and the communication in the human society are processes in the world-1, all sentences on their content are sentences on the content of world-1 and therefore they belong to world-2. 
In short: Explaining something is a process in the world-1 that requires consistency of world-1. Explanations of the consistency of world-1 are not falsifiable and therefore not valid.


In case you doubt that explaining something is a process in the world-1, I cut you with Occams razor. 
Its a no & yes answer, as in -

No: Agrippas Trilemma seems to me a result in deductive formal thought. Formally there are three cases. And formally its possible that a combination may be used.

Normal induction operates over countable chains and transinfinite over chains of higher ordinality. Since you are using an axiomatic system then (as you state) the first part of Agrippas Trilemma applies: the use of an axiomatic system by faith.

Mathematics done formally always resorts to this particular move. 

Yes: However in the practise of mathematics as it-is-done opposed to  mathematics done formally I don't think Agrippas Lemma has much purchase. The reasoning (and inspiration) is of a different order. One interesting possibility is http://plato.stanford.edu/entries/justep-coherence/ coherentism where various parts of a theory are shown to 'hang together'. (One could say this is inspired by circular reasoning - there is a metaphorical similarity - if that is the right word). I'd also throw in aesthetics - which explains why some mathematicians talk about beauty, elegance, profundity as well as simplicity & prettiness.

Perhaps your 'top-down' & 'bottom-up' is a strategy to perform this coherence?

But this probably true of all systems where reasoning applies. For example architecture & physics. Compare for example how one comes up with the design of a new architecture and how one is built. 
Hawking gave a nice remark in one of his pop books concerning the reality of his imaginary new time dimension.

"One might think this means that imaginary numbers are just a mathematical game having nothing to do with the real world. From the viewpoint of positivist philosophy, however, one cannot determine what is real. All one can do is find which mathematical models describe the universe we live in. It turns out that a mathematical model involving imaginary time predicts not only effects we have already observed but also effects we have not been able to measure yet nevertheless believe in for other reasons. So what is real and what is imaginary? Is the distinction just in our minds?"

reference:
http://en.wikipedia.org/wiki/Imaginary_time http://en.wikipedia.org/wiki/Imaginary_time

So to your question, they as real as long as you believe they are to be so.
The argument of Kant, arguing against the infinity of time, contains an error, nobody has pointed out. 

The general intuition that an accumulation of an infinite amount of 'things' would form an "actual infinity", so an infinity which has been completely absorbed, counted, etc., would be a contradiction, is of course correct. But as applied to time, the logical conclusion would be that just because that would be a contradiction, infinity of time is an endless/beginingless proces, unfolding in time.

The critical point then is that the infinite moments of time of the past, and the infinite moments in the future do not exist "at the same time", only the motion of the ever ongoing "now"...

As further demonstration to this, imagine the timeline without begin or end. Now place anywhere on the timeline two points, and measure the distance. The point is then, that wherever you place these two points, the distance between them is always strictly finite.
Infinity then (since the timeline is infinite, it contains infinitely many points) is composed of only finite. 
Every measure of time on an infinite timeline is still a finite duration. Hence the actual infinite does not occur...
In my eyes the answer is simpler than one might think:


If the damage is caused by a failure of the hardware or the software shipped with the robot, the company selling the drone has to be held responsible (within the warranty). Whether the company wants to sue the developer depends is up to the company and depends on the contract that the developer signed. This case corresponds to typical warranty case where a car that was produced with defects causes a damage. 
If the damage is caused because some parts have worn out and the owner did not take care of this (after the warranty), the owner can be held responsible. This corresponds to a car owner not taking care of his tires which leads to an accident.


For the next point it is important do distinguish different cases of controller:


Remote control: If the robot is a drone and remote controlled by a human, the operator is responsible for any damages. Corresponds to guy driving a car.
Autonomous static control: If the robot is executing a fix software which did not get affected by any external causes, then the company can be held responsible for damages. Corresponds to a broken product.
Autonomous supervised learner: If the robot is capable of learning, then the user teaching the robot is reliable if it can be shown that other robots which were trained in a better way don't cause any damages. This corresponds to not worn out tires just on the controller side.
If the robot is doomed to fail i.e. it causes a damage independent of the training - then the company is responsible for the damage. Corresponds to a broken product
Autonomous unsupervised learner: If the robot is doomed to fail, it's the companies responsibility. If a "bad influence" of the owner on the behavior of the robot can be proven, then the owner is responsible. If this is not the case, the damage was caused by a unforeseen constellation in the environment of the robot so that it learned a bad behavior so nobody is responsible (robot has to be reset or destroyed). This is similar to a natural disaster. 

Formally, resoluteness only means being resolute to not flee from the call of Dasein in the Stimmung of Angst. And it is only formal, Heidegger provides no contents. 

This is (a.o.) because Sein und Zeit is a preparation for the question to the sense of Being (Sinn von Sein). To do this, you need to be ready (bereit) to hear the call of your own being. Your own being does not only include your fate, but also your possibilities (of which death is the utmost).

Live as a work of art is something only Nietzschean. Remember 'art' means someting different for Nietzsche than for Heidegger:


For Nietzsche, art is a creation of the will. Life as a work of art for him means creating and experimenting with new values to find those which allow you to affirm life.
For Heidegger, a work of art is an event of truth (Unverborgenheid). 


The resoluteness vis-a-vis a work of art in The Origin of the Work of Art is, as he says, a kind of 'knowing'. What can occur in a work of a art that it tears you from the immersion into the world of beings to the openness of Being. It allows you to know Being. 'Standing within' (Inständigkeit) does not mean that you live as the work of art, but to allow yourself to be open to the event of the work of art.  
Irenaeus saw the pre-Fall Adam as more like a child than a responsible adult. Adam was at the beginning of a long process of development. His fall was not as disastrously transforming  man’s situation, but rather as delaying his advance from the “image” to the “likeness” of his Creator known as God. Ireneus less dramatic conception of the Fall has been carried further by Hick. The Fall is regarded as an inevitable incident in man’s development as a child of God. Only a relatively independent being can enter a relationship of love and trust with his Maker (God), and man’s fall is  a fall into this independence. It is  analogous to the disobedience which signals a child’s assertion of his own individuality in relation to his parents. 

Irenaeus insisted that the fullness of salvation, is only to be found by maintaining communion in Church, outside the church there is no salvation. Here Hick's theodicy begins to differ more from Irenaean theodicy. While Hick's have follow Irenaean theodicy in its broad outlines, his view required universalism. Hick posits an eschatological universalism in which every human person will eventually achieve full consciousness of God and thus salvation or liberation. If anyone were to be denied the salvation, creation is unjustified. Since people are usually not very developed at the end of this life, they go on to become reincarnated in other worlds many times until they are perfected enough to get off the wheel of life. There is no hell, at least no permanent hell. The process of soul making, which requires obstacles for its completion, must then continue in another realm,  until the soul is perfected and brought into intimacy with God. Unless everyone will eventually enter a limitlessly good end-state the problem of evil cannot be solved. Hick thus holds that there can be no successful theodicy apart from eschatology. 
 Main references
 John Hick - Evil and the God of Love 1966
 John Hick - Death and Eternal Life 1976
 John Hick - Theodicy 1967 Encyclopedia of Philosophy
I think this is what you are asking about (although I'm not sure):

The http://www.sivanandaonline.org/public_html/?cmd=displaysection§ion_id=774 astral body (Sukshma sarira) in one bit of http://en.wikipedia.org/wiki/Vedanta Vedanta thought http://hinduism.iskcon.org/concepts/102.htm carries your soul. 


  The Subtle Body
  
  Disciple: What is the composition of the subtle body?
  
  Guru: The subtle body is composed of nineteen principles (Tattvas), viz., five Jnana Indriyas or organs of knowledge, five Karma Indriyas or organs of action, five Pranas or vital airs, Manas or mind, Buddhi or intellect, Chitta or the subconscious and Ahamkara or the ego. It is a means of enjoying pleasure and pain.
  
  Disciple: When will this subtle body get dissolved?
  
  Guru: It gets dissolved in Videha Mukti or disembodied Liberation.


http://en.wikipedia.org/wiki/Videha_mukti Videha Mukti / http://hinduism.iskcon.org/concepts/106.htm Liberaton ends http://en.wikipedia.org/wiki/Sa%E1%B9%83s%C4%81ra#Sams.C4.81ra_in_Hinduism samsara.


http://en.wikipedia.org/wiki/Subtle_body#Hinduism http://en.wikipedia.org/wiki/Subtle_body#Hinduism

Eating your own species is a bad idea from a health perspective since any parasites (prions, etc.) that affected the other individual could well affect you, and any toxins they accumulated that were bad for them are also bad for you.  (Since cannibalism has not been frowned upon strongly enough in all societies there http://en.wikipedia.org/wiki/Kuru_%28disease%29 is a fairly recent example of this.)

Thus, consequentialist ethical systems should oppose cannibalism for pragmatic reasons, assuming starvation is not an issue.

I'm not sure there is a succinct way to consider non-consequentialist positions.  Cannibalism aside from starvation or murder is sufficiently rare that I've not seen it garner much attention.
Yes, yes, and yes.

Look what I found. (Everything can be found in, and was taken from, the next to last link provided.)


  Machiavellianism pur, sans mélange, cru, vert, dans toute sa force, dans toute
  son âpreté, is superhuman, divine, transcendental, it will never be achieved by
  man, at most approximated.


Nietzsche WP 304


  Macchiavell ... [ist einer der] ... Grossen Moral-Philosophen


Nietzsche, Nachlass 1888


  ‘Machiavellism of power’ [as a] love of humanity


Nietzsche WP 776


  [As Machiavelli says] the ‘form of government is of very little importance;
  although the half-educated think otherwise. The great goal of statesmanship
  should be duration, which outweighs everything else because it is far more
  valuable than freedom.’


Nietzsche HH V. 224 108


  Thucydides and perhaps Machiavelli’s Principe are most closely related to me
  by the unconditional will not to gull oneself and to see reason in reality—not in
  “reason,” still less in “morality.”


Nietzsche, TI 558


  [W]hen reformers indulge in politics, as Luther did, one sees that they are just
  as much followers of Machiavelli as any immoralist or tyrant.


Nietzsche WP 211


  We can start by pointing out
  (without claiming that this is the essence of their relationship) that he makes
  direct reference to him in eight passages of his published work and in nineteen
  of his unpublished notes.21 In all of these, he is portrayed as among Nietzsche’s
  most important influences.
  
  21. Once in HH, BGE, TI, GS and four times in WP, even though Nietzsche did not
  publish this last text. The Intelex© database of the Nietzsche Werke Kritische Gesamtaugabe was also used for review of the notes. The terms Machiavelli,
  Machiavellianism, and The Prince were the foci.


http://www-polisci.tamu.edu/upload_images/88/ArtofPowerChapter3.pdf Nietzsche’s Machiavellism

NB: I'm wildly guessing that it (the linked pdf) is part of http://www.goodreads.com/book/show/2251467.The_Art_of_Power von Vacano's The Art of Power, but perhaps somebody else may confirm that... Ah, I just confirmed that myself.



Edit. Now, if this indeed answers your question, I feel sort of at liberty to also provide http://lmgtfy.com/?q=nietzsche+machiavelli&l=1 this link. :)
"Existence" can mean very different things, but there's a tradition to include everything (sometimes even inconceviable things) in (any) logic's domain. 

It is then natural to create predicates for various meanings of "exists", and this predicates would verify different "things" at different worlds (i.e. Pink(pink_unicorn), []Pink(pink_unicorn), <>Pink(pink_unicorn), but ~PhysicallyExists(pink_unicorn) and <>PhysicallyExists(pink_unicorn))
The question of free will certainly is important, especially when one considers the implications in situations of "moral luck". It may be argued that freedom does not allow moral decision making, but can the opposite be true? It would seem strange to suggest that freedom, somehow requires moral oughts to exist, considering how oughts are distinct from facts.

Compatibilists claim determinism can be reconciled with free will, or as Schopenhauer said: 
"Man can will as he wills but cannot will what he wills." Compatibilists contend that even if determinism were true, it would still be possible for us to have free will. Thus someone can be held morally responsible for their pre-determined actions.

Before discussing moral "oughts", it is certainly worth noting the is-ought distinction that Hume famously made in terms of objective morality, emotions must be separated from moral oughts. Nihilists believe these oughts do not exist, this does prevent them having a personal subjective preference to one behaviour or another.

Returning to your question; just because one can make free decisions, does that mean there is a way in which one ought to act? It appears that the two parts of these questions are mutually exclusive. 
That world exists, it's ours.

Firstly, I haven't found any definition of primary and secondary attributes. I'll suppose that a secondary attribute can vary while the object doesn't and primary attributes do modify the object.

But I see some misconceptions, in Special Relativity heating the cabbage will increase its mass (if you suppose that there is not loss of atoms).

The other problem is that when you see an object through a glass, you're modifying how you see its color. So it should be compared to measuring the object's weight while you are pushing the scale, its mass (color) remains the same but not what you measure (see).

It's mostly a matter of semantics. Why do you say it's a cabbage, since it's chemical composition has changed?  

If you try to find some primary attributes I think that they should be in elementary particles. But if String Theory is correct, then they would just depend on the string's frecuency.

So I think it's quite difficult to distinguish between primary and secondary attributes (at least with the examples you gave).
When we say that the universe "sprang into existence from the void", we don't mean that there was some void-thing or void-place there before spacetime from which the universe emerged. We mean that there wasn't anything yet before certain point, i.e. there was neither anywhere/anywhen for the laws of physics to hold "in" yet, nor anything for them to hold about. 
There's a paragraph that, if the book is to be summarized, seems to summarize it well (and is a favorite of Russ Roberts, who recently wrote a book about Adam Smith):


  Man naturally desires, not only to be loved, but to be lovely; or to be that thing which is the natural and proper object of love. He naturally dreads, not only to be hated, but to be hateful; or to be that thing which is the natural and proper object of hatred. He desires, not only praise, but praiseworthiness; or to be that thing which, though it should be praised by nobody, is, however, the natural and proper object of praise. He dreads, not only blame, but blameworthiness; or to be that thing which, though, it should be blamed by nobody, is, however, the natural and proper object of blame.


So, as jobermark pointed out, one should never reduce anyone to a caricature. However, the question from the OP seems to be, in what ways do that caricature fail to explain who Smith is? From the Theory of Moral Sentiments, one can conclude that Smith was not in favor of a cut-throat, profit-at-all-costs existence of society. Rather, Smith acknowledged these two sometimes competing, sometimes cooperating urges that each person has: to benefit one's self and to benefit others one interacts with.

I haven't read enough Smith to know this for a fact, but I know many philosophers since have concluded (based on Smith and based on other independent sources) that the appropriate mechanism for a society is a free-market capitalism in which people are bound by some idea of virtue (treating others with respect, worrying about reputation, etc.).

  Whitehead argues we have no grounds for claiming anything more than that temporal and spatial relations are contingent. They are the modes of division in our immediate epoch--i.e. not the whole cosmic epoch, which impose conditions on the metaphysical description of the present


This is exactly what is proposed by what in physics are called effective theories - they specify a range of experience (energies) at which their description is expected to be effective - that is give good predictions. To quote from the paper Introduction to the Effective Field Theory description of Gravity by Donaghue:, 


  The key point of eﬀective ﬁeld theory is the separation of known physics
  at the scale that we are working from unknown physics at much higher energies. Experience has shown that as we go to higher energies, new degrees
  of freedom and new interactions come into play. We have no reason to suspect that the eﬀects of our present theory are the whole story at the highest
  energies.


Highest energies means equivalently probing structures at the deepest levels of divisibility. If space & time are emergent features at the plank scale, one may ask what are exactly its constituent pieces, a fragment of space seems possible, but what is a fragment of time? Can fragments of time divide or perhaps assume new shapes? Perhaps a fragment of time has several directions of time. Perhaps a fragment of time is no time - like a fragment of a door is not a door but something else entirely. What is to say there is no new physics beyond the plank scale? Inductive experience surely veers towards asserting that this will be the case. We are far far from probing this regime. It may be millenia before we can, or perhaps never. 

This is what gives us the space for speculative metaphysics, and/or speculative physics. 


  The insistence upon necessity prevalent in popular science is the kind of dogmatism Whitehead insists philosophers, especially scientists, should resist.


This neccessity was not apparent in the early physics of the greek atomists by positing the clinamen as the irreducible element of free will. The emphasis on this surely in modern science is due to the success of Newtonian physics and the determinism built into its fabric and remained there for the next three centuries which probably accounts for its longevity in the popular imagination.  Enough, that Einstein wanted to reduce the new ontological indeterminancy to simple epistemological indeterminancy. Enough, that serious physicists, such as Arkani-Ahmed in a public lecture can state with all sincerity that 'there were no choices' in the formulation of the Higgs.


  if the order of nature can change within our cosmic epoch (e.g. laws of nature evolve) then what grounds do we have for adopting the reductionist thinking which says that the conditions of our immediate order holds for all orders?


We don't. This is why we have the speculative physics of string theory, the multiverse. One can really only expect these speculative challenges to increase and multiply in the future as we increasingly become aware of the low energy levels we can probe with.  

  “If Frenkel is only interested in money why would he leave a position that pays him 20 to 30 times the salary to be Bank of Israel Governor?”


In this form, I don't think there is a fallacy necessarily. They ask why he would leave his old position that pays him so much more for his new position, which seems to be a genuine question to me.


  A candidate can be corrupt for other reasons, like the desire to gain power and influence.


That is true, but the quote specifically says "if he is only interested in money", it does not say "if he is corrupt". It is thus not a fallacy for that reason.

However, it could be interpreted as: "(A) He leaves a position that pays more, thus (B) he is not only interested in money."

While A is true, we are not sure whether B is true. It does not follow from A that B is true, since leaving a high-paying job is not a sufficient condition for not being interested in money, as you correctly pointed out. This is an example of a https://en.wikipedia.org/wiki/Non_sequitur_%28logic%29 non sequitur.
Anything with "post-" in the title will be considered "continental". Speculative Realism or Object-Oriented Ontology is also a "continental" approach. This is true even though the practitioners of both are found in North America as well as in Europe; the "continental" term has increasingly lost its geographic referent.
Four names, from the Austrian school itself, that come to mind as critics of Mises' Praxeology are Murray Rothbard, Izrael Kirzner, F.A. Hayek and Ludwig Lachmann.

You should be able to find references to these four gentlemen (and others) in https://direct.mises.org/rothbard/praxeology.pdf this PDF. critiques are mentioned and responded to in various footnotes.
If your definition of revolution is conflict between classes, then a hypothetical ideal communist society would be classless, so the notion of revolution would be meaningless.  Of course, actual regimes which call themselves communist are generally saying that they subscribe to Marx's ideology and that their (ostensible) goal is to achieve Marx's ideal communist society, not that their society at the present has attained that status yet.  For one thing, Marx envisioned a stateless utopia, whereas those countries have governments and thus have a political class, so insofar as there is still class distinction in those countries, you could still have a revolution in your sense.
Think of science more like a cycle. Or rather a linear workflow is never ending and wraps in on itself. In order there is:


observation - recording what seems to occur
description - labeling and naming the things observed
hypothesis making - theorizing connections or implications among the definitions
hypothesis testing - experimentation, trying out the implications
reassessment - when the hypotheses don't completely match up with the observations, go back and fix the definitions or theories.


This is neither normative nor descriptive of the process of science, just an explanation of one possible thread of activity where one task follows another logically. But of course such a linear ordering of these stages never happen in practice so orderly. Just observation depends on your expectations which are driven by theories. And this may go in a big cycle or in many small cycles simultaneously or overlapping in parallel.

Also, 
First, what is described in the question as Popper's solution, is not his solution, but his formulation of the problem. That is, the problem of induction. In essence, Popper fully accepted David Hume's presentation of the problem of induction. Yet Popper rejected Hume's psychological solution to the problem, and offered a solution of his own, involving the method of refutation.


  I approached the problem of induction through Hume. Hume, I felt, was perfectly right in pointing out that induction cannot be logically justified...
  
  I found Hume's refutation of inductive inference clear and conclusive. But I felt completely dissatisfied with his psychological explanation of induction in terms of custom or habit.
  (Popper, "http://philosophyfaculty.ucsd.edu/faculty/rarneson/Courses/popperphil1.pdf Conjectures and Refutations")


Second, Quine's criticism of the analytic / synthetic distinction does not seem to me to touch Popper's formulation. Quine's argument amounts to the result, that a statement that seems synthetically true today may seem analytically true tomorrow, and false next week. But since Popper's formulation covers all the analytic / synthetic combinations, it wouldn't matter for the argument if the principle of induction changes between analytic and synthetic, as Quine allows.

Therefore, to the extent that Popper's formulation was valid before, it is still valid.
I apologize for the change of notation, but it will simplify things in the long run. Consider sentences (1-6):


╔════════════╦══════════════╗
║ (1) x=x    ║ (4) Hx->M    ║
║ (2) ∃x:x=x ║ (5) ∃x:Hx->M ║
║ (3) ∀x:x=x ║ (6) ∀x:Hx->M ║
╚════════════╩══════════════╝


Notice the difference between the columns: in the first the sentential function is "x = x", in the second it is "if x happens, I will get mad" ("Hx -> M"). Briefly, some informal definitions:


  Sentential functions are functions which, when their arguments are supplied, return a declarative sentence. Declarative sentences are expressions that can be given truth-conditions and thus can be evaluated to true or false.


Let g(x) denote "x = x", and h(x) denote "if x happens, I will get mad" ("Hx -> M"), to obtain:


╔═════════════╦═════════════╗
║ (1) g(x)    ║ (4) h(x)    ║
║ (2) ∃x:g(x) ║ (5) ∃x:h(x) ║
║ (3) ∀x:g(x) ║ (6) ∀x:h(x) ║
╚═════════════╩═════════════╝


This table is just to show how formally similar (1-3) and (4-6) are. Now let's get to the problems.


  Claim 1. (1-3) are all equally true.


Expression (1) cannot be true, because it's a sentential function; sentential functions don't have truth-conditions (see the definition above). Sentence (3) says that everything is self-identical, so it's pretty uncontroversially true. Sentence (2) says that there exists something which is self-identical. In order for (2) to be true, at least one thing has to exist, while (3) is true for even empty domains. 

In sum: (1) has no truth-conditions, (2) is true in all non-empty domains, and (3) is true in all domains.


  Claim 2. (5 & 6) have different truth-conditions.


Exactly! For the same reason (2 & 3) have different truth-conditions.


  Question. What's the difference between (4 & 5)?


As I said in my response to your first claim: (1) has no truth-conditions. The same is true for (4); it too has no truth-conditions. (5), like (2), however, does have truth-conditions: (5) is true if and only if: there exists some x such that either: x is not happening or you're getting mad.

Hope that makes things a little clearer. 
Evil only exists as a view point of a specific perceiver. It has no objective reality. For example: if a scientist developed a virus that when released killed 90% of humans, we would call that evil. However, from the view of other mammals this would be a good as it would keep many from extinction.
I don't have the two texts here in front of me, so I can't be sure without checking context, but I think in this case they are just both being a little sloppy logically speaking and writing what are technically open sentences where they should strictly speaking be a couple more quantifiers. Think of it as equivalent to mathematicians "skipping a step" when they write out a long complicated proof a few steps of which are obvious.
Since (daftly) we have no LaTeX capability here, use Nec for the box, and Poss for the diamond.

By 2, Nec not-p --> not-p, so contraposing (assuming classical negation), p --> not-(Nec not-p), i.e. we get 3. So really you've given us just one rule, 2, plus a rule of definitional abbreviation. So the modal system is jolly uninteresting. 

And this one rule is plainly not appropriate if the modality is interpreted as deontic necessity. It may be that p ought deontically to be the case; it sadly doesn't follow that p is the case.

So you've got an uninterestingly trivial system, which in any case can't be interpreted deontically. Back to the drawing board!

Or check out http://plato.stanford.edu/entries/logic-deontic/ http://plato.stanford.edu/entries/logic-deontic/ for more guidance.
It depends, we cannot generalize all types of problems to that. There are also many different definitions for problems, some of them http://en.wikipedia.org/wiki/Problem listed on wikipedia.

People usually speak about problems when there is some discrepancy between how reality is and how they would like reality to be. This is the definition that wikipedia lists for bussiness or engineering.

So if we take this as the definition of problem then indeed there would be no problems without anyone wishing reality to be in a different way. That doesn't solve any problem (that doesn't transform reality) that simply eliminates the problems.

Say for example you are thirsty, drinking some water would solve that problem, for a while, until you are thirsty again. Suicide would eliminate the problem (and some others) for ever for you, but it doesn't really solve anything.

Now, this is not part of the question, but:

Problems seem to be bad, which means solving them would be good and eliminating them would be equally good. However people like solving problems, to some extent games provide artificial problems and people enjoy solving them. The brain produces chemicals as a reward for solving some problem, therefore problems are good as means to get to solutions, which are rewarding.

Eliminating problems by changing your mind isn't as rewarding as solving problems, although eliminating a problem could be a solution for a meta-problem.
Another quick, maybe too quick, comment (or series of comments.) My first impulse, perhaps just an atmospheric tangent, would be to look into certain parts of the Grundrisse, in particular the fragment on machines. He talks about the way in which the machine isn't introduced to make labor easier but rather to intensify and extend it, to latch it onto accelerating and alien rhythms. He also makes an interesting remark there about invention having lost its scientific purity and becoming a business.

In other words, this is the kernel of Marxism insofar as it is generally refracted through an ethical humanism of the common: improving man's (humanity-in-person's) condition in the world by abolishing the exploitation of labor. But thinking is also labor; and today we face both simulation and automation. Marx's machines above involve all the ways capitalism captures us; including even the factories of knowledge, the discourses and disciplinary institutions associated with science. Automation and simulation express capitalism's devaluation not only of our bodies and labor but even our thoughts and the very image of thought.
Humans are always trying to gain as much control over the world and its resources as they can.  We are always obsessed with science and engineering in order to gain knowledge of our world, so that we can control it even further.  We even have social sciences to attempt to control our own species.

Humans will take any opportunity they can to gain more control over their natural environment, and other humans who form part of the environment are no exception.  If a human can control another human with limited repercussions, he will attempt to do so, either subtly or through a formal institution.

Because all humans are not made equal (I do not mean this as an ethical statement about human rights, but about the human genome), they will naturally compete for control of each other, and there will be a victor.  The victor will naturally dominate the others, simply because he can - and humans will never pass up an opportunity for further control of their available resources.
Randomness and causation are in different categories. Something can be both random and caused, or random and uncaused (if you believe in such things). Randomness is not a property of origin (cause) but of comprehension (understanding the origin).

Random can mean simply "unpredictable", or "of or characterizing a process of selection in which each item of a set has an equal probability of being chosen." The roll of a die is sufficiently complex such that the outcome is effectively random, but that doesn't mean the outcome was uncaused. It just means the cause was not reasonably predictable with human faculties alone.

EDIT: Response to the updated question
I see how you are defining randomness now, but I can't conceive of any examples in practice because I can't conceive of a universe in which such randomness exists. Radioactive decay is, in my opinion, only stochastic because our science hasn't figured the causal chain yet. I hold that this is more likely than the opposite case because we already have innumerable examples of causation and non-randomness yet we have no examples of the latter. Occam's razor compels me to chose the one that rests upon the least new assumptions.

That said, I can vaguely conceive of a world like you describe. In this world, for something to be truly random, it cannot be part of any causal chain. This suggests to me the answer to your question is yes, ontologically random events are causeless. But this is all very counter-intuitive; we tend to not like the idea that something can come from nothing...
Ackermann's Rule Gamma is the rule that from "├── A->B" and "├── A", one may infer "├── B," where "->" denotes the material conditional. (Equivalently, from "├── ~A V B" and "├── A", infer "├── B.")

Note that this is distinct from modus ponens or disjunctive syllogism; this is the rule that if ~A V B is a theorem and A is a theorem then B, too, is a theorem. Such a distinction is clear in, e.g., Rule Necessitation in modal logics; from "├── A," infer "├── L A," where "L" denotes necessity. This clearly doesn't mean that a theory is closed under necessitation, merely that all theorems are necessary.
Nothingness has no dimensions, no properties. We cannot say that it is red, or it is warm, or it is anything, because it is nothing, it is not. Nothingness doesn't be. AFAIK, this is how we define this always fictional no-thing since the times of Aristotle, although he didn't use English (obviously).

Logically we can conclude that if nothingness doesn't be, for this to happen or to prevent this from happening then something must be. But I have to admit I'm a bit confused here. I did actually post https://philosophy.stackexchange.com/questions/8251/nothingness-cannot-be-does-that-imply-something-must-be another question.
My answer is tangential to your question because it adresses Weber's key concept of rationalization rather than his views of rationality in general. So see for yourself if it is helpful. But, to my best knowledge, rationalization for Weber is a more or less global process, increasingly taking hold of all social relations. And if so, then there is only one form of rationality for him, unlike, for example, for some poststructuralist thinkers, who would later speak of many (historically contingent) rationalit ies. 

Weber characterizes the world we live in as subject to a process of increasing rationalization. Its objective is to master the social and physical environment by using various methods of calculation (e.g. scientific rationality) and control (e.g. bureaucracy). In other words, rationalization is concerned with the production of 'efficient' forms of social organization.

You are right to point out that rationalization has taken a life on its own, but I think it is incorrect, inasmuch as we are talking about Weber at least, to say that "People rationalize for the sake of rationalization, not for greater efficiency or utility." The logic of rationalization is to increase efficiency and utility. For Weber, the problem with rationalization lies elsewhere.

Rationalization should not be conflated with progress. The increased mastery of nature and culture, for Weber, is not the same as a better understanding of life. Instrumental reason makes a processes more 'efficient' but it is blind to the realm of values: do we need this process to begin with? Weapons of mass destruction or iPods are getting smaller, cheaper, more efficient and more precise. But are they good for us? Rationalization is not in the business of addressing such questions. It creates, as it were, a blind spot on the surface of life: it constantly promises a better life in the future but its every advance is just more of the same. Paradoxically, then, an increase in rationalization is also in a certain sense irrational: the quest for human happiness is replaced by a never ending race to make things more efficient. Rationalization, for Weber, leads to a certain disenchantment with the world. 
There is a straightforward terminological clarification here, and then a much richer philosophical problem beneath it.

An "agent" in this sense is someone who does things. It derives from the Latin word "ago" which means "(I) do." Romans used it as their general "doing" verb for a wide range of activities. Our word "agenda" comes from the same word, and literally means "things that ought to be done." A secret agent is just someone who does things secretly.

A "moral agent" is therefore someone (or something) capable of doing things rightly or wrongly. Typically, this is understood to mean acting with the ability to freely choose (within parameters) what to do. It sometimes also includes the idea of being aware of the concepts of rightness and wrongness, or of what actions are considered right and wrong.

"Agency" is simply the capacity to be an agent, which means the capacity to do things. We see the same relationship between the words "regent" (a monarch) and "regency" (the commission to serve as a monarch or status of being a regent). Moral agency is the capacity to act as an agent. It's something that every moral agent has by virtue of being one.

Once you get the definitions sorted out, I don't think there's anything puzzling there. However, embedded in your question is a challenging question about who or what does the causing when a person acts. Does a person cause his/her actions? Is there some sense in which his/her agency could itself be the cause? This slides us into the longstanding problem of mental causation. It's the problem of how a mind (which seems at first glance to be a non-physical thing known to us through our conscious experiences, thoughts, and feelings) could ever serve as a cause of physical things like our picking up a rock and throwing it. It's very difficult to figure out what could be doing the causing when an agent acts. Given your interest, you may want to http://plato.stanford.edu/entries/mental-causation/ read more about mental causation.
I do not agree. Parmenides did not understand thinking as entirely divorced from being the way most of us do today. The use of the word "imagine" (above) illustrates the distance we've come since Socrates. If we were to compare Parmenides to any "modern" philosopher, I'd probably pick Kant, not Berkeley. Check out www.aletheia.ws/parmenides for a group of essays that address these issues in a more systematic way.

  [S]uppose you know for a fact exactly what someone's actual goals and desires are, and then you observe them doing a certain action. Then which is more likely to be the reason why they did the action:
  
      A) their self-reported reason for doing the action, or
      B) because it was the rational thing to do, given their goals and circumstances?
  
  Even if you think that both A and B have low probabilities of being right, which one has a higher probability of being right?


The better explanation is B), for http://www.faculty.ucr.edu/~eschwitz/SchwitzAbs/Naive.htm people are naturally terrible at introspection, but http://en.wikipedia.org/wiki/Predictably_Irrational predictable if you can model them well. You have presumed that we know the modeling parameters—"you know for a fact exactly what someone's actual goals and desires are"—and we know that there exists ways to predict how people will operate. The secret comes from the term http://en.wikipedia.org/wiki/Predictably_Irrational "Predictably Irrational", which is also a book title: we must be rational not according to a person's

    (1) "self-reported reason",

but instead his/her

    (2) "actual goals and desires".

In some sense, this seems like it will be a dissatisfying answer to your question, because it is not clear how well we can actually measure (2). It is not clear we can ever know a person's actual "goals and desires". If our options are instead,


      A) their self-reported reason for doing the action, or
      B') [the best obtainable model of] their goals and circumstances


, I would still choose B'), on the basis that people tend to be worse observers of themselves than others are of them. There remains a weakness in this model, though. It assumes that we can model people well, which may not hold for all personality types. For example, we were terrible at understanding Autism for a long time, and are only still just learning how to productively interact with severely autistic people. It could be the case that in interacting with severely autistic people, A) would be better.



Keeping my response to the original form of the question: I would rate two of the claims in your question as highly dubious.


  1. "Introspection is a good guide to human motivations,


In his 2008 http://www.faculty.ucr.edu/~eschwitz/SchwitzAbs/Naive.htm The Unreliability of Naive Introspection, Eric Schwitzgebel says:


  We are prone to gross error, even in favorable circumstances of extended reflection, about our own ongoing conscious experience, our current phenomenology.  Even in this apparently privileged domain, our self-knowledge is faulty and untrustworthy.  We are not simply fallible at the margins but broadly inept.  Examples highlighted in this essay include: emotional experience (for example, is it entirely bodily; does joy have a common, distinctive phenomenological core?), peripheral vision (how broad and stable is the region of visual clarity?), and the phenomenology of thought (does it have a distinctive phenomenology, beyond just imagery and feelings?).  Cartesian skeptical scenarios undermine knowledge of ongoing conscious experience as well as knowledge of the outside world.  Infallible judgments about ongoing mental states are simply banal cases of self-fulfillment.  Philosophical foundationalism supposing that we infer an external world from secure knowledge of our own consciousness is almost exactly backward.


The second is like it:


  2. "Rationality is a good way to explain human behavior.


See the book http://en.wikipedia.org/wiki/Predictably_Irrational Predictably Irrational: The Hidden Forces That Shape Our Decisions:


  My goal, by the end of this book, is to help you fundamentally rethink what makes you and the people around you tick. I hope to lead you there by presenting a wide range of scientific experiments, findings, and anecdotes that are in many cases quite amusing. Once you see how systematic certain mistakes are--how we repeat them again and again--I think you will begin to learn how to avoid some of them




Fortunately, neither of these claims need to be true in order for either answer to be plausible. This is because:


A person's inability to accurately self-report beliefs does not mean he/she does not have beliefs, and nor does it mean that he/she cannot be well-modeled as having beliefs.
Predictability does not require rationality.


This is good news to philosophers, who have a history of knowing that it takes a while to think in a properly philosophical manner. [citation needed] I'm sorry, I just had to say it that way. :-)
The dominant ideology of the Republican Party is known as American conservatism, and it was developed by William F. Buckley and his magazine National Review starting in the 1950's.  The http://www.nationalreview.com/articles/223549/our-mission-statement/william-f-buckley-jr founding mission statement of National Review (see "The Magazine's Credenda" at the end) is a good elucidation of this philosophy.  It is formed from two strands: 


Traditionalism, http://en.wikipedia.org/wiki/Traditionalist_conservatism the philosophy of Edmund Burke which states that there is great wisdom embedded in our social institutions and culture, so we should be careful before we try to tamper with them
Libertarianism, http://en.wikipedia.org/wiki/Classical_liberalism the philosophy of John Locke which says that people have fundamental http://en.wikipedia.org/wiki/Negative_and_positive_rights negative rights that the government should not infringe


There are two principles that unite these two philosophies:

A.  The belief enunciated by Hayek (in his essay http://www.cato.org/sites/cato.org/files/articles/hayek-why-i-am-not-conservative.pdf "Why I am not a conservative", which despite its title was one of the driving forces behind the development of modern conservatism) that in the Anglo-American context, traditionalism is a fundamentally libertarian impulse, because America at its beginning was founded on the idea of liberty (and to some extent England was too if you consider the Magna Carta), so if you try to preserve the institutions and spirit that America had at its founding, then you'll inevitably end up preserving liberty.

B.  Fusionism, http://en.wikipedia.org/wiki/Frank_Meyer_%28political_philosopher%29#Freedom_and_tradition the belief enunciated by Frank Meyer in his book http://rads.stackoverflow.com/amzn/click/0865971404 Defense of Freedom, that the promotion of virtue in society, which is the goal of traditionalism, is best achieved by promoting freedom, because if you're forced to be virtuous then your acts are not truly virtuous because you're not the one responsible, so in order to have true virtue we need to allow people to freely choose whether to be virtuous or not.

Those two beliefs are what made people believe that traditionalism and libertarianism depend inexorably on one another, and's what gave rise to the ideology that we call American conservatism.  Of course, this is all just abstract political theory, but in 1964 it finally became a powerful enough force in the Republican party that they chose a conservative to be the Republican nominee for President, Barry Goldwater, who suffered such a profound defeat in the election that Republicans didn't nominate another conservative until Ronald Reagan in 1980.  And conservatives have dominated the party ever since.

Also, I should mention that there have been two changes to conservatism since its founding by National Review: conservatives have become more interventionist on foreign policy (because they see it as the best way of ensuring that liberty and the American way of life are preserved), and they've also become more accepting of the fact that the welfare state exists (they've come to the conclusion that it's a losing battle to keep trying to abolish Social Security and Medicare, so they advocate more modest changes like benefit cuts and privatization).  To reflect these two changes, associated with Irving Kristol and his followers, people often refer to the current ideology of the Republican party as "neoconservatism" rather than just "conservatism".
Yes perfectly random bits would violate the unproven theorem paradox because even if it changed nothing else about the time line it would no longer be random the second loop. The randomness itself is a self inconsistent event. How can we ever have a ONE time pad that loops throughout time way more than one time.

Furthermore the paradox will always remain whenever you create something and send it back in time regardless of the way in witch way the information gets sent back. Trying to cheat by converting in and out of randomness in no way changes anything about the general thrust of this HYPOTHETICAL paradox.

This being said. If you want to treat time travel scientifically there could always be some quantum mechanics principle that allows for your theory to work. You also mentioned parallel worlds witch easily reason away from the problem. If we could test around with this stuff I'm sure we could figure something out but in the meantime just pop on back to the future and consider how cheating with the almanac worked out for Biff in the end.
Yes it has. The answer is simple: Because it is logical.

Assume we don't act morally. According to Kant, that would create contradiction with who we are. With who we are, I mean people and Kant's practical imperative says "So act as to treat humanity, both in your own person, and in the person of every other, always at the same time as an end, never simply as a means." We can simplify Kant's idea as humans are valuable because they are humans, then acting immorally would contradict this value as immoral behaviours insult the people. Then, acting morally is logical where acting immorally is contradictory.
This does not appear to be a kōan at all, but merely a story.

The moral of the story is clear, but if you would like it spelled out, the master is saying (through his actions) that it is time for the disciple to stop following the master around, but to go off and learn on his own.
Interpreting Wittgenstein, especially the Wittgenstein of the Tractatus is always a fraught affair. There is no single, definitive reading of this text, and whatever one says about it is liable to be contradicted by someone else. So what I offer here is not the answer, but I hope it is, at least, an answer.

You write, following proposition 6.373, "And thus the limits of the world cannot change." This seems to me to be precisely wrong or, more exactly, meaningless. The limits of the world are precisely the point whereof one cannot speak (propositions can only express facts; hence, the limits of my language means the limits of my world; what lies beyond the limits of the world cannot be spoken of---it is beyond what language is capable of saying). Thus, we get to this:


  6.41 The sense of the world must lie outside the world.


These limits are outside of the world, and thus outside of the possibility of proposition. They can be shown, but not said, not put into a propositional form, for every proposition concerns the world, that is, concerns facts (e.g., 4.1 "A proposition presents the existence and non-existence of atomic facts." [alternatively Sachverhalte is rendered "states of affairs" rather than "atomic facts"]) and what can be made into a proposition is therefore itself a fact.

The contents of the world, in a certain sense, cannot change; the world is only facts. I do not mean to imply that change is impossible; merely that "the world" for Wittgenstein does not expand and contract: it is always the totality of facts. Yet this says nothing about the limits of the world, just as from inside a windowless room, I can say nothing about what the room is like from the outside. Nevertheless that there are limits can be shown, even if not through propositions (for any limit which can be rendered as a proposition is therefore a fact and therefore a part of the world rather than its limit).

So, then, what is it that might lie beyond the limits of the world? There are, I think, at least three important examples Wittgenstein gives in the Tractatus: logical form (see esp. 4.12), ethics (6.421), and the subject (5.632). It is in the discussion surrounding this last point (i.e. the discussion of solipsism from 5.63-5.641) that we find what might be most relevant for understanding why the world of the happy man might be different from that of the unhappy man. Thus, we find the very pregnant comment in 5.63:


  5.63 I am my world. (The microcosm.)


To which he further comments:


  5.634 This is connected with the fact that no part of our experience is at the same time
  a priori.
  
  Whatever we see could be other than it is.
  
  Whatever we can describe at all could be other than it is.
  
  There is no a priori order of things.


To offer a fairly bold interpretation of this: the world can appear differently to each subject, even though they are presented with the same collection of facts. The subject is the limit of the world (5.632 again), meaning that the subject is transcendental to the world. The subject is an ordering function for the world; it brings together the facts and shows their connections, yet it is no part of the world (5.633). This is what it means to be a limit of the world: to give the world its shape.

And hence we arrive at an interpretation of the sentence in question: it is not that the world of the happy man is some different set of facts from that of the unhappy man; it is rather that the world has a different shape, a different form, a different connection of facts. There is nothing in the world itself which gives it is sense, rather its sense is given from outside the world. Facts in the world do not by themselves "make" someone happy or unhappy. Rather it is almost the other way round: how the facts appear depends on the sense which lies beyond the limits of the world. It is a different world, but only because its limits have changed (and here its important to note that when Wittgenstein speaks of the world waxing and waning it is always the world as a whole which is capable of this---the facts remain untouched by the limits of the world, yet the connection between them, their order, changes).

What might this look like? Suppose you and I were to go to an old medieval church (and I use this only as an example---I have no idea of your aesthetic tastes). To you, perhaps, the decorations, the scale and placement of the altar, the lectern and the pulpit bespeak a sense of wonder and majesty. To me, perhaps, the very same conditions seem cramped and confined, stale and musty, a building setup for a time and purpose that has long since passed. The same building can appear to us as something completely different---and yet this difference does not lie in its arrangement, in the facts about the placement of the various furnishing, in the measurable properties of the building itself. It is something else. And thus we come to what is perhaps one of the most famous sentences of the Tractatus:


  6.52 We feel that even when all possible scientific questions have been answered, the problems of life remain completely untouched. Of course there are then no questions left, and this itself is the answer.

So far as I know, only fictional societies have existed without some assumption of free will, e.g. Huxley's  Brave New World, or Skinner's  Walden II.


  Could a society exist that didn't take that assumption of free will?


Sure. But only if reality actually conforms to that assumption, that is, if man really does not have free will. In that case, even if a prescribed 'punishment' were seen as inevitable consequences of 'immorality', the repercussions would not be considered as punishment, but perhaps more in the light of training, as in Skinner's Walden II. In such a deterministic worldview, the individual does not have a choice as to whether s/he actually does something, any more than they can escape the consequences of the action. Although theoretically it would be possible to have a society in which no one is punished (directly or indirectly) for their actions, I know of none that conforms to those specifications.
I don't know why you've titled the difference as being about "mysticism". To put it simply, Marx is not a very good interpreter of Hegel (for the take of another Hegel scholar see https://books.google.co.jp/books?id=sC1ZdEiKsmoC&pg=PA20&lpg=PA20&dq=but%20since%20i%20think%20that%20the%20technical%20elaborations%20of%20Hegel%27s%20dialectic%20are%20fanciful&source=bl&ots=8NBkuH_Q6V&sig=0Qinhp2xXZ7DBtknwYWOA5YR47E&hl=en&sa=X&ved=0ahUKEwjex5jMpqjKAhXCXaYKHRzcAo8Q6AEIGzAA#v=onepage&q=but%20since%20i%20think%20that%20the%20technical%20elaborations%20of%20Hegel's%20dialectic%20are%20fanciful&f=false Dudley Knowles, Routledge Guide to Hegel and the Philosophy of Right , p. 20). So Marx critiques what turns out to be a fundamental feature of Hegel's philosophy which demonstrates how badly he's misunderstood the dialectic.

For Hegel, there are three different approaches to truth: art, religion, and philosophy. Skipping over quite a bit of the Phenomenology and moving towards the ending, what turns out to be the case is that each of these three can give access to that which is in and of itself (i.e.  Truth) and the means through which truth is accessible is either through imagery (art), through faith (religion), or through knowledge (philosophy). In other words, ideal art is right about what it represents, ideal religion is right about what it believes, and ideal philosophy is right about what it comprehends.This sort of triadic structure is common in Hegel's philosophy and is called dialectic. There's actually multiple forms in the text itself (but we needn't understand that to understand this point). The think that engages in all of this is for Hegel Geist -- rendered in English classically as "Spirit" and more recently as "Mind". Thus for Hegel, religion and thinking of God is not wrong but is second to philosophy.

What causes Marx to disagree with this account? Marx wants to keep a dialectic but does not understand humans as thinkers. Instead, he views the dynamic in terms of capital and how it causes relationships. Thus, his view is called dialectical materialism -- whereas Hegel is dialectical but not a materialist.

Where this matters for the case of slavery is in Hegel's classic Master-Slave dialectic (probably better rendered as "lordship and bondage"). It's a commonly referenced but misunderstood passage and subject to multiple interpretations. On the simplest level, Hegel is making the following points:
(1) the master does control the slave physically
(2) but "master" and "slave" are social identities
(3) the "slave" is made a slave by the master's consciousness and subjugation of the person socially.
(4) thus, the master ultimately depends on the slave for recognition as a master as well.

Hegel's point is that while the master controls the slave "master" and "slave" are identities that are mutually dependent on recognition. (Hegel will later draw this into society by pointing out that the identities of selves depend on each other and society). Thus, for Hegel, the slave can be freer than the master in terms of Spirit because the slave's thoughts are free whereas the master's body is free.

Marx's dialectic does not engage in terms of "Spirit" (i.e. consciousness), so he just sees that the master is getting more use out of the slave than vice-versa on a material level.

  According to Bergson, there are two kinds of time, homogeneous and
  heterogeneous. The latter is the time of our experience, and is named
  by him 'la durée,' to which no English expression exactly
  corresponds. Homogeneous time, which is what we ordinarily mean when
  we use the word time, is, in his view, space, on to which the mind
  merely projects psychological time, the succession of our conscious
  states, thus making it appear to be a successive and continuous
  reality. In fact, it is nothing but an illusion for there is no true
  succession in things which are said to be measured by time, since one
  state has entirely disappeared when another appears. So he writes : '
  Doubtless exterior things change, but their moments only succeed one
  another with respect to a consciousness which remembers them. We
  observe outside us, at any given moment, a collection of simultaneous
  positions ; nothing remains of the former simultaneities.' [http://www.worldcat.org/title/essai-sur-les-donnes-immediates-de-la-conscience/oclc/255701998 Essai sur
  les donnes de la conscience, p. 173.]
  
  Hence, the only time which is not illusory, and which he regards as
  real, is the heterogeneous time, or succession, which accompanies the
  development of our conscious states. Such development is purely
  qualitative, and its parts can only be qualitatively, never
  quantitatively, distinguished, so that they are absolutely
  heterogeneous; for it is clear that all our psychic acts are
  unextended — it is impossible to have a yard of thought — and so if
  distinct their distinction can be qualitative only.
  
  There can be no question as to the subjective character of this
  theory; and to make of time an affection of our conscious states is to
  contradict completely the commonsense notion of it, which undoubtedly
  attaches it to bodies. What is more, it is only the permanent which
  changes, and the permanent endures: so that it is inconsistent to
  admit that things change and to deny their duration. Moreover, if time
  attaches only to our conscious states, each one of us will live in his
  own time, and there will be no unique sense in which two events can be
  said to be simultaneous. This, however, is to deny time, not to
  explain it, for the notion of time surely implies, at least, the
  possibility of comparing the position of two events in the world
  process. Without this capacity, it is altogether useless. Of the
  characteristics of time, as all men conceive it, viz. as measuring
  events, as having parts, past, present, and future, and as continuous,
  the only one which is, in the end, retained by this theory is the
  last, and that illegitimately; for Bergsonian time is, in fact, the
  series of irreducible different qualities, which, therefore, can never
  form a unity or continuity. Much more might be added in criticism of
  the theory, but these remarks may suffice to show that it is
  irreconcilable with commonsense, and inconsistent in itself; though
  highly ingenious, and devised with the best of intentions, viz. to
  rescue living things, and especially conscious processes from the grip
  of a deterministic mechanism.
  
  (For a fuller discussion, see Nys, https://archive.org/details/lanotiondetemps00nysduoft La Notion du Temps [https://archive.org/stream/lanotiondetemps00nysduoft#page/232/mode/2up pp. 233 ff.].)


—R. P. Phillips, https://archive.org/details/modernthomisticp01phil Modern Thomistic philosophy pp. https://archive.org/stream/modernthomisticp01phil#page/125/mode/2up 125-7
This is one of the http://en.wikipedia.org/wiki/The_unanswered_questions Fourteen Unanswered Questions.

There is a http://en.wikipedia.org/wiki/Agga%C3%B1%C3%B1a_Sutta Buddhist Creation Myth told in the Aggañña Sutta, but it is clearly a satire and is not taken seriously.
Marxism talks of proletarian revolution arising out of the class conflicts in the society and to be led by the working class. Maoism talks of a protracted peasantry revolution by eliminating the class enemies by guerrilla warfare. Maoism believes in extreme violence as the only weapon to seize power. 

The key differences are in the Maoist focus on an aggraian rather than industrial society and the degree of violence to be employed in the revolution. Marx advocated strike action and other basically peaceful demonstration with escalation to more violent forms of protest if this proved uneffective. Examples of this can be seen in the labour union disputes of 1970s britain and the early days of the actual russian revolution.
Maoism goes much further, advocating extreme violence and guerilla warfare of the sort the viet cong engaged in in the Vietnam war. 
Aristotle posited the notions of existence & essence in part so he could define the notion of Ousia (substance) which also fed into his Theology. 

Ibn Sina refines these ideas, but also according to the paragraph below, said that existence is an accident. 

Ibn Rushd & Aquinas criticises this position as it seriously, if not fatally, hampers the definition of Allah/God as thought of in Revelation in both Islamic/Christian theology. This means one really ought to understand Ibn Sinas Theology to place this question in its proper context. One can assume plausibly that both Ibn Rushd & Aquinas want to employ some form of the Cosmological Argument.


  Ever since the criticism of ibn Sina’s doctrine by Ibn Rushd who,
  among other things, accused Ibn Sina of having violated the definition
  of substance as that which exists by itself, and of Aquinas who,
  although he adopts the distinction between essence and existence under
  the direct influence of ibn Sina, nevertheless follows ibn Rushd in his
  criticism, the unanimous voice of the Western historians of medieval
  philosophy has been to the effect that existence, according to ibn
  Sina, is just an accident among other accidents, e. g., round, black,
  etc. 


But Ibn Sina qualifies, existence isn't an ordinary accident, but a special one which he holds in relation to Allah. It looks like from


  We have said that when Ibn Sina talks of existence as an accident
  with relation to objects (as distinguished from essence) he just means
  by it a relation to God; it is, therefore, not an ordinary accident.


Meinong gives a typology of non-existants:


  Further, if existence were an accident, one could think it away and
  still go on talking of the object just as one can do in the case of
  other accidents and, indeed, in that case Ibn Sina would have been
  forced to hold something like the Meinongian view held by many Muslim
  Mutakallims that non-existents must also "exist" in some peculiar
  sense of that word. But this is the very doctrine which ibn Sina
  ridicules. 


But Ibn Sina ridicules the idea of non-existants existing - this is a classical view going back to Parmenides, which he elaborated in his poem On Nature; Ibn Sina offers similar arguments.


  The whole discussion on this point can be found in the
  article referred to in note No. 5 of this chapter. Here we give only
  one passage where our philosopher criticizes the view of those who
  hold that a non-existent "thing" must, nevertheless, "exist" in some
  sense so that we can talk about it. He says (K. al-24.iffi', "Met." I,
  5), "Those people who entertain this opinion hold that among those
  things which we can know (i. e., be acquainted with) and talk about,
  are things to which, in the realm of non-being, non-existence belongs
  as an attribute. He who wants to know more about this should further
  consult the nonsense which they have talked and which does not merit
  con-sideration." 


He remarks that Ibn Sina wants to start with the clear & undefined ideas of existence & unity.


  Indeed, according to ibn Sina, the ideas of existence
  and unity are the primary ideas with which we must start. These
  underived concepts are the bases of our application of other
  categories and attributes to things and, therefore, they defy
  definition since definition must involve other terms and concepts
  which are themselves derived (ibid., I, 5). 


He returns to the problems of non-existents.


  It will be seen that this problem now is not a metaphysical one but
  has to do with logic. Ibn Sina has attempted to give his own answer to
  the question : How is it possible that we can talk of non-existents
  and what do these latter mean ? 


He places existence in the mind.


  His answer is that we can do so because we give to these objects "some sort of existence in the mind."


Your answer is in the last paragraph. Ibn Sina resolves the question you've pinpointed by placing existence in the mind. Now if this is the human mind one can see why Ibn Rushd & Aquinas were heavily critical. If it is the mind of God/Allah - then thats a different question, and one must look more closely at the theology of Ibn Rushd. It may also be useful looking at Aristotles Theology & his ideas of nous (intellect).

Finally, one might say he anticipates Kant by placing existence in the human mind.
The two mean the same thing. At 16 minutes (of the first video), he even says "instantiate or exemplify" -- so he clearly means the same thing. He's talking about the Ǝ operator (exemplification or existential instantiation, take your pick).
At the most basic level - the answer is yes.  It is 'bad faith' to blame others for anything.  However, Sartre was not stupid.  He grew up during - and spoke out against - Nazi Germany.

To not place blame on another is a place one stands such that one can be completely free to be responsible for everything that takes place in ones life.  

In the same way Thích Nhất Hạnh has said "I am responsible for the world" (unfortunately I couldn't find this quote, so it is not word-for-word accurate, and comes from my memory), Sartre would say that we are responsible for the world.  Being Responsible can include blame, but the type of blame it includes is not made up of petty, miserable, self-serving grievances; but rather a greater sense of intolerance toward that which attempts to interfere with the ability of men to act as responsible self-determining agents.  

In this sense, we can understand that although Sartre found 'fault' with the actions of the Nazi's, his finding 'fault' was not done from a lack of responsibility, but rather from a greater responsibility.  

If we understand responsibility at the lowest common denominator, then we have no shot at resolving this powerfully.  One of the best definitions I have heard for what I will call 'Existential Responsibility' comes from Werner Erhard, and is as follows:


  The willingness to be cause in the matter of one's life.

It is a conceded fact that something exists.  Martin Heidegger pointed to this as the most fundamental issue in philosophy, that something rather than nothing exists.  Further if the world is an illusion by the radical method of doubt argued by Descartes, we can also infer that our minds must exist even if all else is an illusion.  No argument with premises 1, something exists.

P 1:  Something exists.  

Philosophy has worked hard to establish this most basic truth, and I agree that Descartes establishes that our minds exist.

P2:  We cannot fully explain why something exists.

The ultimate base of reality is not explained.  The limit of our understanding is intimate and permeates our existence. Socrates might suggest at this point, that beginning of self-examination reveals profound ignorance. This self-knowledge of profound ignorance may inspire the thinker to a passion to try and understand what a human mind can come to understand. The passion of the thinker to expand the perimeter of knowledge is a humbling journey since so much remains in speculation, and so many deep insights are very difficult to grasp and involve complex mathematics beyond most peoples capabilities.  

P3: By the Principle of Sufficient Reason everything must have a cause.

Spinoza claimed that, nothing exists of which it cannot be asked what is the cause or reason for its existence.  This is not a universally accepted principle in philosophy.  We may consider the following list of ontological elements: time, space, infinity and nothingness as perhaps needing no cause for their existence, they are simply “given”.  Something like infinity has no boundary, no beginning or end, and since it has these features it may be a candidate for something that exists but needs no explanation it is simply a “given” feature of existence.  If time and space also have no bounds why would they need to be caused since they are infinite and eternal? It seems that both something and nothing exist simultaneously, for the Big Bang started as a point event in perhaps a sea of nothingness? Nothingness seems to exist prior to something, and there is no need to explain nothing since it is not a something and therefore needs no explanation. This is a speculation that perhaps some ontological entities are a “given” feature of the cosmos that is axiomatic and needs no explanation. Axiomatic logic must have at base unproven assumptions, and we know that every system of logic has a limited set of provable theorems. The existence of God is an axiomatic assumption, not a proven fact. This assumption about God is then used to extend a set of logical theological conclusions which every culture has explored to create a rich tapestry of theological possibilities with unique and interesting solutions to community and ritual.  

Conclusion: Since we do not have an explanation to the cosmos, we may evoke a miracle as the best solution to the fact that something exists.

This conclusion seems to be a species of the logical fallacy Appeal to Ignorance. We can have a strong intuition about God, but it does seem to be a personal act of faith at base to make this assumption, rather than a proven theorem from generally accepted first principles. Socrates perhaps would suggest caution and humility, for the base assumptions we make are subject to revision.  
First of all, it is very important to separate the practical question from the theoretical one. This is because there are many more questions that are raised when meshing both together. In real life, as is often the case, it is never always a case of either/or. For not only have societies varying conceptions of liberty, welfare and equality, people's expectations of them differ as well.

That is not to say, of course, that the answer is moot. The question you raise is as contentious as the politics that often use and simplify these concepts. For instance, it is not clear that funding welfarist programs, such as social security or healthcare or free education, would lead to a 'revolt'. The general population may actually want these things because they are good for society - good in general in that there is a broad consensus that these programs are good to keep.

G.A. Cohen is a Marxist analytic philosopher who have tried to answer the question of welfare and market economics. In 'Why not socialism', he gives a brief outline of why both are not incompatible. You might want to check his other books which addresses this in more detail.

Michael Walzer, Michael Sandel (from the communitarian school), Derek Parfit, are some philosophers who have tried to answer these questions, in one way or another. You might want to check out the Blackwell Anthology to Contemporary Political Philosophy to get a more comprehensive answer.

What is important to note is that there are no simple answers to the question of political philosophy or politics in general. Regarding real world examples, the Scandinavian countries and Canada, are often known to be welfarist, providing largely free education and healthcare, while having only moderate taxes (see OECD datasets) and liberal democracies.

Keep in mind however, when discussing about welfare programs, that there further questions. For instance:


To what extent should welfare be provided to citizens?
What are the economic trade-offs?
Do welfare programs prevent people from taking initiatives? (often accused by neoliberals)
Do countries have enough resources to provide generous welfare to their citizens?


If you would like to answer these questions you cannot simply look to real world countries, because there are often historic reasons that affect the political consciousness of a country. These include whether the country has recently suffered from wars or economic depression, or internal political changes on that affect who or which party is in power.
The problem with Einstein's argument is not the insistence that the theory needs unobservable quantities, but the insistence that the theory in question needs the particular unobservable quantities he had in mind, such electron paths. Quantum mechanic of course has introduced other unobservable quantities, just not the ones classical physicists used to deal with at that time.

Historically there were many physical theories, such as the original formulation of Classical Mechanics by Newton, that would consider only observable quantities. It has become handy to use unobservable quantities, hence Lagrange introduced the expressions we now call "lagrangians" into Classical Mechanics. Nobody can observe or measure lagrangians (they are not physical quantities), but many problems of Newtonian Mechanics are easier to solve with their aid.

So if the question is about any fundamental theory that deals only with observable quantities then the answer is yes: Newtonian formulation of Classical Mechanics. 

If, on the other hand, the question is about a theory compatible with Quantum Mechanics, then I'm not certain about the answer, but seriously doubt the existence of such theory because unobservable quantum states seem to be essential to both Heisenberg-Schroedinger formulation (as elements of Hilbert space) and Feynmann formulation (as possible paths). QM insists, in the form of Heisenberg inequalities, on some ambiguity of observable quantities, and the introduction of unobservable ones is the way to build a theory despite those ambiguities, as far as I know.
The short answer is no, you have not really critiqued the Marxian theory of value here. 

One key thing to clarify is that all capital is also a form of labor. Here I will quote the earlier answer, "Ask yourself, where do the parts of the mechanized factory come from?" Here Marx makes a helpful distinction between "living" labor and "dead" labor. Machinery is dead labor. It was made by someone in the past. Still labor, although the distinction is very improtant.

The first paragraph of the quote you have selected states that we are constantly approaching the imaginary scenario you have described. Approaching it, getting closer and closer, but it does not say we can ever arrive. In your imagined case, the mugs are created purely by "instrumentalities[ie automation] set in motion" without any direct involvement of living human labor. While more and more things can already be made that way, nothing gets from being raw materials in the ground to a commodity in the final consumers hand without being touched, moved and changes by multiple human beings along the way. 

So what are we actually approaching then? Living labor isn't going anywhere, its just that the past human labor accumulated presently in the form of machinery and other capital is increasing. The value of living labor is decreasing in proportion. Marx call the ratio of capital to labor the organic composition of capital or OCC. It is always generally increasing. As the OCC increases, the rate of profit tends to fall. If the employment of living labor becomes zero, the OCC would be infinite, the rate of profit would be zero. No profit, no capital.

That's very abstract, what does it mean concretely? In a capitalist system, a capitalist can only make a profit by selling something. Which means workers have to buy stuff. If capitalists don't hire workers, workers can't buy anything, capitalists can't sell anything. So there would be no possibility of profit on the basis of commodity production and exchange any longer. The only logical outcome of such an advanced level of automation, Marx argued, was communism.
In my view, the labor theory of value hasn't been dis-proven so much as it has simply fallen out of favor, for essentially practical reasons.

It is helpful to make the distinction between price and value, or to use Marx's terms, between exchange-value (the amount something is worth in money terms) and value (the average amount of labor time socially necessary to produce it). In theory, the relative prices of commodities in general result from their respective values. In reality, when we are talking about specific kinds of commodities, things get more complicated. The high price of a diamond or a Picasso painting may not correspond to their value, but those are not typical cases. There are different ways of addressing such exceptions that have been debated, particularly among Marxian discussions of http://en.wikipedia.org/wiki/Transformation_problem the transformation problem.

But with this in mind, its also not difficult to see the real reason that labor theories of value in general have fallen out of favor. If you properly understand what is meant by the labor theory of value, you will quickly see that it is very difficult (perhaps impossible) to empirically measure the value of anything. In contrast, we have mountains of data about prices. So, economic theory in the twentieth century has increasingly worked its way around value in the classical sense, not so much disproveing its existence as finding a way to live without it. Modern economics shows us that studying prices instead of their underlying values can be relatively useful. Marxists and others who defend the labor theory could counter, however, that where economists have failed (e.g. their inability to predict of financial crises) it is precisely because the underlying essence of value is still human labor. 

Finally I would emphasize that Smith, Ricardo and Marx each developed their own theories of value. In that sense, I do not think that sweeping, general critiques of "the labor theory of value" in the singular make a whole lot of sense. Ricardo built on and critiqued Smith, rejecting parts of his theory, while Marx did the same to both of the other two. These theories are each quite different and I haven't seen a convincing, general critique that really applies to all three.
Let's examine the description of fixed capital more closely.

First, 


  no part of which enters into its net revenue


This is important, because it means that fixed capital cannot be a part of final goods and services.  So for example, if there is a machine that builds consumer goods, but that machine is bought and sold, then that machine is not a part of fixed capital, as it adds to net revenue.

But wait!


  This fixed capital consists in ‘the materials necessary for supporting their useful machines and instruments of trade'


We now know both what isn't part of fixed capital, but also that fixed capital is not equivalent to the null set (unless, of course, there is no production in this theoretical society).

Perhaps cleanliness of the air, for example, which is not considered in net revenue may be a portion of fixed capital.  If the aforementioned machine is coal burning, the particulate matter expelled confers increased output (over using, say, a solar ray in climate that sometimes experiences cloudy days) but does not in any way affect net revenue.  In this case then, clean air may be a form of fixed capital.


  ‘the produce of labour necessary for fashioning those materials into the proper form’.


To continue with the coal burning example, clean air can be generated by breathing in particulate-inundated air and filtering it with lungs.  In this case, clean air is also a produce of labour, and is necessary, full particulate atmosphere would restrict the ability of other capital to function.

But what is constant capital?


  that part of capital which consists of all material means of production, as opposed to labour power.


Oh!  So constant capital is permitted to enter into net revenue but is not permitted to consist of labor.  So the portions of clean air generated from other sources (we probably don't count trees as members of the labor force, and they also clean air), but not the portions cleaned by labor force lungs are counted in constant capital, as is our coal burning machine, for the fact that it may be bought or sold in no way affects its ability to be capital in the Marxist sense.

Summary:

Fixed capital:  Not counted in revenue, may include labor.

Constant capital:  Anything contributed to output that isn't labor.  

I think it would fair to call the overlap something like "pure capital," as it is pure of both being output and of being labor, and say that this is the relation being drawn.  The theoretical value embodied in capital suggested would be equivalent to this "pure capital."
I'm making this an answer instead of a comment because it turns out to be too long.

The TL;DR version is that while it's possible to draw parallels and contrasts between any person and any other person, firstly, the number of permutations is going to be astronomical or even http://www.quotationspage.com/quote/26930.html economical, and secondly, in this particular instance, I suspect it's not going to be fruitful. Try to contrast http://vserver1.cscs.lsa.umich.edu/~crshalizi/T4PM/futurist-manifesto.html The Futurist Manifesto with any book by Rand.


  Italian Futurism was an art movement in early 20th century Italy which celebrated youth, violence & technology:


Youth and technology have been celebrated by an innumerably large number of people, especially the former. Rand abhorred violence, except in self-defense.


  On this reading one could say that Rand was a point of diffusion of Futurist ideas in the States, which places her in the tradition of polemical artistes or rhetoricians rather than discursive philosophers such as Aristotle.


While one could say anything at all; neither was she, herself raised on any such tradition, nor did she try to mentor others into following such a tradition herself. Based on what I know of Rand, I'd say any such resemblance is only coincidental. From what I know about Rand, she does not seem to be a discursive philosopher. Her methods seem more like the methods of Marx or Nietzsche.


  To the Heroic Worker she counters the Heroic Industrialist
  
  To the Strike of Labour she counters the Strike of Intellect


I'd agree with your impression.


  To the Salvation of the People she counters the Salvation of the Economy


I disagree here. Rand cared about freedom (i.e. individual liberty) foremost. In her discourse, the economy, i.e. capitalism, is what comes about when individual rights (including property rights) are respected.


  To primitive-communism she counters primitive-capitalism (Galts Valley)


The idea of like-minded people trying to start afresh is not really original either. But then, I don't see what this has to do with Italian Futurism.


  An inversion & a revolution around the fixed-point of Technology. As Marx turns Hegel upside down, she turns Marx upside down. 


Technology, just like the economy, is not the cause for Rand. It is, rather, the effect. But, I'd agree that in economics, she is pretty much the opposite of Marx. Again, I don't see the connection to Italian Futurism.
The closest description of Brahman is Satchidananda which literally translates as Existence Knowledge Bliss Absolute. But even that is only describing the outer layer of Brahman so to speak as Brahman is beyond all words. All you can say of Brahman is "neti, neti" - not this, not this (meaning whatever you can put into words or experience cannot be Brahman) Sat is translated as Existence, not 'Being'. Sri Krishna says "It is the Supreme Brahman, which is without beginning and is said to be neither being nor non-being." (Bhagavad Gita, Chapter XIII, verse 12, Swami Nikhilananda translator). All you can say of Brahman is - Brahman IS. After 40 years of study and numerous readings and studies, the most widely accepted translation of Sat is Existence. It can be translated as being, but the use of the word being in English can lead to more mis-interpretations than the word existence. 

As far as a sanskrit term that might approximate letheia, it may be 'maya'. Maya is ignornace obscuring the vision of God (Brahman); the Cosmic Illusion on account of which the One appears as many, the Absolute as the Relative. Maya is that which covers Brahman and makes us forget our true nature as Brahman.      
The question, as I interpret it, is in what direction morality (or virtue) and liberty should move: is morality necessary for liberty or is liberty necessary for morality? I will say the jury is still out as there are two competing paradigm principles on this matter.

One is the harm principle. J.S. Mill postulated the principle to answer the question, "When can the liberty of a person be limited by the coercive power of the law? To Mill the answer is that forceful interference is justified only when the interference is used to prevent harm to others. Force should never be applied to a person for the person's sake. That is, to make the person good or virtuous is never a legitimate reason to use forceful coercion, to Mill. Maximal liberty for individuals is a big deal for Mill because Mill thinks that men are progressive beings, that we can continue to improve and perfect capacities and values that are proper to human beings (cf. Brink's Mill's Progressive Principles)  To Mill, morality imposed on and indoctrinated makes us hypocritical (untrue to selves). When we confront values as individuals (individuality) and test them out through our projects and social interactions (experiment in living), we can become authentic (true) selves: we can truly affirm truth and morality. Viewed in this light, liberty is necessary for morality (or virtue).    

The other idea is the offense principle, postulated by Joel Feinberg. To Feinberg, the harm principle needs a revision since a society that adheres only the harm principle will not actually maximize liberty.  To motivate this idea, Feinberg invites us to a bus ride. Sitting in a city bus, you suddenly realize that people are eating cooked dogs and engaging in sexual orgy with cats. you cannot get away from the sight. Being disgusted and humiliated is an under-statement of how you feel. You are profoundly offended: you are tormented by the image, Dogs and cats are never the way they were to you before the incident. You become un-free. Feinberg thus maintains that when morality is not in place in the society, and when the law is not in line with the going morality of the society, the society cannot secure liberty. That is, to a degree, laws should try to make people good and virtuous. Viewed in this light, morality is necessary for liberty.
Let's try to get straight on the argument of "the philosophers" first. 

I think that what's at stake is a sentence like W: "The world exists". If I can read between the lines a little bit, my guess would be that these philosophers are trying to reconcile Aristotelianism with Islam. Aristotle believed the world was eternal, whereas Islam held that it was created at one particular instant in time. I think these philosophers are trying to find a compromise: the world isn't eternal, God created it, but he created it out of matter which is eternal and pre-existed the creation, so Aristotle got it at least partially right.

I think the gist of their overall argument is: 


(1) either (i) it is necessary that W, or (ii) it is possible that W, or (iii) it is impossible that W. (Premise)
(2) not (iii). (Premise)
(3) not (i). (Premise)
(4) Therefore it is possible that W. (from 1,2,3 by disjunction elimination)
(5) But if it is possible that W, then "the subject of possibility is . . .  matter." (Premise)
(6) But if the subject of possibility is matter, then matter is eternal. (Premise)
(7) Therefore, matter is eternal. (from 4, 5, 6 by modus ponens and hypothetical syllogism.)


Now it looks like (1) is supposed to be just a truth of modal logic--something is either necessary or possible or impossible. This is kind of a weird way of putting it in my opinion--the opposite of necessary isn't "possible", it's "contingent". I'm not sure that's significant though.

The argument for (2) looks to be the obvious fact that the world actually exists. If it does actually exist, then it can't very well be impossible that it should exist.

The argument for (3) is more involved. The author reports them saying, "it is impossible for it to have been necessary in itself, for that which is necessary in itself is never deprived of existence" and I guess these philosophers must have also been taking it as self-evident, or as somehow contrary to faith to think that the world might have been eternal. 

Premise (4) is a valid inference from (1)-(3).

In support of premise (5) they say, "This possibility cannot inhere in possibility itself, nor in the agent, nor in no-substratum, for the possible is that which is in the process of becoming actual. Hence the subject of possibility is some substratum which is susceptible of possibility, and this is matter." I have a hard time seeing what is going on here. But my best guess is that if there is some possibility, there has to be something that explains that possibility. A classic aristotelian example: If a pot does not exist, but comes into existence there has to be some matter there which is potentially but not actually a pot to be the subject of the change, namely some clay. 

The sixth premise is similarly difficult. They say, "Now, this matter cannot be considered to have been originated. If it had been originated, the possibility of its existence would have preceded its existence. In that case possibility would have existed in itself, but possibility existing in itself is unintelligible. " The idea here is something like: if the matter had been created in time, then there would have been some time before which it had been created, and if there were a time before matter, then there would be a time in which potentiality existed without its being the potentiality of anything. That is to say, it would be like there being the potentiality of something coming to be a pot without there being any "clay" correspondingly which had that potentiality. There would have been a time when potentiality just had itself and that's what these philosophers find incoherent. But since the supposition that lead us to this incoherent claim was that matter had a beginning in time, then it must be false that matter had a beginning in time, which is to say that it is eternal.

The tenor of al-Ghazali's reply should now be more obvious. Al-Ghazali just wants to say that there doesn't have to be any substrate that makes a sentence necessarily or possibly or impossibly true. His claims here sound more like Quine than Kant to me, but that's neither here nor there. The important point is that he rejects the argument because he thinks that modality (necessity, possibility) is just a property of sentences or of our understanding, not a property of things themselves. 

He's wrong about this, by the way, but that's a different question.
Well, that would certainly depend on which "god" and prophet you were referring to. The Christian God has made it very simple: see if the prophet's prophecies are actually fulfilled. Old Testament prophets usually prophesied of things soon to come, before prophesying of long-term events. Thus, Joseph, not strictly a prophet, but gifted with the ability to interpret dreams, foresaw 7 years of abundance followed by 7 years of hunger. You simply had to wait 8 years to see whether or not he was legitimate.

To turn this into a more generic answer. The best way of establishing the legitimacy of a prophet is to test whether his prophecies are fulfilled. A good rule of thumb may be that a legitimate prophet will be direct, non-contradictory and unambiguous. So a prophecy like "next year this time, there will be war" is probably true, or at least can be tested quite easily. While something like "the serpent will shake its tail twice and then the hidden grapefruit will spill over the onyx throne" is probably horse-pucky.

If a "god" takes the trouble to send a message, it would probably be easy to understand.
Well I was thinking about this question for a while and here's what I came up with:

The main problem is that you define immortality using time ("living forever"), and time is relative in its very nature, whether we look at it as a physical property or from a more common point of view. So what causes immortality to appear as relative in your example, is the fact that it's defined using time. On a side note, I don't think you can define an absolute value, when you base your definition on a relative one.

Let's see what happens, if we define immortality as "not being able to die", a definition that also comes natural. It implies, that if anyone can see you die, you're not immortal, but in fact, dead. This fixes the black hole paradox, because living forever doesn't equal immortality in the above definition, as long as you can be seen dead by any observer in any circumstances.

Translating it to a more mathematical definition: a person P is immortal if and only if for each observer O in time and place P is not seen as dead by O. In other words: a person P is not immortal if and only if there exists an observer O that can see person P as dead.

My hypothesis is that the 2nd definition describes the concept of immorality that can be found in the culture better. And although in most religions it is said that afterlife is "living forever", it is also said that souls cannot be killed or destroyed, and that is what grants the afterlife immortality. And more than that: spirits and souls are not bound by any laws of physics, including time (at least in Christianity, I'm not a religion expert). Also, note that you don't even have to be seen as alive to be immortal in the 2nd definition.

So, assuming my hypothesis is correct, immortality is not a relative property.

By the way, here's another paradox: is the Shrodinger cat immortal? It lives forever, if you never open the box (immortal in the 1st definition). But it's dead at the same time, so it's not immortal in the 2nd definition.
Peirce (note spelling) is not arguing for anything there. Rather, others are presenting an interpretation of Peirce's project. They are suggesting that while Peirce discusses "truth," he does not do what many other philosophers do who discuss truth. They try to define it, for instance as "correspondence to the way things are." This paragraph suggests that Peirce does not try to define truth, and instead merely places the concept of truth in relation to his understanding of the concept of belief. 

To understand what it means to assert such a relationship without defining terms, consider someone saying that a rectangle is what you get if you add one side to a triangle and make the sides parallel. One can say that kind of thing without ever defining "triangle" or "rectangle" explicitly.  
Gensler's star test is a little confusing and in cases I can think of, unnecessary. 

A very simple way to check for logical validity in a structure is to substitute other words or phrases into the structure. Basically, try and find an instance in which the premises would be true and the conclusion false. 

So here is your logical structure (basically):
P: All A is B.
C: All B is A.


Can you think of a instance where the premise would be true and the conclusion false? I can: 

P: All cats are mammals. (T)
C: All mammals are cats. (F)


In this example, the premise is true, but the conclusion is false. Our initial structure has just been proven invalid. 
I'm not sure I understand the question fully, so let me see if I can sharpen it up a little bit. 

Is your question: Is there a set of possible answers that could in principle be given to any given philosophical question?

If that's your question the answer is No. Different kinds of problems are going to have different kinds of possible answers that could be given to them. 

The space of possible answers is probably smallest in logic. One kind of question that comes up in logic is: Can one create a formal system with property P? And there the answer is either yes or no. But it also often happens that there is a question like Does claim p follow from axioms a, b, and c in system s? and there there are three possible answers that might be given: provably yes *provably no* or undecidable.

In metaphysics it gets much more complicated. Take the question of free will and determinism that you mention. Some people might want to say there's not really a question worth trying to figure here. There are two different ways to make an argument like that: 


Deflationists could say that the question is really just verbal, there isn't a substantial disagreement here, only a kind of misuse of language leading to a pseudo problem.
Mysterians could say that the question is meaningful and perhaps even has an answer but it is an answer nobody in principle could know because of the cognitive limitations of the human mind.


I don't know that these two kinds of solutions could in principle be given for any metaphysical topic, but certainly they are common (deflationism much more so than mysterianism). However, if one thinks there is a meaningful, substantive question at stake in the free will debate and that it is in principle answerable, then there are a number of possible positions. There are actually at least three distinct questions involved here Does moral responsibility require the freedom of will? and Is the freedom of the will compatible with determinism? and Is determinism actually true? At first glance it looks like the answers to these three questions must be either yes or no, so we should expect 2^3 different possible positions. In practice the most common are:


libertarianism (responsibility requires freedom, freedom isn't compatible with determinism, but determinism is false), 
hard compatibilism (responsibility requires freedom, freedom is compatible with determinism, determinism is true),
soft compatibilism (responsibility requires freedom, freedom is compatible with determinism, determinism is false), 
hard determinism (responsibility requires freedom, freedom is not compatible with determinism, determinism is true), 
reactive attitudes (responsibility does not require freedom, freedom is not compatible with determinism, determinism is true) 


These are different substantive positions on the free will issue. Each different metaphysical problem (what are laws of nature? what are numbers? how do dispositions work?) will have a variety of different substantive positions like this, and I don't see any common features those answers share that would allow us to categorize them any more specifically.
You're missing a formulation or two based on the way it is often parsed now. There are three groupings of claims that we often call the Categorical Imperative

Your sequencing is a little weird to me, so I will just reiterate the order most commonly used:

Universalization formulations: Formula of Universal Law = don't do what couldn't be universalized (G 4:421) (the question of whether he means "logically" is debated).  The second half is as if it a Law of Nature --> do nothing that could not be made a universal law of nature. Its relatively undisputed that Kant sees these as two variants on the same theme. There is argument about what the "law of nature" part adds. A big piece of this confusion is if Kant in the Groundwork means by nature what we often mean by nature or what he uses it to mean in CPR.

Rational being formulas Formula of Ends in Themselves* = treat every rational being as an end in itself and not merely as a means (G 4:428-429). **Formula of Humanity = act such that humanity whether in your own person or any other is an end and not merely a means.  There's a lot of disagreement about what humanity means in this case. The main source is that when Kant does define the term humanity elsewhere it ain't what we normally call humanity but rather a synonym for what he calls being a rational being.

The third formulation group is the Kingdom of Ends formulation = act such that you are a legislator in the kingdom of ends.

Sometimes considered part of the same group and sometimes not considered a formulationand sometimes considered its own group are the comments that follow about autonomy.



You then ask: How does Kant derive the other formulations from the universalization formula? The answer is that this is a highly-debated question. It's not hard to get from the formulation of universalization to universal law of nature. But after that, there are several different theories.

I will share an abbreviated version of my own (you can probably buy my dissertation from ProQuest). For Kant, rationality is uniform such that a rational being given the same circumstances would always will what reason dictates -- except insofar as we are semi-rational beings capable of acting against reason (we have freedom and rationality -- we are not rationally necessitated). And reason is the universal. Thus, if we have a set of rational beings, each of them will pursue the universal correctly, and we should not impede their actions, because they are rational/universal. In my view, the word humanity merely repeats the same idea. The kingdom of ends then becomes a realm where we see all other humans as part of the same rational project.

There are some rather significantly different interpretations.
I really can't help with the mindspace problem, and I'm not sure I understand your representations, but I do know where to look for Kant's explanation, so here comes.

The place you'll have to look is the third chapter of the Critique of Pure Reason,  http://www.rbjones.com/rbjpub/philos/classics/kant/kant066.htm Of the Ground of the Division of all Objects into Phenomena. Although I might tell you right away that you won't find a lot there, which is why people have been discussing this issue ever since. Check out http://plato.stanford.edu/entries/kant/#TraIde Stanford Encyclopedia on the two-objects interpretations and the two-aspects interpretation. A contemporary advocate for the first interpretation is Guyer, check out http://rads.stackoverflow.com/amzn/click/0521337720 Kant and the Claims of Knowledge. The two-aspects reading is advocated by Allison, e.g. in http://rads.stackoverflow.com/amzn/click/0521483379 Idealism and Freedom: Essays on Kant's Theoretical and Practical Philosophy.
It is very rare for any philosopher's full set of views to be accepted by anyone else. But, that said, there is an ongoing discussion in metaphysics about “the problem of universals,” in which the problems are very much like ones Plato raised, and forms are probably one kind of universal. 

And, for an example of out-and-out Platonists, Platonism is probably the current majority view in Philosophy of Mathematics. See the Stanford Encyclopedia article http://plato.stanford.edu/entries/platonism-mathematics/ Platonism in the Philosophy of Mathematics.
I'd say that something-from-nothing hasn't gotten very far (either the "how" or "why").

The nature of matter is almost completely answered, save for lingering questions about dark matter and dark energy.  We've found the Higgs Boson, the Standard Model fits experimental data to within a few percent, and quantum chromodynamics hangs together decently well.  Sure, there's relativity mucking things up, but we know what matter is and how it behaves under a vast range of situations.  New theories won't overturn those any more than Newton's laws were overturned as explanations of how planetary motion works: even if there's a more complex way to look at it, -G*m*M/r^2 is pretty much how gravitation works across most scales.

Free will has been penned into a pretty small range of possibilities by neuroscience.  That mind is implemented by brain is almost without doubt at this point, and if so we know plenty about the physical world to scupper ideas of Free Will as being some causal source unlike all others.  No, we pretty much know that it's just a fancy algorithm running on our fancy brain-hardware, and we just have to work out how, and decide whether we should be disturbed, or whether our role as deciding-information-processing-agents actually gets us the freedom we were after in the first place.

The universe gives pretty clear indications that nothing matters objectively in the most global scale.  We also know that evolutionary fitness matters as much to living creatures as anything can.  The universe enforces this one with brutal strictness: go extinct, and there are no more of you, ever, which also pretty much ends any value system that requires you to value things.  If we want a near-universal source of meaning, we can find it there.  But we seem less interested in knowing that it's objectively stupid to make ourselves go extinct (too obvious?), and a lot more interested in knowing whether gays should serve openly in the military.  And if that has any bearing on our fitness as a species at all, the answer could only possibly be had from asking "Well, what will the consequences be?"  And to answer that you have to do experiments, and it will depend heavily on the social and ecological context in which we find ourselves, and just doesn't look like the kind of crisp principled answer we want at all.  So things which matter-to-us but have even less objectivity (like human happiness) tend to receive the bulk of the attention.

Science has done a pretty remarkable job here in my opinion.  I don't see how it's going to get the "something from nothing"-style questions.  But a couple hundred years ago I don't think I could have foreseen how science would have tackled the other three.  So I'm not going to proclaim with too much confidence that it cannot.
Did you try the Stanford Encyclopedia of Philosophy http://plato.stanford.edu/entries/determinism-causal/ article on Causal Determinism?
I think the title of your question and second paragraph of your question look like they are asking a very different question that the first paragraph. In the title and para 2 it looks like you mean to ask: Can somebody say truly that something doesn't exist? That's related to a classic problem in 20th century philosophy of language about the status of negative existential propositions. The answer to that question is that of course it is possible to say (truly) that something is not. Here's an example, "There are no such things as unicorns." That's a perfectly coherent, logically impeccable sentence to utter. What makes it true is the fact that nothing that exists is a unicorn. 

However, in the first paragraph of the question you seem to be asking a rather different question about the legitimacy of using the impossibility of an infinite regress to prove some statement. Again, there isn't anything logically odd going on here. To see why, take an argument like: 

(1) If p were true, then there would be an infinite regress.
(2) There are no infinite regresses.
(3) Therefore, not-p.

I have now proven the falsity of the sentence p. Why we should believe (2) is a separate philosophical question, so if you would like to know more about it, I suggest posing that as a different question.
See on the "deep technical" question SEP entry on http://plato.stanford.edu/entries/continuum-hypothesis/ The Continuum Hypothesis 

It is interesting to compare with the Axiom of Choice : both have been proved to be independent from ZF axioms, but AC has been very "useful" in settling a lot of interesting mathematical problems, so that , in spite of some implausible consequences (see Banach-Tarski "paradox"), quite all mathematicians accept it as a reasonable axiom.

CH has no this kind of status; see Gödel remarks at the end of his 1947 “What is Cantor's Continuum Hypothesis?” :


  [...] it is very suspicious that, as against the numerous plausible propositions which imply the negation of the continuum hypothesis, not one plausible proposition is known which would imply the continuum hypothesis. 


You can see Waclaw Sierpinski, Cardinal and ordinal numbers (1965), page 378, for some results connected with the continuum hypothesis :


  Theorem. The hypothesis is equivalent to a theorem stating that the set of all points in a plane is the sum of two sets of which one is at most denumerable on every line parallel to the axis of abscissae and the other is at most denumerable on every line parallel to the axis of ordinates. [...] The theorem can obviously be expressed as follows: The continuum hypothesis is equivalent to a theorem stating that a plane may be covered with a denumerable aggregate of curves which are either of the form у = f(x) or of the form x = f(y) each. 


See also page 400 :


  Theorem. The continuum hypothesis is equivalent to the proposition that the three-dimensional Euclidean space E is the sum of three sets Ei (i = 1,2,3) such that if we denote the axes of Cartesian coordinates in the space E by OXi (i = 1, 2, 3), then, for i = 1,2,3, the set Ei is finite on every line parallel to the axes OXi.


For a similar discussion, you can see in math.stackexchange the post on https://math.stackexchange.com/questions/79346/proofs-given-in-undergrad-degree-that-need-continuum-hypothesis Continuum hypothesis.

You can also see the "old" Waclaw Sierpinski, Hypothèse du continu (1934).
Frege's logic was really second-order logic (and more ...).

The restriction needed to avoid Paradoxes (Russell's one) is not to avoid 2nd-order and adopt 1st-order, but to the axioms you want to use. The culprits are :


  "naive" Comprehension - Cantor
  
  Basic Law V - Frege


Restrictions are necessary both if you formulate e.g. ZFC in first- or in second-order logic (other aspects are relevant also ..).

First-order is "simpler" and has some nice properties, like completeness of the standard deductive calculus (or proof systems) : see Godel Completeness Theorem. This is not longer true in second-order logic.

This applies also to ZFC.

But all formalized theory sufficently "strong" (and this concept of strong is precise and formal, and it is very ... weak) in term of expressive power are subject to Godel Incompletenss Theorem, that applies to Peano Arithmetic and ZFC as well, both to their version with first- and second-order logic. 
Let α be the set of choices/options. Let C be a unary function from α to {true, false}. Then A-D say:

A. ¬∃x ∈ α C(x).

B. ∀x ∈ α C(x).

C. ∃x ∈ α C(x) ∧ ∀y ∈ α C(y) → y = x.

D.  [¬∃x ∈ α C(x)] ∧ [∀x ∈ α C(x)] ∧ [∃x ∈ α C(x) ∧ ∀y ∈ α C(y) → y = x].



Consider a concrete example for illustration:


  Question. Animals X eat which of the following?
  1. fruits2. vegetables3. meat4. candy
  
  Answer options:
  A. There are no correct answers
  B. All answers are correct
  C. There is exactly one correct answer
  D. None of the above


My interpretation of the question is that "answers" is referring to (in this example) 1-4, not A-D. If that's the case, then A-D say:


  A says: animals X eat neither fruits nor vegetables nor meat nor candy.
  B says: animals X eat fruits, vegetables, meat, and candy.
  C says: animals X eat one and only one of: fruits, vegetables, meat, and candy.
  D says: [the denial of the conjunction of A-C] (consistent?, I think so).


Needless to say, if ¬(D ≡ ⊥) then there is really nothing interesting about this question.
I don't know the answer to the internal question about whether it is possible -- but I do know the literature on it.

You want to look at:

(1) late WVO Quine

(2) Donald Davidson

(3) Richard Rorty - specifically Philosophy and the Mirror of Nature

(4) Hans Georg Gadamer

All four are discussing the meat of what you are asking by wondering whether it is possible to understand something at a distance.

For some other supporting reading,

I suggest:

(1) Some later Wittgenstein and his considerations about language (specifically the private language argument -- and the large body of interpretive literature that asks what it means).

(2) https://fordham.academia.edu/GregLynch/Papers Greg Lynch

(3) There's also the http://plato.stanford.edu/entries/chinese-room/ Chinese room problem. and Searle looking at whether this is possible
Good question! I agree that it looks like Hegel was aiming at a characterisation whose direction approaches the human condition - but I was also struck by how he was aiming at etherealising it: from being in the round, to the flat plane and then to airy nothings, following the progressive movement of the soul from clay, to life to itself. In this it is no different to most cosmologies of religion.

I think, though, it was Schopenhauer that said that music that most approached that condition though - rather than poetry. 

One notes that in Antiquity it was Poetry that ranked as the supreme art. Which might explain Platos antagonism to it as the new purveyors of sophia. In Arabia too, and many other traditional parts of the world poetry is still seen as the best of arts. One ought to recall though, that this is not the poetry that is printed on the page to be read in silence - but to be recited, sung or chanted. Different subject-matter calling for different meters - one sees this in the revival of the spoken word performance and urban rap.

So, Hegel, seems to have the weight of history on his side.

I'd also date the reaction to this - the traditional canon - back to Dada than to Warhol. Warhols innovation was the aesthetic of mass manufacture, boredom & kitsch. 

I say Dada as this was the reaction of at least one section of the artistic elite to the mass murder & destruction that was the second world war. Before then, at least in the visual arts, it was a period of formal experimentation of form and subject - cubism, impressionism, primitivism & surrealism pushed on by the great strides that the sciences were making at that time.

Between them lay Duchamp whose introduced the philosophical gaze to Art, the playful, ironic gesture of the artist who is no longer much interested in his art and questions & undermines its own importance & the cultural establishment.

The categorisation I think still works and still holds. Despite a century of iconoclasm. The arc that Hegel draws, being the arc that most religions make in the cosmos, and being itself the arc we ourselves follow points to something quite deep in the wrorld - though by its very naiveity and simplicity seems a bare coincidence and nothing much of import.
It's easy to overstate the relevance of Nietzsche's pronunciation to the terms of classical Theology.  When Nietzsche talks about God, he talks about God as a cornerstone of Western Culture, not God as the character of a Christian story.  From section 343 of TGS, Nietzsche spells out his intended meaning:


  The greatest recent event - that God is dead, that the belief in the Christian god 
  has become unbelievable - is already beginning to cast its first shadows over Europe.


Throughout Western history, belief in Christianity was not merely seen as True but as a necessary prerequisite to any kind of civilized culture.  It might seem hard for us to think now, given that we seem rather accustomed to a kind of capitalism-driven hollowness underlying the notions of Globalization, but Europe and its colonies was very much founded on the idea of a principled providence, that the West carried the truth about God and that its spread across the globe is that of Divine Right.  Sure, this made empires very wealthy, but that was proposed to be simply reward for the elect and confirmation of their faith, rather than the purpose behind a protracted and vicious campaign of motivated subjection of others who lacked their technologies of power.

Nietzsche addresses the death of God in such terms - namely that given the mass of evil and suffering that has befallen the world in the actions of a humanity spurred on in this way, there can be nothing left of Him now.  Whatever Christian theology might claim of or about God in metaphysical terms is not specifically his concern, because the evidence is clear - we are monsters, and whatever abstract right to rule that we proposed God bequeathed upon us as his servants has clearly been jettisoned in our rush to bring the sword.

In the process of the Enlightenment, of Secularism and Science, the truth of this has started to become clear, and the utter fallacy of Christian imperialism leaves us in a state of not merely uncertainty but of profound ending and absence.  The Christianity that grounded our world's actions is what we do in fact believe about God, and the Redemption and ultimate Salvation that it offered us is part of why we as a society did what we did to the rest of the world.  We have to face up to the reality of what we have done, and to claim that either that self-same God lives on or that he forgives us is an act of escape and pretense; our task is to try now to find some way to live on past it in the cold void of a God that no longer defends or supports our collective action.

Can we say that God's death was freely chosen?  Christ, perhaps, took his choices into his own hands and acted with authenticity, but God's death seems to have been violent and long drawn out by a Christian West that scraped his bones dry for every ounce of empowerment we could find.
Richard Tieszen, After Godel Platonism and Rationalism in Mathematics and Logic (2011), is a detailed study of Godel's late philosophical ideas.

According to Hao Wang (Godel's disciple) [page 1] :


  Before 1959 Godel had studied Plato, Leibniz, and Kant with care: his sympathies were with Plato and Leibniz.


The following extract from Tieszen' book are interesting :


  In the later part of his career Godel thought that finitistic formalism, intuitionism,
  and other forms of constructivism were inadequate as foundations of mathematics and
  logic. He also thought that the views of the logical positivists, whose Vienna Circle
  meetings he had attended, were inadequate. [page 20]
  
  In light of [his] platonic rationalism, one could read the first incompleteness
  theorem for PA as follows. The first incompleteness theorem suggests that the abstract concept of objective arithmetic truth transcends our intuition (or constructive
  abilities) at any given stage, [...] The concept of arithmetic truth then appears to be known as an identity (or “universal”) [...]. This identity (or “universal”) is “outside of ” or “independent of ” each particular intuition (construction). This is how mathematical platonism is often characterized; that is, as claiming that there are universals or invariants that transcend the mind or our intuition. [page 47]
  
  Godel holds that even the completeness proof for predicate calculus depends on the
  application of platonic rationalism. He says that the inability to find
  the completeness proof, although in 1922 Skolem was very close, came from a lack
  of the required platonic attitude toward metamathematics and non-finitary reasoning. [page 48]
  
  The first published expression of Godel’s mathematical and logical platonism appears in
  the 1940s in “Russell’s mathematical logic” [page 49]
  
  Godel [in his critique of Carnap's views] argues that not only does mathematics have content but its content is unlimited in the sense that outside of every axiomatic system that formalizes mathematical truth there exist propositions expressing new and independent mathematical facts that cannot be reduced to symbolic conventions on the basis of the axioms of this system. [...] One of the drafts of the Carnap paper contains a passage that is very important for understanding how Godel thinks of the analogy between sense perception and rational intuition. The view here is very similar to some of Husserl’s ideas about the analogy between sensory and rational intuition [page 59]
  
  Godel’s [in the Gibbs Lecture of 1951] argument is that if mathematical objects are our own creations, then evidently integers and sets of integers would have to be two different creations, the first of which does not necessitate the second. In order to prove certain propositions about the integers, however, the concept of set of integers is required. Thus, in order to find out what properties we have given to certain objects of our imagination we must first create certain other objects. Godel finds this to be a very strange situation. In other words, we have given properties to certain objects (since they are our creations), but then, in order to find out what these properties are, we are required to create certain other objects. One might already ask how we can create properties that are, in effect, hidden from us. We supposedly create the properties, and yet they are hidden from us and we can only access them if we create certain other kinds of objects that allow those properties to be revealed. [page 67]


Godel's ideas are far from building a complete "philosophical system", but they are indeed the most recent and most authoritative view of the "realist" conception about the mathematical objects.

Tieszen's book is very detailed and go in deep into Husserl's inspiration for Godel's reflections.
Studies tend to show that about 50% of variability in behavioral traits is explained by genes and 50% by environment.  Unlike with identical twins, your other could have a pretty similar experience to you.  So, with 25% of your genes different, your other would be up to about 8x more similar to you than a random person is, and would have many of the same experiences and memories.

But of course that very-similar-person's consciousness wouldn't be yours; you are by hypothesis not around to experience anything.  You can't really arrange it so you can without breaking the whole premise.  So the other-you is identifiable as the most you-like entity in that hypothetical universe, and that is about as far as it goes.
Imagine an exotic "universe", which does not have deterministic laws, but does have a notion of discrete time. At each step in time, the state of the universe — its "material" content — is given by a set of objects. It has no conservation laws as such.

What happens is at each step, the set of material elements is replaced by either the power-set of its previous contents, or by any one of the elements of the power-set. In particular, at any point in time, all objects in the universe might disappear leaving nothing behind, and the universe may stay that way for any length of time, only to eventually produce non-empty sets of potentially exponentially growing size. We may suppose that these are all of the dynamics (can we?): while one can derive empirical probabilities of various transitions from any given history of such a universe, we may suppose that the histories are of a sort that cannot be described well even by randomised theories of finite size, simply by supposing that the dynamics are adversarial to any given ensemble of theories that you might propose.

In this universe, it will happen that something may emerge from nothing, and there are no symmetries which I am aware of to give a name of "potential" to any entity in the description, except the transition rule itself.

Are mechanics a "something"? If so, then there by definition can never be even a seeming 'nothing' according to a mechanistic premise, in which there is at least some intelligibility to the world. Otherwise, something can emerge from nothing, simply because the mechanism may provide a way for this to happen.

Furthermore, reflecting on what I could really mean by a "mechanism" or by "intelligibility", it seems really that we're talking about whether there must be a subject of discourse. Can something emerge from — well, from a state to which I cannot refer, because it cannot be a subject? Or is it the case that by abstraction and indirection that I can always refer to a state of affairs, so that there is always implicitly a 'something'? Or is this just our conceit of the same class as the Ontological Argument: that because we can vaguely imagine something, that it must be a some-thing?

The matter is that we mistake the map for the territory. "Mechanism" is our explanatory tool for what things happen and why, and as with the exotic universe I describe above, we are only ever right to the precision we can see because nature is too lazy to be constantly adversarial. That is our good luck, but also it is an intuition which may turn false at any moment. But even 'subjectifying' it by calling it 'nature' presumes too much. Things merely happen, and we seek the pattern.

Mechanism is not a thing in itself — unless we suppose it to be, but this tells us more about what we mean by 'thing' and our prejudices than it does about the world. Anyone who takes this for granted should be warned about what happened to the notion of 'position', or indeed arguably of 'thing', with the advent of the discovery of quantum mechanical phenomena, ie. complicated happenings the likes of which we previously would not even have expressed with naive conceptions of these words.
Strangely enough I just explained this a couple of weeks ago to a friend.

I took a numerological approach.

And I'll justify why I'm doing it here for clarifications sake. Math is a good way to describe reality, because it is pretty much unambiguous.

Ok. Good and evil depend on perspective. What's good for me might not be good for you.

So good for me = +1 bad for me or evil is -1. (from my perspective.)

If good = +1 and evil = -1 then:

-1 + -1 = -2

So you cannot defeat evil with more evil.

An example would be revenge. You hurt me and in order to get back at you I hurt you. And then you hurt me again. Until eventually either one or both of us are so hurt that we are cripples. A lot of -1.

A +1 would be peace and harmony, synergy, cooperation. But that would be a +1.

What you can do however is multiply by -1 instead of adding -1

Then you have -1 * -1 = 1 and you are back to good. Depending on the perspective. 

What happens when you multiply by -1? The direction changes. It's the same thing, like a road sign, but now it points in the different direction. That means that either you have changed your own position and perspective on the issue and can see the good in it now. Or you have somehow turned the "bad" thing around to point in the "right", "good" direction.
I don't know about the literature. If you want I can write a book quickly and then reference it. Or I'll just reference http://staroversky.com/blog/three-minds-conscious-subcosncious-unconscious http://staroversky.com/blog/three-minds-conscious-subcosncious-unconscious. But we have a conscious and subconscious mind. Most of the time not to say always the conscious is just there to pretend to be in charge. Does this then mean the subconscious is in charge or the unconscious?

Well that depends on if you think we exist in a vacuum and are not influenced by our environment. Only then I posit can we have a truly free will and plot our own course - AND know what we will be thinking about in 5 minutes. 

And for a reference on Philosophy mentioning experiments:

http://plato.stanford.edu/entries/freewill/ http://plato.stanford.edu/entries/freewill/


  The will has also recently become a target of empirical study in
  neuroscience and cognitive psychology. Benjamin Libet (2002) conducted
  experiments designed to determine the timing of conscious willings or
  decisions to act in relation to brain activity associated with the
  physical initiation of behavior. Interpretation of the results is
  highly controversial. Libet himself concludes that the studies provide
  strong evidence that actions are already underway shortly before the
  agent wills to do it. *As a result, we do not consciously initiate our
  actions, though he suggests that we might nonetheless retain the
  ability to veto actions that are initiated by unconscious
  psychological structures*.


So yes it is relevant. Still vetoing does not mean having a free will or choice. It's just another more complex "reflex" designed to prevent us from killing ourselves too quickly.
Sortals are words. Types are logical groupings. Otherwise they are very similar. The sort is a type, but the sortal is a term in a language. 
I think this question is best answered with reference to Medieval philosophy. A basic concept in Medieval metaphysics is that effects need a sufficient cause. On Descartes' account of the soul's capacities, we have a limited capacity to know but an unlimited capacity to will. This creates error within us as we can will beyond the bounds of our knowledge. Thus, your question's answer depends on what you mean by cognition. 

If you mean the ability to think, then the question is whether this is the ability to think to act or the ability to think to know. On Descartes' account, the latter is limited by the sort of being that we are. We cannot have knowledge in the same way God does. If the former, then this remains unlimited insofar as we control our actions. Both will for Descartes lead to proofs for God's prior necessity for our existence.

If we look at our ability to will, then we need a cause sufficient to enable infinite willing. The proof is by regression. Either the direct cause of a human can give it a free will or it cannot not. If it can give it a free will, it is omnipotent and possesses a free will. If not, then it is insufficient to produce a truly free will. The latter would lead to an infinite series of real things which is considered unacceptable in medieval metaphysics. Ergo, there must be a cause that is infinite, e.g. God.

If we look at our ability to know, then on Descartes' account, we will discover knowledge of the infinite. This knowledge exceeds our imagination (ability to make things up). Ergo, it must have a real external existence sufficient to merit to our knowledge of it. If it were not infinite, it would need to be similar enough to fool us. We must assume we are not so thoroughly deceived (or wind up in the radical skepticism Descartes rejects). Ergo, our knowledge of the infinite proves there is an infinite, e.g. God.

Needless to say, there are several lines of critiques available to reject both approaches: (1) Descartes' arguments only proves we need a cause that exceeds our ability to know (reject equation between this and God, (2) we don't need to reject the possibility of actual infinities (reject medieval assumption), (3) We can believe that we made up the idea of infinity to fulfill our fantasies (reject connection between logic an reality), (4) we can  assert that we only prove the existence of a being that asserts our capacities not that such a being is identical with God (reject omnipotence of the cause). These are just a few off the top of my head.
My favorite example of a moral philosopher helping resolve--or at least helping to clarify the discourse on--an issue of morality is http://en.wikipedia.org/wiki/Peter_Singer Peter Singer's involvement in animal rights.

He makes a strong (though not inarguable) case for treating animals with much more compassion than we typically do, but without referring to any deities.  So it's certainly possible to reach at least the same level of resolution as one gets from including a religious leader.
You can try to prove it by cases (∨–Elim). The general form is: 


  If you have: ⊢ (A ∨ B),  A ⊢ C, and B ⊢ C
  
  Then you can conclude: (A ∨ B) ⊢ C


This means that if you've proved (A ∨ B) and you have proved (i) C from assumption A, and (ii) C from assumption B, then you have proved C from assumption (A ∨ B). This rule will give you the → direction. 

To get the other direction, that is, from P to P ∨ (P ∧ Q), there is a rule (∨–Intro) to the effect that:


  If you have: ⊢ A
  
  Then you can conclude: ⊢ A ∨ B                                                                          (for any sentence B)


Needless to say, if your system doesn't have those rules, then if it's complete (in the technical sense), then there must be some other set of rules or axioms that will allow you to prove the equivalence; your task in that case is to find those rules and apply them or find those axioms and instantiate them with the appropriate sentence letters.
"Entelechy" has been defined in some slightly differing ways. I was always taught a definition similar to that described by http://en.wikipedia.org/wiki/Potentiality_and_actuality this Wikipedia article.

You could imagine Entelechy as the work required to maintain a particular state - a state which is in some sense an end in itself. Part of it's meaning could be captured by thinking of Homeostasis - a process which works to ensure some proper or advantageous state of being is sustained (constant blood temperature etc). Entelechy could, in this sense, perhaps be contrasted/seen to fit with something like the second law of thermodynamics, which implies that things become less ordered over time unless they do some work to stay ordered by consuming some other resource. This make sense if you consider Aristotle's view of Forms, and his formal cause (which has to deal with the fact of aging both in living things and the public architecture of Athens).

But the final cause seems to be at play in the concept of Entelchy too, and so we have to think about what the final cause of the particular object in question might be (according to Aristotle). For most living things, the Final cause is to do work and produce some effect by it (if I remember correctly, there are passages where he discusses the Final cause of some wild Animals being their useful domestication by man, because that is the state in which they best fulfilled their potential for work). As a result of this sort of conception of the ultimate telos of living things, Enetlechy is the work required once you reach your telos, simply to stay at that point. Remember his view of ethics too - much like the body builder, once we've got our bulging moral muscles, we are still going to have to keep engaging in moral thought and exercise simply to maintain them at the perfect stature. We need to do this with all our "jobs" in general too. 

So perhaps an easily made comparison would be with some one who "sat on their laurels". Or, more academically I guess, the question is in part about the value of expending effort to maintain an existing order. And the contrary of Entelechy? Seems to be something like in-activity. I'm not sure if it's actually possible, under Aristotle, for any living thing to be completely free of Entelechy, or for it not to posses some degree of Entelichal effort, since all beings do posses a final cause, which they are simply more or less capably able to achieve, and it is in the nature of a living thing to be active.
Both Descartes and Luther mean that, for instance, God could have made it so that 2+2=5. Traditional Catholic theologians wouldn't have agreed with that interpretation of God's omnipotence, not least because it isn't a limitation on God's ability to be able to perform an incoherent action. God can't make a round square, not because he lacks some ability, but because there's nothing a round square could be. 
Good question. The same question can be asked of ordinary natural numbers, the negative numbers, infinitesimals as well as various orders of infinity.

The philosophy known as Mathematical Platonism argues that whereas we can see one bottle or three chairs we do not see the numbers one or three, so they contemplate a world outside of time and space - Platos Heaven, where these numbers exist. One could argue this is where we also place the more exotic notions of numbers.

Aristotle when he contemplated the infinite distinguished between actual infinity & potential infinity, and stated that actual infinities cannot exist but that we can imagine a potential infinity.

So, even in Platos Heaven, we cannot find the infinite.

But this doesn't appear to be correct, given what mathematicians have discovered, for they might say, the potential infinity is 1,2,3,...; and we can complete it at the first ordinal omega,- which I'll write as w; but then our friend, who has been watching this demonstration, and who rather mysteriously calls himself Socrates, says

"well, that isn't truly infinity - infinity is where you stop because you cannot go further, but I see here that you can, for I can continue with w+1, w+2, ..; and then one completes this one gets 2w! And so the pattern repeats, whenever the series is completed, we can see it again as the first term in a new series". 

In mathematical parlance w is the smallest infinite ordinal, and its cardinality is equal to the smallest infinite cardinal; the next infinite cardinal, when is at an immense distance when looked at ordinally. We've already discussed the following series

ie 1,2,3,..., w,w+1,W+2,..,w2,w3,..w^2,..,w^3,..,w^w,..w^w^w,..,w^w^w^...

and this completes at what is called epsilon-0. This is still much smaller than the first uncountable ordinal, which is called omega-1. In fact to reach this using the kind of notation we've been doing is impossible, and there is an ordinal that measures exactly this called the Church-Kleene ordinal - omega-1-CK.

And this brings in a very useful understanding of what ordinals can be said to measure, at least in mathematical terms - that is proof-theoretic strength. The strength of arithemtic is epsilon-0; a natrual way to understand this is to imagine a proof of a theorem as a tree of propositions and note that trees are have ordinal type epsilon-0.

So at least we know that ordinals are useful to mathematician, in that they can be applied to something outside the theory of ordinals themselves. But this, though diverting, doesn't tackle your central complaint, which is are these ordinals obtained in the real world.

Now the paradox you mention is reminiscent of Zenos paradox of Achilles & the tortoise; and you mention the classical solution to this problem. Another solution is that there is physically a limit to subdivision - the atomic structure of matter, and perhaps of space.

However, as one begins to think about them, as you have, one begins to realise that the classical solution is only a solution, and perhaps not the only solution, and even perhaps the wrong solution - meaning not the best.

Socrates, again steps in here and says:

"Well, this is all very well, and very good; but this all about infinity in the guise of magnitude; and there are other senses in which this mysterious term the infinite can be used. What about the all? I see for example, in set theory one has the universal set, the set that contains everything, and so must contain every ingenious conception that you have of the infinite, and in fact those which you haven't conceived of yet".

Of course, Russell discovered that this notion leads directly to a paradox, which he solved by inventing type theory, and then one sees that again one gets a hierarchy, types, types of types, types of types of types...; so however one looks at it, infinity is not itself within mathematics, it always remains in potentia.

Socrates interrupts here, "you forget Spinoza, he had a beautiful system for describing everything, the all - the infinite of extension and thought, the reality of the real and the unreality of the unreal as minor modes in the major mode of the infinite of the Good and God; for whilst Plato showed us three worlds and Descarte reduced this to two, Spinoza asked - why two? - if there is one, it is sufficient unto itself, but where there is two, there will be more. It is possibly too beautiful to be true; possibly too beautiful to be understood".

Yes, and too beautiful to be untrue and too beautiful to explain... 
Here you are slightly abusing logic. 2 omega is not 1 omega by "ABSOLUTE" value they are same by the ORDER of magnitude, which means it is same Type of infinity. So by order of magnitude yes you are correct they will be at the same time. But by "ABSOLUTE" value of time B will be slower. It is a question of a debate/thinking/research how to operate with infinity. Clearly what is possible is to compare ORDER of infinities magnitude but not EXACT absolute value, which based on this example ALSO may exist.

  
    how can we study and understand a language?
  


We do not learn the language "by definition", i.e. through a dictionary.

In order to understand the language learning process we may assume (see the theory about "innatism" of Noam Chomsky) the existence of some sort of "mental software" that drive the "bootstrap" process of language aquisition.

We "know" what "mother" is far in advance of being able to read or to "understand" a definition.


  
    all language,including English,have only finitely many words,so you cannot ask forever,one day all words are finished,it goes back to the first word.
  


Exactly so: if you pick up a word i the dictionary and "build up" a tree (in the mathematical sense) using the definitions, surely you will find , well before having finished reading the dictionary, a word that you have already met.

The "process" is circular : there is no set of "initial" words (known by "ostension" ?) such that all other words can be defined/explained in terms of them. 
Depends on what you take a "construction" to be.  Some self-described constructivists accept the Axiom of Choice (Bishop) and therefore accepts the existence of all reals.  Other constructivists do not accept their existence, although as far as I know, everyone thinks their expression is well-formed.  While the common way of expressing a real is "something you approach by a sequence of rationals, which is not rational" it isn't necessary to do so.  You can just ask "Does this sequence converge, and if so, does it converge to a point that exists?"  Some constructivists would agree that the sequence converges (distances become arbitrarily constrained as the sequence continues), but that it does not converge to a point.  I suppose a very hard-lining finitist constructivist might not accept the formulation of infinite sequences, but that's a pretty zealous constructivist.  
Most customers are honest, when customer is actually are the one in the wrong they generally are honest mistakes. The deliberate cheaters are generally the rarity.

Businesses that practices "Customer is always right" has weighed in the risks and benefits from cheaters taking advantage of the system versus the queue that will build up while the employee is arguing with the customer versus other customer's perception if such argument escalates versus customer's disappointment that will inevitably show up even when it's definitively proven that they are the one in the wrong versus the case the customer's delight when their issue is resolved quickly if the employee is the one in the wrong.

Making a "Customer is always right" as a blanket policy also protects employees from being personally responsible for deciding whether or not the customer is right in their claims. It short cuts the decision making process and given that they want to keep things in the line moving as fast as possible, such interruptions need to be resolved as promptly as possible.

"Customer is always right" is not a statement about truth, it is a business policy to assume that to be the case since insisting on the truth is not necessarily advantageous to the business. Especially when you consider that most sales in a McDonald is worth less than some tens of dollars, the cost of figuring out the truth is going to significantly cut into the profit from the sales and potential sales even if they prove themselves correct.
Since you didn't provide a specific author, I'll try to summarize then defend postmodernism as a whole, which is impossible since postmodernism is not one belief and critically any attempt to do so will fall short because of the often-conflicting beliefs of the different postmodernists.


  I see postmodernism as a counter-attack: "modern science is just as valid as any other source of knowledge".


In general, postmodernism pisses off people that are committed to objective truth, but it does so indiscriminately. Postmodernism is not one specific belief, but a short and mostly incorrect summary of it would be that it says some objective truths aren't as objective as we think and also says that objective truth can lead to evil. Maybe you're referring to a specific author which we could provide more useful answers to?


  This authors also say that "modern science is deterministic"


Again, I don't know who you are talking about, but it's likely that their saying science has bias (this is the other thing much of postmodernism says: we have no clue how much bias we have (yep, that's how bias works) (and postmodernism has examples of this, even if they are complex)).


  modern science ... never gives us certainty


Sure, but we still make decisions based on that uncertainty (and bias).


  Some of the tactics of these authors is to hide their usual lack of meaning behind a tall wall of dense prose, senseless phrases and illegible paragraphs.


Briefly, mostly wrong, but probably the only thing that applies to a significant portion of postmodernists: They do that to confuse you and that is good because confusion causes us to question our beliefs (and therefore biases). Obviously specific authors have their own reasons.


  their effect is: ... 2) the lack of scientific training (maths, statistics) 


????


  makes the student accept without doubt those scarce clear passages where modern science is attacked


and that is good, because the passage challenges us to look at the biases in modern science


  Finally, putting the scientific/logic work in doubt, the power is not given to "the peoples", but for those that already have the infrastructure


Science is infrastructure just as much as anything else.


  I think it's because of postmodernism that we're watching this XXI century recrudescence of religion


Nah. Postmodernism hates religion just as much as science that claims it has objective truth. And it likes science that continuously reevaluates it's foundations.

It does however attack the way in which society interprets some science, but only in specific cases that are identifiably bad. It's likely that you author is also generalizing this: society uses science to justify it's biases and science itself is affected by those biases, so be critical of people that claim "science" as a reason because they probably have biases that they are doing so because of and also by doing so reinforce those biases.

Also correlation is not causation.


  So I want to ask the philosophers here: does this "metanarrative" make sense to you? Is postmodernism pro abrahamic religions (in a disguised way)?


Not at all. You'll find plenty of Marxist postmodernists, for example. It's true that some postmodernists (or most) don't see anything objectively wrong with religion, but that's easily explained by the fact that many don't believe in the moral value of objective truth (so what if it's true? it's bad (usually something like causing people to kill others, but postmodernists differ on their value systems) (in fact I'd say political correctness is postmodern)), so even if religion is objectively false, that doesn't make it objectively bad.
Ayn Rand (Objectivism):


  Freedom, in a political context, means freedom from government
  coercion. It does not mean freedom from the landlord, or freedom from
  the employer, or freedom from the laws of nature which do not provide
  men with automatic prosperity. It means freedom from the coercive
  power of the state—and nothing else.


http://aynrandlexicon.com/lexicon/freedom.html http://aynrandlexicon.com/lexicon/freedom.html

Ludwig von Mises (Human Action Chapter XV Section 6):


  Only within the frame of a social system can a meaning be attached to
  the term freedom. As a praxeological term, freedom refers to the
  sphere within which a acting individual is in a position to choose
  between alternative modes of action. A man is free in so far as he is
  permitted to choose ends and the means to be used for the attainment
  of those ends. A man's freedom is most rigidly restricted by the laws
  of nature as well as by the laws of praxeology. He cannot attain ends
  which are incompatible with one another. If he chooses to indulge in
  gratifications that produce definite effects upon the functioning of
  his body or his mind, he must put up with these consequences. It would
  be inexpedient to say that man is not free because he cannot enjoy the
  pleasures of indulgence in certain drugs without being affected by
  their inevitable results, commonly considered as highly undesirable.
  While this is admitted by and large by all reasonable people, there is
  no such unanimity with regard to the appreciation of the laws of
  praxeology.


http://mises.org/humanaction/chap15sec6.asp http://mises.org/humanaction/chap15sec6.asp

Also, you can fly provided you have enough money for a plane ticket. You can't float unaided. I don't know of any philosopher who claims you're not free because you can't float unaided.
Philosophy--because none of it makes any sense.
Most philosophers would hold that all three of those terms are synonymous. The seminal paper on this question is Quine's On What There Is. For Quine the only things that exist are physical objects. 

However, this wasn't the view of some very important ancient philosophers like Aristotle and there are at least a very few contemporary philosophers who would hold that different kinds of thing exist in different ways. One of these folks is Kris McDaniels, who has a paper called Ways of Being or something like that.
Sartre's theory in Being and Nothingness isn't especially alive. There are several reasons for this. First, Sartre himself moved past his own theory in some of his later works specifically * Critique of Dialectical Reason* (which are by and large less read). I'm sure you can learn more about that angle in the entry on the http://plato.stanford.edu/entries/sartre/ Stanford Encyclopedia of Philosophy.

While I've read a decent amount of Sartre, I am most familiar with Part III ("Being for Others"). Here, there are several lines of critique. Sartre's account of how we relate to others is a dialectical approach which in some ways echoes Hegel. But there are elements of his account that are much more negative about human nature than Hegel's. For Hegel, everything will get better and we are meant for community with other humans. For Sartre, we're sex-crazed jerks who want to possess and control others, and the thought of being someone else's object is the most repugnant thing to us. But is Sartre right about this? His most compelling account is about a peeping tom who has the impression of being seen. But there may be other cases that are more appropriate for understanding how humans relate -- parents enjoying being looked at by their babies or such. He mentions this in a footnote explaining that his account presumes there's no possibility of good relationship with others.

Second, one could object to phenomenology more broadly and argue that it does not get us to the truth. Instead, they would maintain that we either need to switch to a hermeneutic method, deal with metaphysics proper directly, reduce everything to science, or be skeptical about any of these ideas. Sartre doesn't seem to have much arrayed against this. A further problem is that Sartre's dialectic is one that lacks the possibility of consciousness-together in a positive sense. In other words, it's Hegel stripped of necessity.

A third angle of objection is that Sartre doesn't contemplate a world with a prior relationship (God or the Other). This matters because if there is a relational God, then the relational system is utterly changed from his account. This objection's force is that if there's a consciousness there that should have priority over mine, then my weird resistance to getting along is kind of moot.
This would be described by a "correct" usage of https://en.wikipedia.org/wiki/Exception_that_proves_the_rule the exception that proves the rule. By specifying boys when perhaps you don't need to (you could say "unruly children"), the contrary of your statement applies for those children who are not boys.

Quite often "the exception that proves the rule" is taken to mean "X therefore not X in general", which is logically incorrect, but not what is meant here.

Generally the utterance "boys can't play" does in fact imply "girls can". Because if both could play, or none could play, you either wouldn't say anything  or would say "children". There is more information in what you say.

It's less clear in cases where there is an adjective, as it is difficult to determine the assumptions that are implicitly made. If you say "boys can't play" it's clear this is applied with a group of children in mind. But if you say "unruly boys can't play" its unclear whether the group you have in mind: all the children, the unruly ones, the girls, or less likely the not-unruly girls and the unruly boys.

So the "unruly" case is using the exception that proves the rule where perhaps it shouldn't. Is it a fallacy with a name, who knows. The exception-that-proves-the-rule-when-it-doesn't-fallacy?
I think one can read Parmenides's claim as saying that intentional properties (being thought about etc.) are existence entailing. So your first construal of that claim is quite right. But notice that Parmenides's has some modal flavour, which is also implicit in the usual understanding of property entailment. So you should prefix your first construal with some operator of (metaphysical) necessity. 

Your second construal is not equivalent to your first. For otherwise 'Necessarily for all x, if x is human, then x is an animal' and 'Necessarily for all x, if x is not human, then x is not an animal' would be equivalent. But obviously they are not, since the first claim is true and the second is false. You're simply misapplying the usual rules of contraposition for material (or, for that matter, strict) implication.   
The expression "comes from" is ill-defined (in an extreme way - most terms we use in our daily languages are just "ill-defined" - because there's no obvious way to objectively define it). Where does smoke come from? Perhaps it comes from a burning object. Oh, stop it: it comes from a chemical reaction between oxygen and some other chemical component. Are you nuts!? Smoke is nothing but a chemical reaction, and all elements come, ultimately, from the Big Bang!

It all depends on where you would prefer to, mentally, stop that chain, beginning on the thing itself and ending with the Big Bang. There was no time before Big Bang, so "before" the Big Bang makes no sense: "before" is a time adverb, so we need to have time to have "before". 

It seem's to me to make much more sense to simply understand and accept that chain, and try to build a valid model of it, something like a sequence of ordered (indexed) events. So when someone asks where does x comes from, you answer with the previous event in that chain. When you reach index 0 (or 1, for the MatLab users :p ), you simply answer: "there's no before when there's no time".
large cardinals can't be proved - they're additional axioms of infinity, the usual infinity axiom in ZF can be regarded as the smallest infinity axiom. The reason why mathematicians investigate them is because they reveal a rich structure amongst other things. They also come up when asking natural questions - in the mathematicians sense - about model theory. This is reminiscent of how imaginary, irrational or infinitesimal numbers were discovered.

Godels incompleteness theorem here is something of a red herring. What can one one prove if I give you nothing to start out with?

Mathematicians do not use proof in a simple-minded way, the Philosopher of science, Whitehead put it well - that its the general structure and coherence that is revealed that affirms that the axioms model something that one wishes to explore.
The book is a very old one : 2nd ed 1903; 1st ed 1890.

As you can see from footnote page 131, Cantor and Dedekind are mentioned as "interesting contributions to the literature of the subject" ...

Thus, you cannot expect that the concepts introduced at the beginning without definition, used as primitive in order to "elucidate" the following treatment, can be exactly translated into modern (i.e.post-1930) set-theoretical notions.

I think that :


  group must mean a finite collection of objects (things)


and that :


  number of things in a group is "clearly" (from the discussion) the equivalent of modern cardinality (restricted to finite collections) and it is called a "property" of the collection (group).


My interpretation is that things are "individual", concrete or abstract (if any). Of course, it is easy to think to them as concrete objects, like peebles in a pocket or soldier in a platoon.

A platoon is a group of soldiers and the number of things in the platoon is the number of individual soldier forming it.

This interpretation makes sense also with regards to the ensuing definition of addition (see CoolHandLouis's answer).

Please, note that here group has the "generic" meaning of collection or aggregate; it has nothing to do with the technical term "group" of group theory.

When we "abstract" from the "characters" of the individual things (i.e.form their individual properties, like colour, size, shape for a colelction of balls) and from the order of the objects in the collection (it is the same for the "modern" set concept: { A,B,C } is "the same" set as { C,B,A }) what we obtain is the "number" of the things in the group (the number of the members of the collection).

Remember that Cantor's original notation for representing the http://mathworld.wolfram.com/CardinalNumber.html Cardinal number of the set A was a "double overbar" over A :


  
    the symbol for a set  annotated with a single overbar over A indicated A stripped of any structure besides order, hence it represented the order type of the set. A double overbar over A then indicated stripping the order from the set and thus indicated the cardinal number of the set.
  

Tom! As far as I know, there are no such thing as "absolute concepts." We do have absolute propositions and statements which involve a concept predicated upon a subject in an absolute way. 

So absoluteness in logic must be a property of an act of predication not of concepts per se. God's attributes are examples of absolute predications. e.g. God is all-powerful.

Another example would be 2+2=4 which is an absolute statement, that is, always true.
In order to prove that a book is inspired by God, it would have to be the only possible explanation. And prediction of scientific discoveries could be potentially achieved by a time traveller of some sort, or another entity from the past able to predict the future.

Let's consider a prediction as accurate as possible:


  1 In the beginning God created the heavens and the earth,
  provoking cosmic microwave background which would be accurately
  discovered in 1978 by Arno Penzias and Robert Woodrow Wilson.


This would be amazing, but can have been written by either an entity from the past knowing the future, or an entity from the future having travelled in the past. While it would definitely be an argument in favor of the book being the word of God, it would not be a proof.
Etymologically, the word for "wave" is connected to that of "water", so it would seem to go back to Thales. Latin http://www.perseus.tufts.edu/hopper/morph?l=unda&la=la unda comes from the Sanscrit "to be wet".

The Greek word for wave is http://www.perseus.tufts.edu/hopper/morph?l=ku=ma κῦμα = "anything swollen" (or hollowed out).
This really revolves around a misunderstanding of dimension and space. Lets stick with General relativity which has a four-dimensional manifold of spacetime. The larger dimensions come from string theory - and there the theory hasn't been justified by experimental proof yet.

Kant is interested in the immediate perception of spacetime, which for us is space and time, and not the two together.

To put it into more simple-minded terms, a cup is a bunch of atoms when looked at under an electron microscope or just thought about in physical thinking, but in your immediate perception it is a cup, with shape, volume, mass and weight, colour and substance.

Its in those categories that Kant is thinking through his critical theory - and not in Physics terms - this isn't to say that Physics is wrong, but they are looking at the world in a very different fashion to how Kant is.
Yes and no (stack exchange is pretty horrible for philosophy eh?)


Badiou is affirming that mathematics = ontology. The status of ontology (being or beings) is hereby sutured to the procedure of mathematics. While we can debate whether or not this is possible or if we like it, in Badiou's philosophy, the transcendental is divorced from its Kantian signification of a supersensible noumena that we can't say anything about and becomes "thinkable" as the One via the language of mathematics. This preservation-destruction of the transcendental occurs in the moment of the "event" where the transcendental is deduced as the regulative "count-as-one" that iterates the event and comprises it within a sequence of events. 
In "the last instance" (I mean this in terms of what his project accomplishes), Badiou's Platonism is a hysterical conservatism that hides a betrayal-realization of the original Platonic notion of forms by lending them some sort of dialectical inertia that destabilizes and complicates the notion of the One = the True. In other words, what Badiou has done is more Hegelian than Platonic: he united being with logic via math so that the transcendental becomes either a mathematical constant or a function. Regardless, for Badiou, it is the "appearance" of the transcendental that authorizes philosophy. So here it is somewhat fair to say that Badiou is returning to the transcendental (this is Francois Laurelle's critique) or recentering philosophy around it. 
However, the transcendental actually does very little in Badiou's philosophy--math is the workhorse that explains the transcendental (by not reducing it to the virtual or subsuming it under the symbolic-real--here Badiou's enemy is obviously Deleuze and the "spontaneous philosophy of the Lacanians"). It would seem that the Platonic inheritance is weighted on the side of mathematics and not the transcendental as it is traditionally understood. The return, then, is to math which is reimagined as the "traditional" center of philosophy in a reversal of the philo-fiction which treats philosophy as anterior to math. The question is what this allows, i.e. what the mathematically preserved transcendental "smuggles" into his philosophy.

A similar question was posted on https://philosophy.stackexchange.com/questions/8814/does-wittgensteins-own-solution-to-russells-paradox-actually-work SE and answer, which I've reproduced here:

Wittgenstein is alluding to how Russell himself solved the Paradox - the theory of ramified types. He alludes to this in:


  3.332 No proposition can say anything about itself, because the propositional
  sign cannot be contained in itself (that is the “whole theory of types”).


And he reformulates as


  3.333 A function cannot be its own argument, because the functional sign already contains the prototype of its own argument and it cannot contain itself. 


A functional sign is simply the sign of the function; the function being what the sign signifies. He expands what he means by this:


  If, for example, we suppose that the function F(fx) could be its own argument, then there would be a proposition “F(F(fx))”, and in this the outer function F and the inner function F must have different meanings; 
  
  for the inner has the form g(fx), the outer the form  h(g(fx)). 


That is F(F(fx)) is different from F(F(fx)) because in the expression they signify different things, that is they have different meanings or precisely functions; and only the sign 'F' is common to both, as he affirms:


  Common to both functions is only the letter “F”, which by itself signifies nothing. 


and by


  This is at once clear, if instead of “F(F(u))” we write “There exists g : F(gu). gu = Fu”.
  
  Herewith Russell’s paradox vanishes.


This resolution is also discussed in the paper appended by user4894, Wittgensteins Tractatus 3.333 and Russells Paradox by Urmas Sutrop:


  On the other hand, Ostrow points that there is no paradox. “In ‘F(F(fx))’, the 
  first ‘F’ and the second will not have the same meaning, since, to use Russellian 
  terminology, the first ‘F’ ranges over propositional functions of type n, while the 
  second ranges over functions of type n + 1” (Ostrow 2002: 66-67). In this case the 
  inner and the outer functions play different roles and the common letter F denoting 
  both functions is not confusing at all. This is very promising approach, but 
  unfortunately the Wittgenstein’s formula “(∃φ) : F(φu) . φu = Fu” is not discussed 
  at all in this paper.
  
  Ostrow, Matthew B. (2002) Wittgenstein’s Tractatus: a dialectical interpretation. 

For induction you need to define a rule of how to go from n to n+1. You fail to define a rule of how to go from {Germany, Berlin} to {Germany, Berlin, San Fransisco}.

The rule could be: Add San Fransisco to the set. Of course you can't use that rule to prove that there's an infinitive amount of cities.

Your rule could be: Add a city that's not already in the list. That rule presupposes that there always a city that's not on the list. Basically you would assume what you want to prove. 
Sartre's claim that we are condemned to be free can be understood on a phenomenological level without reference to whether or not we would actually prove free on a final analysis. The important thing to remember here is that Sartre is actually responding both to the phenomenology of Husserl and to the Phenomenology of Spirit by Hegel.

I'll begin with the older text. In Hegel's Phenomenology, freedom and necessity are both truth of the human self. We are free insofar as we are rational beings engaged in thought (ala Kant), but we are determined on several levels: physically, psychologically, and spiritually*. I mark spiritually* with a star because the standard English word is misleading about what that means. First, it does not necessarily mean a religious sort of spirit (nor does it mean a non-religious one though). Second, it also refers to a certain mode of thought which, ,spoiler alert, refers to our acts of consciousness. But these acts of consciousness and their progress to their ultimate form are for Hegel necessitated. As in, he believes we will ultimately improve in these things and arrive at a rational community. Note, that Hegel's version is explicitly metaphysical (in contrast to Kant's skepticism about metaphysics) with metaphysics located on the plane of reason (= spirit) rather than the understanding.

Moving from the direction of the Husserl and Brentano strain of phenomenology, we can suspend questions about the metaphysics of things. Note that this is confusing in two important respects. First, this is not identical to a total agnosticism about metaphysics. Rather, it is a reordering of the question. Second and consequently, this does not entail a disbelief in metaphysics. Instead, what it does entail is an overturning of the dictum that we should only believe that for which we have sufficient evidence and its replacement with we should believe we are seeing what's appearing to us.

This brings us to Sartre. For Sartre, the most real element of our experience is that we are free. In fact, he strongly agrees with Hegel that we are free in the use of our reason on the basis of our own experience --we constantly experience ourselves as choosing. What we don't get from Sartre is a belief that this choosing fates us to something better or is a tool of hyper-advanced reason. Instead, Sartre believes that we can be deeply mistaken in our reason but guided to that place by our freedom. 

Moreover, while the Hegelian account of reason turns out to be social, the Sartrean one focuses on the need for the self to abandon some of this freedom and to be made an object for others to enter community. For Hegel, freedom is naturally limited and subordinated to reason (and the two are brought together as necessity and probability to produce actuality). For Sartre,  there are no phenomenological limits on freedom, but that also means there's nothing that insures that freedom is well-used. Moreover, freedom turns out to be a burden because nothing forces to choose anything. 

Is this good phenomenology? I don't think so at the end of the day. But if you look at the examples and experiences on which Sartre builds his phenomenology the result is not surprising: being a peeping tom, being hated by others, using others as sexual objects, struggling with the other to dominate identity.
It should be kept in mind that Augustine was a proponent of Manichaeism, a form of Gnosticism. He converted to Christianity shortly after Emperor Constantine's decree of a death sentence for all followers of this religion. This isn't much of a jump since Manichaeists already considered themselves to be Christians, but many leaders in the Christian church of that time rejected them on the basis of their beliefs in determinism/predestination (which Augustine taught), the corruption of the flesh (which Augustine also taught), and the idea that knowledge is required for salvation (a tenet of most Gnostic sects).

Perhaps his lack of clarity was in an attempt to avoid a death sentence, lest he be exposed as a Manichaen Gnostic. Granted, it wouldn't be entirely fair to say that Augustine did not convert to Christianity, as he rejected one of the central tenets of Gnosticism: salvation through knowledge (gnosis). Augustine came to believe that knowledge alone was powerless to save a man and change his behavior. So Augustine likely was grappling with the implications of Christian faith, but he brought his Manichaen worldview and background with him.

But to answer the question: yes, he may have been ambiguous for one of two reasons:


To avoid a death sentence (knowing his views were heretical).
Because he was struggling to define and articulate his own views (perhaps even Augustine wasn't entirely sure what he believed).

Leitgeb distinguishes between statements, which are declarative sentences (he calls them 'descriptive sentences'), from propositions, which, unlike statements, are not linguistic objects. Propositions are the sort of objects that can have truth-values. E.g., [that snow is white] is a true proposition (Lecture 2-1).

Once the distinction is made, the key idea is this: statements express propositions, which are then said to be true or false. E.g. "snow is white" is a statement that itself doesn't have a truth-value, but instead expresses the proposition that snow is white, which happens to be true. That's pretty much it.

As regards your "2 + 2 = 4" example, Leitgeb could say this: "2 + 2 = 4" and "two plus two equals four" are two different sentences that express the same proposition. If you call them both 'proposition', then since the two sentences are syntactically distinct, you'll be committed to the claim that "2 + 2 = 4" and "two plus two equals four" are different propositions (this might be okay with you, but I think something is wrong with that). You might find the following analogy between algorithms and programs useful: given a single algorithm (~proposition), there are often multiple programs (~sentences) that implement it.



Leitgeb, Hartmann (2014 Spring) https://www.coursera.org/course/mathphil Introduction to Mathematical Philosophy (Coursera).
Note that Reinhardt cardinals do not provably exist in ZFC. If they were, it would contradict Gödel's theorem. It is the largest cardinal currently defined which is believed to be consistent with ZFC.

As Mozibur notes, you can't have a largest such cardinal, since given a consistent extension of ZFC, you can always (in theory) find a stronger theory which proves the existence of larger cardinals. However, it may be found next week that Reinhard cardinals are actually not consistent with ZFC. That's the tragedy of the incompleteness theorem.

It turns out, however, that if ZFC is consistent, there is a smallest cardinal which is not provably such in ZFC. To show this, you can simply consider the set of all uniquely defined syntactic objects which ZFC proves to be cardinals, and take the smallest cardinal not in that set.

Edit: I missed the fact that Reinhardt cardinals are inconsistent with Choice. You can replace ZFC by ZF everywhere in my comment though, or Reinhardt cardinals by some smaller cardinal numbers (http://cantorsattic.info/Huge superhuge for instance).
A modern philosophical tradition that fits your description is https://en.wikipedia.org/wiki/Deep_ecology Deep Ecology. The label is fairly new, but in various forms these ideas have been present in many philosophies, ideologies and counter-cultures. More modern philosophies tend to begin with the prefix Eco-, such as Ecocommunism, Ecofeminism, Ecosexuality and so forth. Some older examples are https://en.wikipedia.org/wiki/Anarcho-primitivism Anarcho-primitivism and https://en.wikipedia.org/wiki/Feral_%28subculture%29 Feral Subculture. And of course there is various "green" movements that would fit.

Your story makes me think of https://en.wikipedia.org/wiki/Christopher_McCandless Christopher McCandless and the http://www.imdb.com/title/tt0758758/ moving film made about him
Your broader philosophical question is, I think, an easier question to approach from a philosophical view point.


  "What are one's obligations when interacting with someone who may be too generous for their own good?"


Different View Points

The Utilitarian 

Depending on the utilitarian you are most likely morally right to continue to ask for help as long as the following are true.


The unhappiness you would suffer from not asking for and receiving the information is greater than the unhappiness he is suffering from providing the information.
There are no other options that would produce greater utility.


The first criteria is probably fairly easy to assume. If the person is continuing to reply than obviously they are not suffering greatly as they are under no obligation to reply. One could even argue that people who posses knowledge often times give away their knowledge for free because it makes them happy, so this situation could be mutually beneficial. On the opposing side the person could be unhappily giving out information for free in which case you would be morally wrong to continue to ask them for help (provided #2 is true), however interestingly it is also morally wrong for them to continue to give out information if their unhappiness is greater than the unhappiness you would have without the information (again provided #2 is true). You would have to weigh all the exchanges you've had with the person to determine what you think their happiness would be and also examine what your happiness would be without the information in order to determine if the first criteria is true.

The second criteria is important because it is most likely where your morality is called into question. Provided that the first part is true you are morally obligated to look at all other options, such as enrolling in a class, purchasing a book, or even hiring a personal expert on the subject. All options have to accessed. Then within each of these you must consider the happiness of all parties involved. This may seem daunting however their are a few quick questions that could put to rest most of these scenarios. Most likely you are morally right if the other person is gaining happiness through knowing their own charity and possibly living vicariously through a young mind. You are most likely immoral if you could just as easily (if money isn't an issue) enroll in a course and stop pestering someone who has better things to do.

For more info on utilitarianism see the http://en.wikipedia.org/wiki/Utilitarianism wikipedia page and look for instances of the greatest happiness principle.

A Categorical Imperative

If you believe in Kantianism than you must follow these steps. (taken from http://en.wikipedia.org/wiki/Kantianism wikipedia)


Act only according to that maxim whereby you can at the same time will that it should become a universal law.
Act in such a way that you treat humanity, whether in your own person or in the person of any other, never merely as a means to an end, but always at the same time as an end.
Therefore, every rational being must so act as if he were through his maxim always a legislating member in the universal kingdom of ends.


In essence you would have to believe in something like this: "It is morally right to continue to ask for something as long as the other person allows you to." and believe it should be a categorical imperative. 

Bits of Classical Liberalism

It's important to note that you are making a very big assumption in the second half of your question. You propose the idea that you are able to judge whether or not someone else is "too generous for their own good". Classical liberalism calls into question this idea, in terms of government, whether it is up to you to impose your view of the good on another person. So you could conclude that the only obligation that you have to the other person is that you always give them the right not to answer you.

Conclusion

There is no set answer to this question it has to do with what you believe. I hope that you can agree with one of the above points and that one of them answers your question.
Taking the question at face value:


  Can an Omnipotent Being create something so heavy that He can't lift it?


Since said being is omnipotent, the phrase "something so heavy that He can't lift it" describes a logical impossibility. You probably think of the question as creating a kind of arm-wrestle between the being and Itself, but it doesn't. It creates a conflict between what the being can do (including but not limited to creating things and lifting things) and some words you have chosen to string together as if they describe a thing.

You might just as well ask (and this is a fair question) whether an omnipotent being can create a four-sided triangle. A four-sided triangle is another impossible object. To say that "a four-sided triangle" is impossible is to say that there cannot be a polygon with 3 vertices and 4 edges. To say that "something so heavy that He can't lift it" is impossible is to say that there cannot be an object He cannot lift.

Can an omnipotent being create logical contradictions? I don't believe that question is fully resolved across all people who have ever believed in a being they call omnipotent. Either way you have a somewhat-working meaning of the word "omnipotent", but a different meaning in each case. In one case you pretty much have to stop making logical deductions about omnipotent beings (see for example mysticism), in the other case you don't (see for example scholasticism). You can also consider whether you believe logical consistency is in some sense a "real" restriction on what can be, or just a human state of mind that restricts how we conceive of and describe things. The latter could be incorrect or of course could be influenced by an omnipotent being.

For obvious reasons, believers in omnipotent beings are pretty wary of acknowledging specific things that such a being can't do. Still, the "inability" to create logically impossible objects is not universally considered to imply "not omnipotent" by those who believe they can apply logic to the issue. If you feel that it does imply that, then you might need to go back and re-consider whether you're working from the same definition of "omnipotent" as others. If you allow that an omnipotent being can by definition create logical contradictions then for simple purposes it doesn't really matter whether or not omnipotence is self-contradictory. You've already asserted that's no obstacle. So if your question is intended argumentatively, then make sure you haven't created a straw-man by using a definition of "omnipotent" that is different from the definition relevant to whatever you're arguing about.
A great deal is lost in repudiating the analytic/synthetic division.

Philosophers of the early 20th century had high hopes that an account of analyticity could perform vital epistemological work. There were hopes, for instance, that such an account would explain how it is we are able to get our knowledge of mathematics apparently a priori (although Kant himself, with whom the distinction originated, believed mathematical truths were synthetic). 

Even more importantly, many philosophers regard analytic truths as the principle and proper domain of philosophical investigation. This is the central claim of conceptual analysis and is supposed to explain the armchair nature of philosophical investigation.
The reason philosophers don't have to go out and do experiments to learn about the world is because they are not particularly interested in the world. Rather, philosophers investigate our concepts of things in the world. These conceptual/analytic truths can be investigated from the armchair in the usual way - i.e. by using thought experiments to elicit intuitions which are supposed to be deliverances of conceptual and linguistic competence.

Rejecting the idea that there are analytic truths undermines the traditional conception of the subject matter of philosophy AND challenges the principle methodological approach used by philosophers today.

Quines arguments were very influential in his time but are not considered nearly as convincing now, particularly in light of the now-famous response by Grice and Strawson (1956).

It is not entirely clear yet, what is to be gained from giving up on the distinction. The easy answer is that if the distinction is a false or unhelpful one then by repudiating it we get closer to the truth. We also get a different, and perhaps (as suggested by Williamson in his recent book "Philosophy of Philosophy") a more ambitious conception of philosophical investigation.

The Stanford Encyclopedia of Philosophy has an excellent article on the distinction which you can read here: http://plato.stanford.edu/entries/analytic-synthetic/ http://plato.stanford.edu/entries/analytic-synthetic/
One distinction to make clear is that between "deterministic" and "predictable." Predictability is generally not a precondition for determinism. Even if a world is unpredictable by any means, it doesn't directly follow that it could not be deterministic. For example, say a set of all past events X leads to an outcome Y determined by the probability function F(X), as long as F(X) puts some restrictions on the space of possible outcomes and the probabilities for those outcomes, then there is a causal mechanism in place. As such, even if we are given X, which includes all the possible knowledge of past events, we would still not be able able to predict the following event Y. However, we know that some function of X is responsible for determining Y. (By "we" here I mean in general, not just human beings.)

Such a world would still be deterministic in the sense that all prior events (X) completely determine the following Y. Just because Y can take on several possible values, it doesn't mean that Y can then take on just any unrestricted value with equal probabilities. One can think of it as throwing X into a machine, which crunches out Y. No one can ever know how the machine works but we know that it takes X as the input and only uses that information to produce Y.

One view is that a non-deterministic world would be one where given the knowledge of all past events, X, there would still be no set mechanism for determining (not predicting) Y.
Regarding your statement about Buddhism I would refer you to this passage from the http://en.wikipedia.org/wiki/P%C4%81li_Canon Pāli Canon, (the most complete extant early Buddhist canon).

In contradition to your statement, it shows that Buddha expressly does not speculate on cosmology.


  "So, Malunkyaputta, remember what is undeclared by me as undeclared,
  and what is declared by me as declared. And what is undeclared by me?
  'The cosmos is eternal,' is undeclared by me. 'The cosmos is not
  eternal,' is undeclared by me. 'The cosmos is finite'... 'The cosmos
  is infinite,' ... is undeclared by me.
  
  "And why are they undeclared by me? Because they are not connected
  with the goal, are not fundamental to the holy life. They do not lead
  to disenchantment, dispassion, cessation, calming, direct knowledge,
  self-awakening, Unbinding. That's why they are undeclared by me.


Majjhima Nikaya 63, http://www.accesstoinsight.org/tipitaka/mn/mn.063.than.html Cula-Malunkyovada Sutta

Broadly related:


  "Concerning the seen, the heard and the cognized he does not form the
  least notion. That brahmana who does not grasp at a view, with what
  could he be identified in the world?"


Sutta Nipata 4.5, http://www.accesstoinsight.org/tipitaka/kn/snp/snp.4.05.irel.html 'Paramatthaka Sutta: On Views'

Personally, it seems any cosmological prior state of 'nothing' is existentially problematic.

Heidegger analyses the phenomenology of 'nothing' here: http://www.windmills.freeserve.co.uk/mh.htm The distinction between essentia and existentia in Scholasticism, in which 'nothing' is described as "the purest indeterminate possibility of everything possible" - so not an actual state.  However, the Thomist and Suarez schools apparently differ in their philosphical systems in this area, as described in the last section here: http://www.newadvent.org/cathen/05543b.htm Catholic Encyclopedia, Essence and Existence, so it is unclear whether there is a standard view.
This question turns on a confusion. Identity is a relation that holds between objects, but "Nothing" isn't an object. it's like asking whether the non-existent oldest son is the same as my non-existent son that won first prize at the spelling bee. The answer is that the question is meaningless. 

This is the point of the standard Russell-Frege view of the existential quantifier. 

Edit:

An example to clarify. What you're doing here is treating "nothing" like a name, when it isn't. Think of the sentence, "I ate nothing for dinner". That sentence doesn't assert that there is something I ate for dinner which doesn't exist--it asserts that I failed to eat anything at all. There's no object of which "nothing" is the name. Because there's no object "nothing" names there's no meaningful question of which object that object is identical to.
Looks like quality is some kind of mix between conventional beauty(form, craftsmanship) and functional beauty (efficiency, mathematical beauty of underlying algorithms, inner engineering). 

Like with any other beauty i think quality is synonymous to the word - outsanding.
Thus giving it a very broad range of parameters in which it can outstand competitors.

Regarding your question - yes there are philosophical theories.
In your search you found one of the sanest philosopher of all times.
Who really wanted to help humans now. Karl Marx.
His name is overshadowed by idiots, but he himself is very good.

He discusses what is value(quality, because quality affects value) in his great book http://en.wikipedia.org/wiki/Capital,_Volume_I Capital.

Get it right now and start reading or listening (there are audio versions).
Right at the beginning of the Volume 1 he discusses your question.

Last but not least do not be afraid of him because of historical brainwashing - when asked by journalist Karl Marx said - "I am anything but Marxist!"

  If, according to relativity matter is energy condensed,


Ex falso quodlibet.

Relativity does not say that matter is condensed energy. Rather it says that mass (a property of matter) is equivalent to energy (also a property of matter). Given that matter has other properties which are not equivalent to either mass or energy (like electric charge or spin), it is quite obvious that that you cannot equate matter with mass.

Since relativity doesn't say what you think it says, your conditional has a false premise, and therefore you cannot conclude anything from it.

Note that also your assumption that the Higgs particle is the most fundamental particle is, according to current theories, wrong. It is neither more nor less fundamental than e.g. the electron or the Neutrino. For example the electron cannot be made up of Higgs particles because anything made of Higgs has neither charge nor spin.

Maybe you're confused because of the nickname "god particle" for the Higgs particle. In that case, you may be interested to hear that this name was the invention of a publisher who didn't like the originally proposed title of the book which coined the name: "The goddamn particle".

But relativity is in no way threatened by the Higgs mechanism: Mass is still equivalent to energy; it's just that with the Higgs mechanism that energy is an interaction energy with the Higgs field, rather than a separate type of energy.
I wouldn't read any serious metaphysical conclusions into the difference between the simple present and present progressive tenses in English, if for no other reason than that not all natural languages make such a distinction. 
What is wrong with counting only economic value?  The error would be to assume that economic value is synonymous with what you can get people or corporations to pay for.  There are many areas where there is great value but because of structure or timescale you can't get adequate (or any) payment--preserving a common resource or advanced education for all are two examples.  For instance, quite a few Asian countries have targeted science and technology education as an engine for economic growth (Singapore, South Korea, Japan, China, etc.).  Funding for public arts tends to increase the livability of places, attract better workers, etc., though I don't think this is as carefully studied.

If you allow long-term economic impact and indirect effects, it's not so clear to me that these things are not: legitimately in the public good, measurably so, and thus poor decisions can be detected and those making them can be removed if necessary.

There may be other ways around the problem, but are they needed?
To my knowledge this is not part of the Gnostic tradition at least, not part of the Syrian-Egyptian and Persian schools which I am familiar with.

I would suggest googling counter-apologetic sites for a review of this kind of argument. Its certainly a fascinating idea. In solving the problem of God's origins inherent in classical arguments like the Cosmological Argument, the author has managed to torpedo the idea of a prayer answering god because any god that doesn't know what it is like to be inside the universe would have no idea how to interpret the messages.
Why should one suppose that an omnipotent God necessarily has to be good? In the same way that a child might wish to build something up for the pleasure of breaking it, might it not be that God might have an interest in seeing such evils play out?

What if an omnipotent God were to exist beyond what we would consider the remits of good and evil? What if an enlightened curiosity were instead to be unfolding?

In fact, why should we not suppose that the universe is in fact one with such an omnipotent God? What if time and space were but of the fabric of God and that all sentient life forms are but vessels drifting through their short existences gathering the essence of experiences to once again become one with the Creator?

If this last possible interpretation were to be close to the truth then perhaps the answer simply comes down to 'experience'.



Of course an alternative interpretation more in line with traditional religious thoughts would be that these are tribulations and tests to serve the trial-by-fire of the individuals themselves and/ or the ones who care about them - and/ or even the perpetrators of evil acts.



Of course - pointing towards an omnipotent God for reasons why the mad gunman wasn't stopped from going upon his rampage is perhaps to shrug off the role that any individual might have had in seeing to it that such circumstances are prevented or eradicated in the name of good. Perhaps each disaster should be viewed as the tragic peak of an iceberg of incompetence and callousness. Perhaps humanity should play more of a hand in our own destiny.
You can of course define "perfection"--consult a dictionary for an example.

And it is easy enough to come up with an example of perfection: a "perfect square" has four sides of exactly equal length with all interior angles at exactly 90 degrees.  Everything else is less perfect of a square (and the above is the mathematical definition of a perfect square, so there's really no relativity about it).

Questions about what is perfectly good, however, run into all the problems that are encountered when asking about anything to do with "good", which is that people don't agree on what good is and generally do not manage to come into agreement via discussion.

However, if you postulate a function that can evaluate how good something is, G(.), you can use it to come up with a pretty natural version of what "perfection" means in that context, i.e. x is perfect if there is no conceivable y of the same kind of thing as x (let's assume we know how to determine this) such that G(y) > G(x).  This is essentially the notion of perfection used in http://www.princeton.edu/~grosen/puc/phi203/ontological.html Anselm's ontological argument for God.

(Whether such a function is possible is another question.  You probably would end up with a family of such functions, and then you would start talking about perfect-according-to Gk for a particular k.)
To ask "is this random" is a question ambiguous between the two senses of random?
Here, we need to distinguish between epistemic (concerned with what we can know) and metaphysical (concerned with what a thing or system in fact is) conditions for randomness. 

What you are describing is when we epistemically cannot distinguish between randomness and a complex system which makes an events outcome deterministic (or free) rather than random.
In answer to your question as to whether something epistemically random qualifies as random, that would depend greatly on how yo think what we can know relates to reality itself. And it can also depend on the particular case.

So your intuition is right. We might call something random and use it for those purposes even though it is not in fact random on a metaphysical level-- like the random number seed on your computer which depends on jitter in electronic magnetic pulses or on background radiation. But then do we ever care that the thing is metaphysically random rather than random to our knowledge.
For the sake of concreteness let's consider the notion of fatherhood (I'm avoiding the use of 'concept' here because we'll be giving it a technical meaning). From experience we have a certain (probably) informal conception of fatherhood. We know, for example, that everyone has a unique father. We know that no one is his own father. We know that two persons sharing a father are siblings. And so on.

Once we have an informal conception of fatherhood we can choose (or devise) a logical framework (possibly equipped with a semantics or a proof theory) appropriate for the explication of the informal conception. We can choose, for instance, a language system that includes predicate symbols 'F', 'S'. Then we can let 'F(x, y)' be the explication of "x is a father of y", and 'S(x, y)' be the explication of "x and y are siblings". We can then capture all sorts of logical relationships between those predicates, corresponding to our informal conception of those relations. Here are some examples of that:


                      Conception                                                  Explication
  
  
  Everyone has a unique father.                   ∀x ∃y : F(y, x) ∧ ∀z : F(z, x) → z = y.
  No one is his own father.                           ∀x : ¬F(x,x).
  Persons sharing a father are siblings.        ∀x, y : ∃z [F(z,x) ∧ F(z,y)] → S(x,y).
  


This process of explication goes some of the way towards the clarification of the notion of fatherhood. The next step is the process of axiomatization, whereby the truths about fatherhood (or to be precise, about the relation F) are reduced to a number of axioms about F, from which, by means of certain rules of inference, the original body of knowledge about F can be 'restored'. It's important to note that there are lots of 'truths' about fatherhood, but axiomatization aims to capture the logical truths about F, i.e., the set of formulas that are true in any model (or interpretation) of the axioms of F. Now, axiomatization is not a trivial process for interesting cases, so a lot of thought goes into choosing the right subset of the truths about F to be the axioms. E.g., a few properties that could be among the axioms of fatherhood: 


  F is irreflexive:       ¬∃x : F(x, x).
  F is asymmetric:     ∀x,y : F(x, y) → ¬F(y, x).
  F is antitransitive:   ∀x,y, z : [F(x, y) ∧ F(y,z)] → ¬F(x, z).


Those are just some possibilities among many others. Ideally, the set of axioms would meet certain conditions of independence, completeness (with respect to some semantics), and so on. A theory of fatherhood is just such a system of axioms for F closed under the rules of inference. Needless to say, everything is relative to a language. If we had started with a language that had function symbols (f, s) and '∈' but no explicit predicate symbols (F, S), we could either define predicates by putting restrictions on functions, or we could capture the truths about fatherhood using function symbols as follows: 


  (1) would be reformulated as:  ∀x ∃y : f(x) = y ∧ ∀z : f(x) = z → z = y;
  (2) would be reformulated as: ∀x : f(x) ≠ x;
  (3) would be reformulated as: ∀x, y : ∃z [f(x) = z ∧ f(y) = z] → [y ∈ s(x) ∧ x ∈ s(y)]),


Both the explication/concept and the theory of the informal conception of fatherhood are intimately tied to an underlying language, and consequently will look different depending on the choice of that language. That's only my way of looking at things. Someone else thinking about the logic of fatherhood would probably choose a different language and come up with a different set of axioms. 

For a treatment of explication as the process of moving from classificatory to comparative to quantitative concepts (we didn't talk about quantitative concepts above), look at the first chapter ("On Explication") of the following work:

Carnap, R. (1950) Logical Foundations of Probability.
Set theories need not postulate the a priori existence of any objects or structures. ZFC does, however, postulate the existence the empty set (it's zero) and a kind of successor function based on the empty set as a starting point. The resulting set could have infinitely many junk terms that need to selected out using the Separation (Subset) Axiom, leaving only the set of natural numbers, i.e. a subset that satisfies Peano's axioms. 

You could also simply postulate the existence of some Dedekind-infinite set outside of set theory -- not a huge leap of faith. (If such a set does not exist, the universe would be a very dull place indeed.) Then you can extract a subset from it that satisfies PA.

Having shown the existence of a set that satisfies PA by one of these means, you would be quite justified in beginning your development of number theory and analysis by simply defining the natural numbers using PA.
It looks like you're referring to the Everetts http://en.wikipedia.org/wiki/Many-worlds_interpretation many worlds interpretation of Quantum Mechanics. This is a solution of the wavefunction collapse, where one can say a measurement has been made. This possibly requires a little elaboration.

First, measurement is not just what a physicist does when he measures the momentum of an electon or an atom, but what every system does when it reacts to another: One could say here, that the first system 'measures' a property of another system and reacts accordingly; but it is also true that the second system measures the first system and also reacts accordingly.

Secondly, and putting it simply, one could say - at least intuitively - that the wave-function represents the possibilities which hold until a measurement occurs, and then the wave-function 'collapses'. One ought to note that the wave function evolution is deterministic until collapse, and this collapse is non-deterministic; and so a certain value is chosen at random for the measured property.

Classically, since Newton, physicists have expected that the universe to be deterministic and real and this held upto the discovery of General Relativity by Einstein. Quantum Mechanic broke this paradigm it seemed irretrievably and the locus of the problem seemed to be the non-deterministic (ie random) evolution of the wave function collapse and also the interpretation of the wave function as possibitities.

It was Everetts aim to retrieve this deterministic & real character for the then new Quantum Mechanics. He posited then every collapse engenders a new universe. Thus a possibility is no longer a possibility but another dimension of reality. This seems a rather high cost for determinism and realism.

As an interpretation it is intriguing but esoteric, and at least physically one requires something more; does this picture of reality provide us e*explanatory power* - Everett attempted to provide one by deriving the basic http://en.wikipedia.org/wiki/Born_rule Borns Rule from it. There is no consensus as to whether this has been done.

Its worth pointing out, given the eye-catching, media and science-fiction friendly parallel world vista of Everetts that a different and much less well known intepretation, http://en.wikipedia.org/wiki/De_Broglie%E2%80%93Bohm_theory Bohmian Mechanics also retrieves realism and determinism by allowing non-locality - that is faster-than-light signalling.

Now, given the tremendous success of the atomic hypothesis in modern physics, and this covers not just the idea of the classical atom, but also quanta (for are they not discrete?) it seemed only natural to think that perhaps even the very structure of space & time is atomic (there are various research programmes that look at this - spin foam and causal nets), and one expects this structure to appear at the Planck scale.

Then given that there has only a finite time has passed since the creation of the universe (the Big Bang), it appears only a finite number of universes are possible, though their number is increasing exponentially.

Its intriguing to consider what kinds of conditions might want to consider that allows either a countably infinite number of universe, or simply (!) uncountable. Personally, my intuition would be that at least one of the basic categories of physical materialism - matter/energy, space-time and gauge-forces are infinitely divisible. 

But one also should consider that a rule-of-thumb operates in Physics, which is that infinities are to be avoided: one does not have infinite energies, nor an infinite past, and nor an infinite amount of matter, and nor even an infinite expanse of space. On that basis one might want to rule out an infinite number (of whatever cardinality) of worlds.
I think there are real problems with the idea of developing and ethics out of existentialist philosophy. I know Kierkegaard better than Sartre, so I'll say what I think is wrong with his view. 

Kierkegaard thinks that Hume has shown, pace the history of philosophy before him, that morality (understood as a body of universally binding commands that hold for all people at all times and places) cannot be derived from reason. 

Kierkegaard also thinks that Kant has shown, pace Hume, that morality cannot be derived from the passions either, for the passions are individual, contingent and historically variable. 

Kierkegaard thinks that the source for the binding authority of the moral law, therefore, must come neither from reason, nor the passions, but rather the very phenomenon of choosing itself. His idea is something like: If you really have to face up to the terrifying fact that there aren't external, objectively given sources of moral authority and that you just have to take the leap of faith and make a moral choice, then you are going to choose the right thing. Kierkegaard's idea is that the idea of the leap creates anxiety, but that everyone who faces that anxiety authentically will choose to live a moral life. He doesn't mean that whatever they choose WILL be moral--he isn't a subjectivist about morality. He thinks that if you seriously consider, for instance, whether to live a life of sexual debauchery, or marital fidelity then you will realize that marriage and a family is the only choice worth making. 

Kierkegaard is obviously wrong about this. Just realizing that you have to make a choice in no way indicates that you are going to make the right one. I don't see the existentialist point of view here being any superior to Hume's famous dodge that even though there isn't a rational foundation for morality, that doesn't lead to skepticism, because morality is based in the passions and everyone has the same passions. It seems to me that it is shared cultural and historical baggage in the background that is doing all the pushing in the moral theories of the enlightenment. 

If you'd like to hear more about this, I'd recommend chapters 4, 5 and 6 of Alasdair MacIntyre's After Virtue.
According to http://en.wikipedia.org/wiki/Louis_de_Broglie Wikipedia: 


  His 1924 Recherches sur la théorie des quanta (Research on the Theory of the Quanta), introduced his theory of electron waves. This included the wave–particle duality theory of matter, based on the work of Max Planck and Albert Einstein on light. The thesis examiners, unsure of the material, passed his thesis to Einstein for evaluation who endorsed his wave–particle duality proposal wholeheartedly; de Broglie was awarded his doctorate.


Based on this, Einstein seems to have approved of de Broglie's work and therefore Bohmian Mechanics.
First, let's look at the phrase itself. The phrase, "The War on Terror" is a rhetorical construction that follows a long tradition in America:


http://en.wikipedia.org/wiki/War_on_Poverty The War on Poverty
http://en.wikipedia.org/wiki/War_on_Drugs The War on Drugs
http://en.wikipedia.org/wiki/War_on_Cancer The War on Cancer


During World War II, all of American society was mobilized toward one particular goal. Bureaucrats saw this and asked themselves if we could use the same efforts aimed at destruction pointed at other, more noble, targets. (Need to dig up a citation.) So, it has been common in America to speak of any societal mobilization as a "War on something" in the post World War II years, even without a formal declaration of War.

On the other hand, the War on Terror actually is, in some sense, a violent struggle, even if not a formally declared war. However, the formal declaration of war relies on a nation state. Some of the premise for the War on Terror is that there are parts of the world where, although there is an official border, no nation-state effectively controls the area, such as along the Afghanistan-Pakistan border.

I would disagree that it is simply an international police-action. That is one component of it (soldiers coming and acting as a police force), but a police force is not something that takes control of an area in the first place.
As commenters have pointed out, your question could use a lot of clarity concerning what is meant by "an infinite" and "differentiated". Nevertheless, I will push back on one of the examples you have given, namely that of the infinite line. Yes, the line must necessarily be understood to consists of different points - if it were just one point, well, it would be a point, not a line, and would not in any usual sense of the word be understood as infinite. However, I contend that the points that constitute the line are indistinguishable, or as you seem to put it, undifferentiated.

"Now," you would say, "surely the points on the line are differentiated? For we say that this point is at x=0, this one at x=1, etc." Well, we label them like such only after we choose an entirely arbitrary system of labels (namely, a coordinate system with an arbitrary point as its coordinate origin x=0). As a purely geometrical object, a line is a line even before we conceive of coordinate systems. We can understand a line without any reference to coordinate systems or equivalent notions - per Euclid, an infinite straight line is a "breadthless length...which lies evenly with the points on itself" and extends without cessation in either direction. This is also reflected in the fact that historically, the notion of a line predates the notion of a coordinate system.

To explicate this further, we could pick "this" point or "that" point as the coordinate origin x=0, and the line would look exactly the same. For, since the line is straight, we could only tell the two situations apart by measuring the (signed) distance from the origin to a point that we knew was "the same" in both cases; but before we imposed the coordinate system there was nothing to label said point by, and we couldn't possibly tell that it was the same in both cases!

Thus, I think that the sense of "an infinite" and "differentiated" used above, yes, an infinite can be undifferentiated.
We are absolutely allowed to discipline children on Kant's view, and this does not pose a conflict. Kant does not believe children are fully rational. Perhaps, this is merely a bias of his, but it makes it so that we have no reason to not raise up children through a moral catechism (again as in your other question, it is quite clear you've only read the Groundwork -- you need to read the Metaphysics of Morals and for this question Lecture on Ethics).

There are several issues with what you are stating:

(1) Kant does not speak of essences -- it's important not to confuse vocabularies.

(2) You state:


  To be essentially rational is to be bound unconditionally by the requirement of obedience (of the will) to rationality;


This is a weird way to put it. We are for Kant as rational beings bound first to our rationality. Our very distinction from animals (on his view) is that we have pure reason. But our weakness is that unlike angels or God we also experience subjective desires that incompatible with reason that lead us to act from impure motives. We are always bound to rationality whether in ourselves or others but this is not "obedience", it is rational choice. 

(3) You further state:


  When the object of our actions is another person, we encounter their rational essence.


As above, essence is not a Kantian term nor do I know what it would mean to make "another person the object of our actions." Kantian action works in terms of maxims -- which while difficult to define mean something along the lines of:

 "I tell you the truth because you are a human being worthy of respect"


Maybe by object you mean the reason for my action?

Returning to the problem you raise with these oddities in mind, Kant does not think that children have attained full rationality. Instead, he views them as not yet fully rational and in need of discipline to reach maturity. Moreover, Kant has no problem with legal discipline of the masses or enforcement of law. These are not identical with morality -- which has to do with the reasons behind our actions, but Kant has problem with creating civil barriers to immoral action by making the sort of actions that cannot be morally motivated illegal (e.g. the intentional taking of a human life). This is the primary theme of the Rechtlehre ("Metaphysical Principle of Justice" / "Doctrine of Right")  section of the Metaphysics of Morals
There isn't understanding as you distinguish it.  Your distinction is too sharp.  Imagine Roger Federer's understanding of tennis vs. a college tennis player's understanding vs. mine (not so good).  There are degrees for this.

Taking your example, at a certain level, I suppose, it is possible to have a very solid understanding of an automobile, but then there are people like the guys on Car Talk - they have a sophisticated and refined level of understanding that most people will never achieve about cars - or anything else - their entire lifetime.

One thing I have heard stated is that:


  "when you know something, you can use it; when you [master] something, you are used by it."


So, while this doesn't directly offer a rigorous philosophical answer to your question, I suggest that it proposes a more useful pathway to establish a place where your question can flourish.  Unquestionably, there are epistemologically sound answers that philosophers have proposed to this question - I don't know them - but then answer to your question won't be found there.

Think about the paradox of it - if you were to read an answer to this from a renowned philosopher - Heidegger, Hilary Putnam, etc. - you would find yourself with a new gap between what is possible to understand about this topic, and what you already understand.  In receiving your answer, you would be reintroducing the dilemma that necessitated the question.

What is possible is mastery.  Mastery as I understand it is a process; a process where everything undertaken seriously becomes ripe with possibility.  Because, there is no top to this mountain called knowing, everything can be looked at freshly.   Everything is new and not known, and everything is a potential source of learning.   Knowledge is a side effect of the pursuit of mastery.

In areas where I have any degree of mastery (there are maybe one or two), I find that almost every new thing I learn leaves me knowing considerably less than I did before I learned it.  Now I know that thing (to whatever degree I do), but a whole new heretofore unseen world opens up in front of me with new things that I don't know about the world of what I've just learned.  

Pragmatically, the distinctions could be drawn better than I have.  Perhaps the next answer will do that.
This probably cannot be answered per se. Instead, I'm going to answer by just sketching the interpretive field as I understand it.

The general view among contemporary philosophers who interpret Kant is that Kant does not succeed in his proof in Groundwork part 3. This view is held by Christine Korsgaard, Henry Allison, and Allen Wood. Korsgaard offers an alternative where she argues that we attest to this by engaging in action at all. This occurs several places in her corpus but is the basic outcome of Sources of Normativity.

This might be attested by his reduction of this to a fact of reason in Critique of Practical Reason. An attempt at a proof doesn't reoccur in Metaphysics of Morals, but there is something similar in Religion. In that volume, there's a consideration of how character works.

Some see this as a failing of Kant's project as proof his idea of will is empty and his theory too. This is common as criticism from Hegelians and communitarians. Other's think it's replaceable with a different argument.
There are two topics to be distinguished here for discussion: (1) the object language vs metalanguage distinction, and (2) the use of metavariables (which may be distinguished by using a different font, different color, Fraktur!, etc) in logic. I will limit myself to a few brief remarks about (1) and suggest that you look at the works cited at the bottom, and talk about some uses of metavariables in more detail.

                                                §1. Object-language vs Metalanguage

Whenever you have two languages Lo and Lm such that the expressions of Lm are used to talk about the expressions of Lo, the two languages are respectively called 'the object language' and the 'metalanguage'. For example, so far I've been using English both as an object language and a metalanguage. You can notice the spots where I've gone beyond the object level to the meta level by finding the quoted expressions ' 'metalanguage' ' and ' 'the object language' '. Notice that I used double quotes there, because now I'm using English to talk about expressions (e.g. ' 'metalanguage' ') that are used to talk about expressions (e.g. 'metalanguage') of English. 

                                                      §2. Two uses of Metavariables

Teller's boldface capitals are used as metavariables for arbitrary sentences of his object language. Suppose the object language is that of propositional logic:


  Definition 1. (Lo) Given a propositional letter 'p', the language of propositional logic is generated by the following grammar:   φ   :=   p   |   φ′   |   ¬φ   |   (φ ∧ φ).


This tells us that the object language we're working with has the following sort of primitive expressions: "p", "p′", "p′′", "p′′′", etc., as well as compound expressions formed by logically connecting the primitive expressions, e.g.: "p ∧ p′", "¬p′′′", "(p ∧ p′′)", and so on. Now suppose that we want to introduce a helpful connective such as "∨" (inclusive disjunction) into our discussion. I didn't make the alphabet explicit, but Lo does not include the symbol '∨' among its symbols, so we are denied the option of simply positing the following equivalence for all substitutions of 'p', 'p′':


  (2)* (p ∨ p′) ↔ ¬(¬p ∧ ¬p′),


because while "¬(¬p ∧ ¬p′)" belongs to Lo, "(p + p′)" is not part of the object language, which is defined explicitly by (Definition 1) as the smallest set containing 'p' and closed under 'tallying', negation and conjunction. But '∨' is available as a symbol to us at the meta level, so following Teller's convention about using boldface letters for metavariables, we could express (2)* correctly as follows:


  (3) (p + p′) ≡ ¬(¬p ∧ ¬p′), 


where I'm using '+' instead of boldface '∨' (because bold and or don't seem to work well together here), and we're supposing that (3) is closed under uniform substitution. The '≡' symbol is a syntactical equivalence relation that says that whenever you have an expression of form 'φ ≡ ψ' with φ possibly containing metavariables in it and ψ in Lo, you can replace φ with ψ. For examples let's start with a demonstration of the closure under uniform substitution aspect. This sentence:


  (4) (p′′ + ¬p′′),


while not identical to the left side of (3), is a substitution instance of it, because it is the left side of (3) but with 'p′′' substituted for 'p', and '¬p′′' substituted for 'p′'. Therefore, (4), which again, is not in Lo, is syntactically equivalent to an expression, specified by (3), that is in Lo, namely:


  (4′) ¬(¬p′′ ∧ ¬¬p′′).


This talk of 'closure under uniform substitution' is a cannon for shooting birds, so we want to simplify things. The natural way of doing it, as Teller suggests, is to use boldface letters (we'll use Greek instead) to denote metavariables that stand for arbitrary expressions in Lo. For example, we could reformulate (3) in a way that the condition about closure is no longer needed as follows:


  (3′) (φ + ψ′) ≡ ¬(¬φ ∧ ¬ψ′).


Now (3) defines a syntactical equivalence between or-expressions in the metalanguage and their De Morgan equivalent and-expressions in Lo without using any 'p's and closure conditions.

                                                                     References

Carnap, R. (1958) http://rads.stackoverflow.com/amzn/click/0486604535 Introduction to Symbolic Logic and Its Applications; look at p. 5, §12, §15.
Goldfarb, W. (2003) http://rads.stackoverflow.com/amzn/click/0872206602 Deductive Logic; look at §12.
Quine, W.V. (1940) http://rads.stackoverflow.com/amzn/click/0674554515 Mathematical Logic; look at §§4–6.
Question assumes that:

1.) Not negotiating with terrorists is an actual policy the U.S. follows (it's not*)


http://www.thedailybeast.com/articles/2014/06/10/the-right-didn-t-mind-when-bush-paid-a-ransom-to-terrorists.html http://www.thedailybeast.com/articles/2014/06/10/the-right-didn-t-mind-when-bush-paid-a-ransom-to-terrorists.html
http://en.wikipedia.org/wiki/Iran%E2%80%93Contra_affair http://en.wikipedia.org/wiki/Iran%E2%80%93Contra_affair


2.) That the standard conventions of war should not be applied to the Taliban (who the U.S. declared war in in 2002), just because of an arbitrary political designation of "terrorist" is in play

I propose that "not negotiating with terrorists" is a political tool to attack opponents more than an actual standard to govern by, and as such isn't suitable to actually adhere to.

(Yeah, probably wrong area for this question.  I already worked up my response so going to leave it.)

News From Nowhere by William Morris; written as a novel and its content is post-revolution age. I strongly recommend it.
Ecotopia: The Notebooks and Reports of William Weston by Ernest Callenbach


Here the some futuristic dystopian novels (according to their age of course) :


1984 by George Orwell 
We by Yevgeni Zamyatin
Hunger Games by Suzanne Collins is a popular and famous not only movie bu actually a novel; may not be a full dystopia, but its dystopic.
Jennifer Government by Max Barry; its also dystopic.


And list goes on. All these books contain the same thing: a different living styles of civilization, a different  form of government, society etc. a whole different point of view. 
Your consideration is supported by Benson Mates, https://books.google.it/books?id=3jmQoAEACAAJ Stoic Logic (1953), page 47 :


  Is Diodorean implication the so-called "strict implication" of C.I.Lewis? [...] For, according to Diodorus, whatever is true for all time is necessarily true; thus, any conditional which would satisfy his requirements for truth would also satisfy his requirements for necessary truth. 


And see page 55 :


  Chrysippus, with reference to the (material) conditional, "If anyone is born under the Dog Star, then he will not be drowned in the sea," recommends that it be expresed as a negated conjunction, "Not both: someone is born under the Dog Star and he will be drowned in the sea." 
  
  He recommends this, incidentally, so that people will not be misled into supposing that a true material conditional indicates a necessary connection in nature. 

Actually, the Pyrrhonist position is much more nuanced than that.  They do allow for the evidence of the senses and reasonable inferences therefrom.  As the saying goes, "if I see smoke, I judge there is fire".

Another way of looking at it is this; what KINDS of judgments are the Pyrrhonists avoiding?  Often, it's phrased as avoiding judgment about philosophical things, but this may give the wrong impression about the scope of their epoche.

Have you read Sextus Empricus' http://www.sciacchitano.it/pensatori%20epistemici/scettici/outlines%20of%20pyrronism.pdf Outlines of Pyrrhonism?  It may shed more light on the matter.  Another good resource is http://www.e-reading.club/bookreader.php/134630/Pyrrhonism.pdf this book which goes into some serious detail about Pyrrhonism.  It also compares it with a particular school of Buddhism which helps clarify both schools.

Another interesting angle you could use to shed some light on Pyrrhonism is Phenomenology.  While aiming at a different goal, it adopted techniques and language that should be familiar to those versed in Pyrrhonism.
Crispin Wright in fact denies higher-order vagueness. In that sense he's an anti-realist about that notion. See his recent paper 'The Illusion of Higher-Order Vagueness': 

http://web.mit.edu/philosophy/colloquia/wright.pdf http://web.mit.edu/philosophy/colloquia/wright.pdf

But what does it mean to be a partial versus a universal anti-realist?
At the most basic level, they differ in terms of what they are analyzing. We'll work with your example (in part): It is wrong to kill someone.

A consequentialist theory tells you something is right or wrong based on either the intended or actual consequences. In its classical Utilitarian articulation, it also include a "harm principle" that prohibits harming others in the process of maximizing pleasure. But this harm principle is not justified in terms of maximization -- thus showing one potential problem for these theories. Looking at it "it is wrong to kill someone," the consequentialist says this when there is a negative consequence relative to the valuable commodity lost in killing someone. On such an account, it is conceivable that killing someone could be not merely licensed but morally praiseworthy or possibly even obligatory.

A deontological theory says actions are right or wrong based on whether or not they express the completion of duties or not. Looking at "it is wrong to kill someone," the deontologist tells us that it is wrong because killing someone violates a duty -- either to oneself or to others (possibly including God). On such an account, if killing is wrong as a violation of a fundamental duty, it is always wrong. (It could also be wrong on more contingent grounds -- I promised not to kill you until next week Tuesday so I have a duty to my word and to your promise).

A virtue account generally asks whether they allow the person to flourish and grow. Here, the virtue account tells us it is wrong to kill someone because of how this warps the character of the person and how it fails to demonstrate excellence in response to one's emotions or thoughts. There's a lot of different virtue theories so it's going to be hard to nail down what "virtue theory" says as to when/why it's wrong to kill someone. 

Given these basic sketches, one could see virtue accounts a species of consequentialism centered on a certain idea of the person and its excellence. It's going to be much harder to draw deontology into a consequentialism but it can be done by suggesting that what we are maximizing is the completion of duty. But it won't be identical because you're still evaluating differently when looking at the morality of actions.
it is representential with respect to a presentation we percieve(the thing in itself), and motor emulation is a re-reprentation with respect to the presentation we percieve, but a representation with respect to presentation* which we percieve with our senses.
*: which is itself a representation of the presentation (the thing in itself)we percieve.
here I assume a dualistic view, which is subject to several doubts, maybe we can consume that all is representation and perceiving a presentation is not the case anymore.
In your question, you state the following:


  I have never had the feeling that I can control  my will, and my perceived freedom of choice is (or at least feels like) a choice of acting on one will over another, not of choosing what to will. 


I'm not sure I grasp how you are using the word "will" in your question formulation, but it sounds at least in part like you've transposed some terms from the classical formulation which has its origin in Augustine (and to a much less developed extent Aristotle).

Aristotle refers to willing and acts of willing but not to a will as a distinct entity in the self versus practical reason (phronesis). One particular weakness of Aristotle's account is a discussion historically called akrasia and more recently called "weakness of the will." The  classic problem which occupied Aristotle was that the practical syllogism says that if you know the right thing to do, then you will do it. Thus, right action seems to follow immediately from knowledge. (This is Nicomachean Ethics Book VII for the weakness of the will problem)

Augustine has a much more robust notion that we have a faculty in us that is the ability to choose between options presented to us. This is developed in part with reference to a notion of sin around the idea of concupiscence that prevents the self from acting on the knowledge that would lead to right action. (Augustine treats this in on the freedom of the will which is just an extremely difficult text).

This idea of the will as an entity and desire as something that prevents it went rather unchallenged until Kant. (You can find it in Descartes' account of error in the Meditations for instance). With Kant, you begin to have the idea that the freedom of reason to choose is regardless of the data or somewhat in spite of the data. As I read Kant, the choice is between pure reason and one's desires and passions. For Kant, this is about bringing the maxim of one's will in accordance with universal reason.

Another idea where I cannot give you the exact providence is physical determinism which takes choice to be an illusion. (Note the lack of reference to a notion of will). You can find hints of this as far back as Newton, but it really hits full force more recently.



Now back to your quote, The use of "choice" rather than "will" has been become common, perhaps because it has less baggage, or perhaps because the Kantian picture is amenable to our thinking and works with the idea of choice between maxims more than thinking of the will as some faculty with independent standing (here I'm thinking of Christine Korsgaard's work). it sounds like you use "will" where philosophers historically used "desire", "emotion", or possibly "maxim."
http://en.wikipedia.org/wiki/Stress_%28biology%29 Stress is a medical term; it 


  had none of its contemporary connotations before the 1920s It is a form of the Middle English destresse, derived via Old French from the Latin stringere, "to draw tight." 


and originated from usage


  in physics to refer to the internal distribution of a force exerted on a material body, resulting in strain. In the 1920s and 1930s, biological and psychological circles occasionally used the term to refer to a mental strain or to a harmful environmental agent that could cause illness.


In this form, one can relate it in Buddhist Philosophy to the important notion of http://en.wikipedia.org/wiki/Dukkha dukkha and is 


  commonly translated as "suffering", "anxiety", "stress", or "unsatisfactoriness"...[its] commonly explained according to three different categories:
  
  
  The obvious physical and mental suffering associated with birth, growing old, illness and dying. [This dukkha that relates phenomenologicaly to mortality; and our consciousness of this].
  The anxiety or stress of trying to hold onto things that are constantly changing. [This is dukkha that relates the externals of life - relationships, family, friends; labour, work and politics]
  A basic unsatisfactoriness pervading all forms of existence, because all forms of life are changing, impermanent and without any inner core or substance. [This dukkha that relates to the metaphysics of existence itself]
  


One notices a threefold expansion of the transitoriness or impermanence from life, to society to the world. One of the principal practices is to control dukkha.

In contemporary European philosophy, following on from the Frankfurt school; and developing a notion from Marx - alienation - is to remove himself from the rhythm of Nature to that of the Factory; to thus divide his being; to alienate himself from himself and to aloows himself to be remolded into a commodity; one understands early Capitalism as the industrialisation of the Body; and middle Capitalism as the industrialisation of the Mind; in the situationist analysis of Guy Debord one becomes distracted by the Spectacle; Simone Weil wrote of the rootlessness of the peoples of Europe (L'Enracinement); and Hannah Arendt diagnosed the arrival of mass society as a melting down of particularities (The Human Coindition); similar sentiments have been also diagnosed by poets; for example the disenchantment of the world by the erasure of traditional Christianity in the reactive http://en.wikipedia.org/wiki/Counter-Enlightenment counter-enlightment has Matthew Arnold predicting in Dover Beach that 


  ignorant armies clash by night 


and Yeats recognised the validity of Nietzsches diagnosis that filled him with forboding, as he wrote in the second coming


  When a vast image out of Spiritus Mundi
  
  Troubles my sight: somewhere in sands of the desert
  
  A shape with lion body and the head of a man,
  
  A gaze blank and pitiless as the sun,


The broad nature of the question makes it easy to align other philosophies that in a broad sense also discuss this subject - for example in Antiquity there was the Roman philosophy of Stoicism, this in many ways is aligned with Buddhism; and the Greek philosophy of Epicurus; and here one might usefully recall http://en.wikipedia.org/wiki/Budai Budai or the laughing Buddha and also the Ruba'iyyat of Omar Khayyam, the Persian Islamic Poet who wrotes the quatrains:


  Here with a Loaf of Bread beneath the Bough,
  
  A Flask of Wine, a Book of Verse - and Thou
  
  Beside me singing in the Wilderness -
  
  And Wilderness is Paradise enow.


since he says:


  Oh, come with old Khayyam, and leave the Wise 
  
  To talk. One thing is certain, that Life flies 
  
  One thing is certain and the rest is Lies 
  
  The Rose that once has blown for ever dies

This problem is only illusory.

In paragraph 1, you are talking about the ability to have an idea. 

In paragraph 2, you are referring to whether that thought has a referent in the real world.

The resolution: the thought exists in your head and is real regardless of whether the thought has a referent or not. Basic reason is that thoughts belong to thinkers. Existence in the world is something else. 
i think having a work ethic is not necessarily ethical but can be consistent with ethics in regards to self-development and virtue. i disagree with "Having a work ethic means being disciplined and hard-working" and rather think that everybody has a work ethic regardless of how disciplined and hard-working they are. I think its more like people with less discipline and who are lazy have a poor work ethic in contrast to people who have more discipline and are hard-working have a strong work ethic. Prudence consistently being the number one virtue for many philosophers implies that in terms of enlightened self development that the more regular, consistently and harder one works in this regard the further one will get in self-development. in this context one could conclude that a strong work ethic is a virtue and that laziness is a vice. Also in Aristotles definition of virtue he says that all virtue is a medium on a continuum of excess and deficiency, so one could say that being a control freak or over achiever could be the excess, and laziness the deficiency, with the virtue of a strong work ethic residing in the correct balance. 
Are you thinking of his theory of 'The Gaze' in Being and Nothingness (chapter 1, section 4)? There are also many other discussions of vision and the visual field in that work. Sartre enters a park and discovers he is alone. He is at the 'still point' of the world, his self is 'focus of its visual kingdom'. But then someone else enters the park: 'the intruder himself stands at his own centre of things'. And so on.
This is my position, which could conceivably be wrong. I am not aware of any unanswered criticisms of it.

There is no infinite regress because justification is impossible, unnecessary and undesirable. If you assess ideas using argument then the arguments have premises and rules of inference and the result of the argument may not be true (or probably true) if the premises and rules of inference are false. You might try to solve this by coming up with a new argument that proves the premises and rules of inference but then you have the same problem with those premises and rules of inference. You might say that some stuff is indubitably true (or probably true), and you can use that as a foundation. But that just means you have cut off a possible avenue of intellectual progress since the foundation can't be explained in terms of anything deeper. And in any case there is nothing that can fill that role. Sense experience won't work since you can misinterpret information from your sense organs, e.g. - optical illusions. Sense organs also fail to record lots of stuff that does exist, e.g. - neutrinos. Scientific instruments aren't infallible either since you can make mistakes in setting them up, in interpreting information from them and so on.

What about Klein's specific argument? This is given here:

http://www.arts.cornell.edu/cag2/papers/Infinitismdebate.pdf http://www.arts.cornell.edu/cag2/papers/Infinitismdebate.pdf

He assumes that justification is possible, necessary and desirable. He then argues that other accounts of justification don't work and that the best objections against infinitism don't work. The objections he addresses are 
(1) You can't do an infinite number of steps. Klein claims that what matters is that there is no proposition that couldn't be justified, even if it isn't actually justified.
(2) If there is such an infinite stack of propositions then at some point they will be so complex that no finite mind can grasp them. Klein claims that the propositions need not increase in complexity in this way.

In reality, Klein's position is not tenable and this is not primarily because you can't make an infinite number of justifications, but, rather, because even the first justification doesn't work.

We don't create knowledge (useful or explanatory information) by showing stuff is true or probably true for reasons so how do we create knowledge? We can only create knowledge by finding mistakes in our current ideas and correcting them piecemeal. You notice a problem with your current ideas, propose solutions, criticise the solutions until only one is left and then find a new problem. We shouldn't say that a theory is false because it hasn't been proven because this applies to all theories. Rather, we should look at what problems it aims to solve and ask whether it solves them. We should look at whether it is compatible with other current knowledge and if not try to figure out the best solution. Should the new idea be discarded or the old idea or can some variant of both solve the problem?

See See "Realism and the Aim of Science" by Karl Popper, especially chapter I and "The Retreat to Commitment" by W. W. Bartley III.
It's worth noting, first of all, that this question is somewhat anachronistic for Marx's own time, as income taxes were not generally levied, except under circumstances of war. The majority of taxation existed in the form of customs duties and property taxes. It's worth noting that these forms of taxation place the largest burden of the tax on the poor rather than the rich (this should be obvious for customs duties, as it is much the same as modern sales tax; that this applies to property taxes, one has to remember that the majority of such receipts would have been drawn from the ownership of land that was then rented out to be used; the tax burden, as with most rented property today, would have raised the rent). Nevertheless, it is worth noting that both Marx and Engels, at times, wrote in favour of progressive incomes taxes, as a means of shifting the burden of taxation from the poor to the rich.

At this point it seems possible to address your second question: given that the burden of taxation in Marx's time (and arguably our own) lies primarily on the poor, especially in the form of taxes which raise the cost of consumption, and given that the revenues of these taxes are used not for social programs (the welfare state does not yet exist at the time Marx is writing), but rather to fund wars and other actions of the state, taxation cannot be a means of returning value to labour; rather, taxation becomes yet another means of oppressing the working classes. Thus, in Capital Marx writes that:


  The modern fiscal system, whose pivot is formed by taxes on the most
  necessary means of subsistence (and therefore by in­creases in their
  price), thus contains within itself the germ of auto­matic
  progression. Over-taxation is not an accidental occurrence, but rather
  a principle. In Holland, therefore, where this system was first
  inaugurated, the great patriot, De Witt, extolled it in his Maxims as
  the best system for making the wage-labourer sub­missive,
  frugal, industrious...and overburdened with work. Here, however,
  we are less concerned with the destructive influence it exercises on
  the situation of the wage-labourer than with the forcible
  expropriation, resulting from it, of peasants and artisans, in short,
  of all the constituents of the lower middle class. There are no two
  opinions about this, even among the bourgeois economists. Its
  effectiveness as an expropriating agent is heightened still fur­ther
  by the system of protection, which forms one of its integral parts.
  (Marx, Capital, p. 921)


So why doesn't Marx portray profit as a wage paid to the owner of capital? In the "Preface to the First Edition," Marx sets his goal as analysing the "the social antagonisms that spring from the natural laws of capitalist production" (Marx, Capital, p. 91) In other words, Marx's aim is not to articulate how goods ought to be distributed---this being what much of modern economics is concerned with (given some definition of ought, i.e., to maximise overall societal wealth, etc.)---but rather, the laws by which capital functions, i.e., the assumptions which underlie a capitalist economy (Marx intends Capital to be a descriptive rather than normative study). From this angle, taxation is really of secondary importance to the more pressing question: how does there come to be something (value) to be taxed?

It is in explaining the genesis of value that Marx invokes the labour theory of value, which, https://philosophy.stackexchange.com/q/14687/1815#comment-34780 as you pointed out, is not unique to Marx; in Marx's own view, he is simply taking over the account of the genesis of value given by the most able defenders of capitalism of his day. Thus, Marx's version of the labour theory of value is not terribly different from Ricardo's. But, then, if value is generated by labour, what is profit? Profit is evidently extracted from the surplus of value generated by labour, but if labour is the only thing which generates value, why should this surplus go to those who owns the means of production? (And this basic contradiction is, in part, why the labour theory of value fell into disuse; note that much of contemporary economics no longer concerns itself with how value is generated, but rather how it is distributed).
Mathematics as a concept may not be value-laden (it's debatable whether concepts or objects of any sort can or cannot have intrinsic value), but mathematics in practice certainly is.  Ask any professional mathematician which of two proofs or axiomatic frameworks is more beautiful and the question will make perfect sense to them.  Since beauty implies a value judgement, mathematicians must have values in regards to axioms and proofs.  But axioms and proofs are all that mathematics is!

Put simply: if art is value-laden, https://www.maa.org/external_archive/devlin/LockhartsLament.pdf so is mathematics.
Although I have limited experience, I have come to the conclusion that if you learn logic, and are good at it, you will be able to apply it to law with no difficulty, that's because logic is used to write the (most?) laws.  
I don't think there's any one answer that all will accept on this question, but to simplify the sorting process for you, the real question you are asking is: "What is a state?" and then within this specifically the question of how such a state relates to its members.

In terms of philosophical theories of the state (in this case the polis), the earliest two philosophers, I know of, in the West who consider this question are Plato and Aristotle. 

For Plato, the state is either a small village (early in the Republic) or a complicated system where the members of the state are split among three roles: philosopher-kings, guardians, and producers (for an extended treatment see here: http://plato.stanford.edu/entries/plato-ethics-politics/ http://plato.stanford.edu/entries/plato-ethics-politics/). On such an account, the parties all agree that this is the best way to accomplish justice as they are enlightened by its presence. On such an account, it makes no sense to split off from the state.

From what I understand, there's a different account in the Laws of how things should be arranged but I'm not familiar with the details.

Moving to Aristotle, Aristotle believed the state was prior to the individual and the family. What this means is that the state is the organic whole of human living (like a hive to bees or pack to dogs). On such an account, it seems unlikely that it would make sense to split off, but it seems distantly conceivable.

Many contemporary Aristotelians are communitarians which means that they think each community is determined by a shared set of values, and that these sets of values are incommensurate with others. On such an account, each community is a polis which can be held together in a larger federation -- but this federation is dissolvable.



Augustine in the City of God adapts elements of Plato's philosophy to present the idea of dual citizenship for Christians in Rome and Heaven. On such an account, the state below is more arbitrary and maleable since the image of justice is through religion not the state.

I'm not familiar enough with Aquinas's account of the state to provide the contours, but I gather it's a somewhat communitarian picture but not overly prone to allowing schisms emphasizing the holistic aspects of the Aristotelian picture.



Moving forward to Hobbes and Locke, we arrive at the idea that the state arises through negotiations of power and the surrendering of the right to bash others in (social contract theory). On such theories, I don't see the ultimate objection to schisms in the state. For instance, it's hard to see why such a contract isn't malleable enough to allow for that as say per se Scotland devolving or something like that.

In this era, we also see the rise of the consideration of notions of sovereignty. For Hobbes, sovereignty occurs either when people contract together and agree to follow a common authority or when people bandy together for mutual protection. This sovereignty is revokable --as makes sense under a contract theory of governance. As ben rudgers suggests, one clear method of revocation is to kill the sovereign. But it's less clear whether a sovereign can allow for secession on the part of some parts of the state. (Source for this paragraph: http://plato.stanford.edu/entries/hobbes-moral/ http://plato.stanford.edu/entries/hobbes-moral/)

For Locke, the contract works in such a way that most freedoms are granted to the citizens by the sovereign, but these are established in nature and self-evident. Thus, insofar as the state is legitimate, there should be no need to schism. Insofar as the state is illegitimate, schism is no longer the right word. 



The Kantian picture of the state is a Republic guided by reason with the power of the state. Such an image depends on a type of federating where the size of the particular state is less important than the unity of the rational whole of humanity.

Hegel is similar to Kant in seeing the state as ultimately a product of reason and similar to Aristotle in seeing the state as an organic whole larger and prior to the individual humans and families that make it up. At  the same time, the Hegelian picture depends on internal conflicts and their modifications. The net result of that is that Hegel would find such dissolution where states break apart to be a temporary resolution until their inevitable reunion in something larger and more complete as an integration between the individuals, families, the community, and Absolute spirit. (long story ...).



There's going to be some other theories to consider as well I'm guessing, but these are the ones I can sketch briefly.
No. The contract has been fulfilled. This medical condition should have been discussed and put forth in the contract. 

However, you may still be left with a moral conundrum. Will you feel bad about this situation? 

The only ethical implications you may face from society would be "did you do your due diligence when coming up with the terms of the contract?" Did you, as a proprietor, establish all required facts/data that were needed to execute your end of the contract? (probing questions) As an example, if the customer ordered a cake, you would probably ask, "what kind of cake? Chocolate? What kind of frosting? (Allergies?) etc. Yet I sincerely doubt that you could be completely held responsible and at fault, because after all- you did deliver what was asked for. It (to me) seems like it should be the customer's responsibility to let you know of any medical conditions that might hinder. 

From the perspective of 'big food', take for example General Mills, it is an ethical (and legal) obligation for them to properly label potential hazards. This is because there is no way for me as a customer to ask specifically and directly to GM, "Does your product contain peanuts?"

Hope this helps... 
In the narrow sense, the answer is yes.  Consider the decimal expansion of pi, 3.14159....  It is an infinite series of numbers, but you can derive any number of finite sequences from it (1415, 314, 159, and so forth).

In the larger sense, this is analogous to the problem of evil (how can an all good God create a world that contains evil), in as much as it is a question of how a perfect being could ever create anything less than perfect (where the finite would be considered as imperfect and the infinite as perfect).

As such, I'm not sure it has a definitive answer, but you might look up considerations of the problem of evil to see how great minds have tackled it.
I think that perhaps the biggest point here is that chemically identical but ethically "clean" dairy products could be developed using humane methods, and this would allow consumption with no ethical ramifications.  However, that isn't immediately viable or what you're asking, so I've attempted to address your sub-points more closely.

a) To borrow from economics, animals could reasonably be held to own everything they produce themselves.  I believe that technology is the long term solution to no intervention:  eventually we put all the humans in spaceship and fly off, leaving Earth as a nature reserve (maybe clean it up a bit first).  The costs of doing this immediately would be incredibly high, even just measuring in terms of animal welfare, but in the mean time I believe equal consideration is a fairly reasonable guide as a global utilitarianism (across species).  As plants don't implement nervous systems, they can be reasonably held to either have no utility curve, or at the very least, the worst possible endocrine distress a plant can experience can be held to be less costly than that of any organism with a nervous system.  I would argue that equal consideration does hold for plants, it's just that they experience pain and utility to a lesser extent due to their structure's natural tendency toward stoicism.

b) Reproduction and associated overhead are not zero cost processes, that is, even if there is sufficient milk for offspring, a maternal mammal would still have to more rapidly deplete her body to provide additional milk.  As this is nonconsensual by definition, it is relatively difficult (but not impossible) to defend morally.  

Attempted defense:

It is important to consider that this probabilistically increased milk production and associated body degradation is a low cost operation, and violation of rights in this case may be globally optimal in equal consideration as, for example, the provision of milk for a human caretaker may be considered a form of mutual welfare or a service purchased with labor.  In some cases, the greater good invalidates the need for consent.  Just as paramedics are permitted to assist unconscious patients incapable of communication, it is not unreasonable to argue that a non-consensual partnership between humans and other animals is not just ethically acceptable, but possibly necessary.  Perhaps a better example is the idea of spaying and neutering cats and dogs- non-consensual, a violation of individual liberties, but generally considered a moral mandate.

As mentioned earlier, eggs are an even more difficult argument, but it could still be made.
I think you're criss-crossing some distinct notions here. First, there are moral senses of terms like "rape" and "assault." Moreover, there are legal senses. Finally, there are psychological senses* of these terms.

The legal sense of rape is (historically) as follows:


  Historically, rape was defined as unlawful sexual intercourse with a
  woman against her will. The essential elements of the crime were
  sexual penetration, force, and lack of consent. Women who were raped
  were expected to have physically resisted to the utmost of their
  powers or their assailant would not be convicted of rape.
  Additionally, a husband could have sex with his wife against her will
  without being charged with rape. (http://legal-dictionary.thefreedictionary.com/rape barely respectable source)


Over time, this definition has shifted, but I will leave the details of how and why out of my account here as the ability of the legal definition to shift is part of what it is.

The moral sense would be some specifies of immoral sexual conduct towards others. This could be managed primarily in terms of rights and responsibilities, pleasure and pain, or virtues. In other words, the use of others for sex against their consent could be understood as wrong because of the pain (psychological or physical) it inflicts on another. Or it could be wrong because violating someone's rights by taking without consent is wrong. Or it could be wrong because of what it does to the person doing it. (These are three rough sketches in terms of utilitarian, deontological, and virtue ethics approaches).

The psychological sense of "rape" would refer to either a rapacious intent in sex or to an experience in someone who undergoes what they experience as a rape. Note that for the psychological sense to occur, it is not necessarily the case that someone has been legally raped.

In your question, you seem to identify the moral and legal senses and to believe that we should change the psychological understanding based on these. There are accounts of morality where all 3 are merely unfolding elements in our understanding of ourselves, but there are also reasons to keep them separate.

At a minimum, a good reason to keep them separate is that legal senses deal with what can be proven. In other words, morality seems larger than legality in terms of wrong it identifies. Moreover, the psychological sense and legal sense seem worthy of separation since it is conceivable that someone have the psychological experience of rape without having been sexually assaulted (raped) on any legal definition -- and conceivably any moral definition.
You're mis-stating Chaos theory. You said: "I understand that chaos theory states that any small event or choice determines the next set of events or actions." 

But actually you need to say that SOME systems are extremely sensitive to small changes in their starting point. Other systems are stable. 

So there can be no counterexample. If you have a system that's stable in a region around a point, that's an example of a system that doesn't happen to be chaotic. It's not a violation of chaos theory. 

That's like saying, Some animals are cats. Can there be a counterexample? A hippopotamus is an animal that's not a cat. But it's not a counterexample to the statement that SOME animals are cats.

Some systems are highly sensitive to changes in their input. Some are not. Some systems are chaotic, some are not. 

And you can't "argue" against chaotic behavior. You can just "do the math," as they say. The points around the boundary of the Mandelbrot set exhibit chaotic behavior. Tiny changes in your starting point produces strikingly different behavior under iteration. That's a fact. You can't argue against it any more than you could argue against trees.
The value in Plato's Forms for how we relate to objects requires that you change the formulation a bit:

(1) You see something, A, small, striped, and with weird eyes
(2) You identify the something, A, you see with Cat [capitalization intended]
(3) You see something else, B, fat, beige-colored, with a tail.
(4) You identify B with Cat


Work of the Form: Cat is what enables you to unify the disparate phenomenon that you see under a single idea.



You can disagree with Plato -- several understandings of knowledge and perception do, but the challenge that the forms answer, at least in part, is: "how do I compare things and put them in categories when everything I see is different?"
Pi is not infinite; indeed it is smaller than the very finite number 4. What is infinite is the number of digits you need to represent pi in decimal representation. But that's a thing it shares with every irrational number, like the square root of 2, the golden mean, or the Euler number e.

Moreover, this cyclic universe you describe was never the mainstream cosmology, and is furthermore contradicted by newer data which tells us that the expansion of the universe accelerates (that's the reason why dark energy was introduced as explanation), which means that the universe most probably will not regather its particles even once, let alone an infinite number of times, but will expand forever.

Note that in all those scenarios, pi has still the same value, because the value of pi is completely unrelated to the fate of the universe; it's a purely mathematical concept, although it is indeed also used in descriptions of the universe. But if you look at real circles, you'll probably find not a single one for which the quotient of circumference and diameter is exactly pi. For one, as we know since Einstein, space is not exactly Euclidean but curved; circles in curved spaces generally have a different quotient of circumference and diameter (although in the vicinity of earth the deviation is too small to be measured). On the other end, from quantum considerations we know that there must be a minimal length on the order of the Planck length (about 1.6*10^-35 meters),  so there's absolutely no way to get infinite precision on anything finite in real space.

And indeed, even if you look at a more formal level, there's one difference between the infinity of the decimal representation of pi, and the infinity of the cyclic universe: The digits of the decimal representation of pi are sequentially numbered by the natural numbers: They go on infinitely, but they have a clear start (the decimal representation of pi starts with 3.14159…). On the other hand, to sequentially number the cycles of the cyclic universe you need the integers: They go on infinitely in both directions. Not only would there be infinitely many cycles in the future, but also there would have been infinitely many cycles in the past.

OK, finally one thing both infinities have in common: Both are countable infinities. That is, you can do an 1:1 mapping between both the cycles of the digits of pi and the natural numbers, and of the cycles of the cyclic universe and the natural numbers (but for the latter only if you don't insist on consecutive cycles getting consecutive numbers).
That's quite a simple one:

Let's use Hume's definition of "a violation of the laws of nature". The "laws of nature" are simply descriptions of the best experimental data we have. 

Our best empirical predictions are under controlled circumstances and predict accurately under those conditions only. 

For example, my friend Steffan may catch an apple before it collides with the earth in violation of our previous experimental data, but this does not contradict empiricism, even if in all experiments so far Steffan has not chosen to catch the apple.

Steffan's externality to experimental data means he is not included in the law of gravity. If Steffan ever caught an experimental apple, it would be experimental error.

(Of course this example is an analogy; I'm not asserting Steffan is divine.)

You may or may not believe I have a friend called Steffan, but you have to accept that if he exists, he may be able to disrupt science's prediction about what will happen to the apple with a to-him trivial intervention. 

There's no need for anyone to reject science just because they believe Steffan exists and sometimes catches apples,  especially if he's taken no interest in any apple experiments so far. 

Your beliefs about science and about Steffan are neither mutually contradictory nor mutually supportive.
Nobody who has the skillset to do what you want is going to do it for free. Professional philosophers and advanced grad students are pretty busy people. Would you ask a medical doctor to help you with your medical article for free? Would you ask a lawyer to help you with your law review article for free?
Pascal's wager is a special case of Pascal's mugging in which the mugger claims infinite power.

I'm not really clear on which formations of the wager and mugging you're discussing as they seem to differ for the originals that I am familiar with, but I will attempt to shed some light on your questions.

==================================================================================


  there's some number you get to where the utility is so high (say, 1 trillion people) where the probability isn't low enough to justify non-action 


To which Robin Hanson would argue:


  Robin Hanson has suggested penalizing the prior probability of
  hypotheses which argue that we are in a surprisingly unique position
  to affect large numbers of other people who cannot symmetrically
  affect us. Since only one in 3^^^^3 people can be in a unique position
  to ordain the existence of at least 3^^^^3 other people who can't have
  a symmetrical effect on this one person, the prior probability would
  be penalized by a factor on the same order as the utility.


http://wiki.lesswrong.com/wiki/Pascal's_mugging Source

Why should I not be able to simply say that it's just as likely that the mugger will make a billion people very happy if I don't give him the money, and so choose not to give him the money?

Or in the original formation:


  Mugger: If you hand me your wallet, I will perform magic that will
  give you an extra 1,000 quadrillion happy days of life.
  
  Pascal: I admit I see no flaw in your mathematics


Well if there were actually people out there that could perform such magic, the probability of meeting one would scale with the power of their magic in theory.  Then, the God of Pascal's wager is just a Pascal mugger (or blesser) with infinite power.  By Robin Hanson's criteria, this infinite power confers an infinite improbability.

==================================================================================


  Why should I not be able to simply say that it's just as likely that the mugger will make a billion people very happy if I don't give him the money, and so choose not to give him the money?


The probabilities being assigned are to the mugger being truthful, not being powerful.
The full quote is:


  Yes, my friends, believe with me in the Dionysian life and the rebirth of tragedy. The age of the Socratic man is over; put on wreaths of Ivy, put the thyrus into your hands, and do not be surprised when tigers and panthers lie down, fawning at your feet. Only dare to be tragic men; for you are to be redeemed. You shall accompany the Dionysian pageant from India to Greece. Prepare yourselves for hard strife but believe in the miracles of your god.


He is talking about the miracles of Dionysius; which rather than the simple, virtuous & good life that Socrates advocates and exemplified by the miracles of the God of Christianity; he advocates ecstasy & terror; the two emotional poles of the Bacchic revels of Greece.

Thus strife; thus tragedy; and thus redemption - a curiously Christian word to use in this context.

Rather the straight & narrow path over a flat plain (the rational path); he advocates the adventurous path, that climbs mountains, and drops into abysses (the irrational path); this path is redeemed because of the applause of your peers; and by your own sense of living life fully.

In Aristotelian terms; rather  than occupying the golden mean of virtue; to take an example - say courage (lache); one traverses all three points; the place of quietism, that of recklessness and that too of virtue. This is a re-evaluation of the Aristotelian virtue of courage; which is identified as the rational path; the path of reason; but as Nietszche opposes this; his path is called irrational; this, one should note, is not the same as crazy, mad or stupid; for Nietzsche used his reason to adopt this position.

Or so it appears; still one might suspect he is misunderstanding Aristotle deliberately...

Further one can apply Kants categorical imperative here and ask can everyone live the Dionysion life; or can everyone live the Apollonian life; a close examination would reveal that this isn't possible; and one is lead to the notion of a stratification of society...
One of the primary problems with considering deconstruction a "method" is that it effaces the complexity and nuance of the actual way by which deconstruction occurs, and reduces it into a mechanistic operation that a reader can perform on a text.  Instead, deconstruction is something that happens within the text, and an outside reader then interprets the results of said process.  If you were to perform a "deconstructionist reading of The Great Gatsby", for instance, you would first look to canonical readings of the text, and see what sorts of definitional frameworks, and thus, binary oppositions, such readings of the text depend on.  A "deconstructionist reading" would require considering what would happen if these binary oppositions either did not exist, or were flipped with the marginalized term coming to the center, with the non-privileged term gaining power over the traditionally powered term. The resulting multiplicity in meaning that is produced within the text, and the reduction of a violent power hierarchy to immanence is deconstruction.  To clarify, deconstruction is NOT what systemic reconsiderations the reader makes to ultimately arrive at multiplicity in meaning.  Deconstruction is what the text does after the reader has made this reconsideration.

To provide an example from Derrida's "Structure, Sign, and Play in the Discourse of the Human Sciences", Derrida talks about the anthropologist Claude Lévi-Strauss's works on the incest taboo.  Lévi-Strauss, an anthropologist, is focused heavily on the development and arising of human culture in contrast to its natural surroundings, and thus many traditional readings of his work rely on the binary opposition of "culture/nature" with culture taking privilege over nature.  Yet, Derrida identifies a moment in the text that contradicts the assumptions made by these traditional readings, and thus shows how the text itself of Lévi-Strauss's work resists all of these traditional readings.  This moment is where Lévi-Strauss describes the taboo on incest as a cultural construct, thus belonging to the side "culture" of the binarism, but simultaneously explains that the incest taboo is a universal phenomenon, and is thus natural - belonging to the "natural" side of the binarism as well.  Lévi-Strauss's incest taboo is an example of what Derrida would call a lost middle, since it does not neatly fit onto one side of the binarism, and calls into question the definitions and frameworks that assert "culture is not nature" and "nature is not culture". So, what Derrida did - sit down at his desk, open up his copy of The Elementary Structures of Kinship by Lévi-Strauss, and underline some passages in the text that show the incest taboo being a lost middle - is not deconstruction.  Instead, the little foible in the text and its calling into question traditional readings of Lévi-Strauss is deconstruction.

And, as Derrida did, I will also offer a disclaimer on what I have written above.  Derrida has long since argued that attempting to simply state, "deconstruction is [X]" effaces its complexity and replaces the idea of deconstruction with some verbiage and weak conceptual understanding that can sate a desire to learn what deconstruction is.  As Paul de Man argued, to understand a concept is effectively to feign understanding and beguile oneself into complacency with a reduced, watered-down explanation.  It is for this reason Derrida himself is very careful about offering examples with which the theory itself can be supplanted with.  But this observation also helps to further explain why Derrida resented calling deconstruction a method - for replacing deconstruction with a formulaic process is a surefire way to do exactly what he feared: reducing, oversimplifying, effacing nuance.
In general, the terms I've used are:


  Bourgeoisie - the capitalist class who own most of society's wealth
  and means of production.
  
  Proletariat - workers or working-class people, regarded collectively


Those seemed to be the most common and applicable terms when I was reading Marx.

EDIT:  Thanks Google!

  Is it justified that we have to respect teachers?


It is most likely in your own best interest to respect teachers so that you don't put them on edge and learn less than you could've from them.  So I think it's in your best interest, yes, which I suppose is a type of justification.

If you considerable evidence to believe you aren't going to learn something from a teacher or would become less educated under a teacher, then respect would be less necessary as a teacher, but I believe you should still respect that teacher as a person if nothing else.


  Isn't that too much.


I doubt it, respect is powerful, costs you nothing at least in a physical sense, and contributes to a global sense of well-being.  If you are concerned you are not being respected, I don't think having less respect in general is the solution to that.


  Does saying good morning ..changes anything ?


Good morning is an extension of your best wishes - a method of voicing support.  Supporting your teacher should enable that teacher to teach better, unless that teacher is functioning under non-standard social protocols, and enable that teacher to better provide instruction.


  I find it useless to respect people unless they earn it.


In that case, if you expect to be respected, you should be sure to take steps to earn respect yourself.  Warning, this is going to get wordy:

The best way to earn to respect is to show respect, so if you want respect you have to respect those that you want to respect you that they might earn your own respect to fulfill the objectives of showing respect.

If they are still failing to earn your respect, then I'd exercise caution but still at least outwardly show signs of respect, because one of the partners in a mutually respectful relationships must be the first to show respect if showing respect is a pre-requisite for earning respect.

Maybe I'll come back and edit the wordiness on this down after I've had some time to break it down a bit, but for now I would just encourage you to try to treat all others with respect at all times as this should be aligned with your own best interests.

==================================================================================

Okay I slept on it and think I may have a better wording here.  I'll leave the old one in case that is easier for some people.

Problem:

Four related conditions as follows.


  X is showing respect to teachers.
  
  Teachers are not showing respect to X.
  
  X doesn't want to show respect to those that don't earn respect.
  
  X believe respect is earned by showing respect.


So X either wants a license not to respect teachers, or the teachers to respect X.

What X can control:

X can show respect or not show respect.

Strategy 1:  X does not show respect.

As X does not show respect, by X's own philosophy teacher's won't show respect.  Therefore no respect is earned and no respect is shown.

It is possible teachers may take initiative to show respect.  I'm not going to cover that possibility as we know X has already taken initiative in this example.

Strategy 2:  X does show respect.

As X shows respect, X is worth of respect.  

Case 1:  If teachers operate under X's philosophy or similar they show respect to X.  Mutual respect earned and shown.

Case 2:  If teachers operate under another philosophy, they may not show respect to X.  X has earned respect but does not receive it, teachers have not earned respect but do receive it.

Determining the optimal strategy then requires understanding pay-offs.  Now, as the purpose of interacting with teachers is education, you could, for example, place a value of infinity on teachers receiving respect and a value of zero on teachers not receiving respect, as this should maximize educational potential.  This would make strategy 2 optimal.  If, however, education is not the aim, and minimizing cost is where respect confers a non-zero cost, then strategy 1 is optimal.

I don't know X's utility curve, but this is the game theory beyond my recommendation.  I do assume a non-zero value on education and a zero cost on showing respect, because that is the curve I operate under and was how I determined my own actions when I was in a circumstance akin to X's, and that is why I will always recommend strategy 2 as optimal.
EDIT 23, September 2015

I am updating my answer because my original reply was based on the misunderstanding that the A-series and the B-series are logically equivalent; this misunderstanding being based on an incorrect http://plato.stanford.edu/entries/time/ SEP article on Time which asserts they are "identical".

Your question asks:  can a proponent of A-theoretic time avoid the contradiction and associated infinite regress of the A-series by using the B-series.  The answer to this question is no.  The reason is that a proponent of A-theoretic time rejects B-theoretic time as an invalid representation of time; the two are mutually exclusive.  And furthermore, the contradiction is not a feature of B-theoretic time - in the B-series, there is no way to express those situations which give rise to McTaggart’s contradiction of A-theoretic time.  So let’s look at why this is the case.

What McTaggart is arguing is that time is an illusion.  He does this by arguing that if time is real, then it must be representable by one of two series, those which he calls the A-series and the B-series.  Either time flows or it does not.  There are not alternatives.  Dynamic, moving time is modeled by the A-series.  Static, unmoving time is modeled by the B-series.

A-theoretic time corresponds to our intuitive notion of time as flowing from the future, through the present, and into the past.  The contradiction and associated infinite regress of A-theoretic time is described in my original reply.  Briefly; no event can be both future and present, past and present, or past and future.  Yet time understood by the A-series implies that as time flows and every event will possess all three incompatible properties - future, present, and past.  Attempts to resolve this contradiction by using tenses leads to an infinite regress which never successfully eliminates the contradiction.

B-theoretic time describes time a unmoving.   The temporal properties of events in time can be regarded as fixed and unmoving.  The temporal relationships of “before” and “after” are fixed eternally.  When we think of one moment in time as being before another, this relationship does not change.  For example, the relationship expressed by “in the year 2015, the year 2100 is in the future” is true now just as it is true in the year 9999.  McTaggart argues that the B-series in not sufficient for an understanding of what time is.   According to McTaggart, we know more about time than just the information represented in the B-series.  In fact, the concept of “the present” is not part of the vocabulary of B-theoretic time.  This is because, McTaggart argues,  that a being capable of knowing (and only knowing) all B-theoretic facts, would know all of the B-series relationships between moments in time, but would not be able to tell you today’s date since he would not be able to identify the present moment.  The “present” is only part of the A-series vocabulary.

To recap,  McTaggart would consider your question to be ill-posed.  Eliminating the contradiction of the A-series by using the B-series is not an option.  





ORIGINAL ANSWER

According to https://en.wikipedia.org/wiki/Graham_Priest Graham Priest, McTaggart argued that the notion of past and future and inherently contradictory, and then concluded that there can be no time.  When McTaggart attempts to eliminate this contradiction, he gives rise to an infinite regress.  For the sake of completeness, we will look at the contraction, the infinite regress, and the resolution.  If you are already familiar with McTaggart's argument, then please skip to the second section, below. (That probably means you, OP.)

First, let's look at why McTaggart claims that the notions of past and future are contradictory.

Let us write P for "it was the case that", and write F for "it will be the case that" - i.e., P for past, F for future.  So, for example, if e is some instantaneous event, then we write P(e) to express that "it was the case that e", and similarly for F.  Note that e is an instantaneous event - for example, e could denote the moment I click on the "Post Your Answer" button when posting this answer.  Now, let h denote the statement "e is occuring".  Then we have :


  ¬( P(h) ∧ F(h) ).


But because time flows, before an event happens it has the property F(h), and after it happens we have P(h).  Thus, according to McTaggart we have :


  ( P(h) ∧ F(h) ).


This is McTaggart's contradiction - ( P(h) ∧ F(h) ) ∧ ¬( P(h) ∧ F(h) ).

As McTaggart notes, this argument is not very convincing since an event cannot occur in both the past and future at the same time.  It started off as future; became present; and then was past.  But what are we saying here?  We are compounding tenses.  We are saying P(F(h)) - i.e., it was the case that the event will be a future event - and, F(P(h)) - i.e., it will be the case that the event was a past event. McTaggart then argues that this gives rise to the same contradiction that is outlined above.  Again, we must attempt to eliminate this contradiction by compounding our tenses, but this attempt gives rise to the same contradiction.  This is McTaggart's infinite regress - there is no escaping the contradiction.



We now resolve this infinite regress.

We begin by noting that every situation s(0) comes together with a set of other situations - situations which are either before or after s(0).  Assuming that time is one dimensional, we can represent these situations thus:


  ... s(-2),  s(-1),  s(0),  s(1),  s(2), ...


where those situations left of s(0) are before and those to the right are after.

Here, we have P(h) is true in any given situation s only if it is true in some situation to the left of s.  Similarly, F(h) is true in a given situation s only if it is true in some situation to the right of s.

Recall that McTaggart's argument was that, given that h has every possible tense, it is never possible to avoid contradiction.  Resolving contradictions in one level of complexity for compound tenses only creates the contradictions in the next level of compound tenses.

So how do we resolve this.  Suppose that our instantaneous event h is true only at s(0).  Then any statement with compound tenses on h is true somewhere.  For example, consider F(P(P(F(h)))).  This is true at s(-2).

... s(-3)    s(-2)    s(-1)    s(0)    s(1)    s(2)    s(3) ...



                              h



                       F(h)
                                       PF(h)



                                            PPF(h)
          FPPF(h)



We can do the same for every compound tense composed of P and F in a consistent manner.  Thus, McTaggart's argument fails.



EDIT (31 Aug 15)

Re-reading my answer, I note that I have not made it entirely clear how this eliminates the contradiction in the A and B series. According to SEP, the two series are in fact identical - see my comment below.

In the example given, we apply our zig-zag pattern across the various tenses to arrive at a situation where F(P(P(F(h)))) is true - namely s(-2).  So it is true at s(-2) and at each situation to the right of s(-2), while it is false at each situation to the left of s(-2).  Thus there is not situation where it is both true and false, and the contradiction is eliminated. 

The same reasoning applies to any (compound) tense, where, once we have applied the zig-zag patter across tenses to arrive at a situation where the statement is true, if is then true/false to the left/right according to whether the outermost tense is P/F.
How about an illustration such as this one?https://i.stack.imgur.com/npRhY.png 
The quote is not really in philosophy, so you might also want to ask in a sociology or psychology SE question. But I wrote my PhD dissertation on selfhood.

I see in this quotation three concepts:

(1) The self as a socially constituted entity. A self is created in a context populated by significant "others" at different historical periods in the life of a person. The idea here is that to be a self (here meaning the sort of entity that has self-consciousness) is to be built on certain constituting relationships to others. In other words to be a self is to receive certain ideas and thought processes from others (i.e., one's society).

(2) The self's identity as the self's unity. it has a single identity who partakes through life and is influenced--and exerts influence. This is to say that the self is a unified node that operates in relation to other nodes in the social matrix.

(3) Identity as a complex notion. And while we talk about our identity as if it is a unit, in effect we can unwrap the latent identities that have formed through out lives. Here, the point is that http://en.wikipedia.org/wiki/Social_identity_theory social identity theory and several contemporary philosophical views of the self point out that the identity of the self varies by social context. In other words, sometimes my configuration is a college professor, some times as a white guy (esp. in Japan), sometimes as a man. And these notions of identity don't always overlap; rather different identities matter in different interactive contexts.

I don't know if that made things any clearer for you but that's what I see happening in that quote. There's a lot to unpack there.
Underlying your question are some mistakes.

First, whether eating a particular food is healthy depends a lot on the context. If somebody spends a lot of time doing physically demanding activities, then it may be good for him to eat high calorie foods. The person may be doing manual labour on a building site, or training for a sporting event or something like that. And if a person has a low paying job and there is no fridge available it may be that the best food he can take with him is food you would regard as unhealthy. So you actually don't know whether you are helping or harming the person who takes the food out of the pantry with respect to his health. So from that perspective it is okay for you to put the food in the pantry.

Second, a person may choose to pursue values other than health and you should not presume that you know better than he does how to live his life. Even if the person is doing something extremely unhealthy like smoking, it doesn't follow that you could make his life better by forcing him not to smoke. The only thing you should use to get him to stop smoking is argument, e.g.- pointing out the health effects, pointing to better alternatives, proposing solutions to his problems. And you should give such arguments only if the person is interested and you should want him only to follow a course of action if he has no objections to it. To do otherwise is to expect him to act on ideas of which he has criticisms, which is irrational. One implication of this is that if you put food in a pantry, you should not presume to know that the person who took it shouldn't have taken it. So unless you're willing to spend a lot of time solving another person's problems it might be the case that the best you can do to help him is put your "unhealthy" food in the pantry.

A third problem is that you are implicitly not treating the person taking the food from the pantry as a moral agent. You are acting as if you are responsible for his choices. You're not. His problems are not your problems unless you choose to make them your problems. If putting the food in the pantry is a convenient way for you to get rid of the food, then you should do it. What other people do with that food is not your problem.

Another concern is that you say you "end up with" food items you don't want. You should look for ways to avoid getting stuff you don't want. If somebody is giving it to you, then perhaps you should say you don't want it. If you win it in a raffle you could leave the "prize" unclaimed (or don't enter the raffle).
Assumption 2 is incorrect because the passage never suggests that Malthus said anything about an absolute maximum amount of food.  Malthus's argument is that population will increase much faster than food production.  As for the bolded part, "Here again a fixed supply of land with consequent diminishing returns could have overcome this objection."  There's several other places in the passage that also comment on the fixed supply of land.

Assumption 3 is incorrect because Malthus's conclusion "the population will, if unchecked, double itself every twenty- five years" is based on past results.

Correct answer is likely A.
In simple answer, no, there is no contemporary group involved in informal logic that thinks it should all be a question of formalization.

Historically, there were those including Quine who believed all statements in normal languages could be transcribed into formal logic. This claim is by and large the central thesis of http://en.wikipedia.org/wiki/Logical_positivism logical positivism. The idea has largely passed ...
In regard to your updated question where a person desires to kill but holds back until an opportunity arises to do so legally and with a social benefit: does this not apply to some percent of military persons and police?

In other words: a person has an innate desire to kill, but they choose to do so only when deemed appropriate per their own interpretation of what is socially acceptable. If it has been deemed appropriate then it is also morally correct.

It sounds like what you are describing is an anti-hero.
Heidegger was reacting to Being as objective and theoretic; that is the being of science - atoms, matter and forces. Cassirer for example his most prominent opponent saw science as the culmination of philosophy; Heidegger wanted to re-orient philosophy to being here in the world - throwness and this gives a different aspect onto notions of time, space and ethics. 

Authentic derives from the Latin authentes, one acting on ones own authority; and from the greek auto, the 'self' and hentes, doer and being.


  Primarily it is only Dasein that can be authentic or not.


We are not talking about the authenticity of a forged or not painting by Van Gogh.


  Daseins possibility of being authetic or inauthentic is rooted in the fact that Dasein is always mine...Since it is mine I can lose it or grasp it, for the fact that it is mine does not mean that it is 'properly' ones own. 


To have a hammer, but not to know how to use it, is in a sense not to have a hammer. Thus to have Dasein is not to grasp Dasein 'properly'.


  Dasein doesn't lose itself as it might lose an umbrella. It does so by 'falling concern'. It falls into and is absorbed by the 'world', so that it forgets itself as an autonomous  entity and interprets itself in terms of its current preoccupations...Despite all this, Dasein is still concerned about itself. If it ceased to itself to matter at all, it would cease to 'Care' (Sorge) and would lose all concern (Besorgen) for anything. 


The 'world' I suppose can be an inner as well as an exterior world.


  Inauthenticity is only a 'modification', not the extinction of care. Dasein is never irretreivably lost in inauthenticity. If it were, it would no longer be 'inauthentic' as it would no longer be Dasein. 


Dasein is defined as that Being that cares about being. Thus to no  longer care is no longer to be Dasein.

"Is the idea that we can establish the meaning of our death"? 

I don't think that this is Heideggers concern with authenticity. At least its not mentioned by Innes in the entry for authenticity; its remarked on in his entry on Being; and then not even as a separate entry and not hugely relevant:


  Heideggers preoccupation with death does not survive the BT period...and did not advocate obsession with death...It does not affirm nihilism or the senselesness of being. 


But then, so what? 


  "Not everyone need perform Being-toward-Death and assume the Self of Dasein in this authenticity; this performance is neccessary only in connection with the task of laying the ground for the question of being; a task which is of course not confined to philosophy. The performance of Being-toward-Death is a duty only for the thinkers of the other beginning, but every essential man among the future creators can know of it". (LXV 285). 


Innes comment on this is that running ahead to death primarily secures the integrity and the self-constancy of the individual and not to questions of Being; or rather indirectly so; for those in which it is a duty ('thinkers of the other beginning') Being reveals itself - but it is unclear to Innes how this is so or happens; it is only clear that detachment from 'everydayness' (an aspect of Authenticity) is a necessity.  

This counts almost everybody out. Authenticity is more about the meaning of life and not death; in living as though it was your first day and not your last. Innocence and its fullness when one is alone and not alone in the world as in Shelleys http://www.poetryfoundation.org/poem/174380 Spirit of Solitude; the 'green world' of http://en.wikipedia.org/wiki/Shakuntala Shakantula. In the everyday trite phrase self-fulfilment or in the Greek eudaimonia.

Or is it is more of a +ve reflection on the authentic person's character, that they encounter their own death and not flee from that anxiety? 

In part yes, in part no. Innes says:


  Inauthenticity is not a moral or a theological notion (XXI 232;LXV 302)


Thus its converse - authenticity - one supposes is also neither a moral or a theological notion. Thus not a reflection on an 'authentic persons character'. For the individual, encountering their own death, 'running ahead to death' in Innes terminology 'secures their own integrity' as a person (integrity is not being used here in its moral sense) or as you say 'not fleeing from that anxiety'. Its referenced in Blakes poem http://en.wikipedia.org/wiki/The_Book_of_Thel The Book of Thel.  

What's the point of authentic being towards death?

The main point is as you say to secure the integrity of the person - that is for most; and I'm speculating here that this would be confirmed by a close examination of the anthropological literature on rites-of-passage; for a few ('thinkers of the other beginning') its related to the discovery of Being; in Badious terminology Being as an Event. This is neccesarily obscure; as its encounter can only be for those  who have a 'duty' to meet it: In the Christian tradition, this is exemplified by Abraham/Isaac & Christ on the Cross; in the Islamic tradition of the http://en.wikipedia.org/wiki/Kitab_al-Miraj Miraj which influenced Dantes http://en.wikipedia.org/wiki/Miguel_As%C3%ADn_Palacios Divine Comedy; in the Western philosophical tradition by Parmenides, Pythagoras, Plato, & Plotinus.

(Quotes from Michael Innes Heideggers Dictionary)
Take a look at Arrow's impossibility theorem. http://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem http://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem . 
The problem with this definition is that it proposes an empty list of possible conditions that can inhibit to bring about p (besides a lack of power) - whatever could they be. Thus, we cannot say where limits of the omnipotence are. 

I would say, that the author of the definition seems to reserve for himself the possibility to fill this list in a future. For now, nobody can judge from this definition which possible limits destroy the omnipotence and which of them leave it intact.  
Some categories, like the notion of quantity that underlies space and time, have to be inborn, or the remainder could not possibly gain traction.

We do not learn that time passes, we have already experienced it doing so before we leave the womb.  An unborn child shifts in its sleep in response to its mother's posture, so it is already dealing with space and time and thus the category of quantity.

A baby cries when you scare the breath into it, (to the extent that people still do that) so it has a notion of (pain, and therefore pleasure and therefore) beauty and the underlying category of quality.

Something has to exist as a seed for meaning to accumulate around, and Kant has attempted to isolate the most minimal kernel for that seed.  So the categories, and quite a bit of instinctive correlation around them clearly enter the mind before birth.

Later: 

I do not mean to beg the question here, or to misleadingly affirm the consequent.  Clearly that we are born with these things can be established without establishing that that phenomenon proceeds from our premise in any way.

And I am only saying that a few of the categories Kant believes in need to exist for the very young.

A category is that which can be asserted of any thing, regardless of what it is, regardless of what you are.  From that definition, for me, the question hinges on the necessity of asserting things, when you are a foetus, or a baby.

I am saying that things like 'I have fallen on my arm, and I would be more comfortable if it moved.' are in fact asserted by foetuses, if only unconsciously, as they do move their arms.  And given that very minimalistic example, I am challenging whether anyone can  imagine beginning to acquire knowledge from a position where nothing would ever need to be asserted in this sense.
It is simply not the case that "anything must happen" in an infinite sample space. 

Consider the universe consisting of three possible states, A, B, and C. The universe recurs endlessly forever, taking states A, B, A, B, A, B, ... 

Even though there are infinitely many instantiations of the universe, C never occurs. The best you can say is that some state must occur infinitely many times. But it's not the case that every state must occur.

And what if there's some fundamental physical reason that C can never occur? 

Here's another example. 1, 2, 3, 4, 5, 6, 7, ...

No matter how far you go out, "2" will never reoccur. 

It is simply false that "in an infinite universe, everything will eventually happen."

Now, you can make a probabilistic argument. Take the A, B, C examples and suppose that each state is equally likely, occurring with probability 1/3. Nevertheless, the states recur as A, B, A, B, A, B, ... and C never happens.

In this thought experiment, there is zero probability that C never happens. Yet, C never happens. How can this be? The answer is simply that in infinite probability spaces, an event with probability 0 can actually happen. It's just very unlikely.

A familiar example is "throwing darts at the real line," as the experiment is called. The chance of hitting a rational number is zero, because the measure of the rationals in the reals is zero. http://en.wikipedia.org/wiki/Measure_(mathematics) http://en.wikipedia.org/wiki/Measure_(mathematics)

Yet, the rational exist. I just did the experiment in my living room and my dart hit the number 2/3. How about that! Probability zero events can and do happen in infinite probability spaces.

So even the probabilistic argument that "in an infinite universe, everything must eventually happen" is false. Flat out false. It doesn't matter how many amateurs with Internet connections think it's true.

It's false. 
As regards the first question, the answer is a negative one, since terms can be interpreted as sets, and the syllogistic relations as relations between sets. I have mentioned one way of achieving this https://philosophy.stackexchange.com/a/11273/4240 elsewhere, so I'll just repeat Definition 1 from that post here for your convenience:


  Definition 1. (Set Theoretic Semantics for Aristotle's Categorical Syllogistic)
  
  
  AaB  =df         B ⊆ A              ('all Bs are As'),
  AeB  =df         B ∩ A = ∅       ('no Bs are As'),
  AiB   =df       ¬(B ∩ A = ∅)     ('some B is A'),
  AoB  =df       ¬(B ∩ A = B)     ('some B is not A').
  


Usefulness though is a relative notion; just because we can find set-theoretic models of the syllogistic, it doesn't mean that taking the syllogistic relations as primitives is a useless idea. Compare this situation with modal logic: there is what's called a http://en.wikipedia.org/wiki/Standard_translation standard translation of modal formulas into first-order logic. Despite that, we find it useful to take at least one of the usual modal operators as a primitive and define things in terms of it.
The unstated conclusion is that some vital community goods should be government-provided. On the face of it, one might suppose that (b) does not strictly follow, since the support on offer includes nothing in particular about 'society as a whole.' The evidence offered refers explicitly to individuals in the society (potential free riders, quantities accessible by individuals, individuals requiring a safety net). Thus, one might say that concluding (b) amounts to committing the fallacy of composition [arguing from premises about the 'parts' of something to a conclusion about the whole].

One can, however, legitimately conclude (b) on the basis of a savvy analysis of the evidence. The analysis goes like this: The paragraph states that governments can be concerned with those "public goods. . . where there is no reduction in the quantity available for others when one person has more..." If we take this as meaning 'public goods that benefit society as a whole,' then (b) reasonably follows. This analysis is reasonable because the evidence offers a particular way of understanding the relationship among 'parts' of the whole [while some individuals may have greater access, this fact does not diminish anyone else's access, thus all are benefitted].

While (d) does not follow from the evidence offered, the reason given for this judgment is itself problematic. That a government has 'pursued a policy of privatisation' with regard to some industry is no proof of its efficiency. A better reason for saying that (d) does not follow is that the evidence provided is insufficient for one to draw that conclusion. Without further information about what makes a policy 'efficient' no reasoned claims about the efficiency of this policy [privatisation] versus that policy [government provision] can be made.

I hope that this helps!
There's at least one other angle to consider -- but here I have to assume what you mean by "libertarian" is still a realm governed by some manner of law but with consent as its highest value.

If you're willing to accept that, then I would suggest one reason to oppose such arrangements or possibly even prohibit them is epistemological.  In much of the autonomy literature, there are questions about what one can knowingly consent to with full understanding of what it would mean. Thus, some deny that women can consent to be positions of submission whereas others do not. 

But what matters here is a corollary of the problem of whether someone's autonomous consent can be known. It stands to reason that a libertarian government has as its highest goal the free exchange of autonomous actions among its people. But it also follows that the government should scrutinize most those actions with the highest consequences for a person's autonomy.

These actions would be prostitution, slavery, and contracted death. This is because of two reasons. First, it's hard to tell if there was autonomy in the choice in many cases. Thus each of these actions could occur under the similitude of an autonomous action but actually be the result of an autonomous choice. Thus, we have the drug-addicted prostitute who is being pimped, the child who in desperate circumstances signs up to be a slave to help his family but has cannot fully comprehend what they are committed to -- they enthusiastically say "yes, I do this willingly" but we cannot mark that as autonomous.  Similarly, consent to dying will be difficult to unravel because we cannot ask the dead and cannot prove they autonomously consented from any video or forensic evidence.

Second, the consequences of these actions are the largest. Death, at least on most accounts, is irreversible. Slavery is for life. Prostitution can have lasting consequences for the person prostituted (STIs, physical damage, etc).

For these two reasons (difficulty in externally ascertaining autonomous assent and large consequences), the state may be motivated to highly regulate or make illegal these actions precisely from principles of liberty.
Quine's discovery that every observation is theory laden, led him to adopt https://en.wikipedia.org/wiki/Confirmation_holism confirmation holism. I guess you could describe this as being a form of "epistemic non locality" in the sense that no observation is independent of a theory, and presumably of other observations which were used in constructing the theory. 
In particular, this quote from the http://plato.stanford.edu/entries/quine/ SEP article on Quine, implies a "non locality" similar to the one described in the first quote of your question.


  In particular, Quine claims that holism shows that most of our sentences are not justified by the relation of the individual sentence, considered in isolation, to experience. Almost always, what matters is the relation to experience of some larger chunk of theory (and, in principle, although perhaps never in practice, of the theory as a whole). This means that the correctness of a given claim is almost never settled simply by gathering empirical evidence. 

Its probably best to scope this question a little more widely: I'll take it to mean what books discusses physics along with philosophy in the wider sense:


The pre-socratic Empedocles developed a cosmology of Love (philotes) & Strife (neikos)
Lucretious's de rerum natura, ties together Epicurus's theory of 'life' together with the atomic theory of matter. Quite amazingly, they have the 'swerve' which corresponds to quantum indeterminancy.
Spinoza Ethics discusses classical physics in relation to cosmology and God.
Fritjof Capra The Tao of Physics, which discusses quantum physics with the philosophy of the dao and Buddhism.
Though its specifically not related to physics its worth noting Dawkins The Selfish Gene for its immense contemporary impact where he relates the Fortuna (chance) that governs evolution to an explicit athiestic cosmology. Smolin adapts the evolutionary thesis to cosmology where he defines his own highly speculative multiverse theory.
Simone Weils Gravity and Grace which is devoted to a mystical interpretation of Christianity. Its worth noting a possible and speculative connection here with Empedocles, where Love becomes Grace, and Strife becomes Gravity. 

If http://www.oxfordreference.com/view/10.1093/oi/authority.20110803095350157 this definition is sufficent, then it is referring to the "conditional probability distribution".   Suppose that you have two random variables, described by a probability distribution p(x,y).  One can ask the question, "what is the probability distribution for x if I only considered those cases where y takes on a specific value, i.e. y=Y?".

Thinking about it in terms of a finite sample might be useful.  Suppose that you had a long list of pairs X_i, Y_i, were drawn from the joint probability distribution p(x,y).  Out of this long list of numbers, only keep those entries match your selected (conditioning) value for y, i.e. those pairs (X_i, Y_i) where Y_i==Y.  The distribution for the x values in this restricted subset is the conditional probability p(x|Y).  (Formally you get the exact probability as you let the size of your table of pairs go to infinity).

More often you'll see equations like p(x|Y)=p(x,Y)/p(Y) which embody the same idea, without the rigmarole of thinking about populations.
A scholar no less than the William Smith, L.L.D. (Smith's Bible Dictionary, London: J. Murray, 1863; Revised Edition: ...Compiled from Dr. William Smith's Dictionary of the Bible, n.d., ISBN 0-87981-033-5, s.v.: "Epicureans," p. 95) stated: "The teaching of the Hebrew patriarchs and prophets was independent of any system of philosophy, and it is curious that Greek philosophy arose just after the Hebrew prophets closed their oracles, Malachi being contemporary with Socrates."  After Malachi, there was a 500-year hiatus to the New Testament.  This was known as the period of the Talmudists (to 70 A.D.).  So, there was plenty of time for influence of Classical Greek philosophy.  I strongly suspect this is exactly the case.  Unfortunately no modern thesis materials or dissertations exist on this significant subject.  No university will allow investigation.  Perhaps something written during the Victorian period might exist.  But, so far, my research has produced very little other than the Smith quote which may go back to an edited version of his original text (1863).  The lack of information regarding the obvious Hebrew literary influence of Classical Greek philosophy and perhaps also early Greek poetry (theogonies) and the vernacular narratives (popular Greek myth) preceding Socrates, Plato, and Aristotle is by-itself much more than curious.  It is my estimation that the flow of history goes something like this: (minimally) Indian, Chaldean, Canaanite, Egyptian Hebrew (revelationally), Greek, Roman, European (maximally).  And, we are told in public school we can't be Juedeo-Christian or "Eurocentric" because such is "offensive"?
That's a nice question, but I don't think things can "have" front and back. A chair it's just an object, with it's geometry and configuration; front and back are concepts defined by us for matters of pure perspective, not being some kind of property of the chair. In the course of our existence in earth we find necessary to distinguish between some visual different parts of objects, as we find necessary to develop numeral systems for counting, but that doesn't mean number represents something outside pieces of information inside our brains, or that front and back are real properties of things and not some neurological convention we made it up. Anyway, I think this question is more hard to answer than it appears, because we would have to talk about properties first, and Russell already showed us that properties are not easy business.

Have a nice day.
As this touches a wide field that is discussed and still in motion today, I will just refer to what Henry E. Allison states in his Groundwork for the Metaphysics of Morals - A Commentary (Oxford University Press, 2011). On page 183, before going into the details for every single application, he writes:


  Before proceeding to Kant's examples, however, it will be useful to note four points about his procedure. First, in each case Kant assumes that the reader will grant that the course of action being contemplated is a violation of a generally recognized duty. Second, in each case Kant makes sure to point out that the agent who is applying the test is proceeding conscientiously. In other words, in spite of his self-interest the agent is also concerned with the morality of the proposed course of action, and it is from this perspective that he raises the question of universalizability of his maxim. Third, for this reason the maxim that the agent is considering adopting is the one on which he would perform the action (or omission) in question, not one which might be contocted after the fact in order to provide a veneer of justification. Finally, although in each case the universalized maxim will turn out to involve a contradiction (either in conception or will), priori to the test for its universalizability the maxim which the agent is considering adopting has a certain prima facie justificatory force for that agent.


What makes his application successful on first sight is a contradiction. The main point is how this contradiction is to be understood. The link provided does not help, because it is only an excerpt form a translation that is outdated. The problem is that there are two times four applications (4 of the Formula of Natural Law, 4 of the Formula of Humanity, naming by Allison) and in each case there are numerous essays and books on how they are to be understood.

Therefore, the question cannot be completely answered in this context, but I can recommend to read the sections in the above mentioned commentary. The objections presented are various and sometimes (for me) inconceivable looking at Kant's own wording, but they are presented and summarized.

As for some terms that looking for may be useful in that context: 'false positives' and 'false negatives' are discussed as the most challenging objections against the application of the categorical imperative on pages 191-202.
Most philosophers and theologians I've read would not see a contradiction. One theologian that does a good job of explaining this way of thinking is Frank Sheed. In his book Theology and Sanity, he explains:


  Just as time is the duration of that which changes, eternity is the duration of that which simply IS, the duration of the Being who, in one infinite act of being which does not change and does not cease, is all that He is, and all that He does...
  
  We must try to conceive [creation] in some such terms as this: God who possesses the whole of His Being in one single act of infinite existence wills that a universe should be which possesses its being in successive acts, bit by bit.


He discusses the topic at length, but the two above excerpts get to the heart of it: it is not that God cannot decide one thing and later change His mind out of inability, it is that God, in His one defining eternal act has already acted with perfection.
Your question is basically the same as this one: https://philosophy.stackexchange.com/questions/16455/logical-form-of-the-definition-of-validity/16461#16461 What is the logical form of the definition of validity? . And my answer is a less formal version of what Hunan is telling you.

an argument is valid if having its premises be true necessarily leads to a true conclusion.

The necessarily / must element in the definition makes it so that we are not looking at whether the claims are in fact true but rather whether the forms of the claims are such that their truth implies the truth of the conclusion. Thus, we need to check to see if there is any truth value for the variable involved whether or not it is possible that the premises end up being  true and the conclusion being false.

To do so involves several steps and there are multiple methods.


  "All cats are mammals, All tigers are mammals, Therefore all tigers are cats".


This gives us three statements and three variables. To make it first order logic, we need understand "all" to mean if it is an A, then it is a B:

(1) C -> M
(2) T -> M
Therefore (3) T -> C


As you rightly point out, all 3 claims turn out to be true (assuming by "cats" we mean something other than felinis familiaris). 

Why then is the argument invalid? The key is that the validity looks at if it is possible for the argument to have true premises and a false conclusion.

Test Method #1

We can test this with several methods of varying difficulty to grasp. One of the easier ones to understand for many people is the exhaustive truth table. Here, we are going to create rows where we assign whether variables are true or false and look to see if the claims are true or false. If we end up with a situation where the premises are true and the conclusion is false, then the argument is invalid.

In our case, we have three variables. Per the law of the excluded middle, each variable can be true or false. Thus, either it is true that it is a cat or it is false that it is a cat. [etc] This will give us 8 rows as follows:

C T M
-----
T T T
T T F
T F T
T F F
F T T
F T F
F F T
F F F


This represents every way that these variables could be related -- regardless of how they are related in this world. We then look at whether each claim is true. A conditional is true when the antecedent (left part) is true and the consequent (right part) is true. OR when the left part is false, it is true regardless of the right part. Or to put it another way, it is only false when the antecedent is true and the consequent is false.

C T M   C -> M  T->M    T->C
-----
T T T   T       T       T
T T F   F       F       T
T F T   T       T       T
T F F   F       T       T
F T T   T       T       F
F T F   T       F       F
F F T   T       T       T
F F F   T       T       T


If you look the fifth line has true premises and a false conclusion. Thus it is possible for the argument to have had true premises and a false conclusion. It turns out that in our world the premises and conclusion are true, but the logic behind the premises does not compel the conclusion we are drawing. So the argument is invalid.

Test Method 2

There's a faster way called the short circuit method where you accomplish the same thing as the above method but cheat. Instead of making every row, we just set the conclusion to false and figure out how we can make the premises true if that's the case. If we can make all of the premises true, we've proven it is invalid.o

So we begin like this:

C T M   C -> M  T->M    T->C
-----
                        F


We then ask what it takes for T -> C to be false. The answer is that T must be true and C must be false. (due to the way conditionals work).

C T M   C -> M  T->M    T->C
-----
F T                     F


If C is false, then C -> M is true regardless of the value of M.

C T M   C -> M  T->M    T->C
-----
F T     T               F


The question then is if we can make T -> M true with these values for C and T already set. The answer is that we can -- if we set M to true.

C T M   C -> M  T->M    T->C
-----
F T T   T       T       F


Thus, we've shown invalidity -- because we can have true premises and a false conclusion. Note again, this does not mean that we do.

Test Method 3

Finally, we can show the same thing using rules of inference (which I will leave out here but is probably the most common method in philosophy and math).
The bolded cannot depend upon the virtue or vices of a person insofar as we are willing to apply a blanket statement that torture is unacceptable.

As soon as we say that torture is unacceptable - and support this statement with the argument that torture turns a human being into a thing - we are immediately tied to the reality that follows from "a person is not a thing".  

If a person is "not a thing", a person then is not an object, but a subject: meaning they exist in such a way that we cannot seperate our experience completely from their experience; and thus cannot treat them as merely a means to an end without objectifying ourselves as well.

Martin Buber spoke upon this brilliantly in http://en.wikipedia.org/wiki/I_and_Thou Ich und Du (I and Thou):


  [Buber's] main proposition is that we may address existence in two ways:
  
  
  The attitude of the "I" towards an "It", towards an object that is
  separate in itself, which we either use or experience.  
  The attitude
  of the "I" towards "Thou", in a relationship in which the other is
  not separated by discrete bounds.
  


If we are to accept that we ourselves have value, then the value that we possess is not tied to what we have accomplished.  It can't be, because what we have accomplished can only be assessed as valuable within the context of a subjective experience.  To a rock nothing has value.  Or everything does.  It doesn't matter.

What is valuable in us then must be somehow correlated with our abilities as subjective beings to experience a reality that includes one another.  In other words, when stating that a human being is valuable, we must a priori say that human beings are valuable.

This is also stated in your quoted text:


  
    not as a person with all the value that we associate with persons
  


notice it didn't say:


  all the value that we associate with a person


Because (with this argument) we all already automatically have value, reducing a person to a thing is dehumanizing regardless of the human in question.  The human in question is first a Thou who is "experiening us experiencing him", only secondarily do we relate to him as the actions he has undertaken.
The philosopher who most famously argued that the majority of philosophical problems reduce to confusion over definitions is http://en.wikipedia.org/wiki/Philosophical_Investigations Wittgenstein.  The philosophic movement most closely associated with Wittgenstein is analytic philosophy, although being an analytic philosopher does not entail that one agrees with that premise.

There's not necessarily a term in general usage specifically referring to endorsement of that point of view (although I have heard the coinage syntheism used for the particular application of that principle to the subject of religion). 
I can only enumerate. 

Take "not" and "or" for example. Empiricists believe they express mental states. 

"Not" expresses rejection. When one looks for cheese in the larder, but finds nothing, he may say, "there is no cheese in the larder."

"Or" expresses hesitation. When one comes to a crossroad and does not know which way to go, he may say to himself, "should I go this way or that way?"

  But can repetition characterise infinity? Or should it be natality, that is true infinity is characterised by non-repetition that is however 'far out' one goes nothing repeats, there is always some modality, some aspect that is essentialy new?


Yes to the latter. To understand the infinite, I find it best to first get a firm grip on the notion of the finite. 

Consider the following non-numerical analogy: Suppose we start with a walk through an ordinary (finite) village comprised of several houses. Suppose further that you are free to walk around this village to visit some or all those houses in any order, as you choose. 

If you start at one house, and keep going from one house to another, and go to no house more than once, it stands to reason that you must eventually return to your starting point. You must eventually run out of different places to go. Intuitively, this would be true of any finite village.  This would not be true in an "infinite" village where you could start at one house and never return to it on your walk, even if you could walk for an eternity. Not surprisingly then, a village (or other set of objects) is infinite if and only it is NOT finite. 

A set of objects can be said to be infinite if and only if it is possible to start at some element and keep going from one element to another, and to not go to any element more than once (i.e. no repetition),  and never return to the starting point. 

(Also see "Infinity: The Story So Far", revised just now at my http://www.dcproof.wordpress.com/ math blog, for a formal development of these ideas.)
I cannot answer for the historical aspect of the question (I don't know enough Spinoza) but I would say that today it is generally assumed that the universality of laws is analytic: laws are always and everywhere the same by definition, otherwise they're not laws but local facts (whether there are indeed true laws of nature in this sense is another question).

Regarding modern physics: it's important to distinguish between universality and unification. Physics is not unified because we have more than one theory to reflect different aspects of the universe, but each theory purports to be universal in its application. In particular, both QM and GR apply always and everywhere.
If you take a point on a mobius strip, and some small enough open neighborhood around that point, the neighborhood is "equivalent" to some open neighborhood of zero in the regular euclidean plane (or, if the point is on the edge, equivalent to a neighborhood in the half-plane).  This means that the mobius strip is indeed "locally" orientable, in that locally you can consistently define orientation on the strip.

However, I want to point out that when you say the strip "looks" as though it has two sides, there is some question of whether you actually mean the same thing as mathematicians mean by "locally orientable".  Restricting our attention to 2-manifolds, a mathematician means by "orientable" that there is some consistent choice of "clockwise" and "counterclockwise" loops on that surface, i.e. that if I draw a counterclockwise loop on the surface and then move it around, I can't arrive at a clockwise loop.

But is this really what you mean by saying it "looks" like it has two sides?  It seems to me that you are rather thinking of it like a paper, where you draw on one side or the other; yet mathematically, the strip is merely a set of points, and unlike a paper or a physical mobius strip it need not be embedded in 3-space.  Worth considering.
In the specific context it means "actors", persons that display actions. 

"δρώντων καὶ οὐ δι' ἀπαγγελίας" by actions and not via reciting

I translate from wiki dictionary (Greek) (modern meaning)

drama < from the ancient Greek word drama < act


  noun:
  1. poetic genre of ancient Greek literature that includes the tragedy, comedy and satirical drama 
  2. theatrical or cinematic work with strong passions and conflicts misery, 
  3. passions of a man or a whole group of people living drama


https://el.wiktionary.org/wiki/%CE%B4%CF%81%CE%AC%CE%BC%CE%B1 https://el.wiktionary.org/wiki/%CE%B4%CF%81%CE%AC%CE%BC%CE%B1

From Greek Wikipedia: Article drama (δράμα)


  The drama is a kind of ancient Greek poetry that synthesizes elements
  from both prior periods, the epic and lyric poetry.
  
  The word drama in the new Greek language means unpleasant event or
  undesirable situation.
  
  As for the ancient Greek culture, the word has a completely different
  meaning. Etymologically derived from the verb drao-oh, therefore means
  the kind of poetry accompanied by a representation of actions (as
  opposed to the epic and lyric poetry).
  
  Born and developed in Attica of the celebrations in honor of the god
  Dionysus, which are offered to it many dramatic elements (the events).
  Started by the original song, the dithyramb (διθύραμβος), sung during
  the worship of the god Dionysus and accompanied by flute and
  orchestral or mimic movements. After its
  completion by Lasso of the Hermione, the music lover tyrant of Athens
  Peisistratos introduced in magnificent festivities which he
  established it, the Great Dionysia.
  
  The types of drama are three: comedy, tragedy, satirical drama


so because the drama is developed from the ceremonies in honor of Dionysus it can be said that it originates from "rituals" but during its development it has transformed to a expression/artistic medium. The significance of the beliefs regarding Dionysus is quite complicated, and has influenced both demystification but also mystical-religious thinking (see Orphism for an example). 

https://en.wikipedia.org/wiki/Dithyramb https://en.wikipedia.org/wiki/Dithyramb

https://el.wikipedia.org/wiki/%CE%94%CF%81%CE%AC%CE%BC%CE%B1_%28%CE%BB%CE%BF%CE%B3%CE%BF%CF%84%CE%B5%CF%87%CE%BD%CE%AF%CE%B1%29 https://el.wikipedia.org/wiki/%CE%94%CF%81%CE%AC%CE%BC%CE%B1_%28%CE%BB%CE%BF%CE%B3%CE%BF%CF%84%CE%B5%CF%87%CE%BD%CE%AF%CE%B1%29

https://en.wikipedia.org/wiki/Drama https://en.wikipedia.org/wiki/Drama

https://en.wikipedia.org/wiki/Dionysia https://en.wikipedia.org/wiki/Dionysia

https://en.wikipedia.org/wiki/Orphism_%28religion%29 https://en.wikipedia.org/wiki/Orphism_%28religion%29



δρώμενο < δρώμενα < ancient Greek δρώμενα, neuter gender of δρώμενος, 
participle perfect tense passive of the verb δράω / δρῶ 

(δρώμενο) happening  (usually plural: events)


spectacle (sometimes dramatized) religious
something that takes place, some events or shows, usually artistic, political or social

Let's try to approach the problem through looking at the relationship between the grammar of natural languages like English or French, and the artificial language of logic. This answer will be very long, but hopefully will build up what you need to know step by step. Let's start with some grammar.

Many natural languages, including English and French, use grammar to distinguish between sentences that assert a fact and sentences that express situations contrary to fact. We say sentences that assert a fact are in the indicative mood. "The cat is on the mat" is in the indicative mood.

Sentences that express a situation contrary to fact are said to be in the subjunctive mood. "If only the cat were on the mat!" is in the subjunctive mood. 

A conditional (in natural language) is a sentence that has two clauses, which usually implies some kind of logical or causal connection between them. Conditionals can in either the indicative or the subjunctive mood. 


If the cat is on the mat, then it wants to be fed.
If the cat were on the mat, it would want to be fed. 


Now let's turn to the relationship between logical and natural language. The language of logic is an artificial language that human beings created intentionally in order to model a phenomenon. That phenomenon is the human ability to reason. Most reasoning that most people do is called verbal reasoning. Just by speaking a language competently, people have the ability to draw inferences. Verbal reasoning is just like verbal mathematics in this sense. 

Just by knowing some number words ("one", "two")and operation words ("add" "subtract") one can do some mathematics. However, obviously our powers of verbal reasoning are limited. Consider how hard it would be to express the pythagorean theorem without using the conventions of algebra. ("The square of the length of the hypotenuse of a right triangle is equal to the sum of the squares of its adjacent sides") 

So, what we do is create an artificial language that simplifies and clarifies our verbal mathematics. In this artificial language we start with an arbitrary set of symbols, then we create a system of rules that let us transform strings of these symbols into other strings of symbols, finally we create an interpretation of those strings of symbols to specify what phenomenon we are modeling with that set of symbols and rules. For instance, in the artificial language of arithmetic, we establish a couple of conventions: we use '1', '2', etc to be the names of the numbers, the lower case letters 'a', 'b', 'c' to stand for variables, '+' to stand for the operation of addition, "=" to stand for the relation of equality. Finally we can give these symbols an interpretation by specifying that we will let "a" and "b" and "c" stand for the lengths of the sides of a right triangle. And so we can express that complicated pythagorean theorem with our new language much more simply as "a^2+b^2=c^2".  This is not only easier to understand--it also let's us know just how to work with and manipulate this sentence so we can discover new truths. 

Artificial languages are called formal languages, because up until that final step of specifying an interpretation, the language has no content. It is just a description of how certain arbitrary signs behave together. 

Now what about logic? Logic is just like arithmetic. It is a formal language we have created in order to simplify and clarify certain kinds of verbal reasoning we do. What we are after in formal logic is an account of logical consequence, i.e. how to know precisely and rigorously what follows from a sentence or set of sentences. Now there are lots of different logics, just like there are different branches of mathematics. The idea is that you need slightly different formal languages to describe and model different phenomena.

People always start with learning what is called propositional or sentential logic. In propositional logic, we use the material conditional to express the natural language reasoning we do about a grammarian would call an indicative conditional. In many ways this is a big simplification. "If 2+2=5, then Abraham Lincoln is the current president of the US" would be true in propositional logic, even though that sentence would sound false to many native English speakers. Is this a problem? No, because it turns out that letting that sentence count as true in propositional logic won't let us infer anything false---since it can never be the case that 2+2=5, if will never be the case that we can infer Abraham Lincoln is the president, using the rules of propositional logic. 

Propositional logic, as simple as it is, is still a very powerful tool. It allows us to express in a concise, formal way much of the verbal reasoning that people do in everyday life. However, it has limits. One of those limits is that it only formalizes inferences that people would make verbally in the indicative mood. But clearly people also do reason in the subjunctive mood as well. For instance, the following is an argument made in ordinary language which is obviously valid (if the first two sentences are true, the third has to be true as well) and yet it is made in the subjunctive mood.


If the egg had fallen off the table, it would have broken on the floor.
If the egg had broken on the floor, I would not have been able to make pancakes.
Therefore, if the egg had fallen off the table, I would not have been able to make pancakes. 


The conditions involved here are not material conditions, because the material condition only models the indicative, and these sentences are in the subjunctive. The logic of subjunctive conditionals is much, much more complex than the logic of indicative conditionals, so it is not at all surprising that some of the rules of inference like contraposition that hold for the material conditional do not hold for the subjunctive conditional. To explain formally why subjunctive conditionals don't counterpose would require an advanced knowledge of the branch of logic known as modal logic. What is really fascinating though, is that people's verbal reasoning abilities about subjunctive conditions is actually pretty good. 
Legally a corporate body may be a person. Philosophically, neither it nor its board is a moral or ethical agent.

The individuals who sit on the board are the relevant moral or ethical agents. A corporate body may have rules that define what constitutes a conflict of interest and ethically obligate those agents toward certain actions. Or the corporate body may not.

Operationally, a board depends upon people with an interest in the corporate body which the board oversees.

Where one person may see a conflict of interests, another may see alignment. And the appearance of a potential conflict of interest is not in fact an actual conflict.
This is related to Agrippa's trilemma which is a traditional problem in epistemology.
The trilemma goes like this: every piece of knowledge needs to be justified by another piece of knowledge. If knowledge is possible at all:


either you need an infinite serie of true propositions to justify any piece of knowledge, which seems out of reach for anyone
either you have to stop somewhere and accept that some pieces of knowledge need not be justified, but then you're a dogmatist
either you fall back at one point on the very proposition you were trying to justify, but then your justification is circular


Otherwise you have to be skeptic about the possibility of knowledge.

Non skeptic answers to the trilemma involve accepting one of these three possibilities, respectively:


infinitism (rarely defended), 
foundationalism, sometimes associated with empiricism, where experience is at the root of knowledge, but also with rationalism, where reason and intuition play the foundational role, and 
coherentism, often associated with idealism, where everything reduces to the mental, and knowing Basically equates having a coherent belief system.


See also: http://en.m.wikipedia.org/wiki/Regress_argument http://en.m.wikipedia.org/wiki/Regress_argument
There is always proof by contradiction:


If it is not possible for X to exist, then Y could not exist.  But Y does exist, so X must be able to.


For example: if it were not possible for eggs to exist, then omelettes could not exist.  Here is an omelette.  (In this case, we can conclude further that eggs have existed recently.)
I would say that if that were true, we would always be certain of the morality of every one of our own actions.

Perfect empathy with perfect communication would simply reduce an individual human into the collective of humanity in emotional terms.  But since we are not always perfectly certain relative to ourselves, this combined whole would still not be certain of its correctness, and it would still need an ethics.

Perfect empathy with imperfect communication gives us yet another reasons to doubt our collective decision making.  You still need a way to determine what to do when you understand the other person completely, but you are not certain you have all the information they have or that they have all the information you have, and you cannot be certain that you can correct that situation.

So the assumption of perfect empathy alone still has two strikes against it as a basis for replacing ethics.
It's the fallacy of induction.

No but really. People make assumptions about what things are and what words mean on the basis of the available information. If someone doesn't know anything about islamic law and hears about issuing a fatwa implying issuing a death sentences in the news, and never hears about any other sorts of fatwas, then it is not very surprising that they think that a fatwa involves a death sentence. And since there is no great international interest in more mundane fatwas, their hypothesis hasn't come into contact with falsificatory evidence. It's nothing as grand as a fallacy or bias.
Socrates, at least in his portrayal in the early Platonic dialogs (generally viewed as closest to the historical Socrates), would be more inclined to ask such a question than answer it.  His typical approach was to take someone who felt a sense of certainty about some moral or philosophical issue, and to ask him a question that would introduce doubt about his beliefs.  If pressed on his own stance, he would profess ignorance.
I enjoyed this question (I would upvote it but don't have the needed reputation yet). I'm not a professional philosopher either, but here is my attempt at your three questions:

1.

Under Erasure means that a word is crossed out (literally on the page, as if it were deleted by an editor) but allowed to remain in the final text. This indicates that the word is inadequate, but no better word could be found. It's a deconstructionist technique which calls attention to the limitations and relativity of language.

Language mediates between people and their reality. During this process, language helps create reality as it affects how people 'slice up' their reality by determining where and when they experience differences (contrasts, if you like): hot/cold, bland/bitter, etc. However, these divisions may not always capture the full nuance of an experience and different languages divide up reality differently. Thus language is both relative and arbitrary. There is nothing about the signified (roughly meaning concept) orange which indicates the signifier (roughly meaning word) "orange." Nothing about a dog necessarily or logically leads towards the word "dog." Language is not a direct experience of reality but rather a socially constructed approximation. Hence, no word is ever entirely adequate to explain reality and thus "all language is under erasure" -- or, put very simply (and run the risk of redaction): language is always different from direct experience.

2.

Yes -- the fact that languages possess conflicting, overlapping, and contradictory signifiers which produce inadequacies in expression could be verified. Eco's "Theory of Semiotics" discusses these problems at length.

3.

Check out Catherine Belsey's "Poststructuralism, A Very Short Introduction." It doesn't mention "Under Erasure" directly but will help with understanding where Heidegger and Derrida were coming from. 
http://en.wikipedia.org/wiki/Brute_fact Brute fact is a close relative of http://www.apologeticspress.org/APContent.aspx?category=12&article=1601 uncaused cause, only the emphasis is on explanation rather than causation. Brute fact is a primary fact, one that need not be explained further, or on another reading self-explanatory. Uncaused cause is a prime cause, one that need not be caused itself, or self-causing if one prefers. If one thinks of explanation as building a chain of logical causations the difference disappears completely.

Therefore, declaring God or nature brute facts is effectively a statement of faith, or lack thereof. There is a long history of trying to justify the preference, the famous http://en.wikipedia.org/wiki/Cosmological_argument#Argument_from_contingency cosmological argument can be interpreted as an argument in favor of God being the "brute fact" or "uncaused cause". Swinburne starts his book by pointing out that such arguments are pointless because their premises are disputed. Even if we accept the http://en.wikipedia.org/wiki/Principle_of_sufficient_reason principle of sufficient reason (and there is no sufficient reason for that) we still have a choice between infinite regress and first cause. Infinite regress was disliked by originators of Western philosophy like Aristotle, but there is no logical reason to reject existence of infinite causal chains, and hence eternal "nature". Then there is an insurmountable burden of http://en.wikipedia.org/wiki/Cosmological_argument#Identity_of_a_First_Cause identifying the first cause with God, even if nature is not eternal. In short, any judgement of what is a "better" brute fact will be based on person's emotional, social, cultural, philosophical, etc. preferences, and is purely subjective. People who like "closure" prefer God, people who like "diversity" prefer nature.

There was a similar dispute in philosophy of science about so-called analytic/synthetic distinction. It was about identifying "empirical facts" as opposed to "theoretical speculations", which could then serve as an undisputed foundation for science. It was on a much firmer logical ground, but still led nowhere, the distinction http://en.wikipedia.org/wiki/Analytic%E2%80%93synthetic_distinction#Quine.27s_criticisms could not be made logically. The question of "final ground" for knowledge and explanations preoccupied philosophers for centuries and continues to do so. Hegel's Absolute Spirit, Husserl's pure consciousness, Heidegger's metaphysics of Dasein are the more recent entries to the list starting with God and nature. There are so many of them because there are no universally "better" ones.
It should be noted that describing calculus as an analysis of 0/0 is, at best, such imprecise short-hand as to say virtually nothing — similar to saying that the two-slit experiment proves that electrons can be in two places at the same time. In each case, the description is certainly one way to hurriedly describe what's going on, but omits absolutely all of the machinery and crucial concepts which would make it instrumental — and therefore worth saying. With this in mind, if we are operating on the level of stretching of descriptions in which calculus is a theory of 0/0 (via the concept of a limit of ratios, e.g. in computing derivatives), then it is also a theory of 1/0 (by that same concept of limit, both in computing ratios and in integration).

Much of the interest in foundations of mathematics was spurred on by what was considered to be weaknesses in calculus, indeed by the fact that it originally dealt in such concepts as 0/0, whereas it is a student's exercise to show that admitting 0/0 as a signifying expression immediately allows one to prove 0=1 (and is therefore problematic if you prefer to distinguish between such numbers). In place of limits, we may use a modern development of infinitesimals to recreate calculus in the original spirit of Leibniz and Newton: but while an infinitesimal is smaller than any positive real number and may be describable as 1/infinity (for a sufficiently precise definition of "infinity" as a number by which one may divide), an infinitesimal of the sort useful for calculus is still not zero in any non-trivialising classical model of logic.

We may construct the negative numbers only by abandoning the notion of a lowest number, and the rationals by abandoning the notion of a smallest; whereas the complex numbers demand the abandonment of the idea that numbers can be ordered in any way at all, consistent with having any meaningful relationship to multiplication. A similar extension to allow 1/0 or 0/0 to signify would require us to abandon either the idea that multiplication and division are inverse operations, or a relationship of multiplication to addition. To obtain a mathematical theory with utility, it proves better to use subtler approaches than division by zero, and to leave 1/0 as a gloss as imprecise as the words "big" and "small".
It says that (∀x)Fx ⇒ Fr


  where F(x) is any sentential formula in which x occurs free, r is a term, F(r) is the result of substituting r for the free occurrences of x in sentential formula F, and all occurrences of all variables in r are free in F.


Note that that way of putting it doesn't say that x is free in (∀x)F(x). It says that x is free in F(x) — in the sentence that the universal quantifier in question applies to. In other words, that substitution of r for that x works because that x is not bound in F by any other quantifier.
You are exactly right about Plato - he separates being and time. Plato does this because he sees philosophy as the striving of the psyche towards eternal things, and in order to achieve its goal, it must exclude everything about itself and its world which is finite and changeable. This opens the space for Aristotle's criticism, that such a realm of eternally unchanging forms could not be the reality of the temporal world, because it would have no way to produce change.

But I would have to disagree with the notion that Newton and Einstein argue for the unreality of time. For Newton there is something he calls absolute time, which flows at the same rate regardless of what objects inhabit it or who perceives it. To me this seems like an argument not only for the reality of time, but for its absolute reality. Einstein criticizes this notion, drawing in part on the results of the http://en.wikipedia.org/wiki/Michelson%E2%80%93Morley_experiment Michelson-Morley experiment. In order for time to be absolute, the speed of light would have to be relative, but the Michelson-Morley experiment disproved this, and Einstein shows with a thought experiment that their results imply the relativity of time.

Saying time is relative is much different from claiming it is unreal. If you are interested in pursuing this question, I would recommend reading Heidegger's short lecture http://blogs.sussex.ac.uk/sussexphenomenology/files/2013/05/Martin-Heidegger-Joan-Stambaugh-Translator-On-Time-and-Being-1977.pdf "Time and Being" and the first chapter of Derrida's "Given Time: I. Counterfeit Money". Rather than simply saying time is unreal, these thinkers point out that it is inaccessible yet absolutely necessary as a foundation of experience. All we can experience are temporal things, yet time is nothing temporal. It does not come to be and pass away, and never presents itself as an object in our world. In this regard it is like being, which never presents itself as a being. Despite being nowhere accessible to experience, the entirety of our experience and thought is only intelligible on the basis of time. All of experience is temporal, and it is just as paradoxical to claim that it takes place without any time, as it is to claim that time, something entirely inaccessible to experience, is the ground of that experience. In this it is like God or death, something which is only possible as impossible.

I'm a bit confused by your last statement. Are you saying that you recognize a contemporary trend towards atemporal physics and mathematics?
I would start answering this by pointing out that, even if it is syntactically meaningless, it would be dangerous to assume it is semantically meaningless.  Wars have been fought over those two words, expressed in many many languages.

In the most basic parts of language, syntax catches up with semantics.  When forming a language, the need for concepts proceeds the creation of the syntax (at least it appears to do so for the early phrases).  Virtually all cultures (if not literally all cultures) support the concept of a Self (which can be exactly as slippery as you worry it is).  This concept proves useful enough that it was given a single-syllable utterance (whether as a word "I" or verb conjugation).

Consider: entire schools of philosophy have arisen to combat the question of "what is the self?" because the "self" is such a useful semantic concept to have in virtually everything we do, and yet it does prove particularly difficult to pin down to a syntactic definition.
Nietzsche clearly evaluates past moralities as constructive or destructive, and expresses strong feelings about the goal of a life from 'One must make of one's Self a work of art' to 'Man is what must be overcome' and boundaries on action 'Fighting monsters we must not be made monsters'.

He expresses these as truths.  And he feels urgent value from the eternal recurrence he deduces from Newtonian physics (if incorrectly, with a classical sense of math.)  It is hard to see him, then as a total skeptic relative to shared facts, even facts about values.  Even if, in the end he prefers an aesthetic sense of truth over some obligatory objectivity, he feels aesthetics have a certain kind of objectivity, or he would not bother to quarrel with Wagner.

A lot of 'critical theory' people launch from there and simultaneously undermine or devalue all of our shared standards of aesthetics as well, and that leads to the notion of global anti-realism.  But they cannot cast that whole debt back on Nietzsche, they generally need to pull in Marxism, psychoanalysis or other leverage to accomplish the more important half of the task.

From what I understand of Leo Strauss position on Nietzsche, he thought that Nietzsche had to be an outright nihilist by assuming that he did not accept myth as a form of truth.  This is much the same thing I see critical theorists doing, but he is using the remnants of an abstract Platonism that he himself rejects, to undermine the sense of realism in myth.

It is true that Nietzsche explicitly describes these as contrasting categories, but clarity of language often suffers from art.  He can't mean this too wholeheartedly, because he then fights very hard on the behalf of his own myths.  To my mind, relativism is not nihilism if one accepts that shared myths and aesthetic standards will speak to others in a meaningful way, and that they are worth maintaining for that purpose.  'Choose your delusions' is a form of relativism as an exercise in political aesthetics that is therefore not nihilistic.  It can, in fact lead to very strong religious sentiments, in a way that real Empiricism or Pyrrhonism cannot.
The geometrization of matter is a large issue, and is very relevant in present day physics (through General Relativity theory).

Spinoza in this issue, as in many others, stood on the shoulders of Descartes.

Descartes officially identified matter with geometrical (three dimensional) extension. For example, he wrote:


  In this way we will discern that the nature of matter or body, considered in general, does not consist in its being hard, or ponderous, or coloured, or that which affects our senses in any other way, but simply in its being a substance extended in length, breadth, and depth. (Principles P.II-IV)


On the other hand, many assertions of Descartes' imply that matter, for him, was more than mere geometrical extension. For example, he notes that a body may get condensed, or rarefied. And that


  The body, however, when condensed, has not, therefore, less extension than when the parts embrace a greater space. (Principles P.II-VI)


That is, a condensed body, though smaller in spatial extension, is not smaller in (material) extension.
Which implies that (material) extension for Descartes is not simply identical with spatial, geometrical extension. It is not simply identical with the space that the body occupies.
Something is wrong with your basic notion of 'containing' if you think this 'basic fact' is true.  I am not sure we know that much about the decimal expansions of transcendental numbers, but this idea is clearly an exaggeration based on some of the odder things we do know.

It seems obvious that no infinite rational representation appears literally inside the infinite representation of a transcendental number.  If 1/3 were in the decimal expansion of pi, in the sense I think you mean, there couldn't be anything after it, since the repetition never ends.  Then pi would be rational, as it would end with a repeating pattern.

It is tempting to think it is embedded in there less directly, maybe by skipping digits, or something.  But there is a standard 'trick' for constructing irrational numbers that contain only certain sets of digits, say 1 and 0, that is often used as a first-pass test at proofs about the irrationals.  The number following the pattern .01001000100001... with each run of zeroes increasing over the last, is irrational.  It clearly doesn't contain '2' much less 'every sequence of numbers'.
You said "A child psychologist, however, can be extremely biased about how kids should be raised, and have very strong opinions as well". But that's not what "biased" means. I have a very strong opinion that 2 + 2 = 4, and not 2 + 2 = 5. That doesn't make me biased (towards the number 4 or whatever). A good child psychologist will have some rather strong opinions about child psychology, but not out of any bias, but because of his or her education in the subject and their excellent knowledge. 

Of course a child psychologist could be biased, which would make them an awful child psychologist. 
I think this question comes down to your mathematical orientation.

If your are not mathematical, then infinity is very hard to justify and indeed I could support the claim that there is no "real" infinity. I say this as a mathematician: it is hard to see how a "real" infinity exists in nature. In particular, I cannot conceive of an infinite rope, or any other object composed of atoms.

But if you are a mathematician, then infinity is no sweat. It's simply a well-defined set of rules in (e.g.) set theory that we agree are the "correct" generalization of finite math to the infinite. You should consult any good book on set theory to learn more, like Jech (2000). The rules for infinity initially seem weird, but ultimately are consistent and work. And this is the key: you need to work with the rules of infinity as defined by set theory, and  strongly avoid "intuition", which will fail you mightily with respect to infinity.
No

If anyone has questions like this, the first thing to do should always be to build a test matrix to see if your theory is sound or not.  

P    Q    ~(P&Q)  (~P&~Q)
        +--------+-------+
T    T  |   F    |   F   |  same
T    F  |   T    |   F   |  not same
F    T  |   T    |   F   |  not same
F    F  |   T    |   T   |  same
        +--------+-------+


In four lines of work, we immediately get our result.   ~(P&Q) is not the same as (~P&~Q).  You can do this for any logic, and it saves a lot of time waiting for answers from StackExchange!

What you are actually looking for is DeMorgan's law: ~(P&Q) -> (~P | ~Q).  Note that the operation changes from AND to OR.
It depends on who you ask, but one school of thought holds that there is no time per se, rather there is only change and that we abstract this change and conceptualize it as time.

Looked at this way, time is measured in terms of change.  Something moves, a quartz crystal vibrates, a particle decays and so on.  Even my inner perception of the passage of time is due to my marking some kind of change, even if it's inside my body (breaths, heartbeats, etc...).
I only know a bit of what I've looked up on my own, but perhaps I can get you started, although my approach is sure to be skewed as compared to most others, and I may make glaring errors. I don't know if you are deshi; if so, you may be able to correct some of my misunderstandings concerning traditional practices on your own. Also, I am giving a sort of bulletpoint approach to traditions that have existed for thousands of years. I am therefore dealing with some of the most straightforward and systematic ideas, which may not be considered the core of these beliefs by their practitioners.

Around the same time that the mainland and Eleatic Greeks were developing philosophy - let's just say ca. 450 BCE - Indians were independently and in parallel elaborating many similar ideas in nastika belief. It is hard to know how far back these traditions go, or in what form they existed, for various reasons, but the best-known teachers are thought to have lived around the same time as the best-known early Greek teachers. There are four prominent beliefs, two of which still clearly exist in the widely observable modern world. Each had its own view of "enlightenment" and the "karmic" cycle (samsara). I will make some rather contentious comparisons to Greek philosophy.

Buddhism

Buddhism in its modern widespread form often involves idol worship, but Siddhartha (the Buddha) is supposed to have said to know the way was to know him (whereas Jesus is said to have said 'the way is through me', could this mean the same or the opposite?). I wonder what the Buddha would think of having this belief system named to his memory. Perhaps it wouldn't matter. Buddhists often subscribe to four noble truths, and they often expect to escape from the six realms of existence after spinning around through them, with escape being its own sort of boundless 'realm'.

Anyway, the Greek counterpart I think of is Socrates, who did not expect an unsuffering life, and who seemed to perceive his end as an escape into another unbounded realm.

Jainism

Jainism's best-known teacher is Mahavira. Jains typically subscribe to the seven tattva (I think the number varies). A principal of non-violence is strong in Jainism. The Jainist stories are sometimes seen to involve magic substances, karmic 'leshya'. Jainism claims to be the oldest of the nastika traditions, I believe, although I don't know if this is verifiable. Pali teachings recorded by the Jains have preserved a great deal of ancient history, although this history bears the mark of some alteration. Jainist ideas of enlightenment, as I understand them, involve the idea of sort of leveling up to connect with all spacetime as a sort of circuit; in this way, it is a faith of individual empowerment and freedom, as well as human connection. Jainism strives for actions that are Punya (virtuous, free from expectation), as opposed to Papa. 

The Western philosopher I associate with Jainism is Anaxagoras, who had a sort of magical and all-encompassing understanding of the universe.

Ajivika

The Ajivika belief is probably the least known, but it comes next, because it has the closest ties to Jainism, and historically it was pronounced. The Jains recorded some of their ideas, mostly to show them wrong. A prominent Ajivika teacher Gosala was said to have walked and argued with Mahavira, until he finally killed himself after losing an argument, although it seems I've heard accounts where he is said to have drowned himself, and others where he starved. (He was so much of a wimp that, as he starved to death, a follower offered him a mango pit, and he sucked on it! (sarcasm)) The Ajivika faith was said to have been wiped out in a single purge, in which I think something like 18,000 believed followers were killed, and every writing that could be found was destroyed, so the story goes. I believe there are still practicing Ajivika in both Northern and Southern India. They seem to have been considered somewhat annoying in history, even though they were considered somewhat passivist. The story goes that starving people would show up in villages unclothed, and then when offered food, would give much of it away to animals and other people. They didn't seem to look down on dealings with prostitutes. In addition, they were said to practice removing their finger joints for some kind of life-force ritual, as well as other strange rites. For them, the understanding of the cycle of time can be compared to unwinding string (karma, or at least the idea of karma) from a yo-yo. Eventually the string just falls away after a certain time. The Ajivika were determinists; it didn't matter too much what one did. They were also amazingly specific in terms of quantification, and were atomists. For instance, of the jiva (life) atom that was said to leave the body at death: it could not be split, was of eight parts, the color of palai fruit, and extended 2500 miles. This sounds like a completely self-contradictory statement - how could it be true?! But we now accept that there are atomic subshells that are indestructibly one piece but 8 sections and extend indefinitely theoretically. Another sort of strange embodiment for an atheistic faith, according to the existing writings: when a person is finally reaching the end of the cycle to become nothing, they will reach a doorway; Manibhadra and Purnibhadra will swoop down and try to hold on, but the person who releases will not get wound up again in the karmic cycle.

The Greek analogue I think of is Leucippus. Although we don't know much about him, we don't know much about the Ajivika either. He was obviously an atomist, and he seemed a bit of a humble wandering spirit, a strange mix of realism and fantasy.

Lokayata

'Worldly ones', also known as Charvaka ('sweet-talkers') or Brihispatiya. According to Vedic tradition, Brihispati originally taught this philosophy. It is not a good thing to be called, though, because he apparently did this to trick the asuras, power-seeking deities, so they could be more easily conquered. There's another story that Brihispati broke the head of Gayatri; each fragment became a new head, and the brain matter that fell to earth became differently colored cows, so that perhaps she represents the elements. Anyway, the Lokayata believed in the traditional elements, which were more or less the four Greek elements. Some Lokayata may have argued that death just meant a splitting of elements. Basically they were skeptical naturalists, and they are recorded as having been a pretty contentious philosophical force. They believed that the elements could combine in innumerable ways. I believe the Natya scales and elements of Indian theatre bear their mark. Their best-known teacher in ancient times was Ajita, I believe.

The Greek I would compare is Empedocles, who developed Greek elementalism, and who wrote in verse, a sort of endless speciation of ideas.
Non-expert ideas, but since this question has been up for a couple of days, here are some thoughts..

Although this sounds like a straightforward question, really I think this question unravels into what's been called the 'Laplacean spirit'. Either that, or the terms wind up recursively redefining themselves.


  If it were possible for human understanding to raise itself to the
  ideal of the Laplacean spirit, the universe in every single detail
  past and future would be completely transparent. "For such a spirit
  the hairs on our head would be numbered and no sparrow would fall to
  the ground without his knowledge. He would be a prophet facing forward
  and backward for whom the universe would be a single fact, one great
  truth." And yet this one truth would present only a limited and
  partial aspect of the totality of being, of genuine "reality." For
  reality contains vast and important domains which must remain forever
  and in principle inaccessible to the kind of scientific knowledge thus
  described. No enhancement or intensification of this knowledge can
  bring us a step nearer to the inner mysteries of being. -Cassirer, 'The Laplacean Spirit'


Also, I think perfect ontological chaos entails perfect epistemological chaos.

Firstly, I would think perfect ontological chaos would entail an infinite domain.

Assume an unchanging binary sequence 1011. Assume we consider it as a closed system, then we might reconfigure our own interpretative system to give it order:
'First half is opposites; right side is all 1s'.
Or we might say,
'Alternating sequence, except for last item'.
We can collect up all of these interpretations to give the required information resources of the observer system, and the information associated with the observed system. In any case, the information content will obviously be finite, and therefore we have not reached perfect chaos.

Likewise, if we consider this a peek into a larger system, such as ..1011.. , then we still will develop strategies for defining the extension of our knowledge. Strategies that would extrapolate this in unusual ways would be weighted low; obvious strategies would be considered likely. For instance, if we flip a coin a hundred times in a row, and it comes up heads every time, we would expect it to be a trick coin, and therefore would guess heads on a fair toss; our strategy would be 'heads'. In any case, let's just assume our observer system is not 'perfect chaos'. I think a strong argument could be made that perfect chaos cannot 'observe' or 'make meaningful representations'.

I also propose that the 'unchanging binary sequence' example can be generalized to any finite system under observation while maintaining these conclusions.

So now, in order to approach infinite information, we must approach infinite resources for storing our interpretive program and the data under consideration; therefore perfect chaos entails infinite domain.

Now, if we are dealing with an infinite domain but consider ourselves finite 'strategies', then we can only observe this infinite domain partially at any given time. We must make assumptions as we go, but we cannot make sense of it, therefore perfect ontological chaos entails perfect epistemological chaos.

To show this in better detail, let's say that, as we go, step by step observing, we constantly restructure our strategies. Our strategies might make sense to us for some steps, but over all steps, the information content must be infinite. In this case, it doesn't matter that things made sense 'in the moment', and that we were able to handle them with our finite resources, we can be assured that we cannot in the full scope fall back on old information. Whether we actually can experience infinite 'steps' is a question for Zeno, Planck, or spiritualists. In this case, we may be 'saved' from the possibility of perfect chaos by our own finitude.

Either that, or we might redefine perfect chaos to be the maximization of disorder related to one's own perceptual system. But then it no longer seems a philosophically pregnant term.

Our perceptions have a great ablility to 'scope' information, such as when a complex rhythm played quickly enough becomes a 'timbre', and also to link perceptions together, such as when moving images kick in proprioceptive feelings.
The general answer is "no, there are no special prerequisites for philosophy."  However, Philosophy is a topic which rewards those who are willing to accept challenges to their deepest held beliefs, and to those who are willing to view a topic from someone else's point of view.

I cannot speak to you as a person, but I can speak to the particular set of characteristics you chose to self-identify with in your opening paragraph.  I recognize those characteristics as those commonly held by people who have been so successful that they have never been forced to accept substantive challenges to their beliefs.  Such people often have trouble in Philosophy because they are happy to quickly declare a debate closed because there is no way anybody could disagree.

If indeed such a claim is valid in your case, you may be forced to work harder to attain success than you are used to.  You may have to consider that you could be wrong in situations that you usually would simply shrug off and continue on the assumption you are right.

Or, it is entirely possible that these positions do not apply to you at all!  Humans are wonderfully complicated creatures, and we're surprisingly good at figuring things out over time.  That goes double for things we are told we'll never understand!

Best of luck to you!
I'm far from an expert in Buddhism, but here's my stab. It seems that like much between Buddhism and Christianity, there is certainly overlap between with respect to Annica and Anatta and the Christian concept of matter and souls, but there is also disagreement.

The idea of impermanence is largely shared by most Christian traditions and Buddhism, although some of the details will be different. As an example many Christians are reminded at the beginning of Lent that they are "dust and to dust you will return," which seems very similar to the idea of the absence of permanence described by Annica. It also reminds me very much of the Benedictine idea that our station in life, current assignment, and all that entails are material life is liable to change at any moment, and must be met with a certain detachment.

Some Christian traditions have aspects that would disagree with parts of Annica. Take, as an example, the idea of angels: these are conditional beings (in the sense that their existence continues only because God allows it), but they exist in an eternal dimension, and therefore their stations are not changeable.

The idea of Anatta seems more complicated. In both Buddhism and Christianity, there is the idea that unwise ("unskillful" seems to be the Buddhist term) actions lead to suffering, and a large part of Anatta seems to be focusing on asking skillful questions where a person's self is not the central focus. However, one consequence of Anatta is that the question "Do I exist?" is not answerable - it is an unskillful question, which does not help alleviate suffering. In the Christian tradition, the question has a clear answer: yes, I do exist.
As for your example, is there a reason that both cannot be a valid description of what he believe he sees?  Can the two not be correlated?

In  math, 2/3 and 4/6 are obviously very different symbols, as is sqrt(4/9), but they are all valid notations describing the same number.  In interpersonal relationships, I may be obliged to call your friend Mr. Robert Downey Jr, but you may be allowed to call him Bobbie from time to time.  But he is the same person, regardless.

From the astronomer's (finite) perspective, the sun rising and the earth rotating are indistinguishable without an external influence to force him to distinguish them (such as a desire to point a telescope in that direction to measure gravitational lensing around the sun).  Thus there is no reason he could not experience the qualia of both at the same time.  In fact, the grammar may change to better reflect what he might feel: "the sun-rising-earth-rotating."  There is no reason a skilled astronomer must limit himself to the two choices you gave him.

In fact, a very wise astronomer would recognize that "the earth rotates" is also a finite view, centered on the earth.

As for the rest of your questions, the answer to that is philosophy.  Sadly, I'm not kidding.  Those are the questions philosophy grapples with, and there are thousands of answers to each of your questions.  In my opinion, the joy of philosophy is being able to find the answers which satisfy you while simultaneously allowing others to experience the joy of finding answers which satisfy them, even if you disagree.
Its a tricky question without any obvious answer.  Some side questions that would have to be answered first:


Is a state an entity which is governed by morals, or is it only the individuals within that state which have morals?
Who defines "crimes" at the state level?  This rapidly becomes "Is there a 'natural law' governing states?"
What does it mean to have a "moral obligation?"  Its easy to say "moral obligation for its crimes," but the real meaning is something along the lines of "moral obligation to make reparations to the greater society for its crimes" or something very long like that.  Precision can be important.


Most of those are definition questions, but the first question, whether states can have morals, at all is a strong philosophical question.  I believe the most common answer is yes.  One rationale would be wartime homicides by soldiers.  If the state can have morals, then one is not obliged to find it morally acceptable to kill members of another state in wartime.  Another rationale would stem from the appearance of a state as more than the sum of its parts.

The counter argument would be that states do not have morals because they do not have freewill, only the individuals that make up the state have freewill.  This rapidly becomes a debate capturing the essence of "freewill," which is a major topic in philosophy.
TL;DR

If one adheres to deontological or rule-utilitarian views, it is probably completely immoral. Other views on morality may say that the means justify the ends. Taking The Prince seriously contentwise (not everybody does, see e.g. http://www2.idehist.uu.se/distans/ilmh/Ren/flor-mach-mattingly.htm Garrett Mattingly, who thinks it is sophisticated satire), one has to conclude that Machiavelli himself thought that because of the political reality, immoral deeds are inevitable for achieving a morally acceptable society and political environment. One could say: You have to play by the (immoral) rules.

Long story

I will base my answer completely on the comparatively recent book:

Viroli, M. (2013). Redeeming "The Prince": The Meaning of Machiavelli's Masterpiece. Princeton University Press.

Viroli's main thesis throughout the book is that the twist of the last chapter showed that although there may be immoral action throughout the reign of the prince, the ultimate role is that of a redeemer, of instantiating utopian ideals as real in a time of political chaos:


  What then is The Prince about, and what is its lasting
  value, if any? My answer is that Niccolò Machiavelli wrote
  The Prince to design and invoke a redeemer of Italy capable
  of creating, with God’s help, new and good political order,
  thereby attaining perennial glory. The theory, and the myth,
  of the redeemer is, in my opinion, the enduring value of
  Machiavelli’s little book. As I shall document in the last
  chapter of this essay, the interpretation of The Prince as a
  discourse on political redemption has a long and fascinating
  history. Yet contemporary scholarship, with a few exceptions,
  has instead disregarded or dismissed it. (p.3)


It is, therefore, both moral and immoral: While the political activity cannot be completely detached from morality (see e.g. pp. 1-3, 18, 114), the necessary political action of a prince (or, as Viroli speaks of "enduring value", probably any political actor) may and has to be justified by the achievement for a general betterment of society, i.e. an overall morally superiour status:


  Only if we interpret Machiavelli’s prince as a
  founder and redeemer, Villari noted in the conclusion of his
  work, can we understand and justify his immoral counsels:
  
  But when, completing his analysis, and cruel labour of vivisection,
  Machiavelli proceeds to draw his conclusions, then
  at last the practical side and real aim of his work are clearly
  seen. It is a question of achieving the unity of his Italian
  motherland and of delivering it from foreign rule. This was
  certainly the holiest of objects; but Machiavelli well knew
  that in the conditions in which Italy and Europe were then
  involved it would be impossible to achieve that object without
  recurring to the immoral means practiced by the statesmen
  of his time. Pursued by this idea, and dominated by
  this theme, Machiavelli did not pause to disentangle the
  scientific, general and permanent aim of his book from the
  practical aim and transitory means, apparently and, it may
  be, really essential to its achievement at that moment. It is
  needful, he said in the conclusion, to dare all things, and in
  view of the grandeur and sacredness of the end, to yield to 
  no scruples. Solely by the formation of a united, powerful,
  and independent nation can Italy acquire liberty, virtue and
  true morality. This is an enterprise only to be undertaken by
  a Prince–reformer, and by means suggested and imposed by
  history and experience. The people must afterwards complete
  and consolidate it by liberty, by national arms, by public
  and private virtue. (pp. 176-7 note 38, citing Pasquale Villari, Niccolò Machiavelli e i suoi tempi; English
  translation by Madame Linda Villari, The Life and Times of
  Niccolò Machiavelli, London, T. Fisher Unwin, 1892, vol. I, p. 196)


One could, therefore, conclude that while applying the standards of deontological morals it is a completely immoral book, according to certain utilitarian views the means justify the end, just as Machiavelli himself may have seen it (which surely is Viroli's view).

All in all, every political actor has to be judged by moral standards and Macciavelli does argue this as well. In this sense, The Prince surely is not immoral. All Macciavelli does is opening the scope from individual actions to "the whole reign will be judged by history", which is actually, as Viroli argues, an enduring picture still influential in modern history, and probably the reason why the book is part of the curriculum of (at least most of the) ivy league colleges educating the soon-to-be powerful.
It sounds like he's begging the question.  He's assuming the existence of the external world to prove the external world.

If one assumes nothing beyond appearances, then the existence of objects that behave like me simply mean there are appearances of objects behaving like me. Nothing in the appearances implies that these objects have a subjective inner state like I do. Assuming anything beyond appearances is an inference.

Views that deny the external world (like solipsism) aren't the least bit challenged by his argument. In fact, denying the external world is the kind of position that seems immune from any kind of refutation, for the simple fact that it "absorbs" everything, including arguments that it's not true.  
This may arise from an erroneous https://books.google.co.jp/books?id=HN8TAAAAYAAJ&pg=PA137&lpg=PA137&dq=Socrates%20walked%20in%20garden&source=bl&ots=90lZ71zCW-&sig=ULgwUP8gNW7NslKj8NT8MteitVc&hl=en&sa=X&ei=6OXVVOHYG-OomgWkhYCICQ&ved=0CDkQ6AEwBzgK#v=onepage&q=Socrates%20walked%20in%20garden&f=false parable:


  One day Socrates walked with his disciples into the garden of Pericles, and they spoke of the arts and their divine excellence.


This is in a text by Frederic Adolphus Krummacher from the 19th century.

Another possible origin is in the  http://www.gutenberg.org/files/1636/1636-h/1636-h.htm Phaedrus: 


  Phaedrus has been spending the morning with Lysias, the celebrated rhetorician, and is going to refresh himself by taking a walk outside the wall, when he is met by Socrates, who professes that he will not leave him until he has delivered up the speech with which Lysias has regaled him, and which he is carrying about in his mind, or more probably in a book hidden under his cloak, and is intending to study as he walks. The imputation is not denied, and the two agree to direct their steps out of the public way along the stream of the Ilissus towards a plane-tree which is seen in the distance. There, lying down amidst pleasant sounds and scents, they will read the speech of Lysias. 




My money is the on apocryphal one but I don't think arises from a confusion with other ancient philosophers -- but rather a confusion about the veracity of the 19th century source and some idealization.
St. Thomas Aquinas's Summa Theologica question "http://dhspriory.org/thomas/summa/TP/TP077.html#TPQ77OUTP1 Of the Accidents Which Remain in This Sacrament" should help.

Relevant to your question "Is transubstantiation faithful to Aristotle's categories?," http://dhspriory.org/thomas/summa/TP/TP077.html#TPQ77OUTP1 its article "http://dhspriory.org/thomas/summa/TP/TP077.html#TPQ77A1THEP1 Whether the accidents remain in this sacrament without a subject?" contains an objection that cites Aristotle:


  [N]ot even by miracle can the definition of a thing be severed from it, or the definition of another thing be applied to it; for instance, that, while man remains a man, he can be an irrational animal. For it would follow that contradictories can exist at the one time: for the "definition of a thing is what its name expresses," as is said in http://dhspriory.org/thomas/Metaphysics4.htm Metaph. iv. But it belongs to the definition of an accident for it to be in a subject, while the definition of substance is that it must subsist of itself, and not in another. Therefore it cannot come to pass, even by miracle, that the accidents exist without a subject in this sacrament.


Thus, transubstantiation would seem to contradict Aristotle.

But St. Thomas replies to this objection:


  Since being is not a genus, then being cannot be of itself the essence of either substance or accident. Consequently, the definition of substance is not---"a being of itself without a subject," nor is the definition of accident---"a being in a subject"; but it belongs to the quiddity or essence of substance "to have existence not in a subject"; while it belongs to the quiddity or essence of accident "to have existence in a subject." But in this sacrament it is not in virtue of their essence that accidents are not in a subject, but through the Divine power sustaining them; and consequently they do not cease to be accidents, because neither is the definition of accident withdrawn from them, nor does the definition of substance apply to them.


His argument hinges on the real distinction between being and essence, which he overviews in, e.g., http://dhspriory.org/thomas/DeEnte&Essentia.htm De Ente et Essentia.
I would like to formally challenge (3) on Relativistic terms.

Consider the Minkowski diagram of someone accelerated to nearly the speed of light and then decelerated back.  For a substantial period, their time 'crawls' relative to ours.  But that does not obliterate their past experience or any given future.  We allow that they will have a continuous  experience, we will just have a span of experience in which they will not participate.

Likewise consider the timeline of a bundle of energy which is matter, then emitted as a gamma-ray, and recaptured.  It has a past and a future, even though it has no present.  Its experience is not 'the Void', it is simply suspended relative to our own.

Humans can experience timelessness by suspending memory during meditation.  So we do not expect an ongoing experience to be totally uninterrupted by gaps.  Maybe your photon is just praying at the moment...

And if you accept the lack of experience of time as The Void, then well, people do it all the time, especially during sleep, so there is a much more direct access to your question.  It is clearly there, but can never be shared, so who cares?
... how to make sure a definition captures the intutive reasoning correctly, taking all special cases into account?

Well that's the art! In his preface to Calculus on Manifolds, Michael Spivak says: 


  There are good reasons why the theorems should all be easy and the
  definitions hard.


That quote says it all. The art is to find the right definitions. You mentioned topology. As you know, it took decades of struggle to find the right characterization of continuity. The realization that the notion of the open set was the essence of continuity was a huge breakthrough. It's only obvious in retrospect.

You mentioned Riemann integration. That's another good example, because in higher math the Riemann integral is no longer used. There's a more general theory called Lebesgue integration which behaves better. That doesn't mean that we were wrong to "trust" Riemann. Trust really has nothing to do with it. We live in the world as it is.

The struggle to find good definitions is at the core of the development of mathematics. So when you ask, "... how to make sure a definition captures the intutive reasoning correctly, taking all special cases into account? the answer is ... if we knew, we'd bottle it and give it to the undergrads. There's no magic formula for progress. 

But you are also asking if we can "trust" experts, knowing that in a few decades they'll be proved wrong or foolish. If you had an infected leg in the 1800's they sawed it off. Without anesthetic. Did you trust your doctor back then? What other choice did you have? 

It's the same in every field. Math is no different. Mathematics is a historically contingent human activity. It's never perfect but it's always getting better. Painstaking struggle, false starts, the occasional genius, lots of plain old hard work. That's how progress is made in every field.

Whether you trust, and what you trust, is up to you. You drive over bridges. Sometimes the bridges fall down. Over the years we learn to make better bridges,  never perfect bridges. You'd be foolish to trust all the experts all the time. But you'd be even more foolish to never leave the house for fear of a falling bridge. Someone the other day asked the difference between rationality and logic. Rationality is what lets you drive over a bridge that you know might fall down, even though you can never personally investigate every nut, bolt, and corrupt government contract.

I just happened to run across a guy named http://en.wikipedia.org/wiki/Ignaz_Semmelweis Ignaz Semmelweis. He was a German doctor in the 1840's who said that obstetric deaths could be reduced if doctors would just wash their hands before delivering babies. He was rejected by the medical community, committed to an insane asylum, and beaten to death by the guards. 

That's human progress. 
There is no reason under a Christian world view to believe that point 5 is true. We where made perfect in his image but by our own device we fell from the pinnacle of his perfect creation and through this our sinful nature was born. Luckily for us all a young carpenter from Galilee came so that we should not perish because of our sinful nature.

Your premise may still be true but without a great deal of justifying I withhold belief. Actually I'm rather interested in how this premise would be defended. 

At least all the premises follow so the strength of this argument would hinge on the defending of the premises.
Just to contribute a possible aside, it's not completely clear that what you want is actually about logic as such as much as it's about Critical Thinking.  While it's undoubtedly clear that having a strong understanding of the practices of formal logic helps your ability to interpret arguments and discussions in a tractable conceptual modelling scheme, there is a certain degree to which leaping into logic texts before otherwise developing your reading skills might be using a sledgehammer to crack a walnut.

My university recommends Stella Cottrell's http://www.amazon.co.uk/Critical-Thinking-Skills-Developing-Effective/dp/0230285295 Critical Thinking Skills as a valuable introduction, and certainly students of almost any in-depth course of study would do very well to find a similar sort of book as the first textbook they read.
Not necessarily so. There are determinist interpretations of quantum mechanics: bohmian mechanics, or the many world interpretation.
'Strength' for Nietzsche' is strength to choose our own values. This strength is lost, or never possessed, if we have been infected by 'slave morality' as he calls it. Slave morality prescribes what we must do; the strong for Nietzsche are by contrast the self-affirming, who reject all idea of what we must do, and create their own values. The creation of one's own values is the mark of self-afffirmation and hence of strength. ('Genealogy of Morals', I:2.)

This is clearly a special sense of 'strength'. The strong are not those who subjugate others, who coerce the weak. And the weak are not those who lack the physical power or the psychological ability to stand up to the strong. Nietzsche is working with an unconventional understanding of strength and weakness. When he praises the strong he does not understand strength in the same way as, say, Thrasymachus in Plato's 'Republic'. 

Given this special sense of 'strength - and correspondingly of 'weakness' - it is hardly possible for the strong to oppress the weak and to abuse their own power. If I choose my own values, in which my strength consists, I can scarcely (simply by virtue of this choice) oppress the weak - whose weakness consists solely in the fact that they do not choose their own values. 

Some mention should be made of compassion, on which Nietzsche appears to be particularly hard : 'compassion I recognized as more dangerous than any vice' ('Will to Power' : 54). But in my view what Nietzsche mainly has against it is (a) that it distracts the strong, by its psychological pull, from choosing their own values (they are dragged down by this one); and (b) that it treats others as mere passive objects in need of help. By extending compassion of them, the strong are not helping them to become conscious of themselves as potentially self-affirming, value-creating agents ('Beyond Good and Evil' IX : 270). 

For all his brilliant style, Nietzsche is an extremely difficult writer to reconstruct with any assurance. I have offered a reading of the relevant part of his work. It is serious but tentative. No sympathy on my part should be assumed for any of the views I have attributed to him.
Are you talking about unity or non-duality?  

It's possible to be a non-dualist without asserting unity.  It isn't that you're rejecting unity, it's just that you reject duality and make no (positive) assertions in its place.

Likewise, it's possible to assert unity while implicitly asserting duality.  The problem here is that to even assert something is to imply the existence of its opposite, otherwise why assert? Why do we need to speak (or think) X if there is no not-X?

Can you see the problem?  This is fitting, as the non-dualist points to conceptualization as the problem.  Not a specific concept, but conceptualization.  Well, if you try to fix conceptualization with conceptualization, are you really fixing anything?

In fact, I read this as the fundamental difference between Buddhism and Hinduism.  Hinduism asserts unity.  Buddhism asserts non-duality without asserting anything else.  Yet this is a hard position to maintain, so a variety of positive assertions were made, yet these were a mistake, so a variety of attempts to counter those assertions were made, and the result is much of the (apparent) nonsense, contradictions, logical flouting and... well Nagarjuna :)

Yet if we look at Buddhism and Hinduism as being non-dual, we can see them as choosing two paths to solving the same problem.

The key here is realization; one is supposed to realize non-dualism, to feel or perceive this, perhaps even as a realization of how baseless duality is. One should not reason about this, or if one does so, to do so only insofar as is needed to get one on the right track (or just off the wrong one).

If you haven't done so, I recommend you read David Loy's http://rads.stackoverflow.com/amzn/click/1573923591 Nonduality.  It's a solid treatment of this subject.
This can be a logical fallacy --any attack on an argument that isn't actually related to the strength or the premises of the argument is a fallacy, by definition.  If I make a claim, and you criticize it without an alternative, that does not mean that any correct points you make about my claim are invalidated.

On the other hand (from a sociological viewpoint) it is a legitimate criticism of a person's overall contribution that they never produce any positive ideas --it just isn't a legitimate criticism of their actual arguments.
First off, I want to say this is a really good question that reflects real thought on an interpretative issue in Kant studies. Second, I think you're grasping some major things but also thinking backwards (by which I mean imposing contemporary categories on what Kant is doing).

In terms of your question, one major issue is going to be where in Kant you are reading. The account you are giving sounds closest to the Critique of Pure Reason (Kritik der reinen Vernunft). There, I take Kant's position to be as follows:


As far as empirical science is concerned, our actions are determined
Moral responsibility requires our actions to be free


This is what Kant calls the "Third Antinomy" (or perhaps that is just what contemporary Kant scholars call it).

But there are some specific details where I think you may be deviating rather sharply from Kant (or at least wording them in some significantly different ways). The background for this is that Kant's account of human knowledge is predicated on the belief that our knowledge is limited to objects (those things we place under the forms of sensibility and categories of the understanding). To put it another way, Kant is a skeptic about certain types of knowledge claims, because he thinks we never encounter things in an unencumbered way. But the manner in which we relate to objects is called "understanding."

It turns out that our actions are renderable both through our understanding which places things under the categories of cause and necessity (to name the most relevant two). But our actions take place for ourselves under the auspices of reason which is a different faculty. The easiest way to say this is that I understand your actions, but I reason to my actions on Kant's account.

So to return to the details in your question, you state:


  Therefore, the reason must be part of the noumenal world, from where it is able to cause our behavior.


but at least on my reading of Kant, there's a minor error here. Viz., Kant does not see this as a conclusion but rather as a premise that relates to what reasoning is. But if you're just reading the Critique of Pure Reason as your source, then you might come up with this conclusion. The problem is that Kant changes how this works between the 1st Critique, the Groundwork, the 2nd critique, the Metaphysics of Moral, and Religion. Each of them gives a slightly different explanation of how we are morally/noumenally free yet empirically determined.



You're correct to think this progression is wrong:


  We hold people responsible->We should hold people responsible->Holding people responsible would not make sense without free will (free from laws of physics/empirical influences)->There must be free will in the noumenal world.


No Kant work states this.  

There's two important features in Kant's ethics that do seem similar. I take it that Kant asserts (at least outside the Groundwork this becomes a faktum of reason) we have reason (Vernunft) and this means that we can choose our own actions -- in fact, we can choose them despite our empirical natures. Thus, we are responsible for our actions, and thus, we are not determined.

A better but related argument has to do with Kant's belief that the world is ultimately just / what is called in the literature Kant's proportionality principle/thesis. Kant, for reasons that are nearly opaque, asserts in his moral philosophy that the world will ultimately turn out to be just. But this is contrary to empirical evidence about this world (evil people die happy; good people die sad; etc).  Thus, Kant asserts a God brings about just desserts in an afterlife.



Depending on which work you are looking at in Kant's moral philosophy, the basis of the claim that we are free is different.

Critique of Pure Reason -> An antinomy shows that we cannot know we are free, but we live that we are free. Reason is free and distinct from understanding.
Groundwork -> Part III is an argument that we are somehow free (not well-accepted or understood)
Critique of [Pure] Practical Reason -> we are understood to be free as a fact of reason.
Metaphysics of Moral: Doctrine of Virtue -> we are free as a condition for a just world.
Religion within the Bounds of Reason Alone -> we are free at least insofar as we make a sort of root decision that impacts our later ability to be free.

Notably, it moves from an argument in the first two works to an assertion in the latter three.
Hume's definition of liberty (=freedom) is close to your second formulation:


  By liberty, then, we can only mean a power of acting or not acting, according to the determinations of the will; that is, if we choose to remain at rest, we may; if we choose to move, we also may. Now this hypothetical liberty is universally allowed to belong to every one who is not a prisoner and in chains. Here, then, is no subject of dispute. (http://www.philosophy-index.com/hume/enquiry-human-understanding/viii.php An Enquiry Concerning Human Understanding §73)


Hume was a compatibilist. That is, he held that freedom (=freedom of will), correctly understood,  is compatible with necessity (=determinism). And he held that both freedom and necessity are the case:


  It is universally allowed that nothing exists without a cause of its existence . . . Liberty, when opposed to necessity, not to constraint, is the same thing with chance; which is universally allowed to have no existence. (Ibid. §74)

The actual sentence as such doesn't matter; it's a certain perspective that the sentence can carry - the negative or indefinite judgement; and it's keyed by the form of the sentence.

A positive judgement affirms the positive: Kant is German. Similarly a negative judgement affirms the negative: Kant is not German.

The first sentence says he is German but says nothing about what else he could be - he may have dual nationality for instance; similarly the second sentence though saying he is not German, doesn't say what he is. It's in this sense the sentences are seen as indefinite.
The idea of an imperative, and it's qualification as hypothetical and categorical is most easily understood by examining Kants Groundwork of a Metaphysics of Morality; he writes:


  All imperatives command either hypothetically or categorically:
  
  the former represent the practical neccessity of a possible action to attain something else that one wills, or might will; the categorical represents an action that is objectively necessary in itself, without reference to another end.


Earlier he explains:


  A law to be called moral must be universally and neccessarily valid; a law should not be merely for this or that human being, or this or that nation; but for all rational beings. 


Thus a hypothetical imperative would be, for example, if you (your actual self, not the general you) are at Canary Wharf underground station and about to go up the escalator to ground level; when you see that the person ahead of you is a young mother who is having trouble getting her pram onto the escalator; and there is no one else with her to help; thus you offer your help, which is gracefully accepted.

Here the situation is specific; and thus the imperative is hypothetical - it ought to be done.

A categorical imperative would be for the state to provide schooling - legally provided via private or public institutions, or some mixture; as all rational beings at some point are children and require schooling; here the situation is general and thus the imperative is categorical: it must be done.

Another way of examining these two situations is to examine the consequences if they are not:

In the first situation all mothers who decide to travel through Canary Wharf Stn with a pram and no one with them will be left to themselves to struggle as best as they can with the escalator; London will carry on, as will the nation.

In the second situation, no schooling of any kind is provided; the kids are left to themselves at home (parents aren't allowed to provide schooling - as this is a form of private schooling) or on the streets; it won't be long before London, and the nation descends into chaos.
Socrates was a contrarian to the end, and one of his last acts was to force the Athenians to follow through on an execution they never actually wanted or expected to serve.  

The goal of Socrates' antagonists was really just to humiliate and discredit him publicly, and in that way to break the fascination he held for the disaffected Athenian youth.  But Socrates wasn't willing to play along and he wasn't scared to die.  In court, he served as his own lawyer.  The Athenian system at that time was that when a conviction had been obtained, the prosecutor and defender would each propose a punishment and the jury would choose the one they found most fitting.  The concept was that this would give the prosecution an incentive to not be too harsh, the defense an incentive to not be too lenient.  However, in this case, the prosecutor went for a grand flamboyant gesture, and asked for death. 

The expectation was that Socrates would counter with some minor sentence, maybe some light jail time.  Instead, he proposed that he be sentenced to be fed lavishly at the expense of the state for the rest of his life --a clearly ludicrous "punishment."  To everyone's horror, the only real option left to the jury was either to acknowledge the whole thing as a farce, or to go with death.  Even then, they placed him in a minimum security prison, and gave him every opportunity to escape, which he ignored.

So did this help or hurt Athens?  It certainly did no favors to Athens' reputation or self image.  I imagine, however, Socrates himself would have claimed it had a salubrious effect, by forcing Athens to be more honest with itself and less hypocritical.
If there were some obvious universal coordinate frame ("center of the universe") with some sort of obvious choice of axes ("um...???"), then it would of course be no problem.

But the universe isn't like that.  It's not even entirely clear what the geometry of the universe is.  (Worse still: when you're embedded into a manifold of some higher geometry, you can't tell what shape the manifold "really" is, though you can for instance notice of local geometric relationships that would be true in Euclidean space.)

Happily, this isn't what we mean when we say a particle is somewhere.  It's enough to know the relationship between the particle and some other reference point that you can identify (e.g. the measurement device in your physics lab).  And, better yet, because of relativity that's usually enough; maybe you're moving at 0.99c compared to some other far-away thing, and maybe in some sense that thing is a better choice of universal reference frame, but it's irrelevant because your local physics isn't affected by your relative velocity compared to that far-away thing.

So when one says a particle is somewhere, one needs, at least implicitly, to have some reference frame in mind.  But identification of the reference frame usually isn't a major challenge in practice (when it is, one must take on that challenge).  So we can speak freely of particles having a position.

(Even worse: they're delocalized due to quantum mechanics.  We can still say that the center of the probability distribution has "a position" if we like the idea of exactness, or we can just give up and accept a pretty strongly peaked distribution function in place of "a position".  But this is a separate issue from not being able to find a universal reference frame.)

Finally, what would happen if we have only one particle and nothing else (setting aside the concern about what "we have" means in such a case)?  Well, then there is no need for the concept of space at all.  Saying "it is always at the same place" is meaningless.  Rather, we say that we do not need to consider embedding into a geometry or manifold in order to understand the properties of this particle.
You can interpret the wave equation as expressing this.  There is only 'possibility' everywhere, and it becomes more '[thing]like' some places than others for various values of [thing].

Or, focussing upon virtual particles, there is a field of [thing]iness and anti-[thing]iness that is uniformly balanced almost everywhere, but when they are out of balance we notice [thing]s or anti-[thing]s.  Electrons are not items in space they are places where the wave-mediums of electrons and positrons are not balanced.

From such perspective, a field becoming stronger or weaker in different places is only apparent motion, like the sequenced flashing lights that point the way to a casino doorway.  Nothing moves, the light just gets more intense in one place and less intense in another.

So this rescues both Parmenides intuition and the actual motion we see.  But isn't it just linguistic trickery to dodge the weakness of our basic intuitions of particle, wave and field?  The infinite wait for the elusive graviton notwithstanding, we know that they are all of a piece somehow, but that each intuition fails in its own way.

The field component's weakest fit for bosons is obviously quantization.  Electrical field theory predicts the occasional partial electron.  Electrons cannot come in just any size, like photons.

But for leptons like photons, it saddles us with all of the thinking about aether that preceded Relativity.  The field should be borne by something that acts rigid to some degree.  There should either be an intrinsic push-back against propagating change in the field too quickly, or there should not.  But space acts otherwise for leptons: It resists being driven too fast, but does not begin to resist until right then.
It would be silly to maintain the impossibility of mixing perspectives when one has techniques that are equally examples of both.  Take Fisher's Q-methodology, for instance: http://en.wikipedia.org/wiki/Q_methodology http://en.wikipedia.org/wiki/Q_methodology.

The Q-Methodology seeks to identify the predominant themes in a population's subjective view of an artifact or subject in a mathematical way that measures comparative agreement with various statements.

Since you get data on statements, it is necessary to take a qualitative view to select statements that might indicate differences in perspective and to combine related statements into representative threads.

But you are relying upon a quantitative technique to judge the subjective levels of agreement, since no one can pretend to objectivity in determining that.  Your attitude infects others, and if different perspectives are not represented side-by-side as expressed by their own advocates, your own preferences can be subtly expressed in ways subjects may discern.
I think you moved a little bit too fast from money to work.
As Marx pointed out, money itself is nothing but a medium, which can allow the trading of products between people who are not directly interested in trading their products.

For example, let's suppose that A's got some apples, B's got bananas and C's got strawberrys. Now if A wants a banana, B wants a strawberry and and C wants an apple, they can't actually trade their product, but with money they could. In this scenario, if they all start with 1 coin, they will end the trade with 1 coin. The point here, is not the accumulation of money, it is just a way to simplify the whole thing.

In capitalism though, money becomes the target, and work is the only way to get some money, if you don't have any good to sell. Now, this kind of work is alienating, without any doubt. Nevertheless, free work, the free production by the individual of what he wants (for exaple, art) is for Marx the activity which allow people to exercise their freedom, what makes them humans.
Here is an excellent article on the subject. It points out how the writing should be structured and gives some very useful examples. It summarizes with the following points:


  Writing and the Scientific Process
  
  We began this article by arguing that complex thoughts expressed in impenetrable prose can be rendered accessible and clear without minimizing any of their complexity. Our examples of scientific writing have ranged from the merely cloudy to the virtually opaque; yet all of them could be made significantly more comprehensible by observing the following structural principles:
  
  
  Follow a grammatical subject as soon as possible with its verb.
  
  
  Place in the stress position the "new information" you want the reader to emphasize.
  Place the person or thing whose "story" a sentence is telling at the beginning of the sentence, in the topic position.
  Place appropriate "old information" (material already stated in the discourse) in the topic position for linkage backward and contextualization forward.
  Articulate the action of every clause or sentence in its verb.
  In general, provide context for your reader before asking that reader to consider anything new.
  In general, try to ensure that the relative emphases of the substance coincide with the relative expectations for emphasis raised by the structure. 
  
  
  
  It may seem obvious that a scientific document is incomplete without the interpretation of the writer; it may not be so obvious that the document cannot "exist" without the interpretation of each reader.
  
  None of these reader-expectation principles should be considered "rules." Slavish adherence to them will succeed no better than has slavish adherence to avoiding split infinitives or to using the active voice instead of the passive. There can be no fixed algorithm for good writing, for two reasons. First, too many reader expectations are functioning at any given moment for structural decisions to remain clear and easily activated. Second, any reader expectation can be violated to good effect. Our best stylists turn out to be our most skillful violators; but in order to carry this off, they must fulfill expectations most of the time, causing the violations to be perceived as exceptional moments, worthy of note.
  
  A writer's personal style is the sum of all the structural choices that person tends to make when facing the challenges of creating discourse. Writers who fail to put new information in the stress position of many sentences in one document are likely to repeat that unhelpful structural pattern in all other documents. But for the very reason that writers tend to be consistent in making such choices, they can learn to improve their writing style; they can permanently reverse those habitual structural decisions that mislead or burden readers.
  
  We have argued that the substance of thought and the expression of thought are so inextricably intertwined that changes in either will affect the quality of the other. Note that only the first of our examples (the paragraph about URF's) could be revised on the basis of the methodology to reveal a nearly finished passage. In all the other examples, revision revealed existing conceptual gaps and other problems that had been submerged in the originals by dysfunctional structures. Filling the gaps required the addition of extra material. In revising each of these examples, we arrived at a point where we could proceed no further without either supplying connections between ideas or eliminating some existing material altogether. (Writers who use reader-expectation principles on their own prose will not have to conjecture or infer; they know what the prose is intended to convey.) Having begun by analyzing the structure of the prose, we were led eventually to reinvestigate the substance of the science.
  
  The substance of science comprises more than the discovery and recording of data; it extends crucially to include the act of interpretation. It may seem obvious that a scientific document is incomplete without the interpretation of the writer; it may not be so obvious that the document cannot "exist" without the interpretation of each reader. In other words, writers cannot "merely" record data, even if they try. In any recording or articulation, no matter how haphazard or confused, each word resides in one or more distinct structural locations. The resulting structure, even more than the meanings of individual words, significantly influences the reader during the act of interpretation. The question then becomes whether the structure created by the writer (intentionally or not) helps or hinders the reader in the process of interpreting the scientific writing.
  
  The writing principles we have suggested here make conscious for the writer some of the interpretive clues readers derive from structures. Armed with this awareness, the writer can achieve far greater control (although never complete control) of the reader's interpretive process. As a concomitant function, the principles simultaneously offer the writer a fresh re-entry to the thought process that produced the science. In real and important ways, the structure of the prose becomes the structure of the scientific argument. Improving either one will improve the other. 


The complete article is available here - http://www.americanscientist.org/issues/pub/the-science-of-scientific-writing/ http://www.americanscientist.org/issues/pub/the-science-of-scientific-writing/
I strongly suggest Stephen Toulmin's http://rads.stackoverflow.com/amzn/click/0226808386 Cosmopolis: The Hidden Agenda of Modernity. He presents philosophy, politics, society, and the conflicts which [he claims] powerfully drove Enlightenment thinkers to think Enlightenment things. He explains the "Quest for Certainty" (also known as the "Cartesian anxiety") as a reaction to the incredible certainty of the Protestants and Catholics which thwarted successful dialog and resulted in war. There are two options: (i) critique the certainty; (ii) come up with something more certain, to compete. This historical sketch fits well with observations such as the following:


  The case of Leibniz gives us some clues to the underlying things at stake for many of those who dreamed this same dream. As a boy, Leibniz tells us, he conceived of what he called a http://en.wikipedia.org/wiki/Characteristica_universalis characteristic universalis—or "universal system of characters"—that would be able to "express all our thoughts". Such a system, he declared,
  
  
    will constitute a new language which can be written and spoken. This language will be very difficult to construct, but very easy to learn. It will be quickly accepted by everybody on account of its great utility and its surprising facility, and it will serve wonderfully in communication among various peoples.
  
  
  (100)


Nowadays, we can hopefully see this for the naïveté it deserves. This doesn't keep people from http://ask.slashdot.org/story/15/04/08/162231/ask-slashdot-what-would-a-constructed-language-have-to-be-to-replace-english asking about constructed languages, but I think history has taught us that language and culture are deeply intertwined. To provide a bit more of an idea of what Cosmopolis discusses:


      In the three hundred years after 1660, the natural sciences did not march along a royal road, defined by a rational method. They moved in a zigzag, alternating the rationalist methods of Newton's mathematics and the empiricist methods of Bacon's naturalism. (104)

The original sentence was "wasteful."  Both parties agree that it would have been better if A had said the correct meaning in the first place.  However, resources were expended in the confusion.

If one values those resources, one must value not saying sentences which are likely to be misinterpreted.  If one considers such things ephemeral, and is only concerned with eternal things like truths, then they are not important.

Given that the human condition seems to be sandwiched between finite resources and the search for the eternal, I would generally expect the answer to be somewhere in between the two extremes.

However, the final argument "... you should still admit you shouldn't have said the sentence" uses "should," which is a really tricky word in philosophy.  Ignoring all of the rest of the details, much of the answer as to whether person A or person B is right will stem from your preferred philosophy regarding the word "should."
The history of ideas and the history of philosophy is a world riddled with boogeymen versions of certain philosophers. Some of the more common historical boogeymen are "Plato", "Aristotle", "scholasticism" / "Medieval philosophy" , "Descartes", "Kant", "Hegel", "Nietzsche", and "Kierkegaard" . You may notice two things about this list: (1) every name is in quotes and (2) every one of these is a philosopher and/or philosophical position.

To really follow the history of ideas, you often need to know both the philosopher and the boogeyman version because some authors use these names to talk about boogeymen.

The Aristotle boogeyman usually occurs in the context of science and sometimes in some 20th century logic. The general attributes are:


Some sort of crazy view about biology that we call "teleology"
Horrible observational skills as identifiable from mistakes like miscounting the number of teeth in women
Inaccurate beliefs about pregnancy
Convoluted logical method that does not compare with contemporary logic


Teleology is a deeply misunderstood idea, because later scholastic philosophers used it to prop up vitailism and other views that were deeply mistaken about life. But Aristotle's idea is not (at least on all occasions) so onerously off. But people who at best have read small snippets of Aristotle's works in biology associate the view with him -- because that's the story they are taught.

Regarding 2, he was just wrong. I have no idea why. His father was a physician and he spent a decade looking at animals.

Regarding 3, the picture is more complicated, because he gets right what you need to make offspring, but he does not understand exactly what the man and woman bring and associates this with his hylomorphic account such that the woman contributes the hyle (matter) and the man the morphe (form). But if you compare what he understood with the views, he's critiquing, he's a biological genius.

Regarding 4, could Aristotle solve every problem we can now with propositional logic, modal logic, deontic logic, and set theory? No, but again, think about how impressive it is that he came up with the syllogistic method that after its rediscovery transformed Western thought.

I think Russell is for the most part thinking of a boogeyman Aristotle -- an antiquated ignoramus not well identified with remnant texts we possess.There's a grain of truth in the weakness of some of Aristotle's methods for logic. I would not say this is because they are wrong, I would say it is because they are just limited. (But then I would like to add in passing that many of Russell's forays regarding logical positivism and philosophy of language are no longer current either).
There is this related in http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.01.0052%3Abook%3D1%3Asection%3D983a Metaphysics:


  It is clear that we must obtain knowledge of the primary causes, because it is when we think that we understand its primary cause that we claim to know each particular thing. Now there are four recognized kinds of cause. Of these we hold that one is the essence or essential nature of the thing (since the "reason why" of a thing is ultimately reducible to its formula, and the ultimate "reason why" is a cause and principle); another is the matter or substrate; the third is the source of motion; and the fourth is the cause which is opposite to this, namely the purpose or "good";for this is the end of every generative or motive process. We have investigated these sufficiently in the Physics4;


This is a paraphrase, and I think a more useful one than the one you cited above. In particular, we have the material cause is what the thing is made out of (this seems pretty straightforward), but the formal cause is the "essential nature of the thing."

An analogy would be the difference between a builder's building materials and the blue-print. Both are needed to create a building, but the materials are (obviously) the material cause, whereas the blue-print provides the form that the building will take (and is the formal cause).
Determinism typically means (something like) being predictable in principle, if given adequate information and computational power.  If I understand what you mean by these terms, then I would say that a coin flip is both deterministic but also unpredictable due to the fact that we do not in fact have the adequate information and/or computational power necessary to make a prediction within acceptable measurement error.
If constant change, even when not traversing space, is not rest, then it is a consequence of Heisenberg, and more basically of 'frequency' as an essential aspect of matter due to deBroglie, that there is no absolute rest.

Things either have a frequency, or they cannot be detected.  Interference with another thing with a frequency is the only way of detecting things.  And to a certain degree, things with no effects do not exist in the same way that detectable things exist.  To admit them ontologically opens you up to a profusion of nonsense.

I don't think this is tied to the relativity of space in any important way.

If time is measured as accumulating entropy, then this may have to do with the relativity of the arrow of time.  My pet Boltzmann-inspired way of looking at quantum frequency is that what is increasing and decreasing at that frequency is the local component of entropy, and so what is 'waving' is time.
While https://en.wikipedia.org/wiki/Reproduction_%28economics%29 the Wikipedia article on economic reproduction is kind of a mess, that seems to be the concept that this question is grasping at. I'll quote the following which is actually a very nice summary of Marx's answer.


  Marx distinguishes between "simple reproduction" and "expanded (or enlarged) reproduction".[4] In the former case, no economic growth occurs, while in the latter case, more is produced than is needed to maintain the economy at the given level, making economic growth possible. In the capitalist mode of production, the difference is that in the former case, the new surplus value created by wage-labour is spent by the employer on consumption (or hoarded), whereas in the latter case, part of it is reinvested in production.


So Marx's theory of simple reproduction explains that the circuit of capital must always stay in motion. Note here that the opposite of circulation is basically the "hoarding" of wealth. Capitalists don't hide their money under they mattress, because then they won't make a profit. They keep it circulation by reinvesting it in production (or at least putting it in a bank that can isssue loans). Hoarding (or non-productive investments, like in a real estate bubble) is a basic sign or symptom of an economic crisis. This is where Keynes draws from Marx, although his basic understanding fo the process is very different.

Marx's theory of expanded reproduction gets to the other part of the question, which is economic growth. And for Marx, decisively, this is not just a mere appearance of growth, but an accumulation of value-in-circulation. Picture an electrical circuit where the voltage tends to increase more and more over time. The source of the metaphorical "energy" in the capitalist economic system, for Marx, is human labor. It is the only commodity capable of adding additional new value to the circuit of commodities. The value of machinery and represents previous human labor accumulated in a productive physical form, and that is also part of what allows the scale of circulation to increase over time. 

The other kind of circulation Marx touches on, but does not develop in very much detail, is metabolism, that is, the circulation of matter and energy in general, regardless of whether it is commodified. Humans in every society, like all living beings, take water, food, oxygen, sunlight, use it for our own biophysical reproduction, and then turn it into waste. In a health ecoystem, every form of "waste" is potnetially a necessary input for some other lifeform(s). This kind of circulation goes on regardless of whether or not nature is commodified.  But the expanded reproduction of capial tends to disrupt circulation of matter and energy through ecosystems. It produces more waste (pollution, greenhouse gases, etc.) then the biosphere can manage to circulate. The circulation of commodities and the circulation of useful matter do not always fit well together. Ecological Marxists refer to this problem as the https://en.wikipedia.org/wiki/Metabolic_rift metabolic rift.
A sound argument is an argument that is valid and of which all premises are true.

Your argument is valid, but the second premise is incorrect. A murder trial is not a criminal action. Maybe a murder is a criminal action - but that depends on the country you're in (to be on the safe side).

But, why don't you ask your teacher? :-)
Not quite. It's a little easier to read if we make the sets explicit.

Let curly braces denote any set, where the name of that set is inside the braces. For instance, set x is {x}. The set's name, followed by a colon, indicates the set's members (separated by commas). Hence if a, b, c are members of set x, we can show this as {x: a,b,c}.

Subsets are members of a set. Hence if a law of nature is "any set of worlds that has a subset ", then this is {x: {}}. 

Let's say that a law of nature at the actual world can be denoted by Li. Then the set of all laws that hold in the actual world (i.e., the world we currently live in) is { L: L1, L2 .., Ln }. Let {} be the set of worlds in which the laws in L and only the laws in L are true.

By Van Inwagen's definition, a law of nature just is the set of worlds {Wa} for which  is a subset, or {Wa: {}}. That's all. It may still be possible that a different law not in L holds for some other possible world, but then that law would not be a natural one. For instance, say {} is some set of possible worlds for which { S: S1, S2 .., Sn } are not in the actual world. Then S can still be in the set of possible worlds {Wb}. 

All this means is that if { Wb: {}, {} }, then Wb would still count as a law of nature just like Wa would. { Wc: {} } would be excluded as a law of nature, even if it overlaps with some members from . 

That is, say a is the actual world, b is a possible world for which all and only L hold true, and c is a possible world where all L and some S holds true. Then any W with members a, b, and c can have the subsets { X: a, b }, { Y: b, c }, and { Z: a, c }. If these were all the possible worlds that exist, then W and X would be natural laws, but Y and Z would not.



All this is, is a way of stating very specifically that the laws of nature are just those laws which are our own laws of nature, for the actual world. If we're talking about possible other sets of laws, such as a possible world P where photons experience relativistic effects (e.g., in Greg Egan's http://rads.stackoverflow.com/amzn/click/1597802921 The Clockwork Rocket), then our speed of light is a law of nature, and the laws governing light for P are not. 

It's an astoundingly complicated way to make what may seem to be a trivial statement, but Van Inwagen is concerned with preserving substantive possible outcomes of human decisions. Putting this in the verbiage of modal realism is hard work, but what he wants to say is that determinism is false. If determinism was true, then any possible world could not have all and only the same laws as our world. It would require some other law of nature to obtain for it to be some world other than our actual world. Thus there must be a real set of natural laws which can "lead to" more than one possible world (loosely speaking), if determinism is false.
It seems to me that propositional logic itself, as usually used, is a top-down set theory.  Instead of starting with elements, it begins with restrictions, and it may never converge upon an element.

Many instances of real mathematics really work from propositional axioms, and are only incidentally about elements.  The 'elements' are totally ambiguous anyway, since the sets only exist up to isomorphism.  (Geometry is not about points.  And Group theory is about groups, not their elements.)  Category Theory captures this really well, but from a more Universal Algebra perspective, in the vast majority of instances it is an artifact of the nature of axioms, and so of propositional logic.

To the degree one can use (consciously or otherwise) Nonstandard Analysis of a Universal Algebra, basically without missing a beat, one is really handling only potential objects, some of which just happen to be real.  

This is one reason why the independence of the Axiom of Choice, which seems merely amusing to many, mattered so much to some mathematicians.  You want to handle rules and pretend you are talking about elements, but that is only true if you can just whip out an element whenever you want, as long as you know the rules have not ruled one out.  When you need to be less cavalier about how propositions and elements fit together, the nature of the mathematical process changes.
Yes, these measures exist, and they work.  But they are generally harder than we imagine.

A lynchpin of many variants of artificial intelligence (like car diagnostic equipment, for example) is the application of Bayesian statistics.  You need to know not only the probabilities of your two truths, but the degree to which those are statistically related.  Then you can use Bayes Formula:  The chance of A given B is the chance of A and B occurring together divided by the chance of A occurring alone.

This is closely related to the notion of the risk of falsification in Popper's theory of science.  If I keep making audacious predictions, which have a low odds of being true at random, and they keep coming up true, I can chip away at the likelihood they are unrelated by continually applying Bayes analysis to it.

Further, using the Law of Large Numbers, I can be assured that some estimates of probability are fairly safe to trust.  If I have enough data, from a wide enough variety of sources, I can expect the distribution of their average parameters to be normally distributed.

I can use those two principles together to find those things which have a rather small likelihood of being false.  This is the procedure used to keep folks honest in social science research.  You do a lot of statistics to find out to what degree certain observations predict various consequences.

But first of all, it is far too easy to forget these are statistics, and that systematic errors or prejudices cannot be overcome by randomness.  There may simply not be 'a wide enough variety of sources' because people won't let that variety exist.  You cannot objectively study criminal behavior in a society that does not allow criminals freedom to exhibit their behavior!

Another problem is that only some kinds of things are easy to come by in the requisite numbers.  So we have a lot of information on, for instance sex differences in the student-aged population.  A lot of these are small, or inconsequential, but are very well proven.  But we have also decided politically that this is not really important in the long run, because we want to look past trends and treat people less statistically in certain ways.

For any observation that is hard to make, induction cannot rely upon so demanding a standard.

For instance, medical knowledge on individual predictive numbers cannot use raw statistics to validate their predictions when they are new.  They have to assume certain measures have certain distributions.  (For example the definition of diabetic insulin resistance uses the notion that human blood sugar levels are normally distributed, which is both clearly disproven by the data, and literally logically impossible, because the normal distribution includes negative values.  But it was the only easily checked definition available to start out, and now it is established.)  They also have to assume certain causal factors can be safely ignored.  (If being in a hospital makes cancer worse, we will not find out for a while, since we have no other safe place to study cancer patients.)  Other domains have even bigger obstacles to actually getting good measures of probability.

So we rely all the time on inductive or abductive logic that is not really mathematically sound, simply because doing otherwise is intractable.  Absolute adherence to Bayesian convergence is a great theory, but it does not actually get applied as often as we think it does, and it does in fact never establish truth beyond a constantly decreasing probability, which can easily be inadvertently manipulated by lack of objectivity.
"Unless" specifies a necessary condition. The presence of a lifeguard is necessary to allow using the pool. It is not a sufficient condition: For example, if the lifeguard is present but tells everyone to stay out of the pool, then the use of the pool is not allowed. This is logically the same as "except", but very different from "if and only if". 
I hope this is a bad joke, because it's not a good puzzle. I'll offer my initial thoughts anyway.

A(ckermann) has written down some number x ∈ {1, 2, 3, 4, 5, 6, 7, 8, 9} in an envelope. Only he knows the referent of x, so B(eatrice) doesn't know in the beginning; neither does C(arl).

Now let's look at the sentences and how they update the information we have:


  1) 1 < x < 9


After this statement, we know that x ∈ {2, 3, 4, 5, 6, 7, 8}.


  2) (x = 2) → A didn’t write a number down.


We're told that A wrote a number down, so by modus tollens, we know that x is not equal to 2, so we've narrowed the set down to this: x ∈ {3, 4, 5, 6, 7, 8}.


  3) ¬∃x : [ (x = k) → ∀y : (y = k) ].


That says that there is no x such that if x is [the] number A wrote down, then everything is that number. Moving operators around a bit we get this equivalent statement:


  3') ¬∃x : [ ¬(x = k) ∨ ∀y : (y = k) ],


which upon further manipulation turns out to be equivalent to these:


  3') ∀x : ¬[ ¬(x = k) ∨ ∀y : (y = k) ].
  
  3') ∀x : [ (x = k) ∧ ¬∀y : (y = k) ].
  
  3') ∀x : [ (x = k) ∧ ∃y : ¬(y = k) ].
  
  3') ∀x : [ (x = k) ∧ ∃y : (y ≠ k) ].


That last statement is a contradiction: it says that everything is k, but there is something that's not k. If my gloss of statement 3 is what was intended, then we can prove, on the basis of statements (1-3), by the explosion principle, that the number A has written down is 7. Oh, and that it is 3, and that it is 4, and so on. The point is that because (3) is a contradiction, anything follows from (1-3).
We sometimes pair objects with unnecessary ideas/senses.  However, this is rare because we often encounter objects many times and thus refine our identification based on what stays stable across those encounters.

Let's say you don't know what a pencil is...

One day you hear someone ask for a pencil and get a long, yellow object with an eraser. Why would you associate a temperature, sound or other property with this object?  

But maybe you think pencils must all be yellow and long? Well, multiple encounters should change that. For instance, later you hear a teacher tell the students to pick up their pencils, and you notice some students picking up red, thick objects. Now you've got some contradictory experience and so you ask what does this experience have in common with your previous one?  Clearly all pencils don't need to be yellow and long, so what should they have? 

With more encounters, should keep narrowing the stable properties until your definition of pencil is good enough to fulfill all the social and relational needs of that word.

However, there's another angle here.  Senses are not the full story and may not even be that important; purpose may be more important. For instance, whenever you encounter pencils, it's usually in the role of writing and erasing, so you may think of a pencil as that which writes and erases. In fact, if you had a model of a pencil (which looks like an ideal pencil) and a very unorthodox pencil and someone asks you for a pencil, you're likely to hand them the real (unorthodox) one rather than the model, since a pencil is tied with its purpose. This means you're less likely to conflate ideas/senses since purpose may trump sense.

This process doesn't always work.  Sometimes people don't get enough representative encounters to properly identify things.  Think of people who suffer from red/green color-blindness.  They can distinguish red/green, but they see those colors differently.  Yet, the kinds of relationships that red/green enter into are such that they may never know they suffer from this.

Also, quite a few misunderstandings may be chalked up to this.  When kids are growing up, they'll often use the wrong words until they get more examples.  For instance, some children will end up calling all men "daddy" due to a mis-classification, or they may call dogs and cats "dogs" for similar reasons. Even adults will sometimes get into arguments or misunderstandings over this sort of thing, and from my experience it occurs a lot more with abstract objects (ones in which there isn't sensory confirmation which serves as corrective feedback).  When you encounter something that's contrary to your past experience, do you update your concept, or do you think a mistake was made?

So when we talk of things, as long as our words satisfy the linguistic relationships of others, then we could be talking about different things and no one would ever know. For instance, if someone identifies "pencil" as any object that comes to a point, then this person can get corrected the moment s/he calls a knife a pencil.  But if this person only ever happens to use that term in class, where the only pointed objects happen to be pencils, then how would anyone ever know that this person is talking about an entirely different thing?

The line between object, sense and language is blurred, and necessarily so.  To this end, it may not hurt to read Wittgenstein's http://en.wikipedia.org/wiki/Private_language_argument Private Language Argument.

Yes, you asked about Berkeley, and I pointed to Wittgenstein :)
Accepting death does not remove the terror or excitement of the unknown.  And what lies beyond death is always unknown.  So I do not see how one could really support Query 1.  The devoutly religious and some psychedelicists claim to have put this fear to rest, but they then seem to become attached to the process of dying in a positive way.  So they are still affected by their own feelings about death.  Whether it is a negative or a positive feeling, thinking about death continues to have a 'frisson'.

To me Query 2 seems to contradict Query 1.  If one has lost an obsessive attachment to death, one's life should suddenly be all about death?  I think a lot of people who are leaving us become less self-centered and quite concerned with those surviving them.
I think you're winding up feeling this conundrum because you may be confusing moral anti-realism with a denial of the existence of moral claims in our discourse. I can't remember the last time I read an article by Sharon Street, so I cannot comment on the truth of the claim in question.

Cognitivism, in this context, is the view that there is a truth value associated with moral claims (http://plato.stanford.edu/entries/moral-cognitivism/#Cog http://plato.stanford.edu/entries/moral-cognitivism/#Cog).

Moral anti-realism is not as easy to define as it sounds (http://plato.stanford.edu/entries/moral-anti-realism/ http://plato.stanford.edu/entries/moral-anti-realism/ N.b., I would also recommend the article itself for help in clearing up this issue). At least part of it seems to be some form of negation of moral realism.  One species is to deny that the things we say about morality are about some knowable thing called morality (this would lead to moral non-cognitivism). Another species, however, is to deny that that the things we say in morality follow from things themselves (this is the species called there non-objectivism).

According to the article, Street is a type of constructivist. This is to say that on her view, there are moral frameworks and they do something, but they are not inherently reflective of anything like a natural law or moral order that is pre-built into nature. Thus, the claims of these moral systems do have truth values, but they have them in light of the constructed "moral game". 

Categorizing constructivists is messy business, because there are some constructivists who see the shape and form of the moral system we construct as a necessary consequence of something in our constitution, whether this is a basic evolutionary pathway or, as Christine Korsgaard believes, a function of rational agency. (She thinks that being a rational agent generates the system of morality and obligates all such agents -- she also thinks this is what Kant thinks).

To summarize, cognitivism is compatible with some definitions of moral anti-realism. And this is for the species where the claim relates to the metaphysics of moral claims and their grounding out there "in the world."
Quine's argument about existence relies on Russell's theory of descriptions. Therefore, one source of criticisms on Quine's thesis are criticisms on the theory of descriptions.

The theory of descriptions (On Denoting (1905)) was motivated by a desire to avoid admitting non existing objects. Russell's famous example was "the king of France is bald". The expression "the king of France" seems to refer to an object. But since there is no king in France, what does the expression refer to? Now according to Russell's theory, the sentence "the king of France is bald" does not refer to any objects at all. Instead of reference, there is an underlying quantification ("there is a king in France, and..").

Quine (On What There Is (1948)) merely took the theory of descriptions one step further. He argued that Russell's move applies to every name and referring expression, not just to problematic ones like "the king of France". So Quine, following Russell, eliminated all references to objects in favor of quantifications over classes of objects, as the way in which language connects to the world. That is the meaning of the motto "to be is to be a value of a bound variable".

The theory of descriptions received various criticisms. The most famous work, in this regard, is probably Saul Kripke's Naming and Necessity (1980). Kripke explored the functions of names, and attacked Russell's and Quine's thesis that a name can be replaced by a description, without remainder. Several contexts reveal deep differences between names and descriptions. Some of these contexts are modal (related to necessity and possibility).

Kripke's criticism has been received as very effective. After it, The descriptive theory of names has been no longer widely accepted. Philosophers got back to the (apparently) more common-sensical view that names do refer to objects. This, however, reopened the problem of non-existing objects.
I'll try to provide a partial answer as I do think this is an interesting question about philosophy.

Reasons Philosophy is Hard to Understand

First, I would say that you might be losing something in describing the works of philosophers as "opinions". On a certain trivial level, they are opinions, but on this trivial level so is http://en.wikipedia.org/wiki/The_C_Programming_Language C The Programming Language, the weather forecast, and the dictionary. Presumably, you mean something more negative -- i.e., that philosophy is composed of mere opinions about which people can just choose to disagree. And on a larger scale, that's probably got some validity. But on the smaller scale, good philosophers produce relatively coherent systems that make internal sense.

Second, the task of understanding philosophy is somewhat like understanding the spec for a programming language, there are going to be some points of obscurity inspired by what we don't understand in what  the author is saying. I remember when I was 12 or so that I didn't understand the programming concept array, and even when I read about it, I had trouble fathoming what they were. It didn't help that the language I started with was http://en.wikipedia.org/wiki/GW-BASIC GW-BASIC. My point here is that for some things, we might not know the terms because we're unfamiliar with the terms people use to solve and speak about a particular problem in philosophy (and because this is philosophy, the terms are often idiolectic).

Third, a lot of philosophy refers to obscured events in history or in language. Using contemporary examples, the word "copy" has for me largely changed meanings to mean CCing in an e-mail. Phrases like LOL, IMO, FTW, and others have appeared in our language, and will either eventually become completely acceptable or become obscure enough that future generations wouldn't understand them if they read them. Hegel, for instance, cares a lot about plays that we haven't heard of. The sort of history everyone in Aristotle's time knew is something you would need a specialist to decipher now. Some of the difficulty in understanding philosophy comes from this.

Fourth, some of the philosophers are bad authors -- or at least bad authors by the standards of our times. Contemporary philosophy aims to be clear and concise, but philosophy around the era of Kant aimed to be complex. Medieval Christian philosophy is a giant system built around answers to a set of questions first answered by Bernard Magnus -- it'd be nearly impossible to understand why Henry of Ghent is bothering to word something the way he is without a basic grasp of that.

Reasons People care to bother trying

The most trivial reason is that it's considered at many schools part of a university-level education, either to familiarize people with the great "canonical" thinkers of the past or to teach analytic skills related either to reading hard texts or logic.

More substantively, we still bother reading (some of ) these authors, because they developed interesting systems that have insights for contemporary problems, or at least raise arguments that still pose challenges. I'll give two famous philosophers that have few true contemporary followers: Plato and Descartes. But people responding to them and coming in their wake do have contemporary followers: Aristotle, Hume, Kant, Hegel, Mill. It helps to understand the thought of the former to make sense of what the latter are responding to and to understand the problems they took seriously.

So for instance, there are many contemporary ethicists with a generally Kantian persuasion in their approach. Which means they need to address the problems that Kant faced and explain how their view overcomes them. Part of that task is deciphering Kant's prose. (In answer to why Kant, there's two pieces of that puzzle: (1) it may partially be luck that his is the view of a group of similar ones that people baptized into the canon but (2) he offers one of the more promising approaches to a universal non-arbitrary approach to morality that doesn't center on God (or at least not directly)).

A third reason is that some of the people who post questions are as you suggest, not the brightest or most diligent in their efforts. Some of them cannot write nearly as clearly in English as you or I. We get probably a question each week on the difference between validity and soundness -- which is basically about definitions. 

To wit, you could have found lots of explanations by googling "why study philosophy" (https://sites.google.com/site/whystudyphilosophy/ https://sites.google.com/site/whystudyphilosophy/  http://www.theatlantic.com/education/archive/2014/02/why-study-philosophy-to-challenge-your-own-point-of-view/283954/ http://www.theatlantic.com/education/archive/2014/02/why-study-philosophy-to-challenge-your-own-point-of-view/283954/ / http://users.ox.ac.uk/~worc0337/why_phil.html http://users.ox.ac.uk/~worc0337/why_phil.html / https://gustavus.edu/philosophy/answers.php https://gustavus.edu/philosophy/answers.php ) but instead you asked here. 

Some of our askers ask great questions though which demonstrate a solid grasp of the subject matter in question and point to obscure issues. Or people ask questions that want comparisons or integrations of philosophical texts that are hard to access. The untrained eye cannot decipher a paragraph of Hegel (old German style of authorship, obscure method, references to history we don't study any more), but I can think of at least one user here outside of myself who can.
The presence of quantified probabilities in your question indicates to me that you are asking if this problem can (or cannot) be converted in the computation of a utility function. In the end, you point out a possible exception to this approach: the presence of a singularity: whether the girl is the person's daughter, considered as a unique individual, not as the member of a genus.

An ethical dillema can stay unresolved in both cases. A utility function is just one of many possible candidates, and even if you come to decide for a particular one, it can easily be too hard to compute, or even impossible (undecidable). A singularity can move you towards some kind of response, but this is not the same as moral judgement, in that it doesn't relieve you of the responsability to decide (to judge) what is your standing, considering what happened, even if you had no part in the actual event.

Philosophical theories of moral judgement begin by assuming that genuine moral dillemas stand on their own feet as phenomena, in that they are not reducible to what can be coded as law, or attributed to chance. Will these theories necessarilly lead us to metaphysical considerations? Well, that's another question.
The critical thing to appreciate about Two Dogmas of Empiricism is its context.  You mention the idea that we impose "specific assumptions about the domain of discourse" in Quine's analysis of the Cordate/Renate relationship - well, http://www.iep.utm.edu/carnap/#H2 Rudolph Carnap's Logical Empiricist project was exactly about the processes and mathematics in formulating such domains formally to serve as the groundwork for a precise and mathematically rigorous language for scientific analysis, and it is that project's expression of two unanticipated Dogmas that Quine is addressing.

If you want to take the line that the domain introduces a new notion of synonymy, you might start by focusing on Carnap's use of State Descriptions.  The idea here is that we think of analyticity in terms of a state space of propositions (potentially a probability distribution) whereby if two statements have equivalent truth values in all states, then they are synonymous.  Of course if we have a state space in which in some possible state some animals have hearts and do not have kidneys (even if none in fact actually do) then it's not analytic that animals that have hearts have kidneys, but something synthetic, and that thus needs to be subject to synthetic evaluation.

The work that the analytic/synthetic distinction is doing for Carnap is to show that you can start from the grounding of mathematical axiomatics, and then add something further to this to help elaborate how scientific theorizing can be done in a formally rigorous way.  The analytical truths are covered once we've accepted the legitimacy of the mathematical explication (which we suppose to be well-founded in mathematical practice), and the synthetic truths are those that are determined when you go out into the world and test.

But for Quine, it's not that simple.  Carnap's theory of State Descriptions is, in principle, syntactic.  When I give the suggestion above that there might be some possible state where animals have hearts and do not have kidneys, in Carnap's theory this is certainly a legitimate state to introduce into our framework prior to any sort of empirical investigation.  It might so happen that we later on get to a stage where we realize that the only states that are consistent with the available evidence are ones where hearts and kidneys are indeed coextensive.  But even then, we wouldn't say that the statement is Analytic.  Indeed, we've had to go through a process of synthetic investigation to get to that stage.  If we call things "Synonymous" at this stage and use this to ground a notion of "analyticity" then that's fine, but it's not going to be a notion of "analyticity" that does the work that Carnap wants to put it to.

So coextension alone doesn't decide the matter of what should be deemed prior analytical knowledge.  What about situations where we might think that two statements are simply coextensive "simpliciter", by virtue of meaning?  Quine points to the case of "All Bachelors are Unmarried" as a candidate example.  But to point to "meaning" doesn't really help us out here.  In Carnap's State Description framework, we start by identifying the full modality of propositions as distinct.  If we want to say "John is a Bachelor" and "John is Unmarried" as expressing two distinct propositions in Carnap's proposal then we're going to identify a state (in fact a whole partition of the state pace) where one is true and the other is false.  If we want to appeal to "meaning" then we need to add new, distinct postulates to tell us when two things mean the same and when they mean something different; this is the kind of external appeal that we were hoping to avoid by relying on the mathematics rather than theories of properties or forms.

Quine traces this idea of meanings and synonymy through the next few sections of his paper and ultimately can't see any way for Carnap to get out of it.
A category mistake is when, for the ontology of any particular domain of discourse, an element of a set is unjustifiably excluded from the set.

An obvious example of this is the statement, "It is a time before time". Time cannot be before time because the extension of time includes the extension of every statement of something being before or after something else (i.e. every B-series statement) such that "a time before time" falsely excludes "time" from the extension of "time".

A less obvious example is the statement, "It is before time", however this statement has similar problems to the one before because it is to say, "It is at an earlier point in time than time." This falsely excludes a point in time from time, which is false by contradiction.
"Can you say that in planet earth philosophy only exists because human exists?": 
Yes - the problems of modern philosophy, epistemology, ethics, philosophy of mind, philosophy of science, political philosophy, etc..., are human specific. 

If you resort to older definitions of philosophy, when the natural sciences were considered part of philosophy, then the answer would be different. Questions in physics and mathematics might - emphasis on might - be independent of the human observer, but not questions of philosophy. 
The http://plato.stanford.edu/entries/types-tokens/#WhaTok Type-Token distinction is a modern counterpart of the old http://plato.stanford.edu/entries/universals-medieval/ universal-particular one.

In some field, like linguistic, it is a useful tool; in general, it has the same problems of the old one.

If we consider the mathematical sequence of numbers <0,1,0,1> this is an "abstract" entity : the two occurrences of 1 are not two tokens (like two different "handwritings" of the same word "one") but exactly two occurrences of the same (abstract) object 1.

Regarding the fact that : 


  Even a concrete object can occur more than once in a sequence — the same person occurs twice in the sequence of New Jersey million dollar lottery winners, remarkably enough. If we think of an expression as a sequence, then the air of mystery over how the same identical thing can occur twice vanishes. 


it seems to me that there is a little confusion; if we consider a written list of the New Jersey million dollar lottery winners, then we have a sequence of names, and it is correct to say that we can have multiple occurrences of the same name (an "abstract" ?).

But if we try to "build" the sequence of the men that won the New Jersey million dollar lottery we cannot arrange them with a multiple occurrence of e.g. John Smith; there are no possible "tokens" of him to be used twice in the sequence.

Thus, it seems to me, the individual John Smith is a particular, and it has little meaning to speak of it as a type or as having occurrencs.

The name "John Smith", as a word, is a type, and thus it may have multiple tokens or occurrences.

A is probably B
B is X
Therefore, A must be X


Is deductively invalid, so it would fall under the general fallacy type of invalid argument (assuming that it is presented as a deductive argument).

As an inductive argument, the "must" would make it fallacious on the grounds that the conclusion is not supported by the premises. However, I don't think anyone has named this exact form.

This variant:


A is probably B
B is X
Therefore, A is X


For example:


That animal is probably a frog.
Frogs are amphibians.
That animal is an amphibian.


Would be okay as an inductive argument-though its strength would depend on the probability that A is B. This seems to be similar to a statistical syllogism


X% of As are B.
This is an A
This is a B. 


For example:
1. 80% of humans have brown eyes.
2. Bill is human.
3. Bill has brown eyes.
You just need some experience. After you have seen a lot, you will recognise others more easily. 

If your conversation partners don't know the terms, it's indeed better to explain them. It's most important to be absolutely clear - definitely more important than using the correct terms. Often, you don't even need to tell them they have committed a fallacy. With constructions like "So then you would also say that [something ridiculous]".
Implication is a relation on statements. Causality is a relation among facts in a world (perhaps the real world, perhaps a possible or hypothetical one).

Causality is notoriously tricky to define and pin down. (For example, in a deterministic world, does it make sense to even talk about causality, since given an initial condition there is no other way any event could possibly have been?)

Implication, on the other hand, is really easy to define: statement A implies statement B in all cases except when A is true and B is false.

But this is emotionally unsatisfying because it doesn't match up with our intuitive sense of implication ("I want to know that B is true because A is true"). Well, I can't help you there. That's just what the word means. Totally unrelated statements imply each other. False statements imply everything. I'm really glad that false statements don't cause everything.

Source of this answer: https://www.quora.com/What-is-the-difference-between-implication-and-causality https://www.quora.com/What-is-the-difference-between-implication-and-causality
While the language appears similar, the objects of these comments are very different. Kant (in The Critique), and I presume Shopenhauer (whom I have less exposure to) were referring to matter as something which has extension (space) and which persists (time).  Minkowski was referring not to matter but to space (and time) itself - applicable both to matter and to empty space. One was referring to things, the other to the means of measuring things (and time).
Hodges and Chiswell's mathematical logic may not help much with modal logic, which is more like an extension to predicate logic. I'm not familiar with Peter Smith's book, but Amazon's index indicates that he already introduced the universal and existential quantifiers ∀ and ∃, respectively. Modal logic simply adds to these with the possible and necessary modal operators □ and ◇, respectively.

The textbook I was taught with was Brian Chellas's http://www.amazon.co.uk/Modal-Logic-Introduction-Brian-Chellas/dp/0521295157/ Modal Logic: An Introduction. It's fairly concise, with good examples, if a little dry. You might also try http://www.amazon.co.uk/Modal-Logic-Philosophers-James-Garson/dp/1107609526/ Modal Logic for Philosophers by Garson. I haven't read it myself, but the review on the book seems like it may be just what you're looking for.

As for the philosophy of mathematics, I think most people would recommend a university course, rather than just a book. https://philosophy.stackexchange.com/users/13910/mario mario's suggestions look sound enough for a start.
Here's one answer from a relatively authoritative source. Antonis Coumoundouros, a specialist in ancient philosophy, says the Republic has been Plato’s most famous and widely read dialogue since the mid-nineteenth century (see http://www.iep.utm.edu/republic/ http://www.iep.utm.edu/republic/). However, lamentably, he doesn't provide any evidence in that article.

EDIT: I emailed him for more information. He filled in a few details about why it re-emerged at that time:

"As far as I can tell, the dialogue became quite popular in England in the 19th century.  My guess is that its subject matter (discussion of justice, virtue, and proper education) was concordant with the type of education provided to young elites at the time.  This carried over into the 20th century and we had Cornford and others who produced commentaries on it.  Other English-speaking countries, like the US, maintained the dialogue's popularity in universities as well.  

It is worth noting that the dialogue was lost to the West until the Renaissance.  Arab scholars had access to it and were influenced by it in the Middle Ages but western scholars did not have access to it. "
I believe you just use the standard symbol for consequence, the credulity is implied.  This should work, unless you happen to be working in a system that actually requires three differentiable types of consequence (skeptical, credulous, standard).  
Plato did not seem to think that the philosopher kings will come to power from the ruins of a tyranny. Rather, they will rise in a still- functioning tyranny.

His idea seem to be this: Among the multitude of tyrannies that humanity is bound to suffer, there will sometimes be the happy occasion that the ruling tyrant himself will be truly enlightened - a philosopher - a philosopher king. Such a ruler will have both the knowledge and the means to build a meritocratic-philosophical state.

The first step is the most drastic: the ruler will have to send away all the citizens, except for all the children whose age is ten or less.. Those children will hence be the clay, that the first philosopher king will mold into a meritocratic-philosophical state.

This recipe is presented near the end of book VII of the https://www.gutenberg.org/files/1497/1497-h/1497-h.htm Republic:


  •Well, I said, and you would agree (would you not?) that what has been said about the State and the government is not a mere dream, and although difficult not impossible, but only possible in the way which has been supposed; that is to say, when the true philosopher kings are born in a State, one or more of them, despising the honours of this present world which they deem mean and worthless, esteeming above all things right and the honour that springs from right, and regarding justice as the greatest and most necessary of all things, whose ministers they are, and whose principles will be exalted by them when they set in order their own city?
  •How will they proceed?
  •They will begin by sending out into the country all the inhabitants of the city who are more than ten years old, and will take possession of their children, who will be unaffected by the habits of their parents; these they will train in their own habits and laws, I mean in the laws which we have given them: and in this way the State and constitution of which we were speaking will soonest and most easily attain happiness, and the nation which has such a constitution will gain most.
  •Yes, that will be the best way. And I think, Socrates, that you have very well described how, if ever, such a constitution might come into being.

As far as I can see, there is no logical reason why being sentient would imply exposition to 'biases, thought fallacies and other psychological flaws that a mortal possesses'. It is logically perfectly possible to be sentient (in the sense of having conscience, emotions, ...) but not have it influence your actions or perception of knowledge.

There could then be a being which:


Has absolute knowledge about everything in the past, present and future (omniscience and prescience)
Can do everything (omnipotent), and acts based on his knowledge alone
Has emotions about his knowledge and actions (sentience), but does not let these emotions influence his knowledge or actions.
Is immortal, which does not have to do much with the three bullet points above.

Here's one proposed way of interpreting the sentence.  Suppose that we have a partial function with two arguments that we call a "considered in" function, cons_in(X,a).  Then suppose that we represent memberhood of a system by the relation m<, and assume a regular identity relation =.  We can use a predicate calculus formulation like this: given a system S,


  ∀x. (x< (x = cons_in(S,x))


Questions then arise as to what the "system memberhood" relation and the "considered in" function are supposed to be.  These aren't typical mathematical terms, and don't in themselves appear to carry a lot of significance, but the idea that in principle no sense could be made of them seems a bit hasty.

Addition in response to comments: There is also another possibility, which might be also informative depending on how you want to read "considering in", which is that the two instances of "member" in the quote need not necessarily be the same.  Let's suppose for instance that we take one such system to be the Natural Numbers.  One form of "considering" a number might to take that number's predecessor and apply the successor function to it.

So here we would want to say that the sentence has a slightly different logical form.  Given a system S,


  ∀x. (x< (∃y. (y<


Again, it's entirely logically sensible, though not of itself informative without further assessment of the two concepts above.
I think its a reasonable question; first consider that https://en.wikipedia.org/?title=Edmund_Burke Burke was writing during the French Revolution and he was arguing for maintaining the traditional order, and in 18th Century Aristocratic Europe this would mean retaining the sovereign as soveriegn; but this does not mean (as one of the commenters have pointed out) that aspects of the order cannot be subject to reform - Burke, for example supported https://en.wikipedia.org/wiki/Catholic_emancipation Catholic Emancipation.

Hannah Arendt, is a philosopher of politics, and she analysed regimes that are typically called Totalitarian - the Nazi and Stalinist regime in her book Totalitarianism; she takes a genealogical approach through history to analyse the phenomenon; however she doesn't attempt to analyse the notion of soveriengty; but in fact, according to the http://plato.stanford.edu/entries/schmitt/#SovDic SEP (and in contrast to 18th C Europe):


  Modern liberal constitutions do not acknowledge a bearer of sovereign authority, and modern legal and constitutional theory has often tried to dispense with the concept.


they go on to say:


  But Schmitt argues, in Political Theology, that such attempts to get rid of sovereignty cannot be successful.


and


  Schmitt is right to appeal to Hobbes's dictum that it is authority and not truth that makes the law.


It is this dictum from Hobbes (in Leviathan) that also informs Burkes view of sovereignty; (Hobbes distinguishes between two forms of soveriegnty de jure and de facto, the first is characterised by the Social Contract, and the second by the right to levy taxes, raise a military and enforce ideology - which in his day was religous (these come apart in a situation of contestation)). 

It is this that informs Schmitts famous (in places) 


  sovereign is he who decides on the state of exception


The Italian philosopher, Agamben who is influenced by Arendt, takes this as a starting point in his book The State of Exception; he considers that the sovereign is a liminal figure; that lies both within and without the juridicial order; and he (ie Agamben) who appears to question sovereignty in is in fact not: he is questioning the linkage between that of sovereign order and the juridical one; which in his considered view had suffered a certain erosion through an expansion of soveriegnty - through an expansion of the 'exception'; which is why he prefaced the book with the quotation:


  'Quare siletis juristae in munere vestro'
  
  Why are you jurists silent about that which concerns you.


As he was choosing not to be silent in forming a sustained and considered critique.
Being able to make any change to the state of reality pretty much makes everything an meaningless endeavor. - Most Christians would say something slightly different - creation was unnecessary for God to do, which is different than it being meaningless. Since it was an unnecessary act, Christians usually say that creation itself is an act of Love, and therefore the meaning behind everything in creation is Love. For our part, the way CS Lewis described it is that the actions we take help shape our immortal soul, and so our actions derive meaning from this process aside from whatever happens in the material world. From this perspective, even if the universe "will just freeze into an eternal motionlessness" there is still meaning in what we do, for us and for God.

Since reality has meaning for God, it is not as far that goes dismissible that God would change reality. This is a different question from "Does God change reality?" It seems quite plausible that God could and would change reality but chooses not to. Different religious traditions (even within Christianity) have different opinions on this.
Russell's book "A history of Western philosophy" contains a section on Descartes. 

Of course, Russell criticises certain aspects of Descartes philosophy, e.g. that Descartes' dualism creates unsolved problems. Moreover Russell considers the constructive part of Descartes' epistemology as well as his proofs for the existence of God as lacking original ideas. But Russell emphasizes the importance of the "cogito, ergo sum". The overall estimation by Russell is positive.
This, I don't think is a philosophical question; but perhaps a question for Russelology.

Mathematics doesn't work in quite the way you're suggesting; in that there are definite right and wrong answers - ie following a binary logic of truth; at least in its inner dialectic of development.

Can Euclids work be considered a failure being superseded by non-Euclidean geometry or that of Newtons being superseded by that of Newton?

The importance of Godels work is that it broke new ground in mathematical logic, founding a new field - model theory - as well as elsewhere, for example in computer science: Turings halting theorem is essentially Godels theorem placed in a different context, and in fact one can derive the theorem of Godel from Turing.

Russell's own work, for example ramified type theory still continues but in a new language - type theory in computer science; this then I think as success.

But the larger question of reducing mathematics to logic, even if achieved, is only in itself a question that mathematics can ask and answer; but one, I don't think that can be reduced to it; since mathematics also shows an inductive and deductive dialectic. 
The question “Is the noumena in a sense apeiron?” addresses topics from four different philosopher: Anaximander, Plato, Aristotle and Kant.


Anaximander: Apeiron means “without boundary, infinite”. Speculating 
about the primordial matter Anaximander stands in the tradition of
Ionian philosophers of nature.  Unfortunately, we have only fragments
from the work of Anaximander. Hence everybody is called on giving his
own interpretation.  Apparently, Anaximander does not vote for
creation ex nihilo, because he does not vote for creation at all.
Instead his primordial unbound matter generates the cosmos by
spontaneous self-organization. 
Note: Apeiron does not mean “without form”. Nevertheless the    primordial matter seems to be unstructured, i.e. formless.
Plato: Plato tries to reconcile his two forerunners Parmenides and
Heraklit. They are considered antipodes. The first claims that
insight can only be obtained from statements about immutable eternal
objects, i.e. by detecting invariants. The latter is the proponent of
a process based worldview. Heraklit claims that all objects change. 
Platon proposes a dualistic worldview: With our senses we experience
the world of change. But on a deeper level, by our intellect we
detect the blueprint of the world of change. This blueprint is the
realm of the ideas. Already Platon struggles with problems resulting
from his ansatz to design ideas as analogue to material objects.
E.g. how can many objects participate on the same idea, where are
ideas located?
Aristotle: The problems of Plato's theory of Forms have been expanded
by Aristotle, e.g. Met. 990b ff.. Aristotle does not propose a
solution to single problems because Aristotle rejects the whole
theory of Forms.  The best answer I know, if someone asks where ideas
are located: Ideas are patterns flexibly wired into the synaptical
weights of our neural networks within the cortex.   Aristotle’s own
contribution to explain the existence of objects is his theory of the
four causes. One cause, the causa materialis, asks for the underlying
matter (hyle) of the objects in question. In case of the universe,
Anaximander probably would answer: The primordial matter is without
form and bound, it is apeiron.
Kant: He coins the term thing-in-itself and identifies it with the
term noumenon. The term denotes the objects of the physical world. We
must assume that such objects exist. Otherwise we cannot explain
where the input to our senses comes from. But we do not have direct
access and cannot know anything about a thing-in-itself.  What we
call experience is an intellectual construct, built with the help of
the two forms of perception, space and time, and the categories. 
Because we cannot know anything about the thing-in-itself, Kant
consequently avoids any positive statement about the thing-in-itself.
In particular, he does not link it to Platonic forms.  The wording
“noumenon” is misleading, because Plato considers the term in quite a
different sense. Also the two forms of perception, space and time, do
not belong to the domain of ideas considered by Plato.  I do not see
a link between Kant’s forms of perception and the problem of
universals.


Summing up, I do not see a relation between Anaximander’s apeiron and Plato's Theory of forms. Even less, I consider the three concepts apeiron, idea and thing-in-itself three different concepts, incomparable, unlinked, each on a different conceptual level. At the most, I consider apeiron a kind of hyle.  
Why does it seem natural? Simply because of its phrasing as 'maximising the sum of human happiness'?

Consider, that a cup is the sum of all the molecules that make it up; this tells me nothing about cups. 

Possibly the influence was the other way round given the influence of Newtons physics on the mechanical philosophy of the 18C. 

A modern defence of utilitarian ethics is given in Rawls A theory of Justice; his 'foundational axiom' is the veil of ignorance. 

In his brief outline of the main classical arguments of utilitarianism there is nothing there that can be construed as the integral calculus; but a more definite influence of Playos Republic is discernible.

And in the main body of the text there is nothing there either; nor any other kind of mathematics.
The quote from Russell is in conflict, not with Utilitarianism, but with some versions of Pragmatism, in particular with William James' Pragmatist Theory of Truth.

Note that Bentham's quote refers to the good and the right in actions; while Russell's quote refers to the holding and to the truth of beliefs. Those are two different areas. A rational person is usually supposed to hold a belief in proportion to the evidence that supports that belief, regardless of any practical consequences that the belief may have. And so, utilitarians are not usually expected to hold the view, that Russell's quote opposes, that a belief should be held according to its consequences.

Some others, however, have indeed held that view about beliefs. One such thinker, with whom Russell personally debated, was William James. In the essay http://www.gutenberg.org/files/26659/26659-h/26659-h.htm The Will to Believe (1897) James developed an argument, according to which it is allowed and justified, in some cases, to hold a belief even when one doesn't have sufficient epistemic evidence in its favor. The main class of beliefs that James had in mind were religious beliefs. The basic idea of his argument was, that if we have to wait for evidence, we are bound to miss the benefits that some (e.g. religious) beliefs could bring about. In later publications, James developed the Will to Believe argument into a general theory of truth. He came to hold that a "true" belief was just a belief which was beneficial to hold, in the long run. This received the title "the pragmatist theory of truth".

Russell opposed James' theories, on various grounds. One of his arguments was that, even if some (e.g. religious) beliefs were beneficial, what gave them their psychological power was the that the believer believed that they were really (i.e. not in the pragmatist sense) true.


  Suppose I say there was such a person as Columbus, everyone will agree that what I say is true. But why is it true? Because of a certain man of flesh and blood who lived 450 years ago—in short, because of the causes of my belief, not because of its effects. With James's definition, it might happen that ‘A exists’ is true although in fact A does not exist. I have always found that the hypothesis of Santa Claus ‘works satisfactorily in the widest sense of the word’; therefore ‘Santa Claus exists’ is true, although Santa Claus does not exist. James says (I repeat): ‘If the hypothesis of God works satisfactorily in the widest sense of the word, it is true.’ This simply omits as unimportant the question whether God really is in His heaven; if He is a useful hypothesis, that is enough. God the Architect of the Cosmos is forgotten; all that is remembered is belief in God, and its effects upon the creatures inhabiting our petty planet. No wonder the Pope condemned the pragmatic defence of religion.
  (https://books.google.co.il/books?id=Ey94E3sOMA0C History of Western Philosophy p.728)

Kant's distinction between the noumenal and the phenomenal in his *moral philosophy** is both difficult to follow and integral to his moral thought. Moreover, Kant's use of terms like "nature" and "understanding" have definitions that are not intuitive if we are working from the standard English words.

I think it's easiest to understand it if we start with what Kant wants in a moral theory. Roughly speaking, Kant is hoping for a theory where the moral self using universal reason is able to decide what it morally ought to do and then where the self has the freedom to will this action. 

One simple dictum that captures this is "ought implies can." Kant thinks we can know what we ought to do. And then he thinks we can do it. So if we know murder is wrong, Kant thinks we can always in every circumstance do what is right.

But considering he is writing after Descartes, this is clearly going to be difficult to square with Newtonian mechanics -- where everything appears to be explained by the laws of physics. Kant's solution in his metaphysical works. Put simply, everything was explained in terms of nature and its subsequent determinism.

Kant's epistemology hinges on a distinction between knowledge and reason and then things, sensibles, and objects. Put simply, we do not understand things as they; instead we receive them as sensibles through the forms of sensibility (space and time) and then know them as objects through the categories of the understanding. Nature is roughly speaking synonymous with determinism for Kant, which is one of the categories to which our understanding is always subject. 

But reason does not function through the categories or the forms. Instead, reason is free. In this way, it lies outside the world of determinism. But the freedom comes at a price of being in a different realm than the phenomenal, which Kant calls the noumenal (derived from the Greek word nous which means mind). The moral self for Kant is the self that is noumenal and that can act freely unbuffetted by the deterministic world.

This is the background apparatus for answering your question.

On Kant's view, the self as a moral self is not in the world of nature. Instead, the self is in a world where it is free. And the reason why we don't see that is that we cannot see it since it is not a phenomenon. In fact, on most interpretations of Kant's moral theory, we can never directly perceive than act is moral, because we can only see and comprehend our world in terms of the forms and categories and encounter others regularly under these.

But Kant asserts that we must have this form of noumenal self. He makes very different arguments for this depending on where in his moral works you are reading. In the Groundwork, he claims he can prove this. In the Critique of Practical Reason, it becomes more a fact of reason that this is true. And in later works, the picture gets complicated as he handles cases of habit.

There are certain semi-cartesian features in Kant's account: 


he shares a deterministic picture of the sensible universe.
he shares a belief in the superiority of rationality over the deterministic natural animal 
he has a problem connecting this account to the physical domain.


Where he differs from Descartes is in what is called the "Copernican revolution" whereby he looks at our understanding in a different way  that hints at a cognitive faculty that has power over the world that we perceive. (note that the domain of its power is the "world" which here refers to a concept in the mind). Basically, Kant turns to the mind in a different way than Descartes -- informed by and accepting Hume.

Kant evades in part the question of how the moral self can interact with the world by making claims about the moral self that take it out of the world of our perception -- i.e., what we see is phenomenal, what we are as free creatures is noumenal. How the two meet is also beyond our ability to know, because knowing is the application of forms and categories to things (and we cannot know the things directly).



Note that we are not required to agree with Kant. If you're a reductionist physicalist, then his theory probably won't work for you in the standard form. But there are contemporary appropriations of Kant that might, such as Christine Korsgaard's constructivism -- whereby she believes we are committed to Kantian principles of agency insofar as we are agents. She does some rather elaborate footwork to keep parts of his ethics while jettisoning his account of metaphysics across her texts Sources of Normativity and Creating the Kingdom of Ends.
It's not that there is no distinction between future and present and recalling the future; its recalling the past. It's a question of repetition. In the Hindu philosophy there have been an infinite number if universes before this one and there will be an infinite number in the future. It's only a matter of time when repetition occurs. Swami Vivekananda said in the 1890s (Complete Works, V2 pp 229-230; also available here: http://cwsv.belurmath.org/volume_2/vol_2_frame.htm http://cwsv.belurmath.org/volume_2/vol_2_frame.htm - under the sidebar heading "Jnana Yoga" and then under the heading "Immortality":


  But the question of immortality is not yet settled. We have seen that everything in this universe is indestructible. There is nothing new; there will be nothing new. The same series of manifestations are presenting themselves alternately like a wheel, coming up and going down. All motion in this universe is in the form of waves, successively rising and falling. Systems after systems are coming out of fine forms, evolving themselves, and taking grosser forms, again melting down, as it were, and going back to the fine forms. Again they rise out of that, evolving for a certain period and slowly going back to the cause. So with all life. Each manifestation of life is coming up and then going back again. What goes down? The form. The form breaks to pieces, but it comes up again. In one sense bodies and forms even are eternal. How? Suppose we take a number of dice and throw them, and they fall in this ratio — 6 — 5 — 3 — 4. We take the dice up and throw them again and again; there must be a time when the same numbers will come again; the same combination must come. Now each particle, each atom, that is in this universe, I take for such a die, and these are being thrown out and combined again and again. All these forms before you are one combination. Here are the forms of a glass, a table, a pitcher of water, and so forth. This is one combination; in time, it will all break. But there must come a time when exactly the same combination comes again, when you will be here, and this form will be here, this subject will be talked, and this pitcher will be here. An infinite number of times this has been, and an infinite number of times this will be repeated. Thus far with the physical forms. What do we find? That even the combination of physical forms is eternally repeated.
  
  A most interesting conclusion that follows from this theory is the explanation of facts such as these: Some of you, perhaps, have seen a man who can read the past life of others and foretell the future. How is it possible for any one to see what the future will be, unless there is a regulated future? Effects of the past will recur in the future, and we see that it is so. You have seen the big Ferris Wheel* in Chicago. The wheel revolves, and the little rooms in the wheel are regularly coming one after another; one set of persons gets into these, and after they have gone round the circle, they get out, and a fresh batch of people gets in. Each one of these batches is like one of these manifestations, from the lowest animals to the highest man. Nature is like the chain of the Ferris Wheel, endless and infinite, and these little carriages are the bodies or forms in which fresh batches of souls are riding, going up higher and higher until they become perfect and come out of the wheel. But the wheel goes on. And so long as the bodies are in the wheel, it can be absolutely and mathematically foretold where they will go, but not so of the souls. Thus it is possible to read the past and the future of nature with precision. We see, then, that there is recurrence of the same material phenomena at certain periods, and that the same combinations have been taking place through eternity...

You raise three questions:


  
  What does Parmenides mean when stating to say and to think that is what-is: for it can be, but nothing is not (legein te noein t'eon emmenai: esti gar einai, maeden d'ouk estin, Fragment 6, verse 1f)? 
  What does Hegel mean when stating Pure Being and Pure Nothing are therefore the same (Das reine Sein und das reine Nichts ist also dasselbe, Wissenschaft der Logik, Bd. 5, Seite 83)?
  How do both statements relate?
  


Parmenides is considered one of the most dark philosophers of the Pre-Socratics, while Hegel is considered one of the most dark German philosophers. Having said this I can only make a guess concerning the answers:  

ad 1. Fr. 6 does not support replacing "Nothing" by "Void". The result would be "There is no vacuum". But the context shows that the vacuum is not the topic of Parmenides. Also Fr. 6 does not talk about causal effects of existing things. 

Instead, Parmenides is reasoning either in the domain which today is named ontology or in the domain which is named logic. A much discussed interpretation of Fr. 6 and similar passages reads: Parmenides states as his basic alternative the tertium non datur: Either it is or it is not. If this statement is not taken in an ontological sense, but as a logical claim, then it expands to "Either a property holds or the property does not hold, there is no third possibility." This interpretation has been promoted by Ernst Heitsch, see his edition "Parmenides, München 1974 (in German)".

Plato lived more than 2 generations after Parmenides. The Platonic dialogue "Sophistes" contains a discussion of Parmenides' basic alternative (Soph. 241d ff). Plato sets out to show that in a certain sense - contrary to Parmenides - also non-existent things exist and existing things do not exist.

ad 2. Hegel explains that both being and nothing are indeterminable. He concludes that both are identical because they share that same negative property. 

I consider his reasoning exceedingly problematic. E.g., first he nominalizes an affirmative verb and the negation itself. Secondly, he compares both with respect to a property they do not have. And thirdly he concludes, that both are identical therefore. 

ad 3. I'm not able to compare two statements which both are unclear.   
This would be considered a variation on the trolley problem, specifically it is similar to http://philosophyfaculty.ucsd.edu/faculty/rarneson/Courses/thomsonTROLLEY.pdf the transplant surgeon proposed by Judith Jarvis Thomson.

The general scope of such cases is to look at when we think it would make sense to sacrifice one or more lives to save one or more lives, and the cases distinguish themselves insofar as the number or quality of the lives on each side vary. A second variable is whether someone will die anyway. A third variable is the degree to which you can be certain of the consequences of your action. A fourth variable is action versus inaction as the source of the sacrificing.

There, the basic question is whether it would be okay to kill a homeless drifter if we can use his organs to save 10 people.

I haven't seen your variation in the literature but the distinctive features versus a standard trolley problem are:


The drifter/sacrifice is you.
You are in this case willing (presumably).
The scope of the assistance your death provides is quite high.


There may be more similar cases in the literature.

I would guess your case is slightly less interesting in terms of testing our intuitions about the general utilitarian calculus, because we would say someone can make a choice about their own life, roughly speaking. At the same time, it is interesting in that we could ask whether this counts as a heroic act or moral thing to do. (The ancient Greeks might reject that it's heroic because there is no glory; we might disagree and think there is value in doing good even in secret).
First, Deduktion, a term that Kant uses in his first Critique, gets translated in English as Deduction which misses the sense of this word in German; which is juridicial, and is better translated as Justify.

Deduction in English is closely associated to Logic, and from there to mathematics; and then from both, the notion of proof; but this sense, in German, is better translated as Schluss. 

In Kants work, he uses the word Transcendental in a technical sense; native to him; which is that it argues for the conditions of the possibility of experience; which in the form of a syllogism is:


  if only A makes B possible
  
  B exists, happens or is
  
  then A is true


This is quite different from the usual sense of Transcendent, which has the sense of going beyond experience, and more to the point - the divine. 

There is nothing of this sense in Kants use of it; one might say that his philosophy transcends that of the Dogmatists or that of Wolff-Leibniz as it overcomes every philosophy know  up to that particular point in time; but it's generally named as his Critical philosophy; as he grounds it in reason.

Thus Kants 


  Transcendental Deduction of the Categories


is better translated as


  How to justify the categories from reasoning about the possibility of our experience to a condition of it


And secondly, description and demonstration form a dialectic pair: there are elements of demonstration in description; there are elements of description in demonstration. They are not an identity, but not are they seperable from each other.

For can I describe this tree before me without at the same time demonstrating its existence, even though this is not my intention?

And can I demonstrate or carry through the proof that there is an infinity of primes in your minds eye, without first describing a prime?

Thus, there is no demonstration without some aspect of description, and there is no description without some aspect of demonstration.

A further example: in a book of set theory, the theory has to be described: the axioms need to be listed, as well as the rules  of inference; as in fact so do the theorems; but this book is only one moment in the dialectical progression of mathematics: the theory outlined in this book certainly wasn't discovered in this fashion, and nor justified in this fashion; the book represents an ideal moment of discovery: of demonstration and description.
In some sub-disciplines of philosophy, a distinction is drawn between free will and autonomy. Free will refers to things a person willfully elects but autonomy refers to things that reflect both rationality and choice. This distinction partially echoes a distinction we find in Aristotle's Nicomachean Ethics about the difference between actions we will to do and actions which follow from choice (which is a more elaborate notion invoking both a wish and rationality and will in the choice).

Simplistic Approach

The example you give is one where this sort of distinction is helpful to make sense of what is going on.

Presumably, the individual in question is choosing (in the simplistic sense) to have their arm cut off. But then as we move into the question of autonomy, we have solid reasons to doubt that this is a choice built on autonomy.

The Wrench

An important missing detail noted by Nick R's comment on your question is that I'm answering this from a certain philosophy of psychology, namely, one where we consider the effects of this phantom experience to be altering the self's rationality but not preventing the self's ability to engage in free actions.

Thus, we both need to answer how we understand psychological problems and the nature of free will with respect to autonomy. There is no single answer to this per se, but what I provide above is what I take to be the most common contemporary theory.
In General, a behaviouristic approach to psychological entities wants to identify a specific mental event with a specific behavioural event. according to this, pain will be fully identified with the behaviour of being in pain: screaming "ouch", for example. 
Yet, sometimes we do not present the behaviour of pain while being in pain. To avoid this problem, behaviourists would say that pain is not the behaviour that is identified with being in pain, but the behavioural disposition of pain, or the behaviour identified with pain under normal conditions.
A behavioural disposition, then, is the disposition to behave in a specific way under normal conditions.
The meaning of the symbol "+" will be its use by a person under normal conditions, or in other words the behaviour of addition.
I am going to reframe the Existentialism as Existential Psychology, because I am trained in psychology and understand Yalom better than Sartre.  I feel that Sartre is a big part of modern Existential Psychology, even if they feel very different.  Besides that the tone of the question seems to be looking for a psychological approach over a reasoned ethical one.  But I am sorry if this is shaped wrong for you, and the whole thing seems alien to its origins.  

Inauthenticity is 'characterized' in that way only in the sense that those are its symptoms, not its nature.  And this is only the most common event of inauthenticity.  When we 'split' over the importance of something to our selves, we experience a range of attitudes toward it all at once, and the two most likely attitudes to choose to express are the two extremes of absolute detachment and absolute attachment.

But for those two things to be errors is only a trend.  There are times when real detachment is what you are authentically feeling -- when you really cannot affect a situation and have no empathic drive to do so.  And there are times when you are in the unusual position of being able to capture something important in a way that is purely satisfying.  People do that.  And believing you might is not necessarily an error.  (Just most likely.  Especially if you feel that way all the time.)

You refer to the frustration of authenticity, but it is the substance of inauthenticity that is frustrating, no?  It is when we find ourselves betraying our deeper sense, having different emotional directions thwart one another, for instance, and having to choose one or the other to surface and act upon, when both are, at core, equally ourselves.  The frustration is the result of the idea that these internal forces must be resolved simply because the action they require must be taken.

We are bound to inauthenticity by an obligation to maintain narrative, so that our lives constitute a story and not a pure experience that has no hope of being shared.  This is part of the way in which Hell is other people.  We are tortured by what we think of as internal forces, or by what we imagine as introjected opinions of others, but in fact it is the compromise between our real experience and the narrative we attempt to make of our lives that is the torture.

From a more honest perspective, not every aspect of our lives needs to be encoded in a way that can be evaluated or shared.  We do not need to live a narrative.  And our realized actions and postures (essence) need not be what constitutes our own being (existence).  This goes all the way back to Sextus Empiricus -- he escapes inauthentic commitment by 'bracketing reality' -- acting, but remaining uncommitted to the action taken, and waiting for our judgement to solidify.  Therapists sometimes talk about this as having empathy for ourselves across time -- allowing that our actions are often just wrong, but that a better approximation to our real intentions was not clear or available at the time.

The problem with this is that we are then thrown into another temptation to inauthenticity.  Time moves on, and we are taken with it, the moment of decision is past, and we are tempted to think that we must detach from it, ore return to it, even though we remain basically undecided, so it would be ultimately unwise to do either, and it would just make us feel neurotic.  We can neither live in the past, nor simply suppress our own voice.  Bizarre compromises like giving the suppressed voice its own artificial narrative in writing are common as therapeutic techniques, but in real life, they seem dishonest.

In fact, to maintain authenticity over time, one needs to cultivate the ability to maintain access to the attitudes upon which you have not acted in the past, without making of them some controlling artifact.  We need not to shear the edges off of existence to preserve essence. (Or if we must shear them off, we need to keep the clippings for later use, and not allow them to collect and moulder.)  But we should also eventually make peace with the unaddressed material.  A large part of it remains unaddressed because it is spurious, or just plain wrong.
I think there is an equally strong thread in the Tractatus that supports phenomenology.  There is a theme that some valuable insights cannot be said, but can only be shown.  This is a move back away from abstract logical constructions toward and the whole apparatus of perception.

His 'shown', 'pictured', etc. should not be taken too literally, it would include hearing, etc., as well as the real experience of being in various mental conditions and of going through various mental 'motions'.  Climbing up the ladder and feeling the need to toss it aside is one.

These are the elements of phenomenology.  And he is suggesting that logic be grounded in them, since it cannot stand on its own.

His later notions about language-games are deeply embedded in real experience as an escape from the cage of grammar and the delusions implicit in questions that disrespect the boundaries between different realms of experience.

So I think Wittgenstein is accepting of phenomenological positions, and could even be classified as in this tradition, just not as fundamentalist about it as someone like Husserl.
The entire paragraph from the postscript on page 81 of Boole's "The Mathematical Analysis of Logic", from where your quote was extracted, reads as follows:


  The remarks on the connexion between Logic and Language, p. 5, are scarcely sufficiently explicit. Both the one and the other I hold to depend very materially upon our ability to form general notions by the faculty of abstraction. Language is an instrument of Logic, but not an indispensable instrument.


What we find on pages 4-5 is the following:


  That which renders Logic possible, is the existence in our minds of general notions,-our ability to conceive of a class, and to designate its individual members by a common name. The theory of Logic is thus intimately connected with that of Language. A successful attempt to express logical propositions by symbols, the laws of whose combinations should be founded upon the laws of the mental processes which they represent, would, so far, be a step toward a philosophical language. But this is a view which we need not here follow into detail.*


The footnote on that page begins this way (emphasis added):


  *This view is well expressed in one of Blanco White's Letters:-"Logic is for the most part a collection of technical rules founded on classification. The Syllogism is nothing but a result of the classification of things, which the mind naturally and necessarily forms, in forming a language(...)"


It seems to me that Boole expresses here a view that was common in his time, of Language as a natural phenomenon, and of Logic as the somewhat idealized structure of (adequate) reasoning. Language may have a theory of its own, based on observation, and because the mind spontaneously reproduces abstract forms in Language (which is why Logic as a human endeavor is possible, to begin with), Language can be instrumental to (a theory of) Logic, insofar this theory is produced by Language-speaking humans. Such a theory of Logic, existing nonetheless independently of Language, could in principle be realized by a different kind of mental process, one that is general enough for abstract reasoning, but not necessarily embedded in Language.

He could be hinting at the possibility of "logical machines", that would be entirely within the scope of the speculations of that time. I don't know enough to explain how far has he gone explicitly in that direction, but we all know how instrumental his work has been to the development of the thinking machines we have today.
The formulation is a little unclear. What is meant is that Jennifer has always left for school at 7am until now, and has always been on time until now. It is no premise that Jennifer is always on time, nor that she always leaves at 7am.

Formally we write arguments down as a set of premises P1, P2, ..., Pn and a conclusion C. In this example, the implicit argument could be formalised as:


  P1: Jennifer left school at 7am on 2015-08-01 and was on time.
  P2: Jennifer left school at 7am on 2015-08-02 and was on time.
  P3: Jennifer left school at 7am on 2015-08-03 and was on time.
  ...
  Pn: Jennifer left school at 7am on ... and was on time.  
  
  
  
  ∴ C: Jennifer is on time on any day if she leaves at 7am.


This is the classic form of inductive reasoning. An example of deductive reasoning would be:


  P1: Jennifer needs at most 15 minutes to go to school.
  P2: School starts at 7:15am.  
  
  
  
  ∴ C: Jennifer is on time on any day if she leaves at 7am.

You have to consider that Talbot's book is for beginners and that it oversimplifies a lot of stuff. In this case, explaining Aristotle's ethics in terms of 'the right action' makes it easy to compare his view on ethics with that of Kant, who believed that the right action can be determined using the categorical imperative, and with that of Mill, who believed that the right action is the one that causes more happiness. But this is a simplification. 

So the problem is not Aristotle, but Talbot. I'll just list the inaccuracies:


Virtues are habits, so one can know the right action, perform it for the right reason, and still not posses the relevant virtue.
Aristotle claims that the man of practical wisdom is always able to choose rightly, not the virtuous person. Since practical wisdom requires life experience, one can be virtuous without being wise.
For Aristotle, choosing correctly involves judging practical situations appropriately. This judgment involves not only knowing what is good, but also seeing what the particular situation requires. This is the reason you can't really make general claims about 'the right action' in Aristotle's theory, because minute differences in a situation can change what's right to do.
Casting Aristotle theory in terms of 'the right action' ignores the fact that, for Aristotle, the point of ethics is not to know stuff, but to achieve eudaimonia. Hearing your elders, receiving proper education and practicing virtue is all you need for this; you don't need a method to decide 'the right action'.


I highly recommend Anscombe's Modern Moral Philosophy if you want to see the contrast between Aristotle and modern ethics. If you want to delve into the details of Aristotle's views on practical reason Wiggins' Deliberation and Practical Reason is good.
In formal languages quantifiers are not defined, they are basic symbols manipulated according to axiomatized rules. When language is interpreted then quantifiers are interpreted as infinite conjunctions or disjunctions, but interpretations are external to the language itself, and it does not always behave as "expected". For example, Gödel showed that there are predicates P in Peano arithmetic such that P(n) is provable for n=1,2,..., but ∀xP(x) is unprovable, so the quantifier does not reduce to "infinite conjunction". Peano arithmetic is http://www.encyclopediaofmath.org/index.php/Omega-completeness ω-incomplete. There are even consistent extensions of it that prove every P(n) together with ¬∀xP(x), they are https://en.wikipedia.org/wiki/%CE%A9-consistent_theory ω-inconsistent.

Languages that allow infinite expressions are called http://plato.stanford.edu/entries/logic-infinitary/ infinitary languages and can themselves be of first or higher order, depending on what one can quantify over. Even first order infinitary languages are much more expressive than their finitary counterparts, for example they can specify the standard model of arithmetic, which finitary Peano arithmetic can not, it allows non-standard models with "infinite numbers". However, infinitary languages usually lack nice structural properties, which makes them intractable. For example, any finitary language is compact, if a conclusion is derivable from a set of premises it is already derivable from a finite subset of it. But this is obviously false even in first order infinitary languages, an infinite conjuction is not derivable from any finite subset of its terms.
(This may just be repetition of https://philosophy.stackexchange.com/a/18324/9166 https://philosophy.stackexchange.com/a/18324/9166 in a more extreme form.)

Worse yet, is pleasure even well-defined?

We find a reasonable range of experiences that are simultaneously suffering and pleasure, not just mixed, but experienced as a single inseparable whole:


People derive pleasure from pain, especially when a paraphilia or a tendency toward deep regression is involved.
Depression can be a deliciously decadent experience wherein the release of concern for the world echoes infantile omnipotence, while simultaneously being outright painful.
The autistic experience the 'taco' effect being deeply calmed by being completely thwarted in ways that are claustrophobic and terrifying when they provide only partial constraint.  The terror of interference and constraint does not abate, but somehow converges on something calming.
Other people seek out almost debilitating fear on purpose. Is the resulting mania a good mood or is it emotional torture not to be able to escape such intense excitement?  They say the latter, and go back.
Soldiers in decades-long combat can become addicted to a lifestyle they find physically painful, traumatizing and immoral, and it can be impossible to restrain them after peace is achieved.


The examples all involve atypical psychology but I am not sure this is so much an aspect of their psychology being abnormal, as that it is easily missed by those who are more neurotypical, (like a lot of the detail in the world.)

This whole arc follows the ethical notion we trace from Epicurus, that there is a single best thing, and that serving that interest is our primary goal in all ethics.  From him, the notion of pleasure has evolved.

First of all our science makes it questionable whether it is possible to optimize pleasure.  If the James-Lange or Cannon-Bard theories of emotion (especially as they come together in as they come together in Lisa Feldman Barret's model) (q.v. all on Wikipedia) are right, we assign the positive or negative valence of an emotion well after we experience it.  So, if we would just reassign the valence, given different environmental factors, how is the experience itself absolutely good or bad?  But at the same time, how are we supposed to work to increase something that can just be reassigned the exact opposite value due to mere accidents over which we have no control?

Nietzsche suggests there is something more immediate to serve, the ongoing revelations of one's Self.  

Consonance and dissonance with one's will at a moment are not necessarily experienced as pleasure or suffering in the way one would expect.  It can be deeply satisfying to work oneself into a state of fury or exhaustion that empties you of positive thoughts and even physically hurts when this is in the deeper service of your own will.  And once you have recovered, getting what is called for may be so much sweeter for having suffered for it.  But the will is definite, and the fact of choice gives us a definite definition of what is actually pleasant, at a deeper level.

Though he did not look at it that way, it addresses the scientific problem.  By making subjectivity primary, we can avoid the fact that pleasure is objectively unstable by giving a redefinition of pleasure in terms of choice.  We also get to avoid 'serving' some global notion of choice, by making this all a competition and not a collaboration.

But Schopenhauer (as a voice for a Westernization of Buddha, in which suffering is life and life is valuable so suffering is valuable) had already suggested that suffering is in many ways just as productive as pleasure, however you might tweak the definition of the latter.  Power as pleasure, in particular seems to fail the historical test of fanatical Christianity.  Suffering due to self-abnegation can be seen as the greatest good: independence of the world or service to a transcendental power.  In being so revalued and worshipped, how does it not become more relevant than pleasure?

Similar attempts seem equally doomed if we follow one of the other threads in Nietzsche, from the Genealogy of Morals.  It suggests that humanity tends to reverse meanings just to resist being defined, to remove leverage to which power has been applied, in order to escape domination.  But this has always enabled a different expression of power, almost directly opposed, to arise in the old dominator's place.

Such reversals are easy because negation is tricky.  Opposites often lie closer together than they lie far apart.  So absolute values like pleasure are often undermined by their own inability to be properly set opposite to their nearest possible contrasts.  From a perspective elaborating McLuhan, the manipulation of choice in modern society, and the psychological burden it can easily become, suggests that even the freedom that we imagine is the reason we avoid domination can facilitate a variety of power, with its own set of leverage points.

So we can fall back on the psychotic directive: 'Choose your illusion'.  Crowley's devotion to evil or Starhawk's "Dreaming the Dark" capture in religious terms a worldview that owes much to Nietzsche, and that values difficulty and contradiction and extends a greater value to pleasure if it is complete to the degree that it and contains its opposite.  But at that point, one has assigned all value you are going to allocate to your primary goal, and are valuing its opposite.

But we are all moderns, at heart.  Having seen science, we are unlikely to abandon its foundations.  The ecstatic and revealed form that these post-modern criteria take seems open only to the fanatical and antirealistic.

To me, this exhausts the tradition of Epicurus and the search for a single motive upon which to base ethics.  There is no proper way to just keep the focus and redefine the goal.  We are forced to back down from a single point of reference to something more negotiated.  

Even if those negotiations keep pulling us back to a point of consensus which promises to provide another single point of reference, it will always be as unstable as the original chosen point.
Deduction does not necessarily mean classical logic, but something more basic, which does not necessarily embody the rule of non-contradiction.  

We use deduction rules in Universal Algebra or Category Theory for instance, which have little to do with classical logic, but help us to keep formal operations in order.  The result does not necessarily establish truth or falsehood, but helps us decide when two items in a formal system are equivalent under a certain set of transformations.

You can look at these as logics with whole mathematical models like groups or rings or algorithms or other categories as truth values.  But you don't have to.  An application that is perhaps a bit broad is that of abstract semantics of computer type systems.  

In that sense, some variant of deduction has to apply if you have grammar and sequences.

An anti-realist might easily imagine we live in a reality where grammar or time are not reliable touchpoints, don't behave consistently, or lack real meaning.  This makes deduction still possible, but not trustworthy.

In fact many theories of meaning like those of Desaussure and Lacan insist all grammar is only approximate and not fully shareable between people, or is relatively constructed.

And some philosophical approaches to physics question whether time is real or only an aspect of perception -- most famously, Kant, and one version of the theories of Boltzmann.



@virmaior asked for an example, and the examples are fun but really boring to describe.  I will try to describe one from 'fully abstract semantics', a Chomskyian linguistics model that gets adopted by computing.  I hope it somewhat appeals to human beings.

One place deduction rules apply to something other than logical truth are in looking at abstract grammatical transformations (especially in computer languages, but also in human ones).  The rules take us from one sentence to another, just as one might expect, and preserve meaning.  Since this is not quite a logic, but only a deductive system, meaning has a broader sense than 'true, false or otherwise', and includes things we might really consider meaning.

It can be true that meaning is preserved but rendered very hard to access.  So you can make a subcategory of 'reasonably efficient' such transformations.  (Where reasonably efficient has to not penalize the steps in the grammar itself, so Big-O or something similar.)

It can be the fact that a transformation preserves meaning in way that sometimes is and sometimes isn't efficient, depending on the route through the transformation system.  So important cases are characterized by the local equivalent of P & ~P.  You can efficiently parse the statement as long as you don't take a certain detour, which will make you balk at it.

In that sense the system both does and does not handle the situation.  You can address these by tuning the rules, or you can use the cases in a given language to explain why people choose given grammatical transformations over others or why grammar changes in some ways and not others.

Finding such situations is important when the language is artificial and the equivalent of determining equivalent meaning is that a given variable's type matches a function signature.  (The theory arose in verifying the type system in 'ml' was not impossible to compile.)  The compiler should not spend an inordinate quantity of time merely matching types and not actually compiling any code.  (A real fear in the early entries in the class of languages that eventually led to Haskell.)

It has also been used to prove whether a given optimization is helpful or not.  (The optimized code computes the same thing, but should do so more efficiently and not less, but the compiler should not get lost in the weeds trying to figure that out.)

(These examples are from lectures on abstract semantics by John Gray at the University of Illinois in the late 80's and early 90's, which may or may not have ever reached publication.)

If you focus on the application to a real language, there are lots of more subtle ways of looking at meaning than logics allow.  

You might include considerations like the later Wittgenstein's, where meaning is focussed on given motives and segmented into 'games' in a way that does not allow all sentences to combine and reduce to truth-values, but only to 'moves' in the game.

A lot of the power of arguments in the "Investigations" derives from determining when consistency does not apply and does not matter -- where P and not P is not relevant due to the sophisticated equivalent of a category error.  And I would not even consider Wittgenstein and anti-realist.

More pragmatically you can inject the idea that comprehensibility is contingent, and that incomprehensible statements still have 'best accessible meanings', so reality is constructed by your statements whether you are understood or not.

Either of these remains a world where deduction matters, but does not constitute a logic, and where consistency is not necessarily important.  Since both are reasonable, we might just live in such a world.
Critique of Pure Reason:

Kant made a difference between 1) sensible intuition and 2) non-sensible intuition. Here intuition translates the German Anschauung. Kant always uses this term for our mode of processing our sensible input. The output of this first step is structured by space and time.

Kant names the source of our sensible input thing in itself. Kant’s point: We cannot conceive the thing in itself, we cannot conceive any property of the thing-in-itself, we cannot apply any category to the thing-in-itself. The thing- in-itself is a pure hypothesis, necessary as a base to the whole process of cognition.  Hence noumenon in the negative sense is the term which fits our manner of cognition.

On the opposite, noumenon in the positive sense would refer to an intuition different from human intuition with time and space. Kant states that we are not acquainted to such type of intuition and that we do not even know whether it is possible. 

The whole passage from the Critique of Pure Reason does not relate to the difference between potential infinity and actual infinity.  

Potential versus actual infinity:

The standard example to illustrate the difference are the natural numbers 0,1,2,…. You can continue counting without reaching a last number; that’s potential infinity. On the other hand – at least since Cantor’s set theory - you can consider the set of all natural numbers. This set is actual infinite. Aristotle accepted potential infinity but not actual infinity. 

To your first question:  Paraphrasing the last statement by using your terms I mean that Aristotle’s idea of potential infinity does not contain the idea of completion.  

To your second question:  What do you mean here with “in itself”? Does it relate to Kant’s term “thing in itself”? In any case, potential infinity and actual infinity are two different terms. Neither contains the other. 

To your third question: According to Kant we cannot know anything about a noumenon, notably we cannot know whether it is infinite in any conceivable sense. We cannot even know which concepts apply to a noumenon.

In general, I consider it difficult to speak in abstract terms about infinities. But set theory provides a means for precise terms like finite sets, infinite sets, countable sets, uncountable sets and the whole variety of different infinite cardinalities. 
Space and time are distinct concepts. The fact that relativity makes of time the fourth dimension doesn't mean that space and time are not treated distinctly, as you observe yourself. The metric of relativity makes it clear that one dimension receives a special treatment, in any referential. This is what the concept of time, as opposed to space, subsumes, and the concept remains open to inquiry.

You say that space and time don't exist because of different referentials, but one should not confuse the topology, the metric and a coordinate system. Different referentials assign different space-time coordinates to events. But coordinates are not space or time, they are tools for making calculations. The lesson we should draw from this fact about the concepts of space and time is, again, open to inquiry.

Something is absolute and doesn't depend on the referential: the clock hypothesis, which says that a clock measures the (frame independent) space-time interval along its path. That looks pretty much like an absolute notion of time (since obviously, clock are not meant to measure distances). Arguably this is what the concept of time refers to in relativity.

Even conflating time and the measure of time in a specific referential, the lesson you draw, that space and time are relative to a subject, might be a possible lesson but note that "subject" is not the same as "referential" nor "observer" in the sense of physicists (which really means referential anyway), so you'd have to argue a little more to convince that space and time are not "real". It's really unfortunate that physicists use the term " observer" because it brings confusion: any human observer (=subject) is free to use any coordinate system she wishes to describe the world.

In any case it's certainly not the only lesson to draw. After all, there is also cosmological time, and perhaps there is a priviledged frame of reference, that of the CMB. If quantum mechanics is non-local, maybe that means something for time too, we don't know yet.

Furthermore (to rejoin other answers) the metaphysical questions on space and time are rarely about its existence, rather about its status: is space-time only relations between objects or events, or something more substantive (would it exist without any objects)? Can we account for the passage of time in a block universe, or is change an illusion, to be reframed in terms of different states at different locations in time? What does it imply for our understanding of causation, and the fact that most scientific explanations are causal and time-directed? Is the past hypothesis / entropy account enough to account for all kinds of scientific explanations, even when thermodynamics isn't obviously related? Or is there an intrinsic direction of time associated with "evolution" laws? Or are we merely recording regularities on the distribution of events in a block universe?

All these are meaningful questions which connects science with a broader, big picture of the world, and opinions and intuitions diverge strongly on these topics, even among scientists themselves, so science doesn't have the last word on this. It's a matter of interpreting what science tells us. That's why we are arguing.
The text is The Birth of Tragedy from the Spirit of Music, an 1872 work of dramatic theory.

https://en.wikipedia.org/wiki/The_Birth_of_Tragedy https://en.wikipedia.org/wiki/The_Birth_of_Tragedy

The Apollonian (according to Nietzsche's usage of the term) is the principle of the individualization (Principium Individuationis), it represents the social/historical force that creates the society, the individual, the personality, the civilization, consciousness etc.
It is based on Logos, reason, clarity etc and represents the ability of the individual in the progress of human society to create a rational image of the self inside the world. 
The main aesthetic element is the clear form. 


  Just as in a stormy sea, unbounded in every direction, rising and falling with howling mountainous waves, a sailor sits in a boat and trusts in his frail barque: so in the midst of a world of sorrows the individual sits quietly supported by and trusting in his principium individuationis. Indeed, we might say of Apollo, that in him the unshaken faith in this principium and the quiet sitting of the man wrap therein have received their sublimest expression; and we might even designate Apollo as the glorious divine image of the Principium Individuationis, from out of the gestures and looks of which all the joy and wisdom of "appearance," together with its beauty speak to us. 
  
  – The Birth of Tragedy, Friedrich Nietzsche Russell & Russell 1964 p25)


The Apollonian is contrasted with the Dionysian, that represents the chthonic (χθόνιο) (ground-earth) element, the  incapability of creating a rational view of the world, the instinct. 

One can observe the difference of these two elements as expressed in art forms. Some of those incorporate both elements but some represent more one or the other.
I think that he doesn't talk about this separate from the overall sense of inauthenticity.  Irrelevance is the inauthentic assumption that a choice would not have any effect, before making the choice and finding out, or even really playing it out in one's head.  It is a basic lie that evades freedom, and it does not need separate discussion.

The 'protagonist' in Nausea, for instance, obviously continually rejects possible actions as 'irrelevant'.  He may not put it that way, over and over again, but that is a lot of his internal reasoning.  Meanwhile his continual undercutting of his ability to choose is not rational, and it is destroying him.  If he took some of those irrelevant actions, his ability to abide the remainder of humanity might improve.

  If there is a value which is of value, it must lie outside all
  happening and being-so. 


Wittgenstein isn't denying that there are values which are contingent; perhaps historically contingent or culturally specific - the concern of the anthropologist - but he's interested here in isolating a value that is permenant and so 'outside of all happening and being-so'. 

It's referring to an argument in Plato of the Form of the Good; and like him he locates it outside of this world by the following reasoning:


  For all happening and being-so is accidental.


Accidental meaning contingent here; and thus non-accidental meaning permanent 


  What makes it non-accidental cannot lie in the world, for otherwise
  this would again be accidental.


And hence 


  It must lie outside the world.


This may seem like a strange thesis to locate the source of values outside of the world (and perhaps this is where Nietzsche comes in by relocating values to the world);

But a similar argument shows that a physical law such as the law of conservation of energy - which is a permanent law of physics - a law that has value by virtue of its permanance, cannot lie in the world: 

For no amount of experiment can establish this law, as it is not deductive but inductive (once a general framework is established, ie Hamiltonian or Lagrangian Mechanics - the law can be deduced); but the fact remains: physical theories that are of permanent value are not in this, our contingent world of accident, happening and being-so.
I'm really not sure what is intended,but isn't this part of a general frustration with the trajectory of subject-centered ontologies since Kant, and the seeming political dead-end of constructivism, hermeneutics, and textual analysis? One impulse seems to be the recovery of some sort of non-dogmatic attachment to the natural sciences, and hence to "nature" of some sort. More of a poplar "mood" than a new classification.   
Any object in a scientific model is a bundle of properties.  The necessary circularity in scientific vocabulary always has to reduce to a chosen set of axioms that constitute the form of the definition to be used.

But that is just a side-effect of the choice to use mathematics as the language of science.  We have devolved, in modern mathematics, on the understanding that that is just the way definitions work.  There are so many different ways of capturing a behavior, many of which are so close to being alike, without truly being isomorphic, that we have to corral the behavior into the right sized box with a set of rules before we can proceed.

But those models are models of something.  So, insofar as an electron is being handled by a theory, it is only a bundle of properties.

But then so is a species, or a personality or a biological niche.  And no one would seriously contend that those things are made up of their properties in more than a formalistic way.  The formalism captures observed behavior of something more real, if less definite.
Taken most literally, the statement says that the claim that people optimize their own well-being without regard for others is equivalent to saying that no random variables ever interact with each other. It seems that the second claim is probably strictly stronger than the first: I can imagine a society in which people optimize strictly for their own well being (for example, a subsistence farming society where families need not interact with other families), but I cannot imagine random variables ever always having zero covariance.

Taken a little more generously - someone making the above claim might be trying to say that the pursuit of one's self interest never benefits or harms someone else. This claim also doesn't seem accurate:


There are cases where an individual's self interest hurts someone else, for example, when they are competing for some common thing).
There are cases when an individual's self interest benefits someone else, for example when someone is able to specialize in performing some task or providing some product, and trades that product or service to someone else who needs it.

You might find Graham Priests book The Limits of Thought helpful in refining your question. Priest argues that


  thought runs into true contradictions when it runs up against its own limits 


This was noted by Kant - his famous antinomies - which motivated his critical project; however Priest credits Hegel for deciding the contradictions are unavoidable, and their underlying structure. 

The book runs through a history of limits; and argues for a typology;  limits of:


expression (Plato on something unchanging as a precondition for meaning, Aristotle on Prime Matter, Cusanus on the ineffability of God)
iteration (infinite regresses in Zeno, Aristotle and Liebniz)
cognition (Sextus's sceptism and Protagoras's relativism)
conception (Anselms ontological argument and Berkeleys inconcievability argument for Idealism).


In a different direction, it's worth noting that some of the mathematical Paradoxes of Cantor, Russell's, Tarski, Turing and Godel have been noted to rely on a similar argument - diagonalisation - which was later marshalled into formal argument (under the auspices of category theory).
Hypothetical example: "the scanners look good but cause more harm than they prevent."

This is a "triumph of style over substance".

http://rationalwiki.org/wiki/Style_over_substance http://rationalwiki.org/wiki/Style_over_substance

Noting about gambling, humans have a propensity to "discount the future".  This isn't a fallacy though.


  http://www.psychologicalscience.org/index.php/news/releases/addicts-who-live-in-the-moment-may-get-most-benefit-from-certain-kinds-of-treatment.html The human instinct to choose instant gratification — known as future
  or delay
  discounting

There are some assumptions in this question that I do not necessarily agree with (e.g. perfect insight into Johnny's feelings/motivations, what defines a good friend, etc), so I'll assume the following:

You are perfectly knowledgeable and correct in your interpretation of Johnny's reaction, and the conscious/subconscious motivations behind it.

A "good" friend is one who values your well-being, and will take reasonable actions to promote it.

You wish to also be a "good" friend to Johnny.

Assuming these things, your best action would be to constructively engage Johnny to both minimize his discomfort with the situation ("I'm sorry I cannot provide the information you want..."), and set reasonable expectations regarding future interactions of this nature ("...but I don't memorize these things.").

Then, as a good friend yourself, you would provide support you feel comfortable with, and set clear boundaries for things where you and Johnny's expectations diverge.  If Johnny makes a good faith effort to respect these boundaries, then he is both being a "good" friend and demonstrating that he values his relationship with you.  As long as you do the same, things will work out.

Note: I take issue with one thing you said, "a good friend is not someone who values you based on your ability to augment his daily life."  I would say that is actually the basis of any relationship.  One's relationships are often measured in how much of an effect they have on daily life, whether emotionally or physically.  Listening to a friend complain about their boyfriend, helping a sibling with their homework, reminding a co-worker to prepare for his meeting later that day... these are all actions upon which any relationship is built.
As far as I know, there is no specific branch of philosophy that deals with superstitions. Philosophy, within its various subsets, can be thought of as the study and justification of beliefs so, for example, within theology religious superstitions will be assessed. However, there is no specific discipline tasked with finding superstitions and debunking them. 
Heidegger would reject the connection between rationality and authenticity. When we seek rational grounds for actions, we seek a principle beyond our finitude that can ground the justice or rightness of our activity. Kant is a primary example of a thinker who seeks rational grounds for practical activity, and is also a good example of the type of thinking Heidegger rejects with his theory of authenticity.

According to Kant, we are moral when we act not in conformity with the law, but out of respect for the law. Though the law is something we discover in ourselves, it is universal and necessary, and transcends our particularity and finitude. 

For Heidegger, on the other hand, our finitude is radical and inescapable. The pretense of universal laws or principles is an escape from the responsibility for ourselves that this radical finitude demands. We are being authentic only when we act while being consumed by that finitude - without any grounding in reason.

He would also reject the correlation between authenticity and efficiency. This sounds more like the way of thought he associates with Nietzsche's nihilism and modern society's technological thought, which equates being with value. There is no sign by which one can distinguish an authentic action from an inauthentic one (interestingly, this is true of moral actions in Kant's view as well - one never knows if someone has acted out of respect for the law or merely in conformity with it). The thought of being, as Heidegger says in a later work, changes nothing. 
Quine does not subscribe to scientism, i.e. the epistemological primacy of the scientific method, but he is often taken to because his repudiation of scientism is non-traditional. Quine does consign epistemology to a "chapter of psychology", which would be scientism if he also preserved the traditional understanding of epistemology, as scientism does. But naturalizing epistemology means that he does not. For Quine there is no ultimate grounding of knowledge, even in a predefined organon such as the scientific method. All parts of our knowledge are subject to testing and revision in view of contrary evidence, including methodological parts such as naturalized epistemology itself. There are no assumptions, the preference for scientific method is not a metaphysical claim, it is a provisional surmise of the current state of affairs. 

This is characteristic of naturalized epistemology's response to meta-objections in general. In contrast to apriorism or scientism there is no meta, no presupposed justification principles that are independently validated. In http://joelvelasco.net/teaching/3330/Quine-Epistemology-Naturalized.pdf Epistemology Naturalized Quine writes "if the epistemologist's goal is to validate empirical science he defeats his purpose by using psychology or other empirical science in the validation. However, such scruples against circularity have little point once we have stopped dreaming about deducing science from observations. If we are to simply understand the link between observation and science we are well advised to use any available information, including that provided by the very science whose link with observation we are seeking to understand". 

But Quine does not dismiss metaphysics as such, he credits it as a useful tool for organizing our knowledge conceptually. For example, in http://tu-dresden.de/die_tu_dresden/fakultaeten/philosophische_fakultaet/iph/thph/braeuer/lehre/metameta/Quine%20-%20On%20What%20There%20Is.pdf On What There Is he writes that "physical conceptual scheme simplifies our account of experience because of the way myriad scattered sense events come to be associated with single so-called objects". However, it is  the "phenomenalistic" scheme that "claims epistemological priority. Viewed from within the phenomenalistic conceptual scheme, the ontologies of physical objects and mathematical objects are myths. The quality of myth, however, is relative; relative, in this case, to the epistemological point of view". 
As far as I understand Lewis, the real world is distinguished from all possible worlds solely by the contingent fact that's the world we live in. Hence there are no qualitative differences between all worlds. And I can extrapolate from the characteristics of our world to the characteristics of other worlds. 

If a world contains multiple spacetimes then I would consider it several worlds: From the viewpoint of physics a world equals its spacetime. And if spacetime is not connected, then we have several non-interacting components, hence several worlds.

But I am not sure whether my answer meets the point of your question. If not, please write a comment.
The more conventional notation for Tm in you text would be T(m) with m being an individual constant denoting Mary, and T(x) being a 1-place predicate "x is tall". One can also get atomic sentences from many place predicates with multiple constants in them, e.g. L(m,n) for "Mary loves Nick". These are the typical atomic sentences of https://en.wikipedia.org/wiki/First-order_logic predicate calculus. Finally, there are 0-place predicates (propositions) that require no constants at all, like R for "it's raining". Your text calls them "simple sentences" if they do not decompose into smaller parts joined by connectives, etc. Such propositional constants are most common  in https://en.wikipedia.org/wiki/Propositional_calculus propositional calculus, a more elementary segment of predicate calculus.

The term "simple sentence" (no subordinate clauses) is also https://en.wikipedia.org/wiki/Sentence_clause_structure#Simple_sentences used in grammar, and does typically involve "subject" (typically noun or pronoun phrase) and "predicate" (typically verb phrase). In case of atomic sentences based on 1-place predicates we have an individual constant and a predicate, so there is a clear parallelism between grammar and logic. Many place predicates can be expressed using objects, adpositional phrases, etc. Since English grammar requires a subject in a sentence the placeholder pronoun "it" is often used fulfill this role when dealing with 0-place predicates.
Socrates claims to be rewarded with free feeding at the Prytaneum because he has served well the State by teaching. A Socratic irony. 



The Prytaneion was a building on the Acropolis of Athens. {...}

It was dedicated to Athena Polias and served as Archives. Here dined ambassadors and official people, and Αείσιτοι (aeisitoi - permanent feeding) who were public servants of the Parliament and the City, and because of their position had the right of permanent feeding to the Prytaneion throughout the duration of their mandate*. Socrates in his defense countered instead of conviction to death the feeding at the Prytaneion. {..}

Translated from Greek Wikipedia
https://el.wikipedia.org/wiki/%CE%A0%CF%81%CF%85%CF%84%CE%B1%CE%BD%CE%B5%CE%AF%CE%BF https://el.wikipedia.org/wiki/%CE%A0%CF%81%CF%85%CF%84%CE%B1%CE%BD%CE%B5%CE%AF%CE%BF



*"and Athenians who had especially well served the State, were entertained as public guests"
There is also another approach : http://plato.stanford.edu/entries/mathematics-constructive/ Constructive Mathematics, and in particular http://plato.stanford.edu/entries/mathematics-constructive/#BisConMat Bishop's version, that provides :


  a constructive development of a large part of twentieth-century analysis, including the Stone-Weierstrass Theorem, the Hahn-Banach and separation theorems, the spectral theorem for self-adjoint operators on a Hilbert space, the Lebesgue convergence theorems for abstract integrals, Haar measure and the abstract Fourier transform, [...].


See at least :


Errett Bishop, https://books.google.it/books?id=G4OBMQEACAAJ Foundations of constructive analysis (1967 - reprint : 2012)


and :


Errett Bishop & Douglas Bridges, https://books.google.it/books?id=GF8lBAAAQBAJ&pg=PR1 Constructive Analysis (1985).

As you see from the discussion subsequent to your post the original quote is from
Schopenhauer, Arthur: Über die Freiheit des menschlichen Willens (= On the Freedom of the Will). Brodhaus, Leipzig 1868, p.68. It reads


  You can do what you will, but in any given moment of your life you can will only one definite thing and absolutely nothing other than that one thing. = Du kannst thun was du willst: aber du kannst, in jedem gegebenen Augenblick deines Lebens, nur Ein Bestimmtes wollen und schlechterdings nichts Anderes, als dieses Eine."


The question whether Schopenhauer is right belongs to psychology. We know that some persons in certain situations are unable to make a rational decision between two opposite possibilities (exemplified by Buridan's ass). 

Einstein's statement


  A man can do as he will, but not will as he will.


considers quite a different point of human nature. Einstein explains the meaning of this statement just before:


  In human freedom in the philosophical sense I am definitely a disbeliever. 
  Everybody acts not only under external compulsion but also in accordance 
  with inner necessity.


Einstein stresses that our actions are determined by two diffent kinds of constraints: Exterior and interior constraints. Hence instead of - interior - free will Einstein sees interior constraints. Unfortunately, in this passage Einstein does not give any argument for his rebuff to the concept of free will. 

A well-known philosopher who votes for the existence of free will is Kant; notably in his works on practical philosophy. Because Kant takes free will as presupposition for any moral action. 

Today the issue of free will is investigated also in the field of neuroscience. Until now, neuroscience like any other natural science has no other means to operate than to employ strict causality. 

I expect: Further investigations from neuroscience will show, how former experience shapes our preferences, which serve as standard for the interior evaluation of possible alternatives for future action. This deterministic process of decision is shielded because it is unconscious in general.
Now that I see your answer I have a better idea of your question, and would like to attempt a slightly different interpretation.

I do not have the right editions to cite, but am basically looking at Preface to CPR,2E (very helpful), Third Antinomy, and Canon of Pure Reason, Sec. I. 

I take it that Kant's main concern is not only Hume's skepticism, but the broader issue of his day: How can a natural causal determinism (the basis of scientific knowledge) be reconciled with freedom (the prerequisite of Protestant morality duty or "practical reason")? He is most concerned with preserving "practical reason" against skepticism, utilitarianism, determinism, atheism, and dogmatic authority. Even if sure knowledge loses out.

First, as to the second part of your question. I think he takes our freedom "in experience" as unproblematic.We can simply observe ourselves as "entities" among phenomena and see that we choose this or that. Moreover, to engage in science and discover "causalities" (efficient or otherwise) also requires speculative freedom. We can insert "spontaneity" into the causal chains to do "experiments." Notably he calls this not some "absolute freedom," but a type of "second causality" to preserve, I believe, its moral imperatives. So our "freedom" is traceable as an uncaused, spontaneous "cause" among sensible things, but not determined by them. Hence moral duties.

Now the difficulty. This tells us nothing about the origins, limits, or demands of this practical, experiential freedom. It is free of efficient "causality" and must therefore originate in the noumenal or transcendental realm. Here it can enjoy "logical relations" apart from temporally "causal relations." Like everything else the will or "soul" has a double existence as phenomenal and as "ding an sich." The problem is, how does Kant know? We presumably have no access to such noumenal entities.

In the Preface, 2E Kant argues that we cannot "know" we have this freedom. We cannot "know" things-in-themselves, such as our soul. But we can still "think" them hypothetically, as long as they are not self-contradicting.  So we can deduce this freedom from (1) the observation of experience, (2) the fact that it is not rationally contradicted, and (3) the necessity of some transcendental origin of moral freedom. Such knowledge enables Kant to do what he really wants to do. Which is to makes rational claims about this freedom and practical reason, preserving us from epistemological and moral anarchy.

My understanding is that Kant rewrote this material several times and that nobody, himself included, is entirely satisfied with it. To have his "two causalities" he must separate the phenomenal and noumenal, but must then tell us how he can make claims about the "noumenal" origins of "practical" reason. While I agree with the substance of your criticisms, I am not sure they affect Kant's overall argument. Science can always gain more and more knowledge of cosmological or neural "causes" in the sensible realm. But we can never secure any "final" causes except with regard to moral-practical reasoning.     
I rather like this exercise. You are right to say it is abstract and difficult, but that is why it makes for a good test. 

.1 This is OK. As you say, it is an explicit premise. It is also scientifically dubious since what is sent from the mountain to us are photons and it is only when these impact the eye and are processed by the visual cortex that an image forms. The photons don't shrink. Nor is it possible to speak sensibly of the size of the image in comparison to the size of the mountain. The mountain has dimensions that might be measured in metres; the image can only be measured as a solid angle in our visual field. 

.2 The argument does not say "inaccurate", and I'm not convinced this is really implicit. 

.3 I don't think this is implied in any way. I would replace your 2 and 3 with 

.2' If the image we have of a mountain is smaller than the mountain itself then there is no way to judge the size of the mountain. Implicit premise. Also false, because as noted above, one cannot compare things and images like this. 

.3' If the mountain sends us an image, we would be unable to judge its size. This is your 4, but expressed as a conditional. This follows from 1 and 2' by hypothetical syllogism. 

.4' We are able to judge the size of a mountain by sight. Implicit premise. Also false. We can't judge the size of anything by sight unless we know how far away it is. 

.4A The mountain does not send us an image. This is your 6. I prefer it here because it follows from 3' and 4' by rule of modus tollens. 

.5 This is OK. As you say, explicit premise. Potentially dubious because it may be a false dichotomy: are we sure there are no other explanations of perception? 

.7 Again, OK. This follows from 5 and 4A by disjunctive syllogism. 

In other words, our 'unpacked' version of the argument shows that it is valid but proceeds from at least three false premises. 
Co-constructivism is the notion that society can influence technology at any time, not just at the beginning of a technology's initiation into society, as the Technological Momentum theory states. 

The Technological Momentum theory states that a technology can be influenced by society only at the beginning of its initiation into society. As that technology gains momentum in society and is increasingly accepted, it is then impossible for society to influence that technology.
There were never real Kantians, unless we count more or less faithful popularizations of Kant's ideas like Herbart's, or sympathetic commentary like Strawson's. Helmholtz, Grassman, Poincare and other scientists were mostly interested in Kant's theory of visual perception, psychologically and physiologically reinterpreted. Perhaps the most minimal definition is given in Wikipedia without citation: ""Neo-Kantian" can also be used as a general term to designate anyone who adopts Kantian views in a partial or limited way". By this definition however Hegel and Quine are neo-Kantians, as are most contemporary philosophers.

Historically however two major philosophical schools self-described as neo-Kantians, Marburg (Cohen, Natorp, early Cassirer) and Southwest (Windelband, Rickert, Lask), and they shared with Kant two main themes. First, epistemology subsumes ontology, our beliefs are not representations of any mind-independent "objects". The very concept of such a representation is meaningless since our mental faculties can not "represent" anything independent of themselves, they only deal with appearances. Second, the object of knowledge is constituted by our mental faculties based on some a priori structures. Where neo-Kantians diverged from Kant is in rejecting a priori forms of perception, space and time, they were left therefore with undifferentiated manifold of sensation and logical forms of judgement to do the constitution. 

This has far reaching consequences because it destroys the unity of Kant's architectonic of pure and practical reason, productive ability of imagination can no longer do the work for Kant's noumenal metaphysics of practical reason and judgement. Marburgers gave priority to pure reason, and focused on scientific knowledge, Southwesterners to practical reason, values and transcendental psychology over logic. Both retained priority of rational discourse over religious, artistic, etc. forms of expression, but in mild forms. Rickert, Lask and Natorp paved the way for phenomenology (personally influencing Husserl and Heidegger), Cassirer in 1920s moved beyond Marburg by incorporating Hegel's historical dialectic and elements of Lebensphilosophie, and advocating plurality of expressive forms. 

By historical measure Foucault and Kuhn are frankly a stretch. The closest thing to a contemporary neo-Kantian would be Friedman, who seeks to enrich Marburg with insights from Carnap, Quine and Kuhn, and takes Cassirer as inspiration. In particular, he relativizes a priori forms and analytic/synthetic distinction to lasting but historically revisable notions that help bridge the "incommensurability" of paradigms and mitigate cultural relativism.

In Parting of the Ways Friedman gives a sympathetic account of historical neo-Kantianism and its precipitation of the analytic/continental divide despite Cassirer's best efforts.
Another appropriate example occurs at the other end of life. 

If human life is the essential medium of the supreme good, presumably all manner of life extension, from artificial pumps to cryonics, would be not merely justified but ethically imperative. We might also find in this idea an imperative to be fruitful and multiply 24/7, producing as vast a quantity of human life as possible.

If, on the other hand, human life is "intrinsically" good--that is, good for human life itself--such measures may or may not be justifiable. Certain immanent value judgments might pertain.  But "merely foreseeing" in the last sentence certainly doesn't clarify matters. Can't make out what that means. 
Okay in pieces:


  If a thing arrives at existence it comes either from being or from nothing.


I don't think this particular bit is too hard to follow. Anything that exists exists either because it can from something else or because it just popped into existence. (if it eternally existed then it never arrived).

If A, then B or N


  Now it cannot come from being (statue from existing statue). 


Parmenides rejects a principle of change for existing things. He thinks they are always what they are and thus rejects B.


  Still less can it come from nothing. 


Most of us think it's kind of weird for something to come from nothing. Thus, he rejects N. (I think the only exception is the Christian doctrine from Augustine from creatio ex nihilo).


  Therefore all becoming is impossible. 


This follows by modus tollens when we've denied both B and N.

1. If A, then B or N          A
2. Not B                      A
3. Not N                      A
4. Not B and Not N            ^I  2,3
5. Not (B or N)               DeM 4
6. Not A                      MT 1,5  



  This argument is based on the principle of contradiction or identity, which Parmenides thus formulates: Being is, non-being is not; you will never get beyond this thought.


For Parmenides, being just keeps on being whatever it is, and non-being by definition does not exist.

I'm not quite sure why the author thinks "you will never get beyond this thought." Aristotle has a nice argument and position that is beyond this thought, which is that things can change in multiple ways, they can both enter and leave existence, and they can change modally, like the cheeseburger that becomes a part of my body or the dirt that becomes a part of a tree.

But it still remains nearly axiomatic that "something cannot come from nothing". What's largely denied at this point is Parmenides rejection of B -- because we distinguish between coming into being and matter changing forms. (the former is governed by the law of conservation of matter/energy; the latter is not a problem for chemistry and physics).
Yes, Sartre explicitly says as much.  Consider his lecture: https://www.marxists.org/reference/archive/sartre/works/exist/sartre.htm Existentialism is a Humanism


  In one sense choice is possible, but what is not possible is not to choose. I can always choose, but I must know that if I do not choose, that is still a choice...  
  
  Since we have defined the situation of man as one of free choice, without excuse and without help, any man who takes refuge behind the excuse of his passions, or by inventing some deterministic doctrine, is a self-deceiver...


I believe Sartre once said you still have a choice even if someone holds a gun to your head.  You can choose freely and die.  However, I haven't been able to find a primary source citation for that yet.
I think there is an assumption here that any socialist aspects in society will automatically lead to a reach for socialist aspects everywhere in society.  That assumption is an interesting point to argue, but I'm not confident it's self-evident enough to make it an assumption.

It is possible to have a socialist government that identifies that the "best" way to continue furthering its socialist objectives is to expand outward to take the "vote."  It is also possible to have a democratic government that communally decides the best way to handle a small portion of society is through application of socialist methodologies, and then uses the energy gained by using this "best" approach to further protect the right to vote.

Of course, in all systems, there's a little bit of both extremes.  The debate as to how to manage public resources is a continuing challenge that is not well captured as purely democratic or purely socialist.  Also note that the arguments you put forth could also be applied to the electoral college in the US.  The logistics of the use of any one extreme archetype of government is tricky enough that you'll see mixed solutions everywhere.
Seung, Thomas K. Nietzsche's Epic of the Soul: Thus Spoke Zarathustra. Lanham, Md. [u.a.: Lexington Books, 2005. 

I suggest you read Seung's commentary on Thus Spake Zarathustra if you want to understand what it is all about.
One could say that the existentialists advocated second-order values (authenticity, free choice, responsibility, caring) while Rand also advocated specific first-order values (like being financially independent). So that, for example, in a conflict between a capitalist and a communist, an existentialist could view both sides as commendable (as authentic). Rand would describe the capitalist as good, and the communist as evil.
That's actually a fallacy called either:

Tu quoque (you as well) when used to attack or "two wrongs make a right" (see http://utminers.utep.edu/omwilliamson/ENGL1311/fallacies.htm http://utminers.utep.edu/omwilliamson/ENGL1311/fallacies.htm).

Let's say that we're deciding on a budget. A's plan doesn't give us enough money to eat food from 24th to the 31st of each month. B's plan also makes it so that we don't have enough to eat from the 24th to the 31st of each month. Neither person is in a legitimate place to critique the other's argument. Because the problem with A's plan is still a problem regardless of whether a different plan still has the problem.
I don't believe that this is a proper answer but it's too long a thought to be expressed in a comment.

This problem poses some questions about what we mean by "law of nature". We are assuming that some phenomena are observable only at very high levels of energy, levels that are, for some reason, intrinsically unattainable. If they are unattainable, in which sense a model of what "would happen" but cannot ever happen is a model of reality? What kind of knowledge are we missing if we miss that?

Imagine there's something more fundamental than a quark in the structure of matter, call it a veryverytinystuff, but you cannot observe it until you reach a level of energy that simply cannot be reached. Isn't this exactly like saying (for all practical purposes, but I would also say for all theoretical purposes as well) that veryverytinystuffs are unobservable and have no influence on the way the universe works, and therefore don't exist?

Laws of nature from a materialistic point of view are just a description of the way matter evolves, they are not laws in the human sense. Other philosophical points of view imagine that somehow matter obeys laws of nature like humans obey (...or violate) laws. Still, if matter never reaches those unimaginably high levels of energy, the existence of those laws involving the behaviour of the veryverytinystuff that no quark will ever be obliged to follow is a matter of faith and not science.
They have nothing to do with each other, and that's the point.  

It seems a reasonable principle that if I have strong evidence or justification for some proposition A, and A logically entails B, and I know that A entails B, and I knowingly infer B from A, then I have strong evidence or justification for B. We might call this principle the closure of justification under known entailment. (There are actually potential exceptions to it, such as the paradox of the preface, but we needn't worry about that here.) 

So, let B be "Brown is in Barcelona" and J "Jones owns a Ford". Now suppose I believe J and have strong justification for it. I know that J entails J or B - this is the rule of disjunction introduction. So I have strong justification for J or B. But if it should turn out that J is false and B is true, then my belief in J or B is true and justified, but hardly constitutes knowledge, because I was just lucky. So it is a Gettier case because it is an example of a justified true belief that fails to be knowledge. 
The notion of velocity (rather speed) was not new to Aristotle, it was defined by Eudoxus and used in astronomy, including by Aristotle himself. Aristotle roughly thought that the speed of forced motion is proportional to the "power" (force) causing it, and inverse proportional to the resistance of the medium, so mv=F/R is roughly right.

This applies with caveat that the body is actually moving, because the rest is a fundamentally different state for Aristotle. This also leads to infinite velocity in the vacuum (zero resistance), which is one of the reasons why he thought that "nature abhors vacuum". So there is some inescapable distortion in translating Aistotle's mechanics into modern mathematical notation. http://arxiv.org/abs/1312.4057 Rovelli makes a systematic attempt, and shows that his mechanics is largely reproduced in the limit of highly resistant medium. 

Aristotle's account of projectile motion however can only be interpreted very artificially as a forced motion (because of low air resistance), and was criticized already in antiquity, by Philoponus and possibly Hipparchus earlier. Philoponus pointed out that on Aristotle's account of force moving air moving arrow one should be able to make the arrow move by waiving hands behind it. This convinced Avicenna, Avempace, and later Buridan, to adopt the impetus theory, where forced motion can be maintained without constant impact from a force. See http://muse.jhu.edu/journals/jhi/summary/v064/64.4franco.html Franco's paper.
That there is a threshold force required to move a body subject to friction is an interesting fact, but even cursory observation shows that this threshold is different for different bodies, and depends on their weight. Moreover, it is finite and noticeable, not infinitesimal. Nothing in Aristotle's quotes suggests that he thought otherwise. Some historians argue that http://www.mlahanas.de/Greeks/Syracusia.htm Archimedes publicly demonstrated moving Syracusia (55 meter long ship) single-handedly   using levers and pulleys specifically to refute Aristotle's "one man cannot move a ship". In any case, the story was well known in antiquity, so Aristotle's reasoning on the issue was contested.

The relationship between Aristotle and calculus is more complicated. Infinitesimals certainly would have been anathema to him as manifestations of actual infinite divisibility, existence of which he denied. They would have resurrected Zeno's paradoxes of motion exorcising which was one of his main goals. So calculus of Fermat and Leibniz is out of the question. Newton's calculus is a different matter. In mature works Newton replaced infinitesimals with quantities explicitly defined in terms of motion, which allowed him to talk about "first and last ratios" (limits) without any appeal to infinite divisibility or infinitesimals. Friedman discusses Newton's notion of quantity and approach to calculus in http://www.jstor.org/stable/2185244 Kant's Theory of Geometry (pp.478-482). Newton's qualms about infinitesimals somewhat echo Aristotle's concerns about Zeno and coherence of motion in mathematics, and historians also point out some structural parallels between Aristotle's presentation of mechanics and Newton's in Principia. 

However, these philosophical affinities are not really comparable to Archimedes's much more direct technical influence on Cavalieri's indivisibles, and later on integration. More in that spirit would be also Archimedes's On Spirals, which suggested kinematic method of finding tangents (using parallelogram of velocities), and is known to have directly influenced Newton's kinematic calculus of "fluxions". https://hsm.stackexchange.com/questions/3024/who-discovered-that-the-derivative-of-xn-is-n-x-n-1/3025#3025 Toricelli revived the method in 1640s, and Newton's teacher Barrow was an admirer.
Given String Theory's distant relationship to empirical physics, perhaps they are using "Theory" in the mathematical sense, which is just a set of sentences in a formal language.  Barring any testable hypotheses, it could be thought of as just a set of axioms which are consistent with observations so far.
This extract from the Gay Science appears to refute it:


  What, if some day or night, some demon were to steal after you into your loneliest loneliness and say to you: 'this life as you live it, and as you have lived it, you will have to live it once more and innumerable times more ...'
  
  Would you not throw yourself down and gnash your teeth and curse the demon who spoke thus? 
  
  Or have you once experienced a tremendous moment when you would have answered him: 'you are a god, and I have never heard anything more divine'.


Quite what N means by this has lead to a mini-industry of exegesis through his notebooks and other writings, but nothing really conclusive...
I am not quite sure how to think about your question. In part, I don't have any idea where you are coming from or what degree of training you have in philosophy. I think one issue is that it's hard to define the "core of philosophy" so many of the people writing sociology and political science as continental philosophy do so because they think that is the core. Or to put it another way, many of them are engaged in a critique of standard notions of metaphysics and epistemology (I studied this for several years before deciding on modern philosophy as my AOS because I don't think their critiques are as effective as the hype machines make them out to be).

For instance, I take it to be central to Foucault's history of ideas approach that he doesn't think we're doing much other than playing language games so we should be honest about things are moving. A similar historical approach with different results is taken by Charles Taylor. In both cases, there's a Hegelian heritage at work there. (On the analytic or "post-analytic" side, you may want to compare this with Richard Rorty).

If you're looking for continental thinkers doing "metaphysics/ontology" or "epistemology" however they might define those terms or however similar their projects might be.

Then I might suggest Martin Heidegger and his text "What is Metaphysics?" along with Being and Time as good intros to continental approaches to these questions. A major movement that builds (or at least grows) on this in epistemology is hermeneutics with Gadamer being a key figure.

Alternately, you could look at the phenomenological tradition more broadly going to back to Husserl and then forward to a variety of thinks including Jean-Luc Marion and Jean-Luc Nancy. Levinas is hard to follow but also kind of about "metaphysics" depending on what you mean by the term (and falling in line with the phenomenologists in some respects).

Sartre's Being and Nothingness is about epistemology and is an elaborate (and winding and confusing) critique of Hegel and several other thinks about the nature of knowledge. (It was also parodied by the philosophers of language on the analytic side).

Derrida is also engaged in a kind of critique of knowledge project.
I personally enjoyed Theodore Sider's and Earl Conee's 'Riddles of Existence: A Guided Tour of Metaphysics'.

Here is the table of contents:


Introduction
Personal Identity
Fatalism
Time
God
Why Not Nothing?
Free Will and Determinism
Constitution
Universals
Possibility and Necessity
What is Metaphysics 


And http://tedsider.org/books/introduction.pdf here you can read the Introduction (on Sider's Homepage), which includes short abstracts for each chapter.
It would help to divide up philosophy into some component parts. Logic has certainly made a great deal of progress. Frege's logic is a huge step forward from everything that had gone before and provided the impetus for further advances that have turned the subject into something that Aristotle or Mill would scarecely recognise. We now understand concepts such as proof, validity, decidability, completeness, computability, etc., in a way that far exceeds what was possible 150 years ago. 

Epistemology has also advanced, fuelled by insights from logic and from cognitive psychology; the concept of formal epistemology is fairly recent. 

Philosophy of language has advanced, again partly through developments in logic. The idea of possible world semantics has proved to be fruitful. 

Philosophy of mind is still full of tricky and perhaps insoluble problems, but there have certainly been advances, some of them derived from insights in the field of machine intelligence research. 

Has there been progress in ethics? That depends rather on one's point of view. I rather like Aristotle's approach to ethics, but I wouldn't say there has been no progress. 

Metaphysics is also tricky. We have the benefit of the results of modern science at our disposal now, but there is still plenty to argue about, including some debates such as realism vs. nominalism that would certainly have been recognisable to earlier generations of philosophers. 

Political philosophy is something I suspect does not progress much, but maybe I'm just pessimistic because I don't like politicians and I don't trust ideologies. 
There are in fact several possible answers to the general question you asked as to the legitimacy of regimes. Few of which are:


ANARCHISM: No regime is legitimate
MARXISM: A regime is legitimate to the extent that it prevents the exploitation of its citizens.
CONTRACTUALISM: A regime that has the consent of its citizens is thereby legitimized.
DEMOCRACY: A regime is legitimate to the extent that it succeeds of being a true agent of its governed


EDIT: Not familiar enough with Eichmann's problem to throw light onto the particular question as to when the legitimacy of the Nazi regime might have ended in the moral sense you imply of. Interesting question though.   
Here are a few examples:


Light can be describes as either a particle or wave. Neither description is reducible to the other. Also, neither describes all phenomena fully (the particle model doesn't explain the famous double-slit experiment, the wave model doesn't explain the photon quanta experiment).
Relativity and Quantum Mechanics describe different aspects of reality, but neither describes the other. Similarly to the light example, both models explain some thing well and don't explain other things particularly well.
As another example not from physics, there are models in the study of population dynamics of animals that explain over the course of generations how many of a given species there might be, but you could not use those to predict how many animal births there will be tomorrow. 
As still another example, climate and weather are clearly linked somehow, but models of what the weather will be like tomorrow have little to do with models for longer term climate trends.


As the above examples show, models explain some aspect of reality within some error bounds. In practice then, one does not often speak of a model being "correct," but rather a model is able to make good predictions or not within some specific set of cases.
Classically, there is no difference. Identity is a two place predicate which has the value true if its arguments are numerically identical and false otherwise. One can write such a predicate as Identical(x,y) or one can write it as x=y. The latter is just 'syntactic sugar' that makes sentences easier to read, but it expresses the same thing. This is the way identity is employed in logic, in particular in predicate logic, and by extension in mathematics. 

To say 1=1 does not express identity because there is a spatial difference between the left and right is confusing the thing with the symbol that denotes it. The number one is identical with itself. Of course a serious issue arises over how symbols denote things, and there is much debate over this. Frege held that names are a kind of abbreviated definite description, but this is only one of many accounts of the meaning of names. 

There are plenty of contexts (intensional contexts) in which identity relations appear to violate the indiscernibility of identicals. For example, "Mary knows that George Orwell wrote 1984" might be true, while "Mary knows that Eric Blair wrote 1984" might be false (even though George Orwell = Eric Blair). In general what this means is that while a given identity relation might correspond to a purely extensional equivalence in a particular logic, there might be a more expressive logic in which that identity relation is not extensional. 

Frege, Quine, Geach and Dummett are all worth studying on this subject. The SEP article on identity is a helpful introduction. 
The question isn't particularly clear about what you mean by "what kind" of argument, however Modal Logic primarily deals with the possibility and necessity of statements like the one in the question. Probability is a different option that is used in various systems (such as multi-valued logics that assign each proposition a probability value such as 0.7, with computations from those).

In modal logic, your argument would be written as follows:


  B ⇒ ⋄A
  
  C ⇒ ⋄B
  
  C
  
  ⊢ ⋄A

Gödel's theorems only apply to specific theories. In particular, they must be capable of proving all the provably true statements of arithmetic.

Gödel's theorems have very strong implications if you presume the universe you live in is capable of proving all true statements of arithmetic. This creates neat tail-chasing loops if you believe that the mathematics you have in your head can prove such statements.

However, if you do not start from the presumption of being able to prove all true statements of arithmetic, Gödel's incompleteness theorems do not affect your epistemology. If anything, it states that if you wish to believe the world has several very important and desirable features (such as provability, completeness, etc.), the world cannot be fully defined within a mathematical theory that includes the rules of arithmetic. This means that if you wish to believe the world has those several desirable features, the rules of arithmetic must be thought of as nothing more than an abstract notion which is a useful tool for making sense of the world around you, rather than a fundamental notion which defines that world.  Alternatively, you may give up one of those features (provability happens to be popular amongst religions).

EDIT: Conifold's question pointed out that I had not tied this to epistemology.  This approach identifies some limits as to what knowledge are possible.  It is not possible to know that the universe is constructed in a way which can prove all statements in Peano Arithmetic without knowing, by correlary that the universe is incomplete, inconsistent, unprovable, intractable (recursively-enumerable set of axioms), or illogical (doesn't follow the traditionally recognized definitions of logic, truth, or falsehood).*  Knowing that your universe can prove all statements in arithmetic and knowing your universe does not have any of those undesirable traits are logically inconsistent with themselves, thus you do not have to concern yourself with the possibility of knowing thus.

*Disclaimer: There are a few other ways to sidestep the Incompleteness Theorems, but these do a good job of capturing the main argument.  Gödel states that any omega-consistent system must be at least one of: incomplete (at least one true statement that cannot be proven, i.e. an axiom), inconsistent (at least one statement can be proven to be both true and false), or unprovable (at least one true statement cannot be proven).  Intractable arises from the fact that Gödel's proofs require the assignment of a Gödel number, which cannot be done if the number of axioms in the system is not recursively enumerable.  Illogical points out that all of Gödel's proofs presumed some standard assumptions about math.  There's also a few other escapes, such as not having a multiplication function that is total, but people usually get lost when trying to describe that one.
According to utilitarism your last implication is right "If surveillance doesn't increase happiness of the public, then it would be immoral." 

But the problem is to determine which kinds of surveillance are to be considered and which additional effects - possibly increasing security - also result from surveillance. 

Not until answering these questions one can decide, whether surveillance should be terminated or continued.   
As you probably know, there is no consensus which is the right solution to the original problem. Some people, including Adam Elga say it is 1/3, other people including David Lewis say it is 1/2.

If you're asking what the result of Elga's method would be, you're right, it would be 1/8. But I would write "P(H and day 1)" not "P(H on day 1)", that can be confused with the conditional probability "P(H | day 1)".
Perhaps it helps to keep in mind that behind the veil of ignorance, you never know what position in the society you may get. 

So there is a motivational drive to weigh the respective gains and losses for every position and overall, but especially the ones with the least power to influence anything later on: the powerless and least well-off. 

You will not want to ignore the impact on them if you could become one of them and simply have to bear the consequences.
Comment

But http://plato.stanford.edu/entries/parmenides/ Pamenides writed before the Greek "birth" of logic; see his http://philoctetes.free.fr/parmenides.pdf Poem.

Thus, it is hard to analyze it in terms of "logical arguments".

In a sense, we can say that logic was "codified" by Aristotle also reacting on Parmenides' younger associate : http://plato.stanford.edu/entries/zeno-elea/ Zeno of Elea and his paradoxical arguments.
It depends on what she means by 'middle period'. Usually, the middle period is considered Human, All Too Human, Daybreak, and maybe the first four books of The Gay Science. The works after that are considered his later period, sometimes scholars also take the works of his last sane year (1888) as a separate period, but that is debatable.

The middle period called his 'Enlightenment'-period. In contrast to his previous 'romantic' works (Birth of Tragedy, Untimely meditations), he has a more favorable attitude towards reason, science, and the Enlightenment. His attitude is less historical, more reflective. 

In his later periods however, he turns reason against it self, tracing the lofty ideals back to the not so enlightened beginnings. Paul van Tongeren provides a good introduction on Nietzsche's periods in Chapter One of his https://books.google.nl/books?id=TqxrlA9Qxg0C Reinterpreting Modern Culture. An introduction to Friedrich Nietzsche's Philosophy.

For example, Daybreak 133 is about pity


  "What in the end distinguishes men without pity from those with it?
  Above all  to offer only a rough outline here too  they lack the
  susceptible imagination for fear, the subtle capacity to scent danger;
  nor is their vanity so quickly offended if something happens that they
  could have prevented"


Contrast this with 


  "Nothing is more unhealthy, amid all our unhealthy modernism, than
  Christian pity" (The Antichrist 7)


The commonplace view of Nietzsche is, in this case, based on his later works, so it is kind of a moot point Abbey makes, if this is all she says.
The philosophical concept you're looking for is foundationalism; it hasn't always been neccessary - after all arithmetic  was done and number theory pursued for two Millenia before a foundational movement took hold. 

There are other foundations of mathematics; one that is growing in importance is based on category theory.

Philosophy has pretty much maintained an interest in Language from its beginnings; this being how we think things through; for example Aristotle begins his analysis of logic by looking how we concieve things in language. 

But that there is more to mathematics than set theory, and there is more to philosophy than the philosophy of language - interesting though they are.

A quote from The Republic (Book VI) might prove useful here:


  Socrates: and when they are filling in the work, as I concieve, they will often turn their eyes upwards and downwards.

I take Kant's transcendental philosophy to be a non-dogmatic (contemporary the contender was the "Spinozian") way out of the http://plato.stanford.edu/entries/formal-epistemology/#ThiCasStuRegPro Agrippan Trilemma. The Agrippan Scepticism does say that there may be no certainty in any knowledge, because all sceptic questioning leads to one of the three outcomes of the trilemma (it isn't that correct, because Agrippa had five principles, but I will not go into it for now).

Now, as I wrote https://philosophy.stackexchange.com/questions/33079/what-kind-of-philosophical-questions-are-transcendental-philosophical-questions/33134#33134 in an answer here with some textual support, kantian transcendental philosophy asks for the conditions of the possibility of our reference to objects (of representations). 

Taking this for granted, scepticism is to some extend (as absolute scepticism and as solipsism) self refuting, because it actually has to use concepts (modern speech: language), sensual intuitions and representations to even formulate its position. By this, space and time as forms of the intuitions and the categories of pure understanding have to be involved.

As you can see, transcendental philosophy of course does not work against all scepticism. It is for itself a highly sceptic philosophy, working against all kinds of metaphysics that proclaims entities without corresponding intuitions, like wolffian metaphysics, which were quite popular back then. But it works against some radical forms of scepticism by virtue of dictating them their conditions of possibility as necessary a priori.

The main value of transcendental philosophy against scepticism can therefore be considered as showing the boundaries of the usefulness of scepticism as philosophical method.
Since you have asked for a non-formal answer, I shall try to oblige by not using any numbers or equations. 

Fundamentally, your question is, how does it come about that individual events can be completely unpredictable but when you pile a lot of them together, either in a sequence or in a mass, the behaviour of the whole pile becomes, if not totally predictable, at least substantially predictable? The answer is something called the law of large numbers, and it is one of the most fundamental concepts in statistics. 

As an illustration of it, imagine something called a Galton box: it is a triangular shaped box standing vertically, with its base on the ground and one vertex at the top. There is hole in the top to allow a ball to be dropped in. A series of pins or pegs are placed such that a ball falls either to the right or left in an unpredictable way until it reaches the bottom. As illustrated in this diagram, when lots of balls are dropped in, the result is a heap in the middle. We cannot predict where a single ball will fall, but put enough balls in and we can be increasingly sure that we'll get a bell-shaped curve, simply because it is very unlikely that a ball will consistently move left, or consistently move right. One way to think of it is to count the possible paths to a point on the bottom. There is only one possible path to get all the way to the right, or all the way to the left, but lots of paths will take a ball to the middle. 
https://i.stack.imgur.com/nK7F8.jpg 
This means we don't need to suppose that a ball is remembering the previous falls. Each ball is independent, and the resulting curve (a binomial distribution) emerges spontaneously from it. This is one of many examples of how apparently orderly behaviour can emerge even when there are lots of disorderly things going on at the micro level. Another is radioactive decay: we cannot predict when one atom will decay, but with a large mass of them we can predict very precisely what proportion of them will decay in a given time interval. Another example arises from the kinetic theory of heat: we cannot predict how individual molecules move around, but put enough of them together and we can say all kinds of useful things about their thermodynamic properties. 

So the gambler's fallacy is a real fallacy, even though it is perennially tempting. My favourite way to test peoples' intuitions about it is to ask them this: suppose I decide to play the lottery every week and my preferred strategy for picking the numbers is to look up the numbers that won last week and choose those. You will find many people who think this is crazy because the chances of the same set of numbers winning two weeks running is tiny. But of course the probability of any set of numbers winning is all equal: it is not affected by the previous week's win. 
This is not strictly speaking a contradiction, unless you add some premisses or formal definitions (such as: an omnibenevolent being does not want evil to exist, an omnipotent being makes what he wishes be the case etc.). They are implicit in your reasoning but they can be discussed.

(Even with these premisses, it's only a contradiction, of course, if you assume that God exists, and as you must know the problem of evil is taken as an argument against the existence of God.)

There is no clear cut difference between a paradox and a contradiction: generally we call something a paradox when all the premises seem obvious, but lead to a contradiction. In this case the existence of God is not really obvious since not everyone believes in God and I think it is generally considered an argument by contradiction, not a paradox.

I don't know of any attempt to revise logic in this case but one would have to argue why alternative logics should be used in this case rather than in any other argument, and how it would solve this contradiction but not other contradictions that we would like to retain (since arguments by contradiction are widely used, for example in mathematics to show that there is no greater prime number). Generally, alternative logics are motivated by logical or mathematical problems, by paradoxes, or at least by contradictions that would apply to all facts in the world (for example the problem of change in time) not to a specific being. Denying the existence of this being or revising the premises seems a more natural move.

You can find more information here http://plato.stanford.edu/entries/evil/ http://plato.stanford.edu/entries/evil/
I'm not sure that I entirely agree with your analysis.

Firstly, and perhaps somewhat pedantically, let's note that although randomness has a precise definition in certain mathematical theories - e.g., information theory, where we define randomness as the inability to compress information - in a philosophical context randomness has no precise definition.  Furthermore, it is far from clear that randomness exists in reality.  For example, there are deterministic interpretations of quantum theory.  So let's stick to unpredictability.

In practice, I do not believe that any unevenness in the coins composition - i.e., the coin having anything other than the ideal centre of gravity - would have any real effect on the predictability of the outcome of an individual toss or a sequence of tosses. This is because other factors, such as the force of the toss and the binary nature of the outcome, would overwhelm any bias attributable to unevenness.  The outcome would be completely determined by the original orientation of the coin, the net initial forces exerted, and the characteristics of the landing surface.  For any unevenness to play a role in determining the outcome, we would require a near-astronomical number of rotations of the coin, which, of course, is not the case in practice.

Thus, I would argue that achieving an unpredictable outcome for a single toss is possible.  If the coin's unevenness does not influence the outcome of an individual toss, it cannot influence the outcome of a sequence of tosses.  Any bias that may manifest itself must be bias in those factors that determine the outcome. 
It seems to me that the "tricky" word here is knowledge.

We have that, for http://plato.stanford.edu/entries/aristotle-logic/#AriSci Aristotle :


  The subject of the Posterior Analytics is epistêmê. This is one of several Greek words that can reasonably be translated “knowledge”, but Aristotle is concerned only with knowledge of a certain type (as will be explained below). There is a long tradition of translating epistêmê in this technical sense as science, and I shall follow that tradition here. However, readers should not be misled by the use of that word. In particular, Aristotle’s theory of science cannot be considered a counterpart to modern philosophy of science, at least not without substantial qualifications.
  
  We have (scientific) knowledge, according to Aristotle, when we know:
  
  
    the cause why the thing is, that it is the cause of this, and that this cannot be otherwise. (Posterior Analytics,I.2)
  
  
  This implies two strong conditions on what can be the object of scientific knowledge:
  
  
    i.Only what is necessarily the case can be known scientifically
    
    ii.Scientific knowledge is knowledge of causes
  
  
  [...] Aristotle clearly thinks that science is knowledge of causes and that in a demonstration, knowledge of the premises is what brings about knowledge of the conclusion.


If we equate knowledge with epistêmê, we have that it is hard to speak of "knowledge of causes" in the case of a "bare particular" (like a pebble).



Of course, a more "correct" answer has to take care of http://plato.stanford.edu/entries/al-ghazali/ Al-Ghazali use of "knowledge" and of his interpretation of Aristotle's theories :


  Al-Ghazâlî describes the Incoherence of the Philosophers (Tahâfut al-falâsifa) as a “refutation” of the philosophical movement (Ghazâlî 1959a, 18 = 2000b, 61), and this has contributed to the erroneous assumption that he opposed Aristotelianism and rejected its teachings. His response to falsafa [the Arabic tradition of Aristotelian philosophy, from Greek: philosophía] was far more complex and allowed him to adopt many of its teachings. The falâsifa are convinced, al-Ghazâlî complains at the beginning of the Incoherence, that their way of knowing by “demonstrative proof” (burhân) is superior to theological knowledge drawn from revelation and its rational interpretation. 

Causality is one pattern. You could say that the tiger example of @SwamiVishwananda in your comments states that humans more often are abductive (thinking of a rule intuitively out if a single event that usually is more often right than wrong or where the wrongness is catastrophical, testing it afterwards by the experience of regularities) rather than inductive (having regularities over at least some events and tying these into a rule). Just because it is evolutionary stable to do so.

Causation simply is a rule that is not positively provable, so that the abductive > inductive principle holds as long as there is not enough data (regularities) in form of knowledge underlying. The problem where fallacies occur regarding probability at least in this interpretation lies between abduction and induction, because we can err there and do it more often than in inductive claims that have at least some evidence already. Still, abduction is a very powerful tool and perhaps the very source of Kuhn's revolutionary science.

For more on this topic and the reason why pragmatism evolved out of these thoughts can be read in the works of Charles Sanders Peirce.

Another layer of problems and in my understanding the main source of fallacies is that because inductive rules tend to be fulfilled, but do not have to in cases of probabilities, because this is the very nature of probability, even logic including inductive claims fails, say "This coin was heads for 1000 times now, I know from induction that coins tend to fall on both sides equally often. So there has to be a tails soon.". In normal, deterministic circumstances it would be correct to infer an upcoming event from regularities experienced. Here, it is not.

Conclusion: For understanding probabilities neither abduction nor induction in a normal way works, but only a meta-inductive knowledge that includes the total and utter failure of induction in the one case of probability, which is the essence of this concept. So you have to understand this concept and in addition that the events are falling under this concept. That is quite much you have to know, more than in any other empirical experience. I do not know of a name for this, though.
This remains an open question in philosophy.  It might be possible to objectively evaluate art, but it's difficult to claim that any given attempt to do so has proven definitive.  There are hundreds of different aesthetic theories, and most of them are incompatible with each other to the point of disagreeing even on what counts as art.  A random selection of just a few of the most influential includes Aristotle's theory of tragedy as emotional catharsis, Kant's theory of the beautiful as embodying purposiveness without a purpose, and Danto's theory that art is whatever the artworld calls art.  Part of the problem is that most art theories don't age well --they don't predict or anticipate future innovations in art, and they often do a poor job judging newer or unfamiliar forms of art (as in your example of Adorno's dismissal of jazz).

Without any agreed-upon standard, we might be left with vague intuitions and/or firm convictions that one piece of art outdoes another, but we can't justify those in any universal sense.

It's worth noting that there are also any number of thinkers who claim that art is purely subjective, or that creating a standard of art is impossible or undesirable.  This has proven at least as hard to establish, however, perhaps because of the difficulty of proving a negative.  Furthermore, even some ardent proponents of artistic subjectivity have balked at the entailed conclusion that every piece of art is equal (that Bieber is as good as Beethoven, to borrow from your examples).
Pirsig and his adherents would disagree, but it seems to me that 'Quality' (I capitalize it, because it seems to me at least to be something very different from what we normally think of as quality) in Zen and the Art of Motorcycle Maintenance is not quite the same thing as 'Quality' in Lila (where static and dynamic Quality are discussed). In fact he seems to want to mean all three things at once—his usage in Zen, his usage in Lila, and everyday usage. Perhaps he can reconcile them somehow, but I don't see how.

So one answer to your question might be: Quality means anything you want it to mean, since Pirsig himself seems to have no clear meaning; in fact he stipulates that the word itself is undefinable. It's reasonable to assume that an undefinable word is literally meaningless.

But I think we can take it a little farther than that. It's been a while since I read Zen, but as I recall, his meaning there meant something like the interface or space between reality and our perception of reality. Why he associated that concept with the word "Quality" I've never been quite sure, except, as I said above, he seems to want to mean both that and the normal meaning of "quality," i.e. 'good stuff.'

His meaning in Lila, where he develops his notion of "the metaphysics of Quality" seems like a wholly different thing to me. There he seems to basically go back to our commonsense definition of 'quality,' and split it into two parts: Static Quality and dynamic Quality. I've always pictured it like a http://helix.gatech.edu/classes/me4182/2006S1/webs/Shortbus/deliverables/images/gearLatch.png ratcheting gear (I don't recall if this example is from the book or not). You pull on the lever, and it moves forward, but you can't push it back, because in pulling it forward you have advanced the ratchet. The pulling forward is dynamic Quality; the ratcheting mechanism is static Quality. In other words, dynamic Quality is the good things about change and dynamism, and static Quality is the good things about tradition and conservatism. 

So no, I would not say that Quality is the opposite of 'chaos and disorder,' as both chaos and stability are necessary to Quality.
I think you are confusing the target of "modesty" (as meant in the Latin term). The reference below (under "argumentum") gets it right I think -- "to reverence". I.e. it's an appeal to your modesty to accept something (to treat someone else as an authority). So yeah, a translation issue, but not of the type you are worried about I think.

https://en.wikipedia.org/wiki/List_of_Latin_phrases_%28full%29 https://en.wikipedia.org/wiki/List_of_Latin_phrases_%28full%29
In the Copenhagen interpretation of Quantum Mechanics the answer is no, not all random behavior is uncaused.  Stripping out the negatives: we know that some behavior is caused by other effects, but still truly random.

Schroedinger's equation and boundary conditions together constitute a cause, and the results are distributed in a way that is, at some level, truly random.  There is an aggregate trend toward a pattern if you have enough different particles involved.  But the behavior of an individual particle has only a distribution of possible responses.  Its choice among those will not show any pattern that points to a cause.

In a sense that is less tied to interpretation, we have Heisenberg's principle, which implies there is always some level of detail below which you will discern no pattern in any physical interaction.  So if you look closely enough, things will meet your definition of random.

And this is even true from a pre-quantum-theory point of view, although it requires a little dancing, including idealized calculations we know we can never do in practice.

Statistical mechanics requires that one should, in principle, always be able to extract the underlying distribution that explains all of the traceable causes in a system.  If you subtract that out, the remaining behavior should be random.

The only remaining patterns would be the basic statistical moments resulting from the number of independent agents involved.  That means that the behavior of an individual agent would be truly random, if a smallest part could be isolated.  Having explained all of its motion does not leave it with no motion, as that is a very distinct pattern, but with random motion.

Since we have traced all of the traceable causes, and we do have faith physical motion has causes, there must always be more causes than we can trace.

  It seems to me that people are disposed to accept that [i.e. loss of self and oneness with the world] without much issue — is that a fair impression?


Most of the people in the West (or I should specify in the US) I have met who subscribe to some form of Eastern mysticism seem to interpret "loss of self" as "loss of selfishness" and "loss of pride", not as a metaphysical loss of self. 

Similarly the feeling of oneness you mention that results from meditation is more of an acceptance of the world as it is, a willingness to "go with the flow", a loss of the distinction between good and bad and a letting go of anger, and an ability to no longer judge people, more so than a phenomenological "oneness" with their surroundings or some sort of ontological connection with the trees and the birds, etc.... 

As you mention further in your question, they are usually philosophical laymen/laywomen who don't really bother to study the full philosophical implications of whatever buddhist/hindu/sufi/kabalistic teaching they picked up in yoga class.   


  Why are people happy to let go of one (the Self) and not of the other (Free Will)?


As I mentioned above, the loss of self in question isn't a true metaphysical loss of self, and so it doesn't really scare them the way the loss of free will does. 

Also as mentioned above, many are philosophical laymen, and they don't investigate the full philosophical implications of the positions they adopt. Most "lay atheists" I know for example are happy to brandish their materialist/physicalist worldview until confronted with the fact that this implies that they have no selves and likely no free will either, at which point they either withdraw into paradox or start to have their "atheistic faith" shaken (Full disclosure, I am such a shaken atheist myself). 

The prospect of a true loss of self truly does scare people, and they are not willing to give it up so easily, that's probably why dualsim remains a popular position among otherwise atheistically and materialistically minded philosophers (Searle, Chalmers, Nagel, etc...). 

Daniel Dennett mentions in this https://www.youtube.com/watch?v=jDch5ElHzx8 interview, among other places, that the implied loss of free will is the main reason why people attribute so much importance to qualia and the hard problem of consciousness, despite what he thinks is the very thin ground on which qualia based defenses of dualism stand. 


  What is that which merits desert or bears moral responsibility, if all arises dependently?


I personally have always marveled at this central contradiction in Buddhism: If there is no self, then what entity exactly is losing or gaining karma points? And more importantly, what exactly is being copied over from one life to another in the cycle of reincarnation? 

Here I think lies a contradiction similar to the problem of evil in Abrahamic religions. The answers won't be pretty, but maybe we might find something in approaches to solving the https://en.wikipedia.org/wiki/Ship_of_Theseus ship of theseus paradox, or maybe even borrow from the ideas of http://plato.stanford.edu/entries/structural-realism/ structural realism in philosophy of science. 


  But what is a non-compatibilist Free Will without a Self?
  And what is a non-compatibilist Free Will in a reality of dependent arising?
  What is that which has non-compatibilist Free Will, if the Self is an illusion?


As I mentioned in the comments, there are some good answers in my previous https://philosophy.stackexchange.com/questions/24251/how-can-a-stream-of-thoughts-and-perceptions-have-freewill post. James, Kane, and somehow Kant (I've yet to completely comprehend Kant's approach, or if Mozibur's mention of Kant is relevant at all, but the possibility is intriguing), all provide possible approaches to this question. 

In the months since I posted that question, my thinking has evolved on the question. Here a couple of comments: 


For a materialist who also believes in non-compatibilist free will, the question can get turned around: To "what is a non-compatibilist Free Will without a Self or in a reality of dependent arising?" they can answer that you have the order wrong: The self is the free will that binds the thoughts and perceptions together into an illusion of consciousness. A sort of "self-of-the-gaps" that lives in, or actually is, the space between the microscopic determinism of neural processes and the macroscopic indeterminism of conscious agents.    
Emergentism: In the Dennett interview I mentioned above, despite himself being a compatibilist, he provides an interesting avenue for a non-compatibilist materialist free will as an emergent property, the way color is an emergent property of light waves and particles none of which have the property of color themselves. He also mentions Buddhism somewhere in passing, but you will have to listen to the whole interview, since I can't remember exactly where he mentions it.   

One can find some plausible examples in natural language where 'or' and 'unless' are intuitively the same. For example, "hand over your wallet or I'll shoot you" is the same as "unless you hand over your wallet, I'll shoot you". But there are differences too: for example, 'or' is commutative: A or B is the same as B or A, but 'unless' is not generally so in natural language. One can hardly say that the two examples given earlier are equivalent to "unless I shoot you, you'll hand over your wallet". 

The reason seems to be that 'unless' is a kind of conditional, i.e. it is one of many words, including if, should, provided, barring, when, had, would, else, otherwise, suppose, assume, allow, imagine, etc. that are used to express conditional thoughts. Conditionals in natural language don't behave the way the logic textbooks tell you. They are not truth functions but pragmatic devices with various purposes including stating a rule, a hypothesis, an inference, an evidential claim, a proviso, a precondition, a supposition, an assumption, a disposition, an explanation, a negotiation, a promise, a threat, a plan, a restriction, a requirement, an offer, etc.  
You can do something like that if you are willing to give up classical logic. Paraconsistent logics can withstand honest contradictions (sentences that are both true and false), called dialetheias, without collapsing into triviality, see http://plato.stanford.edu/entries/dialetheism/#3.3 Dialetheism. Sentences like "God can create a stone he can not lift, and then he can lift it" are somewhat similar in nature to the Liar sentences like "I am not true" , which are considered leading candidates for dialetheias. In a paraconsistent logic you can split sentences into pure truths, pure falsehoods and dialetheias, and the first would presumably cover the "logically possible things" that God can do, while the third would cover the "logically impossible things". 

It is worth pointing out that "strong omnipotence" is not a majority position among Catholic theologians, the official teaching of the Church follows Aquinas in asserting that God is bound by the laws of (classical) logic.
However, not being susceptible to them does not put God beyond "any form of reason", or make him "unknowable". He may well be humanly unknowable due to our many limitations, but it is not because of inconsistency alone. Mathematicians use paraconsistent logics to reason about http://plato.stanford.edu/entries/mathematics-inconsistent/ inconsistent arithmetic and analysis for example, and know quite a bit of interesting results about them. 

Plantinga's free will defense assumes quite a bit more than logical consistency, namely Molinist understanding of free will and God's foreknowledge, which is again a minority position among Catholic theologians. In particular, the argument explicitly requires that creatures act identically in identical circumstances, and that foreknowledge of their choices be part of God's "middle knowledge". But as http://www.anthonyflood.com/feltimpossibleworlds.htm Felt writes in Impossible Worlds this posits a "determinate outcome of a free agent’s acting while excluding the acting", and thus creates "metaphysically inconsistent fictions which cannot form an object of anyone’s knowledge, not even God’s". But without them Plantinga's "transworld depravity" simply becomes meaningless, and without limitations imposed on God by classical logic it can not do its work of theodicy. 

As for splitting off the "impossible" part of God, I don't think it can work for theodicy either. The whole point of it is presumably to justify God to humans, if it can not do so in a comprehensible way it becomes pointless, same as it does if it can not justify all of God. If the consistent part could not exclude evil due to consistency, why didn't the inconsistent part do it? If this is beyond our comprehension then why bother with theodicy in the first place.
Special pleading is when something is said to be an exception to a general rule, while it is not justified why that thing is an exception. 

So, in order to not commit special pleading, you should why that thing does not follow the general rule. If "God" is the exception, that's a little difficult, because it is often ill-defined or at least something we don't know a lot about - hence there is not much to go on to show why it can be an exception. 

Even if one could convincingly show that Y is wrong [in at least one case], that doesn't mean X has to be the exception - why not P or Q or 37? 

I.e., even if you could show that an infinite regress is impossible, that doesn't mean that some concept of God is the uncaused cause - why God and not something else? Aquinas sidesteps this problem (a) by saying his ways are just ways to get closer to God and (b) by assuming it is in God's nature that He is uncaused, thereby kind of begging the question. 
Officially, in well written English, you can follow the dependent clause construction marked by the commas and the succession of the pronouns.


  
  If A, [then] if B, [then] C
  


is always going to mean 


  
  A → (B → C).
  


Hereafter, '{Coffee Store}' means '{Coffee Store} is open.' So 'Starbucks' means 'Starbucks is open', and 'not Starbucks' means 'Starbucks is closed.' For example:


  
  If you want coffee, then if  Starbucks is closed, I suggest we make it ourselves.
  


Can be encoded only as 


  
  Coffee ⟹ (not Starbucks ⟹ Make_Coffee)
  


And never with the other nesting order.

The less likely 


  
  (A → B) → C
  


would have to be written


  
  If1  if2  A,  [then1] B;  [then2] C.
  


or


  
  If1  B  if2  A,  then C.
  


In 7, note: if2 is the '←' Logical Connective, with no comma. 

You have to close clauses in order.  Put short: like parentheses, references in most Latinate grammars are 'last-in, first-out'.

"Then" has a referent, and officially, references must bind to the closest available potential candidate, that is the rightmost "if" that is not already spoken for.  So in 6, then1 must go with if2 and  then2 with if1.

When the "then" is merely implied, the comma that closes the dependent clause must close the clause most recently opened that has not already been closed (by another comma or reference).  Same rule, different official reason.  So you can just read it as if the implied 'then' were inserted.

When each "if" does not come with a comma or a "then" of its own, the comma or pronoun must split the one that has a clause, not the one that is a connective.  Connective conditions like "B whenever A" have to bind most tightly.

Of course, in practice one is seldom going to see the two 'ifs' in a row.  One or the other is going to be since/when/while, or some equivalent.


  Since when Hyperion is closed, Starbucks is also closed, we will have to make our own coffee.


or the equivalent


  If Starbucks is closed whenever Hyperion is, then we will have to make our own coffee.


unwinds as 


  (not Starbucks ⟹ not Hyperion) ⟹ Make_Coffee


And never the other order.  The 'when' clause here must be closed before the preceding 'since' and connectives bind tighter than clauses.
The problem of evaluating the truth of a proposition (including whether it leads to a contradiction or not) from a computational point of view amounts to evaluating https://en.wikipedia.org/wiki/Boolean_expression the boolean expression corresponding to that proposition. 

Determining whether your proposition F would lead to a contradiction or not is the same as being able to determining whether the corresponding boolean expression is satisfiable or not. At the present time there is no known method for evaluating the truth of a general boolean expression without actually calculating the expression itself. This is known as https://en.wikipedia.org/wiki/Boolean_satisfiability_problem the boolean satisfiability problem, and it is conjectured that there is no efficient algorithm for evaluating whether it has a truth value or not. The only guaranteed way of determining whether it is satisfiable or not, and determining the corresponding variable assignment, is to evaluate all possible combinations of the boolean expression.

This fact that there is no known general efficient solution, and the conjecture that the can't be one, is known as the https://en.wikipedia.org/wiki/P_versus_NP_problem P vs NP problem. 

Here efficient means that it can be solved in (deterministic) https://en.wikipedia.org/wiki/Time_complexity#Polynomial_time polynomial time.
Inefficient means that the problem is solvable in https://en.wikipedia.org/wiki/Non-deterministic_Turing_machine#Bounded_non-determinism Non-deterministic polynomial time (The "NP" in NP-complete). For practical purposes this means the only way of finding a solution is to evaluate every possible input combination, which can take up to an https://en.wikipedia.org/wiki/Time_complexity#Exponential_time exponential amount of time.   

The P vs NP problem first gained importance after Cook and Levin independently proved the https://en.wikipedia.org/wiki/Cook%E2%80%93Levin_theorem NP-completness theorem in the 70s. In particular Cook was working on automated theorem proving procedures, and it was in this context that he ended up with his result regarding boolean satisfiability. 

There is a remote possibility that P=NP and that there is such an efficient procedure, http://www.scottaaronson.com/blog/?p=122 but it is considered highly unlikely, and if it were true, the consequence would be significant for our understanding of computation and science in general. 


  "If P = NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in "creative leaps," no fundamental gap between solving a problem and recognizing the solution once it's found." — Scott Aaronson, MIT


To summarize, the answer to your overall question "Before starting the Reductio Ad Absurdum, how can you guess or divine that F causes the contradiction?": There is no known method for doing so beforehand. Being able to do so implies an efficient method for solving boolean satisfiability, and it is conjectured (but not yet proven conclusively) that an efficient method is impossible.     
From the logical perspective you take at the end, all these forms fall under the rubric like


  [All/Some/No] X but Y, are Z.


which becomes


  [All/Some/No] X that is not Y, is Z.


Then X can be omitted and filled in from the context.

If I say


  None but Y, are Z


I mean


  No X but Y, are Z


where X is everything, resulting in the interpretation you already reached


  All Z are Y


But if I say


  All but Y, are Z


And I take that as 


  All X but Y, are Z


And I take X to be 'everything', so we get 


  All of everything that is not Y is Z


The 'everything' does not cancel out in the math, as it does in the other cases.  But I cannot reduce that to the right form.  We cannot quantify over everything in a positive way by reference to a property.  Instead, we have to capture the main point in one statement,


  No Y is Z


And the reference to everything indirectly in another, in the form of 'everything else'


  All non-Y are Z.

To understand this, it helps to be clear about the terminology. The term "chances" is usually used to mean a physical interpretation of probabilities. The idea is that a symmetrical, unbiased coin has a physical chance of landing heads with a probability of 0.5, or that an urn containing 1 million red marbles, 1 million blue and 1 million green, has a physical probability that a marble drawn at random will have a probability of 1/3 of being red. The first thing to note here is that this is only one way of understanding probabilities: on an epistemic account there are no chances, and what we call probabilities are statements about how much information we possess. I'll leave that thought to one side for a moment and proceed with chances, since the author of the article you reference believes in them.

The important question is, if I don't have any direct access to the physical chances, i.e. I can't test the symmetry of the coin or count all the marbles in the urn, and the only information I have is gleaned from performing sampling experiments and observing the frequencies in the sample, what inferential relationship is there between the physical chances and the observed frequencies of the samples? What Bernoulli showed is that one can draw an inference from the chances to the observed frequencies: this is the law of large numbers, and it implies that if you keep tossing the coin, the long run frequency of the sample result will converge to the physical chance. Or if you keep drawing marbles from the urn, the long run frequency of your sample will converge to the actual proportions of the marbles in the urn. Note that this is a convergence result only: it doesn't mean that your sample frequency must agree with the chances, only that it will tend towards doing so in the long run. 

What Bernoulli doesn't tell you is how to perform the inverse inference from information about the observed frequencies of the sample to information about the chances. This is a very common problem in real life: often we want to know something about a system or a population, perhaps because we want to make future predictions about it, but we only have access to samples of data. Solving this problem is much more problematic and there is no perfect way to do it, or even a general consensus about how to go about it. Fisher held that the best approach is to make hypotheses about the chances, design experiments to test them, and reject the hypotheses if the test results are significant. Neyman and Pearson used the approach of defining type 1 and type 2 errors and of approaching the values of chances in terms of false positive and false negative error rates. Bayesians use Bayes' rule by specifying prior probability distributions and using the data to update those distributions. Likelihoodists take two rival hypotheses and calculate a likelihood ratio that allows one to say which hypothesis is confirmed relative to the other. 
The two expressions :


  
  "x is a Philosopher" 
  


and 


  
  "for all x, x is a Philosopher" 
  


have not the same "meaning".

9 is false if we interpret it in the "universe" of all men.

For 8, we have to note that a free variable acts as a "pronoun" of natural language, i.e. a FV denotes something only "in context".

Thus, 8 is true if we interpret the variable x as denoting Socrates, while it is false if we interpret the variable x as denoting Napoleon.



The crucial notion for the interpretation of quantifiers and free variables is that of domain (or universe).

The same expression can be true in one domain and false in another one.
There are rules for moving all the quantifiers upfront, in order to rewrite a formula in an equivalent https://en.wikipedia.org/wiki/Prenex_normal_form Prenex Normal Form.

The rules are based on several provable equivalences; in particular :


  ϕ → ∀x ψ is equivalent to : ∀x (ϕ → ψ)


provided that :


  the quantified variable x is not free in ϕ. 

We can use a step-by-step approach.

We have already learned that : "Every human is mortal" is formalized as :


  (x) ( Hx ⊃ Mx ).


Now conisder [1.] : "Any heavyweight can defeat any lightweight" and firstly "approximate" it as : "Any heavyweight is a defeater".

This statement has the same logical form of the previous example, i.e.:


  (x) ( Hx ⊃ Defx ).


Now consider : "x is a defeater of any lightweight". We can rewrite it as "Any lightweight is a defeated by x",i.e.:


  (y) ( Ly ⊃ Dxy ).


Now you have only to replace "x is a defeater" [i.e. Defx] with "x is a defeater of any lightweight" [i.e. (y) ( Ly ⊃ Dxy )] to get :


  (x) ( Hx ⊃ (y) ( Ly ⊃ Dxy ) ).

Px is not equivalent to (x) Px.

If we know that "all (the men in the universe) are Philosopher" is true, we can certainly infer that "it is a Philosopher" is true, whoever the pronoun "it" denotes.

But if we know that "it is a Philosopher" is true, when e.g. we are "pointing at" Socrates, we are not at all entitled to infer that "all (the men in the universe) are Philosopher".

This fact is reflected into Hurley's proof system in the proviso of the UG rule
(see p 483, A Concise Introduction to Logic (12 Ed, 2014) by Patrick Hurley
):


  Restriction: UG must not be used within the scope of an indented sequence if the instantial variable y is free in the first line of that sequence.




Note

When we "evaluate" the truth value of a formula, like Px ≡ (x) Px, of course the domain of the interpretation must be the same for all the variables (free and bound).
"Man is born free. Therefore, man has the right to be free."

First, we might ask Man's mother about that. Philosophy as well as religion tends to neglect the role of Mrs. Man in all this splendid a priori freedom. Hobbes is the only philosopher I happen to know of who actually refers in anecdote to his mother, his difficult birth, and the consequences for his philosophy, one in which "rights" are conspicuously absent in "nature."

The point being that observations of "nature" itself give absolutely no evidence of such "rights." Humans are quite obviously social and interdependent, and moral rules entail the forfeiture of conflicting assertions of "right." Marx referred mockingly to the a priori British assumption of individual rights as "Robinsonism,"after Robinson Crusoe.      

In his stricter development of Locke's empiricism, Hume's own observations of "natural" perceptions led him to state pithily that: "You can't get an ought from an is." In other words, facts simply do not contain moral values, as assumed in "rights," and for many years this "fact-value" dichotomy hobbled the atomistic Anglo-American stance, as opposed to the more socially inclined Continental traditions. 

So, yes, one can argue that the inference of "rights" from "nature" is not empirically valid, and in logic would appear not as a fallacy per se, but as a dubious premise. But "nature" itself is another rather dubious premise, and the question of "rights" is really quite enormous, with many philosophical responses. Much of Kant's philosophy was precisely an attempt to rescue moral premises from Humean skepticism by means of reason.This was revived in Rawls' pragmatic, highly influential attack on the traditional "fact-value" divide.       
I don't have Hurley's book, so I can only proceed from what you've quoted, but I take him to be saying that it is the quantity of the occurrences of the methods that is most significant, not the type. He is not saying that one type of method is intrinsically better than the others, only that the more occurrences you have of any the better. Roughly speaking, this is like saying the more data you have, the more confidence you can have in the inferences you draw from it.

Having said that, such a claim is fraught with difficulties. Merely having more occurrences, or data, is not in itself a guarantee of anything. To make plausible inferences from data one must attend to all kinds of considerations about how the data is gathered, the quality of the data, whether the data sources are independent, what possible biases might be present, what confounding variables might exist, etc. 

In particular, the sentence


  the strength of the conclusion is proportional to the number of occurrences that are included 


is far too strong. No such proportionality can be justified. At most one might claim that an increase in the number of occurrences has a tendency to increase the strength of the conclusion. 
To answer the specific question first, take this analogy.  How does an apple own its 'red'?  It obviously doesn't, in some sense.  All apples are black in the dark.  No object has exchange value outside the context of a specific market.  Yet in different contexts, beside bananas, say, rather than pomegranates, some apples are more red, and some are less red.  And all commodities get prices through competitive comparison.  The ephemeral quality is something Marx is trying to mark out as illusion, so we will question it.  But is an apply any less red, once you realize that it is the context and the perceiver who declare it red?

The basic summary answer for the overall question is 'that it exists' which all other forms of economics find a problematic assertion.

A fetish is an attribute of the consumer that imputes extra value to something when and only when it takes a specific form or is represented in a specific way.

To go for the obvious sexual analogy, a sexual fetish is something that imputes extra attractiveness to a given trait (often so much that without the additional trait sex is compromised or seen as valueless).

There are obviously things that are sexually fetishized, in a way unrelated to their evolutionary usefulness, such as uniforms, amputations, shaved heads or other very strikingly non-sexual aspects of a person that must logically add sexual value only because of psychological projections.

There are other places where this is far less applicable as a notion.  Someone who attributes higher sexual value to those with certain body hair patterns, can be seen as having a fetish for them.  But there is an argument that body hair on a man simply is attractive, to different degrees, positive or negative, to anyone attracted to men as an aspect of secondary sexual traits that are just biological markers of genetic qualities.

Mainline economics puts price firmly in the second camp.  Price is something that objects acquire in a market, whether or not it correctly represents utility.  And having price can make something valuable to the market as a way of holding value.  Gold has very limited direct utility, but maintains its price.  (In fact when gold holds direct utility, as in electronics, it is sometimes subsidized for sale below market to remove its secondary value as a marker for price references.) 

Marx would claim that almost the entire value of gold is added by fetishism and that the utility of the gold is more real.  Then he (mistakenly in my interpretation) imputes the utility to its use-value: its cost and expected deployment in later costs.

(The most straightforward way to mock all attempts to tie use-value back to labor-value is that a link here implies the value of a good meal after it is digested should depend upon the work involved in cooking it, whereas all fertilizer is pretty much equal in utility.)

From that point of view, the market itself is simply a fetish-driven competition between addicts to the same fetish.  The real value of things inheres in its utility, or some objective balance of its different levels of utility to different individuals.

I think, in a direction parallel to Marshal McLuhan, that there is a middle path here.  The market is not just a mechanism, but also a 'medium', which is impressed with the standards of all the processes that affect it.  For example want the expensive goods not the cheap ones, sometimes because they are simply better, and sometimes because we are in the thrall of the market as a medium of indoctrination which teaches us to behave in certain ways.  

(This action of the market as medium is more obvious to me when we want the cheap ones even if the expensive ones really are very much better.  'Saving' money, especially on food, is a kind of entertainment provided by the market as a communication medium -- a sort of poor-woman's gambling.  We go to McDonald's because a real restaurant is presumed to be pretentious and wasteful.  Then we buy too much cheap food, eat it fast and over time we get insulin resistance.  In that way we objectively fail to use most of our food for either enjoyment or energy.)

But that does not mean that the whole thing is an illusion, or even most of it.
Hurley's use of the word "evidentiary" suggests that he is talking about real world hypotheses in this section of the text, so in order to get a feel for what Hurley is talking about here let's look at a real world example.

In the 1990's observations were made that undermined the accuracy of our Big Bang model of the universe. Firstly, it was observed that the rate at which the universe is expanding is accelerating. Secondly, it was observed that the rotational characteristics of galaxies are uniform.  This is not at all what the prevailing cosmological model predicted.

Cosmologists were faced with a choice.  They could make ad hoc modifications to the existing cosmological model or they could extend the existing model by introducing new auxiliary hypotheses in order to explain these unexpected observations.

The introduction of ad hoc modifications is not desirable for a number of reasons.  The existing model had been working in a satisfactory way up until then. Making ad hoc modifications may have unforeseen consequences leading to the need for further ad hoc modifications, and then more ad hoc modifications, etc..  This would undermine the desired simplicity of our scientific model and may also restrict its fruitfulness and accuracy. As the number of ad hoc modifications increases, you run the risk of ending up with a model that features an ad hoc modification to describe every observed feature rather than a model that predicts observed features.

Instead, cosmologists chose to add two new auxiliary hypotheses to the model, namely dark energy and cold dark matter.  This results in  simpler model than a model based on ad hoc modifications.  It maintains its fruitfulness and accuracy. Also, importantly it is a more elegant solution to the problem.

(Also, tut-tut for not taking a break.)
If you take knowledge that gets things done as one form, and knowledge that captures data as a second, and your third entry is messy, emotional and mysterious, to my mind, you are setting up a trip around the one of the three elemental configurations that maps directly onto Lacan's four discourses, which we can map further onto the powers of the sphinx.  The point is not to be abstruse, but to have any model of knowledge that actually got used and included similar divisions.

There is a point in noting the greater similarity to part of a set of four, instead of looking at this as a Fixed/Mutable/Cardinal configuration (equivalently Real/Ideal/Symbolic), other than the difficulty of fitting the latter.  I think, given your examples, that you are vaulting over a more obvious form of knowledge that includes aesthetic decision-making, the ways we 'read' people or situations (even if these are just recursive 'theory of mind' predictions) and the selecting out of which experiences constitute stories with significance.  Quale, familiarity, suffering and numinousness, etc. are on a layer below that after individual rational psychology, intersubjective 'chaos' and the irreducibilities of mutual social manipulations have been removed.

So I might suggest that this third/fourth form of knowledge is the hysterical factor to a world that is first analyzed in terms of effects and contents, (and then maybe philologically/deconstructively/aesthetically.)  Since 'hysterical' is provocative, I want a synonym.  I am going to use both words, but alternately.  Hopefully one will be a foil against the annoying nature of the other.

If the Master discourse is Will and the University discourse is Knowledge, the Analyst discourse is clearly Daring, and the Hysterical discourse is left to be the enigmatic Silence.

The Hysteric's discourse does what is necessary for knowledge that cannot be captured or used to be embodied, and not lost.  Silence is a posture that allows the universe to be solid, with all of the movement introduced by the three active principles grounded out so that the three other sorts of power have a stable position from which to arise, and back to which to return.

So what use does science make of Silence?  I think that one form of Silence is embodied in the structure of emergent principles that allows for the separation of disciplines.  By solidifying quantum motion, chemistry can have a domain of study.  Orbitals are not a lie, but they are surely less than real.  This knowledge that what goes on down there should only be considered when the normal way of looking at things fails is a proper and productive Hysterical repression.

The layering also allows each different science to have its own paradigm and its own character.  Like the way someone is your friend only because you know them in a given way, you can like Chemistry and dislike Physics even though Chemistry is Physics.  So you can look at Silence as the thing that holds a paradigm in place.  Paradigmatic function is about questions that one does not ask, because we have decided, quite properly, but kind of oddly, not to ask those for a while, while pretending to keep an open mind.

Your notion of qualia is also intimately tied up, in my mind, with the way in which emergent properties like 'temperature' are very real, but don't exist independently.  Temperature has in common with redness that it represents a statistical convention that suppresses detail to good effect.

Looking at how these principles are part of the process of science might indicate how science itself should incorporate them into its explanations.

These are aspects of the process of scientific decision-making itself, which requires its own separate model so that it can bounce back and forth against the theories of what has been observed and predicted.

If you do not have a theory of observation its requirements and its limitations, even after factoring out biases due to social and intellectual factors, your model of the observed phenomena will have systematic flaws that cannot be removed by any process.
Well, you can probably get the best answer for your purposes simply by googling. There is an entire branch of philosophy called "philosophy of law," which runs from Plato to Grotius and Hobbes to Dworkin and Rawls. Many texts and anthologies are devoted to the subject 

It is closely related to philosophy of political science and ethics, as you note. I would not say it is related to "logic" per se, especially not modern logic, but more to argumentation and rhetoric, as developed by the Sophists. The philosophy of religion is also somewhat related, in that most monotheistic religions have foundational "law givers," such as Moses or Mohammed or, to stretch the point, "We the People."

As an aside, I would note that philosophy itself could be described historically as a "branch" of law, or at least as a descendent of the forms of competitive, public argumentation developed earlier in the law courts of the Greek polis and other "political" assemblies of government. Socrates, like Jesus, came to his finale in a law court. 

And I would add that in terms of crucial shifts in the modern age, both Kant and Hegel are very important here for developing the modern complexities of self-imposed human "laws" and the discovery of human "freedom." The literature is vast, so any number of overview texts might be a good starting point.   
They would not in so far as idealists are not realists. The no miracle argument is an argument for realism: it says that realism is the only (or best) explanation, so the argument works against any anti-realist position, including idealism. The idealist and the empiricist are in the same position and can use the same arguments to respond, such as the one you mentioned.

Van Fraassen proposed that the success of scientific theories can be explained by the fact that our theories are in fierce competition and only the best survive. However the proposal was criticized because this kind of explanation does not answer the right kind of question. For example when asking "how do birds fly?" you can answer with an evolutionary argument (they were in competition etc.) but that's not the right explanation: what we'd want is, for example, a mechanistic explanation (their wings are such and such...). Similarly the explanation required for realism should sat what makes theories so successful in their prediction, not how we came to conceive such successful theories.
The circularity objection you are raising was a popular objection against empiricism in classical epistemology, Husserl became famous for using it against "psychologism", empiricist theories of logic: since empirical knowledge is formed through logical reasoning how can it be used to ground the reasoning that forms it?  

We are lucky because Hume had an influential philosophical reincarnation in the 20th century, who shared his empiricist intuitions and picked up his skeptical arguments just where he left them off, Quine. "What then of the doctrinal side, the justification of our knowledge of truths about nature?" he asks in http://joelvelasco.net/teaching/3330/Quine-Epistemology-Naturalized.pdf Epistemology Naturalized, "On the doctrinal side, I do not see that we are farther along today than where Hume left us. The Humean predicament is
the human predicament". The circularity objection had its force when Kant could point to logic, mathematics and physics as established sciences with "apodictic certainty" of synthetic a priori at their basis (Kant even opined that Hume forgot about mathematics, or his "good sense" would have abated his skepticism, Hume did not). Or when Husserl could point to epoche of pure consciousness as the ultimate ground for all sciences, or even when logical positivists could point to "atomic facts" to the same end. But not after all of that fell by the wayside. 

Self-justification is undesirable only in the face of better options, but all pretenders to the latter role proved to be ephemeral. Empirical science is not justified on a "proper" basis? What is? The circularity objection remained valid, but it became irrelevant for empiricists. We discussed this some more in https://philosophy.stackexchange.com/questions/28470/how-does-quine-answer-the-metaphysicians-claim-that-scientism-is-self-refuting/28473#28473 How does Quine answer the metaphysician's charge that scientism is self-refuting?
Of course, Hume did not know all that, he did not yet have to deal with Kant's creative reimagining of justification, and its various derivatives. But he was already unimpressed even by the supposed certainty of justification in mathematics, and rightly surmised that the rest can not fare any better. "It was sad for epistemologists, Hume and others, to have to acquiesce in the impossibility of strictly deriving the science of the external world from sensory evidence". The Humean predicament is the human predicament.

And so came Quine's Humean response:  "But why all this creative reconstruction, all this make believe? The stimulation of his sensory receptors is all the evidence anybody has to go on, utimately, in arriving at his picture of the world, why not just see how this construction really proceeds? Why not settle for psychology? Such a surrender of the epistemological burden to psychology is a move that was disallowed in earlier times as circular reasoning. If the epistemologist's goal is to validate empirical science he defeats his purpose by using psychology or other empirical science in the validation. However, such scruples against circularity have little point once we have stopped dreaming about deducing science from observations. If we are to simply understand the link between observation and science we are well advised to use any available information, including that provided by the very science whose link with observation we are seeking to understand".  
These interactions can be better modeled with Drama Theory, which covers a set of individuals playing multiple games in a row, with the ability to change their decision making process between game theory games.  This better models human interactions.

If you have drama theory, you can explore more complicated interactions, such as a subset of drama approaches known as tournament theory, where it is believed that people competing for a large share of the pie yields better results than sharing the pie.  Tournament theory is one tool which has been used to describe why executive pay is so high: its not because the executive deserves it, but rather because it acts as an incentive for the subordinates to strive to one day be paid highly.

Also, consider a secondary issue which is not mentioned in your example.  The dealership is not simply in the business of selling as many cars in the short term as possible.  It also needs to ensure it has the best salespeople in the future.  Determining who is a good sales person is not an easy task.  In fact, it can be frighteningly difficult to build a metric for determining who is a good employee in general, and sales is even worse than the average case.  The tournament structure has the added benefit of assisting management in identifying who fits their mold, and who doesn't.  If this benefit is sufficient, it may overwhelm the management's ability to sell a few more cars in the short term by having everyone work together.
Words are often overloaded with meaning in philosophy.  A "gift" in philosophy may be a far more pure concept than a "gift" given in modern culture.  They could have given it a new name (I'm partial to "a gift freely given," myself, but that's a longer phrasing), but they chose to call the concept they were exploring "gift" to associate it just enough with cultural gift giving to help give the idea lift.

The idea behind such a gift is that if you have conditions, it is no longer considered a gift, but rather a transaction.  For the most extreme examples, we can look at the mafia, where a gift from the mafia Don rarely comes without strings attached.  Often, it looks like the Don isn't giving anything, but rather taking under the guise of giving!

A less extreme example is a gift given in exchange for a favor.  "I'll help you move, but you owe me a favor."  It's not specified what that favor is, but it is understood that the transaction is "move your stuff" in exchange for "an obligation to return the favor later."

You can continue this way of thinking, approaching less and less of a transaction, as we go through the various shades of gifts in one's culture.  The philosophical "gift" mentioned here is the limit of that approach.

So as for your questions:

I believe it is fair to say a something given with an expectation of repayment, but for which one does not analyze what the repayment may look like or when could qualify as a gift, if one truly does not analyze it.  If you feel the other person has every right to not repay you, it may qualify as a true gift because you have accepted that a purely one sided transaction may occur, and that transaction is "good enough."  Let's say I give you $100, and say "pay me back when you can."  If I have some expectation that you will pay me back, I just don't know when, and I feel slighted if you never pay me back, then it is not a gift by this definition.  On the other hand, if we are close friends, you are down on your luck, and I think it's entirely reasonable that you may never again have $100 in your pocket, or if you're about to leave my life forever (perhaps a perceived permanent move to a foreign country), that $100 may be a gift, in that I never actually expect it to be given back again.

In fact, I found a fascinating ritual from India which pushes this to the limit.  One of my friends recently got married and had invited a friend whose family still had strong ties to Indian culture.  In addition to the traditional wedding gifts, he explicitly gave a single dollar bill.  He explained that this was not a gift, it was a loan.  The idea was that his family and my friend's newly married family must now stay close together, or else they'd never be able to repay the loan.

It does appear that this "loan," despite its name is a gift.  It's quite clear you are never expected to actually repay the loan.  In fact, I think repaying the loan may be a grave insult!  And its also clear that a mere $1 is not going to really have any influence on keeping the family together, so it's clear its not actually buying any closeness.  Thus, this loan is truly a gift: there's no expectation of anything in return, though there is an encouragement associated with the act of giving to keep the families close together.

The second question is the opposite half of the first concept.  If one has "earned" a gift, that implies a transaction in the opposite direction.  It implies the gift giver has come under an obligation to give a gift.  Thus, the transaction is the resolution of this obligation in exchange for the gift.

And yes, this sort of gift is defined by the actions and thoughts of the giver only.  If I truly "give" a McDonalds meal to a homeless man on the street who has a sign that says "hungry," and he chooses to stomp it to bits and flip me off, insulted that I didn't give him a dollar, that is his right.  The gift has been given.  This is also part of why an obligation cannot be part of a gift in this respect.  If I gave you a dog, and you didn't want it, you might not take care of the dog.  I could not come back and say "I gave you the dog, so it was your job to take care of it," because that means the "gift" came with obligations.

I found another fascinating story along these lines from Siam, now known as Thailand.  In their culture, White Elephants are a symbol of peace and prosperity within the kingdom.  However, they have a dark side.  If a king did not like the actions of a courtier in their court, they may "gift" a White Elephant to them.  This "gift" was far too much of an honor to possibly refuse it, but it came with an obligation to take care of it (making it not qualify as a gift by Derrida's standards).  The cost of maintaining a White Elephant was astonishing, because they were expected to keep this elephant in a life of luxury, being such a valuable gift from the king.  A courtier could literally be bankrupted by this "gift."
It is natural to use it, both aim at the problem of vagueness in predicates. The http://plato.stanford.edu/entries/sorites-paradox/ Sorites paradox is as ancient as the Liar, and much more pervasive, as a list of nicknames suggests: paradox of the heap, paradox of the beard,  https://en.wikipedia.org/wiki/Continuum_fallacy continuum fallacy, line drawing fallacy, bald man fallacy, etc. One grain is not a heap, adding a grain to not a heap does not make it a heap, therefore no number of grains makes a heap. More generally, if there is an unbroken chain of intermediaries between x and y then the argument concludes that x and y are not essentially different, be it handful and heap, black and white, romance and porn, or art and kitsch. Or contrapositively, if they are essentially different then there must be a bright line separating them. Soritic reasoning is considered fallacious, but telling what exactly is fallacious in it proved to be as intractable as the Liar. Many http://plato.stanford.edu/entries/sorites-paradox/#3.3 responses revise classical logic to assign neither true nor false to borderline cases, or both. https://en.wikipedia.org/wiki/I_know_it_when_I_see_it "I will know it when I see it" is a practical response on a par with Diogenes walking to "refute" Zeno, or http://www.jstor.org/stable/2709600 Johnson kicking a stone to "refute" Berkeley.

Family resemblance (James suggested it for religions already back in 1902, but without the name) is a way to go beyond philosophical stone kicking. One implementation was suggested by Searle's extension of Russell in 1950s. Scope of a predicate is decided by a cluster of descriptions, not a single essence, just a critical mass of them is enough to meet it. But this formalistic solution is not in the spirit of late Wittgenstein, more so is http://www.jstor.org/stable/25668224 Mary Hesse's non-Aristotelian theory of universals used to explain metaphoric shifts in meaning:"without assuming that there is any universal "P-ness"... we assume that in an FR class (for example, "the Churchill nose"), the members of all pairs of objects in the class resemble each other in some respects relevant to P, and that those resemblances form as it were a chain like structure through the class in such a way that there are relatively clear cases of objects falling within the class, and relatively clear cases of those that do not". http://www.jstor.org/stable/4544648?seq=1#page_scan_tab_contents Bambrough in Universals and Family Resemblances even goes as far as to say that Wittgenstein solved the problem of universals.

But when it comes to aesthetic judgement at least, one does not have to settle for Wittgensteinian skeptical solution. Let us consult the usual authority on mental faculties:"If we judge Objects merely according to concepts, then all representation of beauty is lost. Thus there can be no rule according to which any one is to be forced to recognise anything as beautiful. We cannot press by the aid of any reasons or fundamental propositions our judgement that a coat, a house, or a flower is beautiful. We wish to submit the Object to our own eyes... the necessity which is thought in an aesthetical judgement can only be called exemplary; i.e. a necessity of the assent of all to a judgement which is regarded as the example of a universal rule that we cannot state". Kant gives a non-skeptical explanation of it in the resolution of the antinomy of taste in http://oll.libertyfund.org/titles/1217 Critique of Judgement, as usual by drawing a transcendental distinction:"At the basis of this there must necessarily be a concept somewhere; though a concept which cannot be determined through intuition... Yet at the same time and on that very account the judgement has validity for every one (though of course for each only as a singular judgement immediately accompanying his intuition); because its determining ground lies perhaps in the concept of that which may be regarded as the supersensible substrate of humanity... the explanation of the possibility of their concept may transcend our cognitive faculties". 

Making the usual move of relativizing Kant's absolutes, one could say that while taste is culturally acquired and communicable, it relies on a faculty that does not translate into propositional descriptions, it is "exemplary". On such reading Kant and Wittgenstein are easily reconcilable, and both accounts validate "I will know it when I see it" in practice.
"Using against the edifice the instruments or stones available in the house" means developing or progressing a problem by analysis rather than contrarian argument.

For a simplistic example, in tacking the problematic stance: "God exists", the reactive contrarian argument is to (attempt to) grasp the opponent's concept and deny its existence with arguments from physics.  In contrast, to deconstruct the problematic is use the tools at hand and ask what might be posited by the concepts "God" and/or "existence".  A successful deconstruction moves the original problematic onto new terrain. 
Broadly speaking Kant argues against the view that our intuition is shaped by the external objects. Instead he advocates to revert the view: Our intuition shapes how we register external objects. The passage is from Bxvi of Critique of Pure Reason (CPR).

Intuition is one of Kant's main technical terms. The two forms of intuition are space and time. Kant explains them in more detail in the beginning "Transcendental Aesthetic" of CPR. Space and time are not properties of the external objects; they are the means by which we observe external objects. 
Broadly speaking, the scientific method in physics is


  1) observation – 2) theory – 3) observation etc.


1) In the case of quantum mechanics the observation of spectral lines had to be explained.

2) The Schrödinger equation, embedded in the theoretical framework of quantum mechanics, explains the discreteness of the spectral lines and facilitates computing their corresponding frequencies for the most simple atoms like Hydrogen or Helium.

3) Further subtle observations of spectral lines detected the fine structure. 

4) The introduction of electron spin allows to explain the fine structure.
Quantum mechanics did not change this established scientific method. 

Also Popper’s emphasis on the principle of falsification is not restricted to quantum mechanics. It is an idealized description of the relation between experiment and theory, which applies to all natural sciences. Falsification is independent from Popper’s opinion concerning the Copenhagen interpretation.

A paradigm for the revolutionary step of quantum mechanics is the  Heisenberg uncertainty relation. It shows that the classical concept with physical observables, having always a definite value, has to be abandoned in the domain of microphysics. 

Hence from the viewpoint of philosophy of nature quantum mechanics has created a lot of deep open questions, in the domain of ontology as well as in the domain of epistemology. Does the concept of individuality pertain to microphysics, do the values of certain observables originate in the act of observation, how to speak about microcosmos with our concepts from mesocosmos? Some of these questions are examined by Heisenberg in his lecture Physics and Philosophy.

The coincidence of quantum mechanics and of the successors like quantum electrodynamics with the observed values from observation is striking. But the interpretation of the mathematical framework is still discussed. The main challenge is to explain the transfer during the act of measuremen from the microcosmic world of possibilities to the mesocosmic world of definite results. The best explanation at hand is the mechanism of decoherence.

Hence quantum mechanics provides us with an example of a theory which makes very precise predictions. But simultaneously, quantum mechanics provides a challenge for interpretation for each generation since its development at about 1925. 
For 3: The cause of Annie's concern is not hunger nor lack of male companionship, etc. The cause of Annie's concern is her career and lack of self-development. Blackburn is portraying a situation in which Bertie is not interested in addressing those causes but is instead interested in distracting Annie from those causes with dinner/companionship/sex. Bertie's concern is not Annie's career but only that Annie is concerned (about something). That's apparently what Blackburn means by "objectifying" -- Annie's concern itself (not her career) is the (sole) object of Bertie's focus.

For 4: "Concern" is a very different thing certainly than "career". Presumably Annie sees her own concern not as a "problem" but as a first step toward a solution (of a "career problem"). But even if they are both "problems", they are certainly not "the same problem".
"Bachelor are unmarried men" is an analytic proposition given the contemporary meaning of "bachelor" and "married". Words had different meanings at different times but it only follows that the same sentence was expressing a different proposition, not that the proposition that it expresses today is not analytic. Since formal logic is concerned by propositions, not sentences, it doesn't have to bother with this issue.
If you use induction to create conjectures, e.g. the Riemann Hypothesis, that's quite OK. Every method is allowed to create conjectures. Using induction to create conjectures is the method of generalisation.

The crucial point is how to confirm the conjecture. 

Obviously in mathematics the only method is to prove the conjecture - or to disprove it by generating a counter example. But in science one cannot prove general results. A finite number of confirmed cases does not increase the probability that the general result is true. That's the problem of induction.
Nietzsche himself talks about it in his auto-biography "Ecce Homo". He chose Zarathustra because he saw the real Zarathustra (Zoroaster) as being the first one to establish the moral system which eventually evolves into Judeo-Christian morals, and which Nietzsche sets out to demolish in "Thus Spake Zarathustra". He saw it fitting that a fictional Zarathustra should be the one who brings down the moral system that the real Zarathustra started.    
"The people can't imagine breaking some of the city's rules."
A person can be educated in epistemology but still be wrong about a fact, so unfortunately education in epistemology doesn't offer you any kind of factual knowledge about scientific discoveries. Thus, if a person makes a scientifically inaccurate claim, I'd rather call them scientifically illiterate regarding at least that certain topic.

A person believing that frozen bread causes cancer is anything from misinformed to scientifically illiterate but they are not necessarily not knowledgeable in epistemology, the study of the acquisition of knowledge and knowledge itself.

If their scientific illiteracy spreads over multiple facets of well accepted science, I would use the term in its general form instead of specifying "regarding this topic". However, when a person tries to argue against science itself with poor arguments, then it is time to speak of epistemological education issues. That said, this depends on the quality of the arguments (I don't expect there to be a good argument against science as a whole but I'm just stressing that this is not an axiom).
There's a lot of bits in the question that are written with apparent certainty that appear to be idiosyncratic. I don't follow your vocabulary, so I'm going to ignore that and just give a general answer.

The general answer across contemporary philosophical schools is that having an impression and attending to that impression are distinct. In most schools, they are also viewed as possibly different, but much of the difference hinges on what precisely is meant by "having" vs. "attending to". Probably, the clearest version of this is going to be in Husserl's phenomenology.

But the basic idea is that consciousness is consciousness of, i.e., it is the directing of my attention towards an object whether that object be in the world or in my own mind. So then we can distinguish between:


Me looking out the window at a squirrel (which by itself wouldn't be something I could articulate in those terms)
Me thinking about [Me looking out the window at a squirrel]
Me thinking about [me thinking about [...]


Note that I said above "distinguish". The question, however, is what is different between the things I'm doing with consciousness. For phenomenologists, the answer would be:


in the above 1, My consciousness is attending to an object out there in the world -- that's the object of my focus.
In 2 and 3, the object of my focus moves to myself and to what my mind is doing.


Of course you're right that when I reflect on the 1 at the top, I realize that this too is a mental process and not just something out there in the world. So in a sense, all consciousness is arguably of the form of the top 2 and 3. But this is a more debated and contentious point -- the distinction still remains between this sort of reflective engagement on our thoughts and our impressions from things in the world.
I don't understand why Aristotle's final cause has become controversial in modern science.

Science has no place for teleological 'explanations'. Science is in the business of finding causal relationships. 
Science doesn't attempt to 'explain' in any other sense. An intention to do something may accompany an action but provides no mechanism in any causal sense. Intentions aren't even observable so they cannot be part of any observable description of a causal chain.     
My answer might work out to the same thing as Shane's, but I'm not entirely sure.

On a trivial level, everyone knows that thought is always "situated." Thus, it's relatively safe construction that just about anyone could use. 


  "Of course, Hegel's thought was situated and the questions he addresses are those that made sense to a 19th century Prussian." (made up but plausible sentence).


At the same time, that alone is a thoroughly trivial claim unless the speaker also means something in a holistic direction. This could be either:


Our thought is not situated at all.
Thought is always situated.
Thought is merely situated.
Thought is problematically situated.


Claim 1 (not situated) seems potentially problematic -- because well when we read things from different cultures, we can really feel the cultural position of things. I take this to be at a minimum Kant's position. (In philosophy of language parlance, our sentences are precisely propositional at all times).

I take Claim 2 to mean the least controversial claim -- that Plato was a Greek and wrote in Greek and thought in Greek and addressed questions that mattered to people living in Athens. This isn't necessarily relativistic. But it might be. (In philosophy of language parlance, people's utterances are sentences). I'd say this is the view of Hegel.

Things get more relativistic when we get to Claim 3 (that it is "merely" situated). In this case, we're not just saying Aquinas writes in Latin but also that his thoughts and questions are trivially Latin. I.e., this claim is that there are no transcendental thoughts that escape from  their cultural underpinnings. This has some pretty strong relativistic implications, because now the claims cannot be translated or generalized (in philosophy of language parlance, people's sentences are not able to be propositions). This is roughly speaking the place Rorty thinks we wind up.

Claim 4 "problematically" adds a kind of "woe are we" because we cannot figure anything out to the third version. I think this is the crowning view of the post-structuralists like Derrida.

Most philosophers depending on the question are going to be either in the non-situated camp or in the always situated camp depending on the type of question. Most everything about doing philosophy is lost if we go to 3 or 4 since now we're just shuffling things around for no reason.
Unless you have made a prior definition of priority this is ambiguous (this is sometimes done to avoid the use of too many parentheses, usually operators like 'and' are then assigned to be the strongest in order etc.). The pure FOL doesn't do this however, so yes it is not clear what that formula means.

Note that M(x) → [ H(x) ↔ B(x) ] is not the same as [M(x) →  H(x)] ↔ B(x).

Ambiguous formulae are never well-formed.
Much of philosophy actually engages in a stripping away of things that can be known.  In that respect it is similar to a field called Reverse Mathematics.  Normal mathematics typically tries to prove as much as they can using the assumptions given.  Reverse mathematics explores how few assumptions have to be made to make a proof.

Philosophy generally starts from as few assumptions as possible.  As Philip mentioned, "Cogito ergo sum" is a popular point because we have not found a way to reduce our minimum starting point to anything less than that without removing our ability to think about it.  Thus, when you ask "what can we know for sure," the answer is very small.

Your quote from Self Inquiry is an excellent case study:


  When one persistently inquires into the nature of the mind, the mind will subside leaving the Self (as residue).


How do you know this for sure?  Granted it's probably quite sage advice, but you talk about what we know absolutely.  How do we know persistent inquiry will yield the desired results?  Descartes explored a philosophical position related to this that resulted in the so called Cartesian Demon, where there isn't such a guarantee (or if such a guarantee does exist, we have to define the "Self," which is a tricky topic indeed).  There's a branch of philosophy known as physicalism which contents that the mind is actually an illusion!  There's philosophies where we all have freewill, and there are philosophies where every action we take is deterministic.

In the end, one chooses which axioms they wish to believe.  Perhaps, for you, Ramana Maharishi's quote is a good axiom, and you choose to accept it.  From there, there's bountiful bodies of philosophy going in the normal direction in the form of "If you assume X, here's the natural conclusions from X."  However, the initial assumption of X is always up to you.

If anything, philosophy points out that these assumptions are choices.  It explores worlds where those assumptions may not be valid, demonstrating that you are choosing a path, not being forced into one.  You ask the question, "Does Philosophy tell how to get to this state of awareness?"  The answer is no, it does not.  What it does do is give you a lot of advice on what the path could look like, and lets you decide which path to take.  It also gives you solid arguments as to why you should not simply assume a particular path will lead you to where you want to go.  You can choose the path of Self Inquiry.  And in doing so, you can search for the "Self," knowing there's a huge volume of philosophy dedicated to trying to answer questions regarding what the Self is and what it is not.  You may even find helpful directions where you never expected them.  Personally, I found Arne Naess's philosophy of the "ecological Self" very helpful for putting me on the path I have chosen.
The meta-argument you attribute to Spinoza is closely related to the rule-following regress considered by Wittgenstein in Philosophical Investigations. To apply a rule in a particular situation we first have to interpret what it means, he muses. But then we need another rule to make the interpretation, and another, and another. We can no more apply a rule, it seems, than a runner can start running in http://www.iep.utm.edu/zeno-par/#SSH3aiii Zeno's Dichotomy. Nonetheless, we do manage to follow rules, we read, we write, we play chess (and runners do run). Therefore, concludes Wittgenstein, "there is a way of grasping a rule which is not an interpretation". 

Similarly, there is a way to "grasp" the willing without "an act of will". The meta-argument is based on the so-called volitionist theory of action, usually traced back to Descartes, and accepted by Spinoza, Leibniz, etc., before Kant. It is not an argument against free will, but one of many arguments against that theory. As confirmed by psychological studies, we do not first perform an act of will, which then causes us to do something, we just do it, willingly. This is reflected in the language, rather than say "I willed my hand to rise, and it rose" we say "I raised my hand".

Hacker's http://rads.stackoverflow.com/amzn/click/1444332481 Human Nature places the theory of volition in the conceptual context of modern philosophy and science. He summarizes Wittgenstein's response  to the meta-argument (Wittgenstein was influenced by Schopenhauer on the will issue) as follows  (pp. 148-152):


  "When one utters a sentence, every word is spoken voluntarily, but it would be ridiculous to claim that one consciously performs successive acts of will, one for each word (or phoneme?) an instant before utterance... The willing must not be conceived as doing something, the doing of which then causes the movement of one’s body. That would be a case of bringing about the movement of one’s body by doing something else. Rather, the willing would have to be an ‘immediate causing’".


The law of cause and effect, a.k.a. the principle of sufficient reason, is  another postulate of traditional metaphysics, once considered impeccable but controversial today. Belief in it leads to determinism, which unlike the volitionist theory is coherent if implausible. The traditional arguments for it often confuse causes with reasons, and reasons with necessities. Philosophers started broadly questioning it after Kant, who limited it to "phenomena". According to the standard interpretations of modern physics, determinism is false, there are effects that have no causes, or are self-caused depending on terminology. Physics itself however, as empirical science, can not settle metaphysical matters. There has been a burst of interest in free will in light of recent neuroscience experiments designed to test "folk intuitions" about it. Roskies surveys their results in http://isites.harvard.edu/fs/docs/icb.topic889975.files/May%202nd/May%202nd%20papers%20to%20be%20presented/Roskies%202010.pdf How Does Neuroscience Affect Our Conception of Volition?, and concludes that "to date no results have succeeded in fundamentally disrupting our commonsensical beliefs". 

The modern consensus is that libertarian free will, as it is called, is coherent and unfalsifiable, but so is determinism, and the two are incompatible (there is also compatibilism which redefines the meaning of "free" in "free will"). So we have a choice to believe or to disbelieve it. As William James put it, "My first act of free will shall be to believe in free will". http://www.informationphilosopher.com/freedom/history/ Information Philosopher gives a nice overview of historical and current views on free will.
I would claim that yes, those things are art, just as reasoning things out in a logical way with oneself is, in fact, an application of logical argument.  It may be the ultimate aim of logic to allow each person to make his own decisions correctly, and not to resolve disagreements between individuals.

In the spirit of Sartre, you are always the primary witness to yourself.  All other witnesses are in some sense superfluous, except for the mirror they give you.  But that mirror is a truly magical and necessarily transformative implement.

I think people like Crowley (see "Liber Aleph Nought") and Starhawk (see "Dreaming the Dark" or "Truth or Dare") depend highly upon Nietzsche's notion that art is not done for a witness when they elaborate personal or small-group rituals to delve into self-expression and elaborate one's personality and confront one's cultural and personal bases and biases.  Modern Witchcraft and Ritual Satanism (along with the whole range of Neo-Pagan, Thelematic, and other Ceremonial Magicks) are, it seems to me, very much about "Making Art of the Self",  "The Creator in all of us" and "Investigation of Personal Power for its own sake."  Concepts that pedestrianize the central messages of Nietzsche to good effect.  Nietzsche often acknowledges that at his best he writes like a religionist and not a philosopher, and his true followers may be religionists of the 'New/Old Religions'.

It is also obvious that having a witness makes art a much riskier endeavor, and that that risk elevates the effect on the artist.  In the spirit of challenging the will and taking power in steps as large as is wise, therefore, having witnesses is not a negative thing, only dependence upon them.  There is power in a proud performance that is absent from narcissism, and personal art is much more powerful when exposed even in dyads and small groups.
The precise definition given for the Event evolves from Being & Event up to Logic of Worlds. So depending on what period one is reading of him, the presentation of this concept may be more or less complex. 

The most complete definition, given in Logic of Worlds presupposes different levels of "happenings" (my term not his) in a World (at a site): 


The most primary level:  modifications 
Next level : facts 
Next level : weak singularity 
Final level: events (strong singularity)


Each of these things represent on occurence at a "site", where a site is defined in the following manner : 


  Take an object (A, Id) in a world m. It is a site once it comes to be
  affected by the ontological relation A ∈ A (self-belonging) and,
  consequently, by a transcendental evaluation of existence* of the type
  Id(A, A), that is EA = p.


So what distinguishes these types occurrences are both degree of existence (think intensities of existence) of the site and the appearance of something previously inexistent at the site. 

He defines degree as ‘measures’ of identities, differences or existences relative to a determinate world.


If the degree of intensity remains lesser than the maximum, it is a fact.
If it is equal to the maximum, it is either a weak singularity or an event.


Maximums are defined in the following manner: 


  Given an order-relation* over a set T, we say that it admits of a
  maximum, or of a maximal element, if there exists an element of T
  which is greater than or equal to every element of T. This element is
  written M, if it exists. We can then write that, for x ∈ T, we always
  have x ≤ M.


What distinguishes a weak singularity from an event are consequences. 


  An event makes the inexistent* proper to the object* in question pass
  from the minimal* transcendental value to the maximal* value. A weak
  singularity is incapable of doing this. We will say that an event
  absolutizes the proper inexistent of its place. The trace* of the
  event, often written ε, is the prior inexistent maximized (or
  absolutized, relative to the world* in question).


Think of May 1967 and May 1968. The brewing of turmoil in 1967 was not yet real transcendentally. It only became absolutized when the inexistent proper to the the brewing passed to a maximal value such that consequences (traces of the event) are forever left behind. 

By "transcendentally" I'm using his terminology, which designates the constitutive capacity of every world to assign to what abides there, in that world, variable intensities of identity vis-à-vis what also abides there. 
Usually, "P unless Q" is "symbolized as P ∨ Q. See :


Stephen Cole Kleene, https://books.google.it/books?id=q-YEuuZ_j8EC&pg=PA64 Mathematical logic (1967 - Dover ed  2002), page 64.


According to the truth-functional definition of conncetives (see truth tables), we hvae that:


  P ∨ Q is equivalento to ¬P → Q.


Thus, the answer to your question is: NO, for P → Q we get: "¬P unless Q"
Anecdotally, yes, there is a famous example of such a metaphysics, usually referred to as "turtles all the way down...." 

Since the joke usually attributes this, via William James, to Hindu philosophies, perhaps there is some actual version of it in Eastern traditions, I really don't know. There are, of course, theogonies dating back to Hesiod, in which the present God has an ancestral lineage, a casual regress back to Chaos or Void, which might be defined as "infinite regress itself." But I don't think that's what you mean.

I believe most Western philosophers would regard it as useless, irresolvable speculation and a misunderstanding of infinity. It might qualify as an example of Hegel's "spurious infinity," Kant's antinomies of first cause, or even a variant of Everett's "many worlds" thesis. As far as I can tell, which isn't far, that implies a kind of "causal infinite" residing in mathematics. If you've gone that far, why not toss in God?  

In general, I believe both God and Universe are taken to be absolute identities. Since God, at least, is already "infinite," nothing happens if we add more "prior" Gods, the successive totality remains the same. I don't know enough about Cantor's sets, but I don't see some convenient analogy where infinite beings from Aleph on could "line up" in some sort of causal sequence.

The problem seems to lie in the contradiction or incommensurability of "infinite" and "causal," which is why God is not regarded as understandable in either analytic or synthetic terms. Hence faith in He Who Is "beyond all understanding." 

Now, there might be something pertinent in Hegel's theology. Geist is not infinite regress but more like infinite progress. Hegel does seem to mix causality or "history" with the "true infinite." But then Geist is not God either.    

  he cannot possibly have a personality or character associated with him, a personality is built upon decisions, what decisions we make based on the input given to us is what defines a personality


What you are referring to here is https://en.wikipedia.org/wiki/David_Hume#The_self the bundle theory of self, which not every one subscribes to. In particular, someone who believes in God is likely a dualist, and dualism provides a situation where one can have a specific personality and character independent of experiences and perceptions. See for example Leibniz's soul monads. 


  Could one argue that the universe is not a construct created by god, but the universe (all versions of it) ARE god?


This is known as https://en.wikipedia.org/wiki/Pantheism pantheism, and has adherents even among certain interpretations of the monotheistic religions.  
Whether something is, or isn't depends on your standard. That is, "what is the standard that you use to evaluate whether a particular behavior is ethical or not ethical?" Before you answer that though, you should first ask the question: Why does man needs a code of ethics? From there you can derive what the standard should be. And from there you can derive your answer as to whether a particular behavior is moral or immoral.

Ayn Rand is a philosopher, may be the only one, who approached ethics from this angle.
Science aims at explaining our observations in the world. Hence the input comes from outside science. The explanation is given in the form of theories, often formalized by mathematics. The theory allows to make predicitions which can be confirmed or refuted by observation.

In this sense - input from observation and prediction of further observations - science is linked to the real world. But to predict observations does not necessarily mean to apply science. Application of the results of science is named technology. Here one has the aim to get some benefit from science.

An important confirmation of Maxwell's electrodynamics was the discovery of electromagnetic waves by Hertz. The technical application of this discovery is wireless communication.

Aside: That all masses fall with equal velocity in vacuum is due to the equality of gravitational and inert mass. I think conservation of energy is not relevant here.
(Not a linguist, so take this with a grain of salt, but I believe it's accurate.)

So, first we need to divide historical linguistics which is the bit of linguistics concerned with grouping languages into historical families from what we might call descriptive linguistics which is more closely aligned to psychology and the cognitive sciences. 

Let me say a bit about methods in historical linguistics. To create a family tree of languages you first start by gathering words with similar meanings that look obviously related: 


Latin: unum, duo, tres, quattor, quinque, sex, septem, octo, novem, decem.
Spanish: uno, dos, tres, cuatro, cinco, seis, siete, ocho, nueve, diez.
German: ein, zwei, drei, vier, fünf, sechs, sieben, acht, neun, zehn.
English: one, two, three, four, five, six, seven, eight, nine, ten.


On a first glance, it's obvious that Latin and Spanish are more closely related to each other than to German and English, and it's obvious that German and English are more closely related to each other than either is to Latin or Spanish. So we now have two candidate families. But notice there are some similarities between the two families---the words for "six" sound similar in all, for instance. 

So perhaps we come up with a hypothesis: there was once a language which was the last common ancestor of the Latin/Spanish family and the German/English family. To flesh this hypothesis out I need to do two things: 


I postulate some primitive vocabulary for this last common ancestor language, and then
I postulate some sound change rules that would let me systematically transform the primitive vocabulary of the last common ancestor language into the vocabulary of the descendent languages.


For sake of concreteness, let's get a proposal on the table. (Not being a linguist, I'm sure the actual claims are wrong, but it's just an illustration). Suppose I call my last common ancestor language proto-indo-european, and I hypothesize that the word for "three" in PIE was "tre". Further, I hypothesize that the Latin/Spanish family didn't like words that ended with a soft e sound, and so they tended to add an "s" to such words, and so you get "tre" > "tres".
Suppose, however, that the German/English family didn't have a problem with words ending in a soft vowel, but then later they began to not like the initial consonant cluster "tr". Perhaps the German speakers tended to mutate "tr" to "dr" and the english speakers tended to mutate "tr" to "thr". Then you'd get intermediate forms like "dre" in German and "thre" in English. Postulating further vowel changes would give us "drei" and "three" respectively.

Of course, what I've drawn here is a really simplistic picture. Languages are constantly mutating and evolving, and they always come in a variety of dialects. The point is that each of the hypotheses above is testable.
If my historical hypothesis is true, I should expect to find some dialects of German, or some historical inscriptions in German where the word for "three" is "dre" rather than "drei". Further, we can also look at historical and archaeological evidence for examples of language change. 

Also, notice that we can draw on some important non-linguistic evidence to help us chart the chronologies too---we already know from history that Latin is the older language, and Spanish descended from it and that will help us figure out that PIE is going to be a lot more like Latin than Spanish probably. 

tl;dr. Historical linguistics uses a variety of methods: comparison of dialects, archaeology and anthropology to help verify its reconstructed languages.
Aristotle is well aware that one can act justly towards those with whom one is not friends, even to one's worst enemies. But why should friends not need justice ? Surely I can cheat a friend ? Don't I need justice to check my bad tendencies even towards friends ? 

▻ KINDS OF FRIENDSHIP

We need to make two moves to understand Aristotle's views on justice and friendship. The first is that he distinguishes between three kinds of friendship  (Nicomachean Ethics,VIII, 1156a7, 1157b) : (1) friendships of pleasure where someone's company - witty, generous, indulgent - is merely but genuinely enjoyable and satisfying; (2) friendships of advantage where an easy relationship is based on mutual advantage as in certain business ties; (3) friendships of virtue where a person is appreciated, valued, and their company sought because one recognises their moral goodness. A person is fine and admirable, a model of good living, and for this reason one wants to be with them and to enjoy them. 

It is only to the third kind of friendship that the idea that friends have no need of justice applies. More specifically, it is friendship where there is a mutual recognition of moral goodness. 

This is not to say that the third kind of friendship is without pleasure - very far from it. But it does not arise for the sake of pleasure as the first kind of friendship does and it does not produce pleasant incidentally as does the second. 

▻ JUSTICE AS A VIRTUE REQUIRING RESTRAINT FROM HARM IS IRRELEVANT BETWEEN FRIENDS

If Aristotle is focusing on friendships based on mutual recognition of moral goodness, it is fairly clear that, in such friendships, restraint from harm is inapplicable since there is no inclination to harm that needs to be restrained or checked. This is brought out in the following passage from John Cooper :  

...justice can exist perfectly well among those who care nothing for one 
   another and who would not lift a finger to help any one else, except insofar 
   as rules of justice might require. The sense of justice, understood as 
   respect for fairness and legality, is compatible with a suspicious, narrow, 
   hard, and unsympathetic character. Hence, as Aristotle says (1155a26-27),
   those who are merely just in their mutual relations have need also
   of friendship, whereas those who are friends do not need to become
   just in addition: since, as friends, they already feel a lively concern
   for one another's welfare, they already acknowledge reasons not to
   harm or work to disadvantage and can be expected to reach an
   accommodation without having to invoke strict rules of justice.
   Those who are truly friends will not wrong one another, not, however, out of 
   love of justice and legality, but from love of one another. (J.M. Cooper, 
   'Aristotle on the Forms of Friendship', The Review of Metaphysics, Vol. 30, 
   No. 4 (Jun., 1977), 646.)

▻  JUSTICE AND FRIENDSHIP : A TWIST IN THE ARISTOTELIAN TAIL

Though friends have no need of friendship, Aristotle adds that when a relationship goes wrong and one does act unjustly towards a friend, the injustice is more serious: Cooper, 647.

▻  A QUALIFICATION

Much of Aristotle's language suggests that all three kinds of relationship based respectively on pleasure, utility, and mutual recognition of moral goodness are forms of friendship. But there is at least one passage in the Nicomachean Ethics which suggests that only the third kind is genuine friendship while the others are only approximations to it or similar to it : Nicomachean Ethics, VIII, 1158a19. 
I think you're missing some premises.


The haze in Singapore causes problems for the capitalist economic system. (Premise)
The haze in Singapore is caused by the capitalistic system. (Premise)
If the haze in Singapore causes problems for the capitalist economic system and the haze in Singapore is caused by the capitalist economic system, then the capitalist economic system is self-defeating. (Premise)
The haze in Singapore causes problems for the capitalist economic system and the haze in Singapore is caused by the capitalist economic system. (conjunction intro 1, 2)
Therefore, the capitalist economic system is self-defeating. (conditional elimination 3, 4)


That argument is valid. But I question its soundness. Someone else has also queried the truth of (1) and (2), but I'm also worried about (3). Maybe capitalism causes some problems and solves others and the magnitude of the solutions is greater than the magnitude of the new problems introduced. That would suggest that capitalism is limited in that it can't provide some solutions without introducing other problems, but not that it is utterly self-defeating. 
The Golden Rule:   Do unto others as you would be done by.  
The Platinum Rule: Do unto others as they would be done by.


(Stated by Gerald M. Weinberg in one of his books, but I am sure it is much older than that.) Solves the entire problem. Oh, that wasn't the actual question. DOH! Well, I would want a satisfying answer, so I am posting it.
The idea that you mention is similar to Marx's concept of https://en.wikipedia.org/wiki/Marx%27s_theory_of_alienation alienation: When a person performs labor in a capitalist industrialized society, they slowly loose their connection with their work and their community. The become alienated. 


  The theoretic basis of alienation, within the capitalist mode of production, is that the worker invariably loses the ability to determine life and destiny, when deprived of the right to think (conceive) of themselves as the director of their own actions; to determine the character of said actions; to define relationships with other people; and to own those items of value from goods and services, produced by their own labour. 


Marx develops the idea mainly from an economic point of view. He sees it as result of capitalism. However, modern capitalism is a direct consequence of the industrial revolution, and wouldn't be possible without modern technology. 
So in a sense, your idea that "we loose our qualities" - we become alienated - because of technology is supported by Marxists theory. 
Karl Popper offers a solution in his book "The Open Society and its Ennemies":


  The so-called paradox of freedom is the argument that freedom in the sense of absence of any constraining control must lead to very great restraint, since it makes the bully free to enslave the meek. The idea is, in a slightly different form, and with very different tendency, clearly expressed in Plato.
  
  Less well known is the paradox of tolerance: Unlimited tolerance must lead to the disappearance of tolerance. If we extend unlimited tolerance even to those who are intolerant, if we are not prepared to defend a tolerant society against the onslaught of the intolerant, then the tolerant will be destroyed, and tolerance with them. — In this formulation, I do not imply, for instance, that we should always suppress the utterance of intolerant philosophies; as long as we can counter them by rational argument and keep them in check by public opinion, suppression would certainly be unwise. But we should claim the right to suppress them if necessary even by force; for it may easily turn out that they are not prepared to meet us on the level of rational argument, but begin by denouncing all argument; they may forbid their followers to listen to rational argument, because it is deceptive, and teach them to answer arguments by the use of their fists or pistols. We should therefore claim, in the name of tolerance, the right not to tolerate the intolerant. We should claim that any movement preaching intolerance places itself outside the law, and we should consider incitement to intolerance and persecution as criminal, in the same way as we should consider incitement to murder, or to kidnapping, or to the revival of the slave trade, as criminal.


  in which sense in the Tractatus "Philosophy never ends"?


Why ?


  6.5 When the answer cannot be put into words, neither can the question be put into words.
  
  The riddle does not exist.
  
  If a question can be framed at all, it is also possible to answer it.
  
  6.52 We feel that even when all possible scientific questions have been answered, the problems of life remain completely untouched. Of course there are then no questions left, and this itself is the answer.
  
  6.522 There are, indeed, things that cannot be put into words. They make themselves manifest. They are what is mystical.


Thus, when all the questions have been answered, what remains "cannot be put into words".

But where there is no language, there is no argument, and thus also no philosophy at all. Only the mystical.
Yes; writing to Russell from Monte Cassino in 1919, Wittgenstein explained Sachverhalt as what corresponds to an elementary proposition if it is true, and a Tatsache as what corresponds to the logical product (i.e. the conjunction) of elementary propositions when this product is true. [GEM Anscombe, https://books.google.it/books?id=7oWZPwAACAAJ An Introduction to Wittgenstein's Tractatus (2nd ed - 1963), page 30].


  2 What is the case — a fact [die Tatsache] — is the existence of states of affairs [Sachverhalten].
  
  4.25 If an elementary proposition is true, the state of affairs [Sachverhalt] exists: if an elementary proposition is false, the state of
  affairs does not exist.


Thus, a Sachverhalt is an atomic fact, or elementary situation, that corresponds to a true elementary proposition.

A non-existent Sachverhalt correspons to a false elementary proposition (see: 2.06 We also call the existence of states of affairs a positive fact, and their non-existence a negative fact.)
Being lame and restricted to chair shows that the person is not free to act. But in general, the person is free in her will and decisions like a non lame person. 

One has to discriminate between free action and free will. The hard problem is the problem of free will. Libertarian view, determinism, and compatibilism refer to the problem of free will. 

Hence the example of a lame person does not seem relevant to this issue.
Most philosophers didn't feel that determinism needed to be proved per-se. Instead they thought determinism to be a logical corollary of materialist universe governed by the laws of physics. Democritus was arguably the first determinist, with his concepts of physical determinism and logical necessity, both of these positions he saw as consequences of his materialist atomist theory of the universe, where everything was causally determined by the motion of atoms, thus removing any need for supernatural gods and fates. Similar views on causality and materialism were held by the Stoics. 

Similarly, most modern philosophers saw determinism as a direct consequence of successful classical physical theories like Newton's laws of motion. 
Again, they saw the issue as an obvious consequences of these physical theories, and one that didn't require a proof in itself. https://en.wikipedia.org/wiki/Laplace%27s_demon Laplace's demon is probably the most famous statement of such a position: 


  We may regard the present state of the universe as the effect of its past and the cause of its future. An intellect which at a certain moment would know all forces that set nature in motion, and all positions of all items of which nature is composed, if this intellect were also vast enough to submit these data to analysis, it would embrace in a single formula the movements of the greatest bodies of the universe and those of the tiniest atom; for such an intellect nothing would be uncertain and the future just like the past would be present before its eyes.
  
  — Pierre Simon Laplace, A Philosophical Essay on Probabilities


It should be noted that the type of determinism you mention has been disproved, first by the empirical results of quantum mechanics, and more recently by https://en.wikipedia.org/wiki/Laplace%27s_demon#Cantor_Diagonalization Wolpert's theorem. Wolpert's result is particularly interesting, since it puts a limit on what an intelligent agent can predict in a universe, regardless of whether the universe is random (by QM) or not, effectively showing that Laplace's demon is impossible. 
Concerning the given explanation:


  For A, the analytic a posteriori, we can learn each of the words in this sentence through experience (in an a posteriori manner), and yet the meaning of it is tautological.


To learn in an a posteriori manner means to learn by induction i.e. 
(1) To learn from examples, such that each positive example strengthens one's confidence in the result.
(2) That there always remains the possibility of a negative example, a counter-example, of dis-proving the result.

Whether "red is rouge" is a posteriori depends in particular on (2). That is, is it conceivable that one will suddenly realize that red is not rouge? For Kant, who was the first to discuss these distinctions at length, it is not possible that red will turn out not to be rouge. But by other conceptions of meaning it may be possible. The example is controversial, and so is the very possibility of analytic a posteriori statements.
Conditional statements are closely related to disjunctive statements. Using logical notation, this can be written as:


  A → B ⇔ ~A ∨ B


Given this relation, the first statement can be interpreted as asserting one of two things:


  It is not raining.


or


  The grass is wet.


Since the second statement asserts that if the grass is not wet, eliminating the second possibility, the first will be true: It is not raining.
Mill is speaking of liberty:


  The human faculties of perception, judgment, discriminative feeling, mental activity, and even moral preference, are exercised only in making a choice.


This implies also "creativity":


  He who lets the world, or his own portion of it, choose his plan of life for him, has no need of any other faculty than the ape-like one of imitation. He who chooses his plan for himself, employs all his faculties.


But human freedom is not for Mill aimed only at knowledge and understanding, but also to "doing"; see his second http://plato.stanford.edu/entries/mill-moral-political/#PerDefBasLib basic categories of liberty (I 12):


  Liberties of tastes, pursuits, and life-plans


This means the liberty of pursuing personal growth trough "active life":


  Supposing it were possible to get houses built, corn grown, battles fought, causes tried, and even churches erected and prayers said, by machinery—by automatons in human form—it would be a considerable loss to exchange for these automatons even the men and women who at present inhabit the more civilized parts of the world, and who assuredly are but starved specimens of what nature can and will produce. Human nature is not a machine to be built after a model, and set to do exactly the work prescribed for it, but a tree, which requires to grow and develope itself on all sides, according to the tendency of the inward forces which make it a living thing.

As virmaior has commented, this is a difficult question to read and includes many apparently different statements.

With regard to the first part, you ask for a term describing the view "time itself doesn't exist and that, really, is just a timeline to put change against".  This is a form of relationism which views time as a measure of change.  Relationism incorporates elements of realism and idealism.  It is idealist in that it treats time as a merely subjective matter, with nothing in reality corresponding to it.  Relationists take the view that time is simply a way we relate events to one another, but the relations are real.  The relation being referred to here is the "before-after" relation.

This is the view put forward by Aristotle in response to Plato's view that equates time with change.  For Aristotle, the relation between time and change is not one of identity, but rather it is the relation between the thing being measured and the means of measuring it.  Here, time is not a process, it is an abstract "number" or unit that can be used to describe processes in nature, analogous to the way numbers can be used to count things.  As Aristotle put it : "time is the number of change with respect to before and after".  Thus, time is a subjective system which captures something real about nature without being part of nature.

The remainder of the question is difficult to address.  It appears to express views contrary to the initial view of time as a measure of change.  In addition, it appears to include inconsistencies.  You lost me with the toothpaste versus stamp buying comparison. 
I refer to the definitions of the terms “formal reality” and “objective reality” from http://www.trinity.edu/cbrown/modern/descartes-Reality.html http://www.trinity.edu/cbrown/modern/descartes-Reality.html

Formal reality of an object depends on the object’s kind, being a mode, a finite substance, or an infinite substance. The degrees are, respectively, low, medium, and high.

Only ideas have objective reality. Its degree of objective reality is the degree of formal reality of the content of the idea.

In your example:


cup of coffee (formal reality, objective reality) = (medium, n/a)
the idea of the cup of coffee (low, medium)
a person (medium, n/a)


@virmaior Thanks for the reference to the terms.
If you wanted to approach this question as a pure Heideggerian, it would be a matter of deciding whether a new epoch of being has overtaken us, determined by some change in our relationship to technology, or whether we are still immersed in the same epoch described by Heidegger. He describes modern technology as completely determining the possibilities of Dasein, so that we see ourselves as set forth by technology, rather than vice versa. If you understand us as continuing within this epoch, then the possibility of salvation (so to speak) still remains in recognizing the essence of technology. 

If you prefer the theory that our technology has opened a new epoch, then you could take these reflections in any number of directions. I believe that Bernard Stiegler has developed a philosophical project along these lines - you might take a look at Technics and Time, 1: The Fault of Epimetheus.

My own preference is for Derrida's response to this direction (or Weg) of thinking. Derrida questions the possibility of distinguishing authentic from inauthentic thinking, and thus deconstructs the oppositions between animal or technological existence and that of Dasein as they are developed by Heidegger. You can take a look at Derrida's Of Spirit: Heidegger and the Question or "The Pit and the Pyramid: Introduction to Hegel's Semiology" (In Margins - of Philosophy for more on how the deconstruction of authenticity and inauthenticity leads to a questioning of the distinction between Dasein and mechanical thinking.

One way to think about how deconstruction can change our thinking about our relationship to technology is to consider what it is that we are trying to get away from when we try with Heidegger to disclose a thinking that is not technological. Derrida would argue that the possibility for technology, which is the possibility for any sort of prosthesis that extends or alters our "natural" capacities - of voice, reach, or physical power, for example, is not something that comes along after the fact to affect a subject who is completely self-contained and authentic, but rather an extension of the difference-from-self that is already present in all of our self-relations, including thought. This or that technology may change our relation-to-self, but never in the essential way that would transform a self-present (authentic) subject into an absent-from-self or inauthentic one. Of course, according to Heidegger we are always falling away from authenticity, and requiring an effort to arrive back at an authentic relation to our own possibilities for being. But I would like to question the extent to which "technology" is a force preventing our return to authenticity. It may be that there is still something technological, technical, something of technique that is still a part of even the most "authentic" thinking.

The developments of mechanical and computer processes that increasingly resemble human thought should also lead us to pose the question whether or not authenticity and/or inauthenticity are possible for machines, that is, for technology unto itself.
If one is remarkably confident that one can, indeed, observe things, then this is a dilemma.  To such a person, this word, "observe," has a very clear crisp meaning that could not possibly ever be challenged.

They can use that confidence to be sure of logical or metaphysical truths.

Of course, those observations are never deceiving:

https://i.stack.imgur.com/phjoJ.jpg 

Actually, if you study empiricism, you find that it is a subcategory of epistemology, the study of what we can "know."  Empiricists believe that all knowledge stems from "sensory observations," though what those are is a heavily debated topic.  Another branch of epistomology, rationalism, believes that all knowledge stems from the use of reason independent from the senses.  In rationalism, it is logical or metaphysical truths that one can be certain of, and the "observable" world outside is the part which is treated with suspicion.
The http://plato.stanford.edu/entries/logic-inductive/ Stanford article on inductive logic that Mauro referenced is a good, though lengthy, account; the short version is that the Bayesian approach to statistical problems requires specifying priors. These priors are not determined by the experimental evidence, but represent the state of play prior to the evidence being taken into account. At the time Fisher was working, there was no satisfactory answer to the question, where do these priors come from? Are they are just arbitrary assumptions? Fisher hoped that some kind of logic of induction could be derived that would avoid such assumptions. Such a logic would provide objective answers to questions of the form, how much evidential support does this proposition provide for that proposition? 

The task was taken up by John Maynard Keynes and Rudolf Carnap, among others, who tried to derive a purely syntactic set of rules for a probabilistic theory of induction, incorporating the principle of indifference. Ultimately most theorists regard this project as a failure (although there are still defenders of the logical interpretation of probability). As Goodman showed with his "grue" example, there are no purely syntactic criteria that determine whether some hypothesis is projectible from known to unknown cases: it depends on what the terms mean and, on at least one popular account, whether they correspond to natural kinds. Also, as Duhem and Quine pointed out, hypotheses are underdetermined by data anyway, so there cannot be a purely objective way of saying how probable a hypothesis is given a set of data. 

The result is that there is no general consensus on the best way to perform statistical inference. Classical frequentists use methods based on the work of Fisher, and Neyman and Pearson. Bayesians continue to use their methods, but have updated them to try to solve the problems with finding objective priors. Likelihoodists use a kind of Bayesian updating, but forego finding priors in favour of assessing the relative merits of competing hypotheses. 
You're conflating things a bit, so let me try to parse what you're trying to say.


  Statements that lead to contradictions can't possibly be true


This is true. By the principle of explosion, if we were to allow for contradictions, anything can follow (e.g. https://i.stack.imgur.com/9Vxbe.png ). So the system is meaningless.


  The existence of God leads to contradictions, so it can't possibly be true


Essentially, you're arguing that because God can create "square circles" -- a logical impossibility -- he cannot exist. Conversely, if he can't create "square circles," God really isn't omnipotent so, again, God can't exist. This argument doesn't work due to a very old distinction between (what Avicenna) called particulars, universals, imaginaries, and impossibles.

A "square circle" is a logical impossibility so God couldn't create it by virtue of its meaninglessness rather than God's lack of power.
Jung would deduce there cannot be such, and a long history of philology tends to agree with him.  Writing is a psychological process, and psychology is anchored in the collective unconscious.

So we are shaped by our culture's shared fund of stories to the degree that we cannot help but be influenced by some 'archetypical' material that would touch upon our mythological roots.

That does not mean the influence is chosen, or that it is even strong.  You cannot escape archetypes, but there is all kinds of other material.  From a point of view like Jung's (or Lacan's) the very vocabulary is built on exemplars of archetypes, which are older than rational analysis, and therefore mythological.  We certainly learn our own language in a matrix of mythologies built on layers of other mythologies. (In Westerns, there is a set of tropes imbued with a mythology of rugged individualism, build on a specific mythologizing of US history and 'American-ness' built on the notion of Christendom, built upon religious positions chosen by Roman Catholics against Orthodox positions chosen to resist Caliphate Islam...)  But any story is not just made up of words, or even of basal tropes, or it would completely fail to be art.

In that sense, how does even our non-fiction escape mythological roots?

We derive models in modern sciences by analogy with past models, which ultimately go back to religious impressions.  The frequency of particles is the music of the spheres (the songs of angels) and the subtle vibrations of Ayurveda.  What is really going on has absolutely nothing to do with vibration, and was originally conceived of as rotation.  But we are used to the story, and it has ongoing religious resonance.

We demand a creation myth for our universe, even if it involves an imaginary dimension to time, not because physics actually needs one but because religions always gave us one, and we have come to expect them.  (In fact, it is not entirely in accord with the predictive nature of the new views of science to retroactively predict what we will never observe, especially if it requires rules significantly different from the ones we do observe)

And our science is an extension of our philosophy.

Questions here still consider Aristotelian and Platonic views favored by the Church and supportive of a religious creation myth.  The whole of our philosophy has been drenched in theology so recently that we are still talking about some 'secular' notion of God, framed as the omnipotent creator, but independent of any acknowledged religious orthodoxy.  We make it ontology rather than religion by tying it back to the Greeks.
Possibilities are pure nothings. Whitehead discusses the logic of possibilities or "eternal objects" (as he calls them) in Process and Reality and his many other works. Possibilities, in themselves, do exist but only as wholly non-actual--we abstract from the actual world in order to inquiry into boundless possibility. There are nothing without the realization of actualization. Before there can be the actual you, there has to be the possibility of you which is indistinguishable from nothing. Temporally speaking, past possibilities pertain to "might-have-beens" whereas future ones involve "might-bes." The possible qua possible makes room for infinitely many modes of formal relatedness. How or for what purposes possibilities are selected is a separate issue from their existence as pure nothings.   

None of this is meant to suggest that the actual is superior to the possible or vice versa, as to posit some ontological necessity. Whitehead insists they are co-equal and seeks to avoid the bifurcation of nature.      
We all have no choice but to treat our mothers as means.  So your reading of this version of the imperative would mean we all had to stop being humans.

If we could not use one another as means, we would have no professions at all.  But those people also need to be included as ends.  Professional culture needs to not foreclose them from attaining their desires, and it needs not to lock them into their function in a way that violates their autonomy.

In societies that treat the basal working class (unskilled labor) as ends, any grocery stocker could also be a poet or an artist, and might earn his way into any other profession.  That does not mean that he can simply walk away from his current duties any more than the pilot of your plane can resign in mid-flight.  But a reasonable level of flexibility must exist for the individual to have autonomy about his daily decisions.

(I am told -- I have no reference) Kant himself argued for limiting one's intake of meat on the basis that work as a slaughterer in a mass concern in his own society is a use of a man as an end.  In his culture, it paid poorly enough that it required continual labor that prevented pursuit of much else, it was done forthrightly in ways that directly contradicted natural human impulses to compassion, and it was easily disrespected socially because the resulting effects on one physically (smell, ruined posture, etc.) were easily observed.
Really, I think that outside of scientists of a rather 'religious' stripe we got there already.  Theories of meaning like those of Lacan and Desassure already work in this way.  We are used to them.

All experience is intersubjective negotiation.  You can attempt to ensure agreement by modelling the view of the other subjects in triangulation, but you cannot fully capture or predict their experience in detail.  What is shared is also shaped by the process of observation, and you can only get so close to the perspective of someone who is viewing something that is changing at the same time.

It is not really hard for us to take in this mutualized, psychologized notion of language.  It is almost impossible, and utterly unproductive, to avoid falling back on more absolute models for efficiency, but the problems of dealing with other people in all their psychodynamic complexity make the case that this is far closer to reality than the models from which we work on a regular basis.

Why is it somehow seen as almost impossible for people to use this picture of our shared mental reality in the context of our shared physical reality?

But as for figuring out what the effects are, they are the same effects already uncovered by modernist collapse in psychology, though with a deeper, more inescapable texture: the problems of Sartre, Wittgenstein, Nietzsche and Lacan.  The model is not new, it is simply more thoroughgoing than we might have imagined.
First of all, there are many forms of equality: Racial equality, gender equality, equal opportunity, economic equality, etc...you seem to be mostly concerned with economic equality.  

Second, based on your wording, you are conflating equality and fairness, which are not the same. In fact many would argue that fairness and equality can be contradictory: Is it fair that all employees get the same pay, even though some work harder than others? 

Your utility example (better form me to have 2 utility points even if someone else has a 100, than for all of us to each have 1 utility point) echoes John Rawls difference principle. 

John proposes the theory of http://plato.stanford.edu/entries/rawls/#TwoGuiIdeJusFai Justice as Fairness, discussed in his book "A Theory of Justice". Here, I will quote the SEP article on John Rawls:  


  These guiding ideas of justice as fairness are expressed in its two principles of justice:
  
  
  First Principle: Each person has the same indefeasible claim to a fully adequate scheme of equal basic liberties, which scheme is compatible with the same scheme of liberties for all;
  Second Principle: Social and economic inequalities are to satisfy two conditions:They are to be attached to offices and positions open to all under conditions of fair equality of opportunity;
  They are to be to the greatest benefit of the least-advantaged members of society (the difference principle). (JF, 42–43)
  


As you can see, John Rawls seems to agree with you that inequality is acceptable, as long as it works to the advantage of everybody, i.e. everyone ends better off in the arrangement (everyone gets more utility points than they would have in an equal distributions, but some more than others). 

There are also arguments for economic equality. Settings aside purely moral arguments for economic equality, one can provide the following pragmatic reasons for economic equality, which fall under the heading off everyone stands to benefit more from situations with greater equality, even the very rich (sorry for lack of sources, I will have to dig them up later): 


Economic arguments: too much inequality will lead to economic crises, as the rich produce all sorts of goods and services but the poor can't afford to buy these products.
Social arguments: too much inequality leads to social instability. A rich person might benefit from making sure that none his neighbors are poor, so that none of them will be tempted to steal from him. Is is not a coincidence that egalitarian societies like the Scandinavian countries or Japan also tend to have some of the lowest crime rates in the world.   
Game theoretical arguments: Situations like https://en.wikipedia.org/wiki/Nash_equilibrium#Prisoner.27s_dilemma the prisoner's dilemma show that on average, people have a higher probability of obtaining a positive outcome if they collaborate together, than if they work against each other.  

Part 4 of Nietzsche, Friedrich: Thus spoke Zarathustra contains a section entitled „The Higher Man“. Here Zarathustra addresses the higher men (paragraph 11):

“Ye creating ones, ye higher men! One is only pregnant with one's own child.”


  What sort of creativity do Nietzsche's higher men have?


Because God is dead, there is nothing more in the way of the higher men. Now they can take over the command by surpassing “the petty people”, who “are the Superman's greatest danger!” (paragraph 3).

Hence the creativity of Nietzsche’s higher men is to create Superman, their child.

I'm not yet convinced that Goethe would count as a higher man in the sense of Nietzsche's characterization. The criterion is that higher men create Superman. Hence one can ask whether Goethe's poetic creation Faust was Superman. But I am not sure about the answer.
You are right that Bell's inequalities do not rule out "superdeterminism" (Bell's term), as he himself acknowledged:"...if our measurements are not independently variable as we supposed...even if chosen by apparently free-willed physicists...  then Einstein local causality can survive. But apparently separate parts of the world become deeply entangled, and our apparent free will is entangled with them". Bell's inequalities are instead conditional: if experimenters are free to choose which experiments they perform then the outcomes of those experiments as predicted by quantum mechanics (and confirmed in labs) are inconsistent with local realism. Testing determinism requires assuming indeterministic freedom. So at first glance the Bell's inference appears circular, as http://mathpages.com/rr/s9-06/9-06.htm Brown puts it in Von Neumann's Postulate and Bell’s Freedom:" He proved, assuming the predictions of quantum mechanics are valid (which the experimental evidence strongly supports), that not all events can be strictly consequences of their causal pasts, and in order to carry out this proof he found it necessary to introduce the assumption that not all events are strictly consequences of their causal pasts!"

But all is not as circular as it appears. The catch is that even the strictest of mechanical determinists typically applied their determinism to the experiments they conduct, not to their ability to conduct them, even though their determinism dictates that they may not be able to conduct them at will. If they applied their determinism consistently to themselves as well (which is what Bell calls "superdeterminism"), then it becomes not only empirically unfalsifiable, but also vacuous: no counterfactual can ever be tested because all setups are pre-arranged. So what Bell's inequalities bring into sharp relief is that one can not be a determinist about nature without also being a determinist about their ability to "interrogate" it, in Galileo's word. And that determinism is highly implausible to a point of fantastic for the reason mentioned by Bell, it requires "deep entanglement", fine tuned correlations between vastly distant regions of the universe, correlations that eventually force spatially remote experimenters to make one measurement rather than another. In practice (that is applied to anything other than dubiously to the universe as a whole), environmental decoherence will quickly wipe out any such correlations.

The irony is that it was quantum "spooky action at a distance" that originally motivated Einstein's demand of local realism, yet in view of Bell's inequalities he'd have to accept something far spookier to keep it. But the good news is that while Bell's inequalities do not rule out superdeterminism, they do not mandate it either, they are perfectly consistent with measurement choices being undetermined, along with their outcomes. And that is by far a more plausible interpretation.  
I tend to interpret Quine's conclusion in terms of the readers' side of things: in order to interpret even the most basic, small facet of a scientific result, you need to impose a big background of theory.  For an obvious example, take the report that the Higgs Boson has a mass of XXX +/- YYY GeV/c^2; huge amounts of background knowledge are required to even make sense of this one reported number.  Even something as basic as "we measured the thickness to be ZZZ mm with calipers" implies a theory that the thickness of the whatever (as opposed to say, its surface roughness) is the salient factor in this context.  Similar considerations affect the practitioners' reporting: they can't provide all of the background information so they need to assume (usually implicitly) that the reader will interpret their results in the light of a commonly held theory.  This then pushes back into what practitioners actually do: if I can't sensibly communicate it within the theoretical constructs of my scientific community, then it's not worth doing (or if I do it, I'll end up being outside my scientific community).

Science has values.  Not just that the people of the scientific community have values, but rather the enterprise of doing science imposes/requires a minimal set of values, i.e. things that are deemed "of value".  These include things like: complete, transparent, and accurate reporting of findings; reproducibility of the processes used to derive the results; dispassionate reporting et al. When you interpret scientific results you can (or at least should be able to) assume that these results are being reported in accordance with these values.  These are the values of science, as an ideal, and in my estimation/view the values that shape the actual practice of science as we know it. You can go down a rabbit hole of the hows/whys/wheres of deviations from these ideals do occur within science and/or when enough of them are violated we are no longer dealing with "True" (Scotsman) science etc.  But for the purposes of this discussion, it makes sense to accept that science (or with more detail: sepcific communities with science) has some intrinsic/essential values.

That these core values of science affect how results are conveyed and interpreted is a more subtle point, and can be described in a way that makes this interaction less interesting than the theory-ladenness of science.  In considering theory ladenness it is relatively easy to come up with counterfactuals: e.g. without special relativity, measuring masses in GeV/c^2 doesn't make sense.  Trying to construct the same kind of counterfactuals where the essential values of science are violated leads to situations where you are not dealing with science.  Public policy research institutes, which adhere to a different set of values, produce research papers that include specific objective facts, but are not doing science. As I currently understand it, some segments of the biomedical research community have stopped doing (or failed to do) science, since the cherry picking of positive outcomes amounts to incomplete reporting of their results.  The point is these core values are, for some contexts, less interesting because they are just part of the background that comes into play when discussing science at all.
The argument is based on two premises:


Whatever has no beginning is eternal.
Whatever has an ending is not eternal.


If the premises are accepted, the conclusion follows and may be formalized as so:


A = Is eternal
B = Has beginning
E = Has end



{1}          1.   ¬B → A                   Prem.
{2}          2.   E → ¬A                   Prem.
{3}          3.   E                        Assum.
{2,3}        4.   ¬A                       2,3 MP                     
{1,2,3}      5.   ¬¬B                      1,4 MT
{1,2,3}      6.   B                        5 DNE
{1,2}        7.   E → B                    3,6 CP


Translation:


Whatever has no beginning is eternal.
Whatever has an end is not eternal.
Assume that something has an end.
It would follow that it is not eternal.
Furthermore, it wouldn't be true that it has no beginning.
So, it would have a beginning.
Therefore, whatever has an end has a beginning.


Are the premises true?

The word "eternal" might be taken to be by definition that which has no beginning and no end. However, these propositions assert more than what might be taken as just a question of definition, because they exclude the possibility that something which is not eternal might have an end with no beginning. In order to support their position, the authors of the article resort to a mathematical argument which dates back to http://plato.stanford.edu/entries/aristotle-mathematics/supplement3.html Aristotle and still continues to be debated today. The argument involves the distinction between actual infinities and potential infinities: 


  "Furthermore, it is evident that anything which has parts must have a
  whole, since a whole is merely the sum of its parts. Therefore, it is
  not possible for something infinite to be comprised of parts, because
  a part, by definition, is an amount separated from another amount, and
  through the part the whole is measured, as Euclides mentioned in the
  fifth treatise of his book of measures." ("http://dafyomireview.com/article.php?docid=398#ch5 Shaar HaYichud")


The authors are arguing that anything which has an end but no beginning would be an actual infinity because the idea of an end implies an actual limit as opposed to a potential limit. Although infinities of this type are conceivable as mathematical abstractions, many believe that their properties are too paradoxical to be considered real phenomena. The German mathematician, David Hilbert, tried to illustrate this problem by means of a thought experiment known as https://nrich.maths.org/5788 Hilbert's Hotel.

In order to better understand this argument, it helps to consider the distinction between the infinite by division and infinite by addition. A given distance, for instance, may be conceived to be infinitely divisible along its length, but there is a significant difference between that and an infinite series of real quantities. The Stanford Encyclopedia of Philosophy describes the problem encountered with actual infinites by addition:


  "[T]he only acceptable infinite series in actuality by addition would have to satisfy the same finitistic constraints. However, any such infinite series in actuality will be identical with
  some infinite series in actuality by division. Hence, there is no
  infinite actuality by addition for sizes or weights, etc. Aristotle's
  views on infinite time are less clear, but he is committed to some
  sense of an actual infinite by addition in the case of time (going
  into the past), but only in a weak sense, since past changes no longer
  exist." (Stanford Encyclopedia of Philosophy, "http://plato.stanford.edu/entries/aristotle-mathematics/supplement3.html The Infinite")


Although I don't intend to try to definitively answer this question of actual infinites, the resources provided are a good starting point for further study.
For Sartre's Being and Nothingness, we can see Paul Vincet Spade's http://pvspade.com/Sartre/pdf/sartre1.pdf Notes; unfortunately, the comment on Bad Faith (page 133) does not seem relevant to the point.

For the pair "immanence"/"transcendence" see Spade, page 37:


  what is “immanent” is mind-dependent. The correlative opposite, “transcendence”, means: not wholly contained in the mind, not really inhering in, not really a characteristic of, the mental act.
  
  So [...], the pair of terms “immanence”/“transcendence” means roughly “in
  the mind”/“outside the mind.”


This explanation fits with your point 1.

Bad faith is connected to lie, and thus to kowledge and truth/falshood [Sartre, page 48]. 

But it differs from lie in that bad faith is lying to one's self: it is a conscious assertion of a falsehood.

Lie is in relation with the "reality" outside of the consciousness; thus it is based on transcendence.
I consider the view of the first person (the subjective view) to hold the libertarian position and the view of the third person (the objective view) to hold the determinist position.

The compatibilist position is the view of most neuroscientists. They strive to resolve the opposites between both other views: To keep the subjective view, but to explain it by a deterministic approach.

A good introduction is Walter, Henrik: Neurophilosophy of free will: from libertarian illusions to a concept of natural autonomy (2001). 
If  you construct the https://en.wikipedia.org/wiki/Bayesian_network Bayesian network for this problem, like for the three die problem below, you won't find anything in the network's topology that implies any kind of ordering on the "is greater than" nodes, so there is no reason to think that there should be any sort of ordering on those nodes, since we have complete freedom in selecting the distributions over the "dice" nodes (i.e. we could make dice with any sets of numbers on the sides that we like).  Although counter-intuitive (like the https://en.wikipedia.org/wiki/Monty_Hall_problem Monty Hall problem), it is a non-problem when analyzed systematically.

Note, although Bayesian networks are most often applied with an underlying Bayesian interpretation, in this case it is just applied to decompose the overall probability distribution in terms of conditional probabilities.  No issues of interpretation arise, we're just given a fully specified game. And all parties can agree that these are the correct conditional relationships.

https://i.stack.imgur.com/WExVQ.png 
I think that the alienation of man by man is the result of the capability of individualization within the modern urbanized societies, due to the development of means of production and communication and as opposed to the traditional forms of society's existence. I have found the notion in the book of Jean-François Lyotard https://en.wikipedia.org/wiki/The_Postmodern_Condition The Postmodern Condition (as contradiction between the individual and society)

The notion of alienation is particularly important in the dialectical thought and philosophy and Marx uses the notion to that effect. https://en.wikipedia.org/wiki/Economic_and_Philosophic_Manuscripts_of_1844 Economical and Philosophical manuscripts.

In dialectics the being is constantly alienated through the becoming. 
The collective and individual existences are in constant change passing through the stages of Βeing, to the Being-for-itself, to the Being-in-itself, and ultimately leads to the for-itself- and in-itself-Being, the absolute -a new stage of dialectical movement (in Hegel's dialectics). 

Alienation has numerous meanings and functionalities, positive, negative and neutral. 
Marx points (in the manuscripts) that a dialectical movement seems to have evolved in the proletariat as it becomes the negation of its own self (the laborer alienated from its product) and this would lead to a further dialectical movement in the economical structure of the society. 

An analogy can be found between the idea of the alienation of the laborer and this of the alienation of man by man in contemporary societies, as each individual is stood on its own opposing and alienated to the means of production and economy. The vital connection between people, that emanates from his equal contribution and his equal status seems to have degraded. 

From another side it is always more complicated as it may appear, because people are divided in economical classes so the "individual" is not generally a "revolutionary subject of the history". This contrast is reflected in politics and the two perspectives are kind of divided with Marxists taking the side of "community" and opposing the "individual" which is the subject of "capitalism". 

By a dialectic perspective both stances can be considered "essentialisms" as the individual is the other of the society so you can't really separate them for long and at the same time they can not be joined completely. 
I don't think Nietzsche's last man refuses life. Rather, he accepts the life of a herd animal. No more exceptional human beings. 

According to Nietzsche in Genealogy, man will never find life intolerable. Near the end, he said something to the effect that man would rather will nothingness than not will at all. That would at least still be willing. 

Efforts to make life livable are not necessarily an affront to humanity. We all try to make life livable. Nietzsche himself tried to make life livable. It's all about what one considers livable, how one goes about living. 

Nietzsche laid out values that for him defined how he himself needed to live. For example, in the Antichrist, he said service of the truth is the hardest service. And then there's amor fati, eternal recurrence, be hard, courage, honesty with oneself, etc. 

What is making man undesirable are the values of the herd. These prevent great human beings, creators, legislators of new values -- values more conducive to human flourishing and growth. 
Part 1, question 2, article 3 from Aquinas, Thomas: Summa Theologiae enumerates five ways to prove the existence of God:

1) God as the first mover (primum movens)

2) God as first cause (causa efficiens prima)

3) God as necessary by himself (necessarium per se) 

4) God as cause of being, and goodness (causa esse, bonitatis, perfectionis)

5) God as the designer of the ends (causa finalis).

The first way is taken from Aristotle’s Physics, book VII and VIII. The second way is taken from Aristotle’s Metaphysics, book II. The third way is similar to a reasoning from Aristotle’s Metaphysics, book XII. But Thomas changes the argument supporting the claim that not everything passes away.

I agree, inductive reasoning and starting the chain of reasoning with a first cause is common to all five ways, not only to the first three. 

My conclusion:


Thomas did not aim to generalize all "proofs" to the abstract principle of the impossibility of an infinite regress. Instead, his aim was always to recall explicitly as many arguments as possible from Aristotle. Because Thomas wants to show that a huge part of Aristotle’s philosophy (reason) justifies the argumentation from theological statements (faith).
In addition, if people are not used to the abstract level of principles, possibly one can convince them by appealing to specific and concrete examples of a principle in question.        

To my mind, Lakatos's approach does not resist Kuhn, or mediate between Kuhn and Popper.  It fully accepts Kuhn, and just solves a problem in his framing (whether Lakatos himself saw it that way or not.)  It allows for 'ongoing revolution'.

One main problem with Kuhn for a lot of people is that neither strictly normal nor strictly revolutionary science seems to happen very often.  Normal scientists do tweak theories.  Revolutions don't halt the ongoing process of normal science.  There is always something halfway in-between.

Even in the most rigid periods of science, theories evolve and do not just elaborate.  And even during clearly revolutionary periods, we see piecemeal advancement that remains dependent upon some of the old paradigm and yet usually gets integrated into the new one.

The awareness of Lakatos's 'divider' between 'the core and the mantle' of a paradigm, and the idea that it moves back and forth (or rather in and out), including more or less material in the core, allows for a notion of ongoing normal and revolutionary science to happen in parallel.
It does make sense in a way. Kripke's thesis is that proper names have essences, properties that belong to them of necessity, not accidentally. Putnam extended this thesis to "natural kinds" of objects, whose essential properties "carve nature at the joints", in Plato's metaphor, rather than according to our cultural biases, practical needs, etc., those would be the "artificial kinds". 

This provides a semantic framework for a realist ontology, as opposed to semantic theories of Quine and Wittgenstein that reduce meaning to use in a language game, which requires no realist referents, or deny such referents to "natural kinds", which only acquire meaning as placeholders in a theoretical "web of belief". E.g. gold, water, etc., only mean in the context of chemistry, which relates to experience only as a whole, and reflects pragmatic human considerations as much as nature. Of course, if "natural kinds" do "carve nature at the joints" then there is something "in nature" corresponding to them, even if we do not yet discern it fully and precisely. This provides a framework where Kripke-Putnam reference is preserved across scientific revolutions despite Kuhn's "incommensurable paradigms", this promise of continuity is what attracted Putnam in 1970s, when he was still a realist, and others. Rigid designation is tangential to this, it enters only in that if we believe in nature given "essential properties" then it makes sense to keep them fixed across possible worlds when analyzing "physical" counterfactuals. http://www.richmond-philosophy.net/rjp/back_issues/rjp3_norris.pdf Norris's Realism, Reference, & Possible Worlds makes the case for essentialism as an aid to realism along the lines of Putnam of 1970s and the OP quoted lecture.

However, Kripke's essentialism is not "a path back to scientific realism", that would be putting the cart before the horse. It works if we presuppose a form of scientific realism, that would be https://en.wikipedia.org/wiki/Scientific_essentialism scientific essentialism, but in itself it is a semantic theory that purports to describe use of language based on speakers' "linguistic intuitions" (similarly rigid designation purports to account for "modal intuitions"), not metaphysics. Ironically, Kripke himself is partial to Wittgenstein, and Putnam apparently discarded even his very weak "internal realism", which was of Quinean pseudo-variety. 

That folk intuitions are faithful to "reality" is also highly doubtful, or as Cummins put it "there is no more reason to think that innate philosophy is a good basis for philosophy than that innate physics is a good basis for physics". Cummins's https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxyb2JlcnRjdW1taW5zcGhpbG9zb3BoeXxneDoyZWEzNTQ5MjgyNmNhY2Fl Reflections on Relective Equilibrium is a sharp critique of Kripke-Putnam's approach in general:"It is commonplace for researchers in the Theory of Content to proceed as if the relevant intuitions were undisputed. Nor is the reason for this practice far to seek. The Putnamian take on these cases is widely enough shared to allow for a range of thriving intramural sports among believers. Those who do not share the intuition are simply not invited to the games". Recently even semantic adequacy of Kripke-Putnam's theory of natural kinds has come under fire, see https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxyb2JlcnRjdW1taW5zcGhpbG9zb3BoeXxneDoyZWEzNTQ5MjgyNmNhY2Fl Ben-Yami's Natural Kind Terms.
"However, to 'understand what it is for thought to be determinate' requires that such a thought is itself determinate."  This does not seem to be the case.

Determinacy simply is not necessary to establish reference to a meaning or an argument.  We are perfectly happy with a range of potential references that share adequate traits to satisfy similar patterns and capture the relevant aspects of the meaning.

Arguing entirely from constraints, and relying entirely upon references as bundles of constraints is a perfectly reasonable way of establishing a consistent model between humans: we confirm shared perceptions all the time on that basis.  It is not necessary for our actual perceptions to literally refer to parallel experiences.  They don't.  We can still share a perceptual field.  In the same way, it is not necessary for arguments to construct similar effects upon individuals' thinking.  They very likely never do.  But we can still share a robust conceptual field.

In that way, we can have a cohesive notion of anything we could describe determinately, including determinacy, which is adequate to establish the understanding of humans about the meaning, even if it does not somehow construct a single point of reference in any semantic field.  And we are free to argue from that concept as long as the constraints faithfully express its structure.

If perception is indeterminate and provides the basis for our points of reference, and even our very idea of referring to things, it seems silly to consider thought determinate.

< Long aside if you think perception is determinate >

We have good evidence that perception works by pattern-matching, and not by assembly from elements.  The sense data is not collected and collated and then assembled into a cohesive model of the sensed world.  Instead, the model is constructed and reality is probed for confirmation of the presumed representation.  Only if the representation fails tests against reality is it altered.  Change-blindness, very hard to explain in a world where sensation is 'determinate', is the natural order of things.

We can verify that the information flows in this direction, out from the presumed model rather than in from the surface, by looking at the priming of responses to experiences like emotions or reflexes, which are planned for by our physiology too far ahead of the actual experience for the information to move the other direction, coming in from the environment.

This explains, among other things, why we think we can 'see around' the hole in our visual field imposed by the optic nerve site.  Its constant presence ensures that it never introduces contradictory information.  Similar logic explains why various other sensory illusions that appear in isolation do not really confuse us in real life.  But it rules out the notion that we actually share internal models of what we perceive.

< / Long aside >

One can argue from a mathematical point of view that thought must be determinate in some domain established as the factorization of the real domain through the filter of the patterns of constraints that allow things to match.  But the odds of those patterns actually establishing anything close enough to an equivalence relation are very low, and it seems almost guaranteed that they are not consistent.

So there is no good reason to think that the notion of determinacy is an aspect of thought, or that this matters.  It is a convenient simplifying fiction, but is neither sufficient nor necessary, and it seems inconsistent with the way a large part of our experience works.
It is reffered to the concept of epistemic violence put forward by foucault. You violate agents who are irreductibly heterogeneous by amassing them all under a category such as "black". It was fairly useful for post-colonialist philosophers to dismantle the ideas created by european intellectuals about the so called third world.

For example, the very category "indian" would hardly be used by the dwellers of that sub-continent to describe themselves, until it became politically useful and after the nationalist indian movement, that became a staple category in indian politics. However, it was mainly advanced by the Brittish to refer to the hindus in their fight against the muslim Mughal rulers who challenged their dominance
"True randomness" and "exists" are two concepts that are notoriously hard to pin down, so it is hard to give a straight up answer, but here are two directions of thought.

You can consider the idea that the digits of normal numbers conform to the formal results of probability theory; that's what it means to have proven that they exist mathematically.  But now, what you've done is established that this one type of formal/conceptual objects stands in a particular relation to these other formal/conceptual objects.  Is that existing? If you are a mathematical realist, then sure, they exist.  But if you are a mathematical realist, you probably (ha!) don't have a problem with the existence of (formally defined) randomness in the first place. If you reject the "existence" of purely formal objects, then this formal relationship between concepts won't impress you much.

Sticking to the real world.  Given one of these numbers we could construct a seeming perfect random number generator -- a machine/program that can construct more and more of the digits of one of the numbers and provide it to you.  But is this really random?  Some people could argue that it's not really random since the particular sequence of digits constructed by this machine was fixed (determined) by the normal number that was used to "seed" it.  Conversely, if you take a more empirical approach, you might contend that its output is random, since by any computable measure it "looks random".
In the relevant sense the answer is "no", the appearance of a "yes" is created by projecting classical intuitions about locality onto quantum objects. This is confusing because the definition of locality adopted in classical physics becomes misleading when transplanted into quantum physics. "Quantum non-locality" of entanglement is a misnomer, rather than demonstrate non-locality entanglement demostrates non-classicality, that the language of "objects" and "points" is inappropriate in quantum theory due to indeterminacy. Entangled quantum pair is not two separate objects that "coordinate" across long distances instantaneously, it is a single distributed "quantum object" described by a joint wave function. It can "split" in two when observations are made, which is why we are tempted by classical intuitions to think of it as an interacting pair. 

If we imagine it as something like two interacting classical objects then there are restrictions on how much their behaviors can correlate called https://en.wikipedia.org/wiki/Bell's_theorem#Overview Bell inequalities. "Quantum non-locality" refers to the fact that they are violated for entangled pairs. What this reflects however is that quantum objects can fuse (entangle) and come apart (decohere) in a way classical objects can not, not non-locality, despite the common phrasing in popular sources. Even in quantum mechanics, which is non-relativistic, entanglement violations of Bell inequalities still do not allow energy, mass or information to travel instantaneously despite the appearances caused by classical anticipations. This is https://en.wikipedia.org/wiki/No-communication_theorem Bohm's no-signalling theorem.

On the other hand, quantum field theory (Standard Model), which is the governing theory in modern physics, is relativistic, which means that it explicitly requires all interactions to spread no faster than the speed of light, or in 4D picture, influence of any event is confined to its future light cone. The same Wikipidea article you linked states in https://en.wikipedia.org/wiki/Principle_of_locality#Relativity subsection on relativity:"Locality is one of the axioms of relativistic quantum field theory, as required for causality. The formalization of locality in this case is as follows: if we have two observables, each localized within two distinct spacetime regions which happen to be at a spacelike separation from each other, the observables must commute". Translation: no interaction is possible between regions of spacetime that can not be connected by trajectory of a photon ("spacelike separated"). So not only does entanglement not contradict the relevant notion of locality, but locality is one of the axioms of the theory that describes it. 

For the relation of Bell inequalities to local realism and determinism see https://philosophy.stackexchange.com/questions/33421/doesnt-superdeterminism-follow-from-einsteins-local-realism-in-quantum-mechani/33443#33443 Does Einstein's local realism in quantum mechanics imply superdeterminism? Whether we call violations of Bell inequalities non-locality or not, they allow for some remarkable phenomena like sending dense messages over a channel seemingly lacking capacity to carry them ("superdense coding"), or creating "remote copies" of quantum systems, while destroying the originals ("quantum teleportation"). An illuminating philosophical discussion of issues surrounding entanglement, like realism, locality, causality, relativity, etc., in various interpretations of quantum mechanics is http://arxiv.org/abs/quant-ph/0212140 Timpson and Brown's Entanglement and Relativity.
Answer: No, Scitovsky's view does not disprove utilitarianism. On the contrary, 
utilitarianism, interpreted appropriately, vindicates that Scitovsky's intuition in Joyless Economy is correct. 

I take it that the point of Scitovsky's Joyless Economy is that economic policy of a nation that aims to increase material wealth (e.g. GDP) will eventually lead to the people of ennui: happiness obtained from consuming material goods will reach a satiation point, and once reached, people will become bored or pervertic in their preferences to gain more pleasure out of their consumption (like the guy in the 50 shades of something on carnal knowledge). Scitovsky thus asserts that the govt should guide the consumption habits of the people to the direction of unbounded joy: the enjoyment of arts and nature, which lacks the satiation point.

You are right if, by utilitarianism, you mean Benthamite utilitarianism that identifies happiness with hedonism. The pursuit of hedonistic pleasures will eventually lead to joyless pleasures.  The utilitarianism is susceptible to Scitovsky's criticism. 

But Mill's utilitarianism is not hedonistic. Mill maintains that hedonistic pleasures are pleasures fit for pigs. The kind of pleasures that properly belongs to human beings is not derived from sensations or mental states. To Mill (a la David Brink) pleasures appropriate for humans are activities rooted in rational capacities. The human-proper pleasures obtain when we are deliberating on the good, writing a novel, or running a super-marathon. This view of human happiness actually coincides with Aristotle's notion of happiness (it is well established that Mill's existential angst resulted in taking Aristotelian view of happiness, despite his father's Benthamite indoctrination)     

Mill and Aristotle's view of happiness, when applied to political philosophy, is called the perfectionist public policy. The goal of the perfectionist policy is to help people to live a good life. To this end, the gov might guide the consumption habits of the people by imposing the soda tax. It might encourage people to go to classical music concerts and discourage them watching *Rick and Morty."' Rawls criticized perfectionism for being illiberal and paternalistic. The debate between perfectionists and Rawlsians still continues.

Thus, Mill's utilitarianism actually explains why welfare economy can lead to joyless economy and provides different policy directions as delineated by  Scitovsky.
I would like to emphasize the differences between the three cases:

1) The fair coin: We know the probability distribution of the single experiment - both results have the same probability p = 1/2. Using the law of large numbers we can mathematically derive how the result of many tosses approaches this distribution.

2) Statistical mechanics: We hypothesize that the molecules obey the lays of Newton mechanics. Then we can mathematically derive that the mean values of the observables satisfies the laws of thermodynamics, e.g., pV = RT (state equation of the ideal gas)  

3) The fundamental laws are the laws of quantum mechanics itself, e.g., the Schroedinger equation. We do not know other laws from which the laws of quantum mechanics can be derived mathematically.

Hence: The laws of quantum mechanics cannot be derived mathematically as in the example 1) and 2)?
Zeno's paradox occurs in a continuous space.  It isn't about taking individual step, it's about a series of events which must occur before you reach your destination if you are moving continuously.

It's impossible to get to the destination without first getting half way there.  It's impossible to get half way there without first getting a quarter of the way there.  And so on.

The theory was that it would take an infinite number of such events occurring, in order, before you could get to your destination.  Thus, it "should be impossible."

If you indeed have a discrete world, such as "I am two steps away from my destination," and you only consider discrete transitions from the start of your walk, to half way, to completed, Zeno's paradox does not apply.  However, if someone were to stand in your way 1.3 steps into your "discrete" walk and try to impede your motion, you would find this discrete model is not a good model of reality.  Reality is typically considered more continuous than that.

Zeno's paradox still has its place in philosophy, but the physical application of it regarding movement in the real world has been displaced by calculus.  In calculus, we can use limits to manage these infinite strings of events in a way which modern physicists and engineers have found sufficiently valid that we no longer mind these sorts of paradoxes which create an infinite string of infinitely small events (or, to be more precise, we have very strict criteria as to which strings of events are physically realizable and which ones are not, typically formalized as epsilon-delta proofs.  Zeno's original paradox is physically realizable)
Bell's inequality doesn't say that there can't be any hidden variables. What it says is that any theory consistent with quantum mechanics can't have hidden variables that are both causal and local. 

David Bohm's hidden variable theory, for example, is consistent with quantum mechanics but is non-local.

As to your point about pre-determined systems. The key point is that one can set up a quantum system whereby a random event in one part of that system can affect the state in another part faster than message could be sent. Sure you can argue that the original system "knew" about the state of the random event generator before it started but this very swiftly gets into the realms of magic.  
This brand of radical doubt was in use in Buddhism since over two and a half thousand years to facilitate detachment and mental calming.  The wisdom behind it was that humans are driven by instinct to strive, fight, crave etc. so by being aware of the manipulative nature of base instincts they can be curbed.  This leads to the idea that appearances are generally deceptive, summed up in the concept of Maya.


  It is all like a mirage in which springs of water are seen as if they
  were real. They are thus imagined by animals who, made thirsty by the
  heat of the season, run after them. Animals, not knowing that the
  springs are an hallucination of their own minds, do not realise that
  there are no such springs.


http://www.sacred-texts.com/bud/bb/bb08.htm A Buddhist Bible, page 49

As for using "intuition to grasp what reality actually is", this is indeed all you have to go on.  You can never be sure at which point you may be completely mistaken about something, but you can take a punt.  Still it's a shot in the dark and you might be wrong.
Descartes himself considers the question how we can have false beliefs, given our having been created by a perfect God in the Fourth Meditation. The ultimate answer, Descartes thinks, is because God has given us a power to know the true from the false, but that power is limited, not infinite. Therefore, when we use our intellects to think about things beyond the scope God designed them to work for, we fall into error. In other words, it isn't God's fault we have false beliefs. It is our fault for using our minds improperly.


  And no doubt respecting this matter could remain, if it were not that
  the consequence would seem to follow that I can thus never be
  deceived; for if I hold all that I possess from God, and if He has not
  placed in me the capacity for error, it seems as though I could never
  fall into error. And it is true that when I think only of God [and
  direct my mind wholly to Him],18 I discover [in myself] no cause of
  error, or falsity; yet directly afterwards, when recurring to myself,
  experience shows me that I am nevertheless subject to an infinitude of
  errors, as to which, when we come to investigate them more closely, I
  notice that not only is there a real and positive idea of God or of a
  Being of supreme perfection present to my mind, but also, so to speak,
  a certain negative idea of nothing, that is, of that which is
  infinitely removed from any kind of perfection; and that I am in a
  sense something intermediate between God and nought, i.e. placed in
  such a manner between the supreme Being and non-being, that there is
  in truth nothing in me that can lead to error in so far as a sovereign
  Being has formed me; but that, as I in some degree participate
  likewise in nought or in non-being, i.e. in so far as I am not myself
  the supreme Being, and as I find myself subject to an infinitude of
  imperfections, I ought not to be astonished if I should fall into
  error. Thus do I recognise that error, in so far as it is such, is not
  a real thing depending on God, but simply a defect; and therefore, in
  order to fall into it, that I have no need to possess a special
  faculty given me by God for this very purpose, but that I fall into
  error from the fact that the power given me by God for the purpose of
  distinguishing truth from error is not infinite. [emphasis mine.]


You'll find, if you continue reading on after this passage how Descartes thinks the will enters into this picture.
I think you're misunderstanding what's going on in this passage. The "freedom" Heidegger speaks of here isn't what I understand by "freedom" in a particularly political sense (at least not in the first instance). Heidegger's use of the word "freedom" here derives from the conversations in German philosophy of his time. Pertinent to this is Schelling's Philosophical Investigations into the Essence of Human Freedom, where Schelling writes that "free is what acts only in accord with the laws of its own being and is determined by nothing else either in or outside itself." Freedom, in this sense, is the capacity to be what one is.

A key to understanding what Heidegger means by freedom is in §40 (p. 182), where he writes:


  Anxiety reveals in Dasein its being toward its ownmost potentiality
  of being, that is, being free for the freedom of choosing and grasping itself. Anxiety brings Dasein before its being free for ... (propensio in) the authenticity of its being as possibility which it always already is.


Freedom [Freiheit] here isn't a goal, its more precisely a characteristic of Dasein that it always already is. The freedom in question is its freedom to choose and grasp itself [Sich-selbst-wählens und -ergreifens], i.e. to take itself up as it is. Hence, in the same passage he writes:


  But, at the same time, it is this being to which Dasein as being-in-the-world is entrusted.


In short, the freedom at stake isn't "the power or right to act, speak, or think as one wants" (or something along those lines) but rather the freedom to be what one always already is. This freedom is the condition for the possibility of their being something like "authentic, existentially projected being-towards-death" at all. More precisely, this "freedom" is the condition of possibility of the authentic / inauthentic relationship that Dasein can have with itself. Thus, in §41 / p.185, he writes:


  Being free for its ownmost potentiality-for-being, and thus for the possibility of authenticity and inauthenticity, shows itself in a primordial, elemental concretion in anxiety.


One can object that "freedom" isn't what is at stake here. Very well, but that's to use another conception of freedom from the one Heidegger develops throughout Being and Time.
You can look at this through the lens of "Mathematical fictionalism" http://plato.stanford.edu/entries/fictionalism-mathematics/ http://plato.stanford.edu/entries/fictionalism-mathematics/ and the related sort of bounded dialethianism that results, allowing contradiction to harmlessly exist all over the place, even in something like Classical Logic.

The issue is not whether there is a consistent model of the universe.  You can assume from the start that there just isn't.  The question is how large your universe of discourse can get before it degenerates, instead.  Something like Russell's paradox is a real contradiction inside Classical logic, but it is seldom entailed by anything, so it can just stay there, and other parts of the universe can still be useful.  The resulting universe is huge and such large parts of it 'conserve truth', that it is worth having on hand as a tool.

If you take this notion of separate fictional universes seriously, but deny their fictionality from a Meinongian point of view, then yes, these things exist, but they cause the universes in which they would/do exist to be quite small, since they run into contradiction very quickly.  Very little can be said that conserves the truth of its premises, unless none of the subjects involved have shapes.
Waking Life is somewhat sui generis, but I would highly recommend "https://en.wikipedia.org/wiki/The_Possibility_of_Hope The Possibility of Hope," a documentary by Gravity director Alfonso Cuaron, included as a DVD extra with his incredible http://popculturephilosopher.com/top-ten-movies-children-of-men/ Children of Men.  Depending on your opinion of Slavoj Zizek, you might also enjoy his "https://en.wikipedia.org/wiki/The_Pervert%27s_Guide_to_Cinema Pervert's Guide to Cinema."  A movie that is less explicitly philosophical, but that shares some similar themes of reality and identity (as well as a certain psychedelic sensibility) is the Gondry/Kaufman classic "http://popculturephilosopher.com/reconstructivist-art-eternal-sunshine/ Eternal Sunshine of the Spotless Mind."

If it was the style of the film that appealed to you, I can't immediately identify any full-length animated films that are comparable, but there are some excellent philosophical shorts, including https://www.youtube.com/watch?v=cCeeTfsm8bk More, https://www.youtube.com/watch?v=79PmZVhb0DM Vrykutasy, and https://www.youtube.com/watch?v=1CTesYaduBA Balance.  There's also Dan Hertzfield's https://www.youtube.com/watch?v=1IUX0Qy-IDM Everything Will Be OK and https://www.youtube.com/watch?v=XdV1uFwtCpo World Of Tomorrow.

As far as I know you are correct in thinking that established academic philosophers don't take non-Abrahamic Western religions in general and neopagan religions in particular seriously. Some religion fare better than other. However as you yourself show (by stats on Buddhism and Hinduism), some major eastern religions are do considered.
There might be quite a few reasons why neo-pagans are not taken seriously  -

1) Neo Paganism is actually a newer phenonmenon that claims to derive from earlier historical pagan beliefs. This means that a set of beliefs that was lost was given life by entirely different people, much later, who only developed their beliefs from the texts and other sources. The lack of continuity and tradition raises severe questions as to whether neo-pagans are actually following the same religion they claim to derive from.

2) Major religions that exist today are dependent on either a miraculous event or a person that is said to have possessed some supernatural powers or divine revelation. With Neo Paganism, the question of origin is simply not a question. Without an authoritative figure, they are rendered too plastic, and neo Pagans differ on many issues. Hence it is difficult to determine whether the beliefs that neo Pagan holds are a result of that person's prior beliefs or beliefs or experiences that he gained from Neo Paganism.

3) One feature of Neo Pagans that seem to unite them somewhat is that they believe in some sort of magic. The important point is that, as magic and rituals can alter reality, or are claimed generally, they can be actually tested. Hence such a religion can be proved by an actual test and thus is not of much significance in philosophical discussions, as a person who want to establish validity of that religion can actually demonstrate that by experiment.

4) The "core" beliefs and ideas of Neo Pagans are actually discussed (or have been discussed) by philosophers. Collective Consciousness, Idealism, are taken somewhat seriously. However they have are neither completely Neo Pagan beliefs nor they have necessarily been looked into because of Paganism. Hence some interesting parts of Neo Paganism are discussed but under other contexts.
and 4. I do not think that Neo Pagans do present their beliefs in such a manner as can be critiqued by philosophers, or are interesting to them. However some philosophies that share some properties with Neo Pagan beliefs are considered.


You can search for Collective Consciousness, Idealism, Jungian archetypes, Animism, etc. to know what philosophers think aout the ideas that resemble some beliefs of Neo Pagans.
And if you look in it, polytheism, animism etc., are generally easier to explain by anthropology etc. than beliefs of major non neo-pagan religions and thus have gone out of favour. It is hard to approach these beliefs from modern Science and they do not even have a clear epistemic justification based on other fields like history etc. You can say that materialism and naturalism made it hard for them to survive in academic circles. 
1) Concerning Logical Positivism see Audi, Robert (Ed.): The Cambridge Dictionary of Philosophy:

“logical positivism, also called positivism, a philosophical movement inspired by empiricism and verificationism. … The driving force of positivism may well have been adherence to the verifiability criterion for the meaningfulness of cognitive statements. Acceptance of this principle led positivists to reject as problematic many assertion of religion, morality, and the kind of philosophy they described as metaphysics.”

Concerning the verifiability criterion of meaning:
“they [all positivists] were convinced that a genuine contingent assertion about the world must be verifiable through experience or observation.” 
Concerning necessary truths:
“Another central tenet of logical positivism is that all meaningful statements fall into two categories: necessary truths that are analytic and knowbale a priori, and contingent truths that are syntheric and knowable only a posteriori.”

2) Conversely, Scientism is a term with no sharp boundaries. It comprises a much broader spectrum of meanings than the term Logical Positivism. 

In addition scientism is often used as a fighting word against any attempt to transfer the methodological ideal of natural sciences to the humanities and to sociology. 


E.g., “Scientism is a matter of putting too high a value on natural science in comparison with other branches of learning or culture.” (ascribed to Tom Sorel) or 
“Science, modeled on the natural sciences, is the only source of real knowledge.” (ascribed to Ian Hutchinson) 


see http://www.aaas.org/page/what-scientism http://www.aaas.org/page/what-scientism

In the 1960th the term was used by members of the Frankfurt School (Adorno, Habermas) as an accusation against the Critical School (Popper, Albert). The former critized the concept of freedom from value judgement (Wertfreiheit) of science as well as the scientific concepts of judgement and truth.

Apparently, scientism is compatible with Logical Positivism.
Both theist and atheist claim that they accept facts. Facts just happen. The difference is their explanation of the facts.

A theist has a personal world model with a certain god as the base concept of his model. While an atheist often employs a naturalistic word model, based on natural science. This model operates without a personal creator and controller of the world.

As a consequence, the atheistic world model has to leave open some questions. Questions where the theistic model offers the god concept as an anthromorphic explanation. 

Conversely, the god concept of the theistic model is at risk of being contradictory. At least, it creates several delicate questions, e.g., the compatibility of omnipotence, omniscience, and being omnigracious. But also the compatibility of omniscience and the free will of man.

Summing up for a short answer to your question: Also the theist accepts any brute facts about the natural world, but he uses a different model than the atheist to explain these facts.  
It's just the https://en.wikipedia.org/wiki/Fallacy_of_composition fallacy of composition. The person is reasoning: It is possible for me to make money on a single hand, therefore it is possible for me to make money on a (sufficiently large) set of hands. The inference is incorrect, for the reason you mention above.
You raise a diverse range of questions, which I'll try to address in some form.

Lyotard is not really the "founder" of postmodernism, though his book is sometimes understood as something of a manifesto of postmodernism. Lyotard presents "postmodernism" as a name for something already in progress, a name which summarises what philosophers have been up to in developed industrial societies. The term "postmodernism" itself was used prior to Lyotard's book. It was possibly coined the American poet https://en.m.wikipedia.org/wiki/Charles_Olson Charles Olson. Whether what Olson meant by postmodernism is the same as what Lyotard meant is debatable. Perry Anderson, in his The Origins of Postmodernity (from which that Wikipedia quote is drawn), claims that Lyotard got the word from https://en.m.wikipedia.org/wiki/Ihab_Hassan Ihab Hassan. In any case, it had been used in art criticism and architecture prior to Lyotard. Hence, http://plato.stanford.edu/entries/postmodernism/ Gary Aylesworth's assertion that "postmodernism" "first entered the philosophical lexicon" through Lyotard's book is probably the most accurate way of phrasing things. Lyotard uses the word "postmodernism" to characterise a range of philosophical views that share certain concerns.

When, in the interview Wikipedia cites, Lyotard says that he had a "less than limited" knowledge it should be read, in part, as something of a joke, similar to what he explains in the introduction to the original report:


  the author [of this report] is not exactly an expert; he is a philosopher. An expert knows what he knows and what he does not know, because an expert knows what knowledge is in his game. By doing me the honour of addressing his order to the philosopher that I am, the President of the Council of Universities with the Government of Quebec obviously knows that I do not know what knowledge is in the most developed industrial societies [(this being the subject the report was devoted to)]. He simply asked that I question it....
  
  Les problèmes du savoir dans les sociétés industrielles les plus développées, p.2. (My translation)


Lyotard here is having a bit of fun (indeed, he is explaining, in the introduction, why the report is a failure): he has been asked to produce this report but "obviously" it is on a topic he is not an expert in. Nor is such an expert what is required; after all, an expert already knows what knowledge is but can only tell you what he already knows, because an expert's notion of knowledge is only knowledge within a certain language-game (Lyotard makes fairly heavy use of Wittgensteinian "language-games"). Instead, the report is written by a philosopher because what is required is not expertise, but a willingness to question which is foreclosed to the expert who already knows what knowledge is and thus has no need to ask.

At one level, this is just fun and games (and Lyotard's language in the passage cited above is quite over-the-top), but it also establishes a serious point: there isn't just one mode of knowing, but several; there isn't just one way of responding to the demand that prompts Lyotard's report, but several. In some ways, this has been well-known. Traditionally, from Plato and perhaps before, philosophers have argued that philosophy is different from expertise, and that what philosophy aims at ("wisdom") is superior to expertise. While making something like this first move (philosophy is something other than expertise) Lyotard doesn't try to make this second move; there are different forms of knowing (expertise, philosophy, etc.) and the point is to attend to these differences. Expertise is not required because "knowledge" is no longer understood as a single thing; rather, there are a range and variety of "knowledges" depending on the language-game one is engaged in. It's this distinction between "knowledges" and the transformation that it produces in our notion of "knowledge" that is the subject of Lyotard's report, not "the influence of technology on the exact sciences" as Wikipedia claims. (Despite the citations, neither of Wikipedia's sources reinforce this claim; Bruneault claims that Lyotard's report was written on the legitimisation of scientific knowledge and Perry speaks of it as dealing with "the epistemological fate of the natural sciences," p. 26).

Despite the occasional humorous tones, postmodernism isn't just jokes or parodies. Where they are used, they are in the service of more serious points, but with the conviction that how a point is argued can be as important as what is argued per se. This is often seen (as with Lyotard) as an implication of a consistent application of speech-act theory: arguments aren't just formal propositions; they should enact what they theorise.
Even if it was (by transplant) "a cat's tail" (phenomenological), it would still be Gabriel's tail (i.e. the tail of Gabriel, possessive/as a predicate), and since Gabriel is a wolf, it would be the tail of a wolf, namely of Gabriel the wolf (possessive/as a predicate).

Therefore, it is a clean deduction, though perhaps a bit clumsy in the formulation.

Addition including the comment of @quen_tin: The reason why the formulation is clumsy is that the fine differences between "tail of a wolf" and "wolf tail" make the difference between deduction and induction or possibly (as this is a single occurence) even more precise: http://plato.stanford.edu/entries/abduction/ Abduction.
In Boolean Logic, the answer is no. For any statement (A) in a set of possible statements (or propositions), there is exactly one unique opposite statement (¬A). 

There can be multiple distinct propositions B,C,D,....such that  A ∧ B = FALSE, A ∧ C = FALSE, A ∧ D = FALSE. And there can be multiple distinct propositions I,J,K,...such that A ∨ I  = TRUE, A ∨ J  = TRUE, A ∨ K  = TRUE,...

But there can be only one unique proposition that satisfies the conditions: 


A ∧ ¬A = FALSE 
A ∨ ¬A  = TRUE.
¬¬A = A


This is because the rules of Boolean Logic lead to a mathematical structure called an https://en.wikipedia.org/wiki/Complemented_lattice#Orthocomplementation orthocomplemented lattice. 

Consider the set of days of the week: 

The proposition "Today is Monday" is not the opposite of "Today is Tuesday" because even though the statement   ["Today is Monday" and "Today is Tuesday"] is always False, the statement ["Today is Monday" or "Today is Tuesday"] is not always True. 

The proposition "Today is Tuesday" has one unique opposite proposition which is "Today is either Monday, or Wednesday, or Thursday, or Friday or Saturday, or Sunday".

However, in other forms of logic, such as some - but not all - https://en.wikipedia.org/wiki/Fuzzy_logic Fuzzy Logics, or https://en.wikipedia.org/wiki/Quantum_logic Quantum Logics, it is possible for a single proposition to have more than one opposite. This is because such logics lead to different structures which are described by https://en.wikipedia.org/wiki/Complemented_lattice#Orthomodular_lattices orthomodular lattices instead of orthocompelmented lattices. 

In particular, in Quantum Logic, the reason why one proposition can have more than one opposite or complement is because just as in your initial example, statements are represented as vectors in multiple dimensional Hilbert Spaces, instead of being represented as subsets of a Boolean Algebra. 
There seem to be several overlapping concerns in your issue with proof by contradiction.


You have an objection to the truth table for material implication:



  I've never been satisfied with the argument that two false propositions create a true implication however. What good justifications are there for agreeing with this?



You seem to misunderstand proof by contradiction:



  
  Show that p -> q, where "->" is the conditional. 2. Show that q is false. 3. Deduce from a truth table that p must be false.
  


I will start with the second issue. I'd say a better definition of proof by contradiction is as follows:


Given P, A
Given P, not A
Ergo, given P, A & not A
Thus, not P  due to contradiction when P


This is somewhat related to material implication as you rightly note. But this is not really about proving A false -- it's about proving A & not A simultaneously true. But since this is impossible on standard logics, then we must have erred in accepting P, therefore not P. 

Returning to the topic of standard logics, we can partially address your concerns about material implication. There's three fundamental rules that classical logic follows:


Law of Identity - we need to mean the same thing by the same thing every time. (we cannot change the meaning of variables and terms mid argument).
Law of Excluded Middle - every proposition we address must be either true or false (and just one of the two on this meaning of or).
Law of Non-Contradiction - we can not accept that both A and its opposite (not A) are true at the same time.


We can also express this succinctly:


A = A
For any A, true or false
not (A and not A)


Material implication is a logical operator that operates on two terms and lives in this world. Its purpose is to work with conditions, i.e. places where the value of one variable depends on another. Given that we have 2 variables which (per rule 2 can each have two values), we have four possibilities.

For A -> B,


A is true and B is true
A is true and B is false
A is false and B is true
A is false and B is false


What implication does is test whether the implication holds. Thus, we accept that it holds (see the entire implication as true) when A is true and B is true. We also should be able to see that the implication is false when A is true but B is false.

The situation is a bit more complicated and confusing when A is false (if we are thinking "if, then" rather than just accepting it as an operator). Most recently, the explanation I've been giving in my classes is as follows, 


  When A is false, we don't have a chance to check whether or not the implication holds directly. But given the three laws (particularly 2), we must declare this to be either true or false. Given that, we have not disproved the implication, it remains true for our purposes.


But the thing is, we don't specifically need this for proof by contradiction, because in proof by contradiction what we've done is show that some assumption P leads to a contradiction. And contradictions are unacceptable based on the third rule. Ergo, the assumption itself must be rejected. 
http://www.iep.utm.edu/divine-c/ Some theistic bases for morality do not require consequentialism as typically defined.  If what god wills is good, then it's good whatever the consequences.  

More generally, addressing the perceived problems involved in "http://plato.stanford.edu/entries/consequentialism/#ConWhaRigRelRul killing one person to use his/her organs to save eight others" (the "transplant" problem) often requires appealing to (or making a case that is essentially equivalent to) abstract human rights like self autonomy that start to seem like supra-consequentialist considerations.  Consideration of the problems raised by "https://en.wikipedia.org/wiki/Utility_monster utility monsters" can also lead to similar solutions.  If you accept the idea of inalienable rights, then you've moved beyond strict consequentialism.

There is a bit of ambiguity in the language: if you choose to count the "affront to god" or "violation of human rights" as a consequence then you might be able to pull these kinds of ideas within some moral framework that could be called "consequentialist", but this is more of an issue of the ambiguity of language than anything else.
While it's kind of funny to say an unorthodox stance for a utilitarian to take about Mill considering he's the most famous Utilitarian there is, I think your point is something like this:


"Utilitarians" are all about pleasure.
Therefore, it's weird for them  to then be obsessed with pain, which is generally taken to be the opposite of pleasure.


There's two ways of explaining why Mill is doing this.

First, there's what I will call the "hedonist ratchet."  And that's this pattern:


Pleasure is good.
Therefore drinking is good. (assuming it produces pleasure)
Thus, drinking more = better...  (maximal pursuit of pleasure)
But hangovers are very unpleasant  = bad.
Drinking + hangover is pretty bad and seems worse than not drinking in the first place.


This functions as a kind of reductio against maximal pursuit. But if we want to maintain that pleasure is good (and we should pursue it), we now need a more complicated plan.

= we need to do a calculus (= calculation) where we wind up with less hangovers and more drinking fun. In effect, we've transformed our position from "pleasure is good" to "the average of pleasure is good." And we can see Mill making this move.

The same ratchet happens in nearly all philosophical forms of hedonism. We can definitely see it Epicureanism which despite the common characterization is all about balancing our lives to experience the most pleasurable kind of life which includes goods like friendship, community, and thought. (Note that most other forms of hedonism appear to be boogeymen imagined by the philosophers rather than well-considered ways of living).

Thus, on a certain level, this is just the recognition that pleasure and pain represent a pair of experiential states that can't be so easily disconnected.

Second, historically, Mill makes this move in response to an objection Jeremy Bentham's utilitarianism. Bentham doesn't distinguish between types of pleasures, so it's just as good if you enjoy playing a game of Powergrid or if you enjoy snorting lines of cocaine. But this doesn't really seem right, but if our only parameter is pleasure, then I'd guess (having not experienced it) that a line of coke is more bang for your buck than a game of Powergrid.

Thus Mill was forced to recognize a distinction between kinds of pleasure and with it to recognize that some kinds of pleasure also involve feelings of pain -- or pain along the way to something becoming pleasurable.

As Guambra's answer suggests, we have good reason to think that Mill would be fine with taking pleasures of the best and most noble kinds in unlimited quantities if it were possible to do so sustainably. (But there are good reasons to think this is psychologically infeasible for humans).
See Diogenes Laërtius, http://classicpersuasion.org/pw/diogenes/dlaristotle.htm Lives and Opinions of Eminent Philosophers: V,1: Aristotle. for description. 

But Aristotle lived 384–322 BC and Diogenes ca.180 – 240: 5 Centuries is a lot of time !

In general, portraits and marble statues are not reliable sources; but you can see:https://commons.wikimedia.org/wiki/File:Aristotle_Altemps_Inv8575.jpg Ludovisi's Aristotle: roman copy of an original from the Greek https://en.wikipedia.org/wiki/Lysippos Lysippos: 4th century BC and personal sculptor to Alexander the Great.

See: J.H. Jongkees, https://www.jstor.org/stable/4429084?seq=1#fndtn-page_scan_tab_contents On the Portraits of Aristotle and Menander, Mnemosyne (1965).
The simplest answer is that, yes, there is some unfairness in the division of labour. No matter what the occupation (whether it's hunting/gathering or designing software) there will be some unfairness when an individual works out that they can get away with doing less. We all probably remember the days of elementary school projects when one person in the group would just attach their name to the assignment after doing little to nothing. 

There is also inequality in the way that certain people are only able to access jobs which are lower status and/or harder work. Far from Plato's "Republic" (in which people are given the work they are most suited for) our civilization leads to people doing certain types of work depending on the education they afford, what types of connections their families have, and what types of work are available in their region. This is not necessarily a bad thing. With the last example (regional availability) we can see a less sinister version of division of labour: it isn't necessarily that people are coerced into doing unpleasant work because of some cosmic unfairness; but, rather, there are some things (e.g. sewer cleaning) which must be done for society to function and somebody has to do those things. We may all want to do fun artsy jobs but somebody needs to keep the water running. We may also all want high paying/high status occupations (e.g. doctors) but that doesn't work: if everyone had jobs like those then there wouldn't be anyone to do all the less desirable jobs.

Second: it's important to note that, despite what how it is talked about a lot of the time, "society" is not a single, highly coercive, entity. Individual people within society may try and force you to do certain things, and the need to eat may force you to take a job you can't stand, but there is no single mind behind it all that is trying to force people to do certain things.

About "being in the same boat": this is, in a strange way, somewhat true. This goes back to the social contract: we have agreed as a society (in a purely metaphorical sense-see my previous point) that we will work together. This means that anyone who pretends to be going along with societal contracts will reap the benefits of other's labour. We have not yet found a  way to solve the "free rider" problem without causing greater harm. What I mean by this is that the only way I can think of to really make someone participate fully would be to be extremely strict with them, removing their ability to make choices about work and leisure This is a reduction of the free will even greater than the "coercion" described in your last statement.

I don't know if I've answered this properly, I'm pretty new to this stack exchange. I'd be happy to make any changes to my answer that are suggested.
The Jewish Question is a criticism of Bruno Bauer, who argues that the emancipation of Jews is subordinate to the emancipation of mankind:


  Bruno Bauer replies to them: No one in Germany is politically emancipated. We ourselves are not free. How are we to free you? You
  Jews are egoists if you demand a special emancipation for yourselves
  as Jews. As Germans, you ought to work for the political emancipation
  of Germany, and as human beings, for the emancipation of mankind, and
  you should feel the particular kind of your oppression and your shame
  not as an exception to the rule, but on the contrary as a confirmation
  of the rule.
  
  [...]
  
  Why should the German be interested in the liberation of the Jew, if the Jew is not interested in the liberation of the German?
  
  By its very nature, the Christian state is incapable of emancipating the Jew; but, adds Bauer, by his very nature the Jew cannot be emancipated. So long as the state is Christian and the Jew is Jewish, the one is as incapable of granting emancipation as the other is of receiving it.


(Marx's emphasys)

So Bauer demands that Jews cease to consider themselves as Jews, as a precondition of their emancipation: you are free to be Jews, as long as... you are not Jews. Then the stigma of Judaism, imposed upon you, is unjust and discriminatory; but as long as you remain Jewish, you cannot argue against discrimination, for you discriminate yourselves:


  Bauer, therefore, demands, on the one hand, that the Jew should renounce Judaism, and that mankind in general should renounce religion, in order to achieve civic emancipation. On the other hand, he quite consistently regards the political abolition of religion as the abolition of religion as such. The state which presupposes religion is not yet a true, real state.


Marx then, having expounded Bauer's positions, states:


  At this point, the one-sided formulation of the Jewish question
  becomes evident.
  
  It was by no means sufficient to investigate: Who is to emancipate? Who is to be emancipated? Criticism had to investigate a third point. It had to inquire: What kind of emancipation is in question? What conditions follow from the very nature of the emancipation that is demanded? Only the criticism of political emancipation itself would have been the conclusive criticism of the Jewish question and its real merging in the “general question of time.”
  
  Because Bauer does not raise the question to this level, he becomes entangled in contradictions. He puts forward conditions which are not based on the nature of political emancipation itself. He raises questions which are not part of his problem, and he solves problems which leave this question unanswered. When Bauer says of the opponents of Jewish emancipation: “Their error was only that they assumed the Christian state to be the only true one and did not subject it to the same criticism that they applied to Judaism” (op. cit., p. 3), we find that his error lies in the fact that he subjects to criticism only the “Christian state,” not the “state as such,” that he does not investigate the relation of political emancipation to human emancipation and, therefore, puts forward conditions which can be explained only by uncritical confusion of political emancipation with general human emancipation.


And then he poses the correct question, cleaned up from Bauer's confusions:


  If Bauer asks the Jews: Have you, from your standpoint, the right to want political emancipation? We ask the converse question: Does the standpoint of political emancipation give the right to demand from the Jew the abolition of Judaism and from man the abolition of religion?


And then proceeds to clarifying the relation between religious emancipation and what he calls human emancipation:


  The political emancipation of the Jew, the Christian, and, in general, of religious man, is the emancipation of the state from Judaism, from Christianity, from religion in general. In its own form, in the manner characteristic of its nature, the state as a state emancipates itself from religion by emancipating itself from the state religion – that is to say, by the state as a state not professing any religion, but, on the contrary, asserting itself as a state. The political emancipation from religion is not a religious emancipation that has been carried through to completion and is free from contradiction, because political emancipation is not a form of human emancipation which has been carried through to completion and is free from contradiction.


The religious citizen is politically free (ie, free to follow the superstition of his own choice without fear of political retaliation) when the State is free from religion. But his political freedom of religion, or even from religion, is not his emancipation from superstition, from religion, as such. Religion ceases to be a State issue, a political issue, but becomes a private, civil, issue, and continues to enslave men and women at that level, while the State is now free to play the role of Pontius Pilatus.

The Jewish citizen can now go the Sinagogue and worship the Abrahamic God in his particular way, without fear of being burnt at the stake by the Christian Leviathan; but he continues to have to abstain from pork, under the fear of whatever punishment YHWH unleashes unto those who so do - and under the fear of whatever merely social, cultural punishment the religion prescribes for such sinners.

And then:


  Therefore, we do not say to the Jews, as Bauer does: You cannot be emancipated politically without emancipating yourselves radically from Judaism. On the contrary, we tell them: Because you can be emancipated politically without renouncing Judaism completely and incontrovertibly, political emancipation itself is not human emancipation. If you Jews want to be emancipated politically, without emancipating yourselves humanly, the half-hearted approach and contradiction is not in you alone, it is inherent in the nature and category of political emancipation. If you find yourself within the confines of this category, you share in a general confinement. Just as the state evangelizes when, although it is a state, it adopts a Christian attitude towards the Jews, so the Jew acts politically when, although a Jew, he demands civic rights.




This is the spirit of the book, which can be found at the https://www.marxists.org/archive/marx/works/1844/jewish-question/ Marxists Internet Archive. We can of course discuss whether this is anti-semitic, from an informed point-of-view. But we should not take a few sentences out of context, in order to demonise the author. Yes, the book contains the sentences quoted in the OP, and others of similar gist; but they are there not to stand by themselves, but as part of a much more complicated reasoning, in which Judaism is not a race, nor merely a religion, but a especial role necessary for the functioning of the "Christian" society.
Short answer: no.

Long answer: 'Capitalism' isn't a static concept, it's a term made up to describe an aspect of many economic implementations around the world today. Those economic implementations vary wildly.

Historically, capitalism can't have an end goal because it's origin doesn't point to any single actor or body. Rather, I'd describe it as the manifestation of human nature on a mass scale. When human beings organise themselves they tend toward socially-democratic nation-states. This hasn't happened with conscious intent, it's just happened, and we've labelled it with the term 'capitalism'.

And so while it can be comforting to imagine that international politics is organised and intentional, this is actually not the case. Rather, it's like a couple billion apes who are capable of using complex language bouncing around and trying to produce enough food for everyone under geographic and resource limitations that are mostly beyond our control.

edit:

One thing I'll add, though, is that in a sense 'capitalism' works toward the end of improving people's quality of life in the short term, but rather I'd describe it as people wanting to improve their quality of life being capitalistic. Capitalism as an economic model is the effect, our natural tendency to capitalize is the cause.
I'm not an expert on Pandeism, but it seems that the concept is not that God is "annihilated," but that God transforms into the Universe (and that the Universe may someday transform back into God).  The obvious motivation would be to bring into existence the dynamic experience of a living universe, as opposed to the inert stasis of absolute perfection.

For a mundane metaphor, you might ask why someone who is comfortable at home might undertake a difficult and potentially dangerous journey --for the experience.
We may split your question as follows:


What is the relation between a play and different instances of it?
What is the ontological status of the play?




The answer to the first is that it is the relation between types and tokens:


  The distinction between a type and its tokens is an ontological one between a general sort of thing and its particular concrete instances. (http://plato.stanford.edu/entries/types-tokens/ SEP)


This of course applies more broadly than your example. Consider the following:


There are different tokens of your question displayed on screens of Phil.SE users around the globe. These are different tokens of the same abstract question type.
There are different performances of Beethoven's 6th symphony by different orchestras and conductors. These are different tokens of the same piece of music.
People say "good morning" to each other everyday. Each such utterance is a different token of the same type.


You get the idea.

Note also that this relation may be vague. For example, change 1 note of Beethoven's 6th. Is it still a token of the same type? Change 2. Still the same type? Change 3, 4, etc. At some point we get a borderline case for which it's not clear whether it is a token of the same type or not.



The answer to the second may be more complicated. It can now be reformulated as follows:


What is the ontological status of types?


Well, what kinds of things are types anyway? Also, types are usually thought to be abstract. So do they exist, and in what sense? This latter question is of course another realism vs non-realism debate. For discussion of these two questions see: http://plato.stanford.edu/entries/types-tokens/#WhaTyp What is a type? and http://plato.stanford.edu/entries/types-tokens/#DoTypExi Do types exist?.

  But it would seem that the origin of our language is rooted in
  ostensive definition. It is after all how children with no prior
  knowledge of a public language begin to learn a language. Their mother
  or father points to something while stressing a given word.


That would be Augustine's reasoning (or rather, remembrance) that Wittgenstein criticises. But it is hard to agree with Augustine; children definitely do not learn their first language by the method you suggest, which would give them a lexic, but no grammar.

I have seen little children babbling, imitating adults in conversation. Their sounds make no sense at all, but what is important is that they have grasped that talking is important, because adults talk. Meaning comes afterward, and it is only secondarily linked to a list of substantive nouns that children learn by heart. Instead, children must first learn to do basic operations such as demand, refuse, accept, call, react to calls, etc. They do not learn to call their mothers "mummy" by someone pointing to their mother and calling her "mummy", they learn it by realising that their mother reacts immediately and joyfully if they emit sounds like "ma", "mo", "mem", "muma", etc.


  As such, what allowed him to criticize ostensive definitions in the
  private language argument while not coming to criticize language
  acquisition through ostensive definition in the case of children?


As far as I understand, he opens PhI by exactly criticising language acquisition by ostensive definition in the case of children. In fact, it seems to me that he strawmans a remark by Augustine that has no greater ambitions than recalling a first childhood that has actually been forgotten into a whole "philosophical theory of language" that doesn't seem to match any actual body of philosophy.
Let's simply assume that, whatever else it may entail, "prestige" is a form of value or power. 

Some products may in fact bestow power. A gun lends its owner a real physical (and often compensatory) power; a private jet gives it owner a real, measurable capacity to do what others cannot and, being very expensive, can only be owned by those with plenty of money, an indication of further exceptional privileges and physical capacities. Nothing illusory about it.

A shampoo cooed over lasciviously by a celebrity, on the other hand, could be bought by almost anyone and is unlikely to impart unusual powers via one's hair. The appeal to authority is here appeal to "aura." To buy the product is to act on the belief in a superstitious transfer of qualities. By vague magical association, one expects that using the same shampoo will transfer that celebrity's aura of sexiness, for example, or some other characteristic that is not, quite obviously, derived from shampoo. So the "fallacy" is to believe in the transfer of human qualities through inanimate objects, something like Marx's commodity fetishism. 

However, it is not at all clear to me that a kind of transfer of "aura" cannot to some degree take place in a universal commodity culture. If you own what celebrity (x) owns or travel to the remote place celebrity (Y) travelled, others may, however faintly, associate you with celebrity (x), for better or worse. You do now have something in common with these celebrities. And since "celebrity" itself may be a kind of communicative power and value, perhaps you are faintly channeling it, assuming highly impressionable acquaintances. In an information society of complex, maximal feedback the author's classical "fallacy" of fetishism may not be as fallacious as it once was.        
The title "Tractatus logico-philosophicus" indicates the strong affinity to logic. 

In my opinion Proposition 1 means that Wittgenstein considers the world - or better a logical model of the world - as the set of all true propositions. In the most simple case a compound proposition is a conjunction of component propositions. Wittgenstein assumes a decomposition into independent component propositions. A priori, each of these component propositions can be true or false, independent from each other. 

Apparently, if the compound proposition is true, i.e. it refers to a fact, then also each component proposition must be true, i.e. refers to a fact. And vice versa.
If you want to distinguish between description and explanation in Wittgenstein's sense, you have to consider his concept of the autonomy of grammar first. 

Three features of the autonomy of grammar:


Why is grammar autonomous? It is not answerable to any external reality. Recall the pivotal concept that meaning of an expression is it's use in a language game. For example, ostensive definition is effective only after the use of an expression is already known. If I'm trying to explain to you that "this is sepia", you already have to know that I'm referring to the color of an object and not to it's shape for example. In other words, you have to be acquainted with the grammar of an expression sepia prior to my explanation of a sample of sepia. 
Why is grammar arbitrary? It's for the same reason as above. It does not depend on any state of affairs. Arbitrarity of grammar means that every symbol system (language, logic, mathematics) is in principle good. Besides that rules are constantly changing. Why:



  https://i.stack.imgur.com/OapvS.jpg (Glock, Wittgenstein's Dictionary, 133)  



Why grammar is constitutive? The rules of grammar determine what makes sense and what not, not what is true or even worse, what is useful to say. In this way they constitute the meaning of an expression. 


Description vs. explanation

Now, after this is clear, it can be drawn a distinction between description and explanation. Descriptions belong to propositions of grammar and explanations belong to empirical propositions. Your example of "Jim and various things he's doing with his banana" belongs under empirical propositions and therefore can't be described in Wittgenstein's technical sense. In other words: you can't describe state of affairs only various uses of an expression (grammar of an expression). Great example of such task provides Hacker, one of the most distinguished Wittgenstein's scholars. Here I attached his surveyable representation of thinking - description of how we use the word thinking: 


  https://i.stack.imgur.com/PEsWq.png (Hacker, The Intellectual Powers, 363)


It is important distinction because it distinguishes philosophical investigation from scientific. Empirical sciences explain why or how something happens while philosophy only describes how a word is used. 
Emptiness or Sunyata, is a key concept in Buddhist rather than Vedantic ontology. 

It describes the lack of svabhava, a term whose closest parallel in Western philosophy would be essence.

The term almost explains itself, if you take the components of the term separately: sva, meaning together with, or self and bhava meaning subsistent or being. 

Nagurjana is a key thinker in the Mahayana tradition who also expounded upon the emptiness of emptiness.
Qualities such as hot, light, white, cold, etc. are phenomena that objects produce in us. However, the average person isn't aware of that, so they usually attributes those qualities to the objects themselves. Physiologically that's impossible, because we simply don't have direct access to the objects themselves. There's a neurologically chain of events that takes place in order to carry signals from the outer world to the brain. The following is from a psychology text:


  "The brain never receives stimulation directly from the outside world.
  Its experience of a tomato is not the same as the tomato
  itself—although we usually assume that the two are identical. Neither
  can the brain receive light from a sunset, reach out and touch velvet,
  or inhale the fragrance of a rose. It must always rely on secondhand
  information from the go-between sensory system, which delivers only a
  coded neural message, out of which the brain must create its own
  experience." (Psychology Core Concepts, p. 90)


Thus, when Locke speaks of  qualities "commonly thought to be the same in those bodies," he is talking about how the common man often attributes how things seem to us (the phenomena) to the things in themselves. For example, the sensation of cold belongs to our perceptual faculties, i.e. neural signals carried to the brain and the particular manner in which the mind interprets those signals as conscious experience. Those sensations should be distinguished from the causes. In the case of snow, we can attributed the cause to the low thermal content of the ice particles. The sensations belong to us, and the energy content to the snow. The same can be said for our other senses, such as the perception of color. The phenomenal experience of white should be distinguished from the electromagnetic energy that stimulated the photoreceptors in our eyes. The sensation of color belongs to us, and the energy belongs to the light rays that enter the eyes.

It should be noted that Locke used the names of colors when referring to phenomenal qualities, i.e. to the ideas in the mind. However other philosophers have strongly objected to using language in this way. Thomas Reid, for example, criticized the "the way of ideas" for this very thing. Reid also recognized that phenomenal experience should be distinguished from the things in themselves, but he objected to calling the phenomenal experience of a red object as "red." Instead, he insisted that the name of the color belongs to the object and not to the phenomena.
This may not be exactly an answer, but it is too long for a comment.



We say things like:


Black swans exist.
Ghosts do not exist.
Finland exists.
God exists.
God does not exist.
My belief in God exists.
Emerging properties do exist.
Honesty doesn't exist (anymore).


If someone tells us that black swanns don't exist, we will usually tell them that they can be easily found in zoologics, or show them a picture of black swanns. If someone tells us that Finland does not exist, we may show them a map, or a travel agency's fares for travels to Helsinki. Is someone doubts the existence of emerging properties, we might point to the fact that while a plane can fly, no separate piece of a plane can. Or that while Boris Johnson is for Brexit, the cells on his liver, toe, or even brain, do not know anything about the issue.

We would, in fewer words, propose a "verificationist" approach to the subject: "you think X doesn't exist? Here is an instance of X: a black swan, a post card just coming from Finland, the emerging property of Mr. Johnson's support for Brexit."

Things get more complicated if someone tells us that ghosts or unicorns do exist. A verificationist approach seems insufficient, because we would have to search for either ghosts or unicorns in the whole universe. "Proving" in a verificationist way that there are no unicorns in the Isle of Man may be not too difficult, but our interlocutor may argue that "perhaps they exist in Alpha Centauri system, who knows". The obvious retort is that the burden of proof lies on the person making such claim. But this is not a very good answer; the person may well tell us that "I am not making any claim at all, except the very limited one that you cannot prove that unicorns do not exist in Alpha Centauri, or, indeed, in any place that you cannot directly inspect." A better line of argument is to show that unicorns are material impossibilities: horses have evolved in certain ways, that preclude the existence of horned horses; and the evolution of horses in other planets is even more impossible, for the natural history of another planet is necessarily different from Earth's own natural history.

But things get complicated again if we allow the interlocutor to move the goal posts (for instance, if he points us to a rhynoceros, and tells us "here, the unicorn; I told you it existed". Of course, the rhynoceros is not a horned horse, and the definition of unicorn requires exactly this). This is relevant for the discussion of the existence of God, for one of the argumentative tactics of theists is to get their interlocutors into admitting that they cannot prove that some "superior" entity doesn't exist (that is what the traditional arguments for the existence of God do), and then trying to confuse us into a quite different idea - that this "superior" entity, a) created the world, b) is omnipotent, c) is omniscient, and d) is benevolent towards humans (or even more, maintains a "personal relationship" with some or even all humans). The goal post is moved; while the theist originally intends to make us believe in a being with all the properties from a) to d), he then gets us to admit that we cannot prove the inexistence of a being that has at most the property a). The proper response, of course, is that property d) is incompatible with property b), or at least with properties b) and c) combined.

Anyway, what we seem to be discussing is a property independent of the person, or people, talking about it. If black swans exist, they exist whether or not I believe in them, see them, like them, and whether I am looking at them, awake, aware of their "existence", or even alive. This independence we use to call, rightly or - more probably - wrongly, "objectivity". Existence is "objective". Which brings up the issue of


My belief in God exists.


While we can verify that black swans exist, or conclude that unicorns must not exist because their existence would contradict what we know about the structure of the universe, or that God doesn't exist because its description is self-contradictory, a sentence that refers to the psyche of an individual is much problematic. The faithful in question could be lying, or could have not given enough thought to the issue of God to really hold a significant faith - and we may not have any actual means to confirm or dismiss the claim. Besides, this seems to in some way break the idea that existence is "objective". Whether someone's faith in God exists or not, that certainly depends, at least partially, on that person and her beliefs - and we can't demonstrate that such existence is self-contradictory; while the belief in itself can be absurd, people do often believe in impossible things. In that sence, it would seem that the beliefs of a person - be them religious or not - do not "exist" in the same way that Finland exists. We can perhaps assert that certain symptoms of the existence of the belief exist, and that they may indicate the existence of the belief (whenever John is going to cross the street, he looks both sides first, which indicates that he may believe that cars exist and are dangerous) - but is that the same thing?

This lack of objectivity is, of course, part of the problem with


Honesty doesn't exist.


Here the person uttering the sentence is admiting to being dishonest (which brings the question, why would we believe what they are telling us, but that is a digression). But is that person being honest about her own dishonesty, and how can they assess the existence of honesty in other people? This brings on a very interesting issue: that of statements that imply the impossibility of any verification. Any person that tries to answer to this with a sentence by asserting their own honesty will probably be told that this in fact "proves" the inexistence of honesty, as their answer is itself one more instance of lying.

Similarly, the assertion of the existence of invisible green pixies: "of course you cannot see them; as I told you, they are invisible".
Either one is correct.  For some technical purposes it is convenient to bring all the quantifiers out to initial position as in your second version.  For that, see "prenex normal form" on Wikipedia.  But other purposes might favor the first version and first order logic per se just finds them equivalent.
Whenever you dabble with infinities, intuition must be challenged.  They do not behave as finite quantities do.

It is not immediately provable that infinite regress of causation is impossible merely due to the example you provide.  An equally valid argument might be that the soldier will fire the bullet after an infinitely long wait.  Or, alternatively, the soldier may fire the bullet in a finite amount of time if it is possible for the soldiers and their superiors to communicate with infinite speed.  It's even plausible that the soldier could fire the bullet in a finite amount of time with non-infinite communication speeds if one could argue that the order to fire was given infinitely far in the past, before the soldier ever had eyes on their enemy.

These alternatives may seem awkward, but they must be.  At the heart of the logic puzzle is an infinite number of mathematically perfect soldiers all of which are incapable of acting without a superior's authorization.  By putting such polished gleaming pistons into your machine, you create a physically unrealistic scenario which may be responded to with equally physically unrealistic solutions.

Mathematicians do have tools to explore such infinities, and you may be able to phrase the question in the language of mathematics to come to an answer.  For example, if you wish to find a solution using ZF set theory, it is entirely plausible that your representation of "causality" may posit the existence of an infinite regress in a form which is contrary to the Axiom of Regularity (which has much to say about infinite regress).  In such a case, you could confirm that such a construct would be impossible in ZF.  However, the burden would then be on you as the philosopher to argue why this result has the intended implications in our world.

  I would suggest that IME it functions to consolidate capitalism not just by division or distraction, but by disempowering the white / male / etc. working class; relative to the capitalist class of course.


Hmmmm, porbably not. Marx and Engels saw women as the original oppressed group and marriage and monogamy as instruments of capitalism. See https://plato.stanford.edu/entries/marriage/#UndMarHisOri the SEP article on marriage, Section 2:


  Marxists also saw marriage as originating in ancient exercises of force and as continuing to contribute to the exploitation of women. Friedrich Engels (1820–1895) argued that monogamous marriage issued from a “world historical defeat of the female sex” (Engels 1884, 120). Exclusive monogamy “was not in any way the fruit of individual sex love, with which it had nothing whatever to do … [but was based on] economic conditions—on the victory of private property over primitive, natural communal property” (ibid., 128). Monogamy allowed men to control women and reproduction, thereby facilitating the intergenerational transfer of private property by producing undisputed heirs. Karl Marx (1818–83) argued that abolishing the private family would liberate women from male ownership, ending their status “as mere instruments of production” (The Communist Manifesto, Marx 1848, 173). The Marxist linking of patriarchy and capitalism, in particular its understanding of marriage as an ownership relation ideologically underpinning the capitalist order, has been especially influential in feminist thought (Pateman 1988, cf. McMurtry 1972).


So I don't think he would have worried too much about male dis-empowerment, and it is safe to assume that Marx would have sympathized with liberal feminist identity politics. 

Marx has made some dubious statements about race and slavery, but I think that had he lived in a more cosmopolitan environment (i.e. one like modern U.S society were class and ethnicity correlated strongly), he would be sympathetic to ethnic identity politics as well, if only by extrapolating from his position on women and capitalism.  
I infer that you argue legal execution is a "zero-sum game" and that as such it stands opposed to your ideal condition, which is rehabilitation of the condemned, both for the sake of that individual and for the sake of society.

I assert that the death penalty is not intended to be a punishment, a deterrent, a service of justice, or a tool for rehabilitation (and it fails in each of these roles). It is a protection. The system of law, policing and incarceration has one goal: the protection of the individual liberties of all persons in a society. Since legal execution ideally is reserved for those criminals who continue to constitute clear and present dangers to the rights of others even when imprisoned, and for whom such a fate would be commensurate with their violations of the rights of others, the death penalty is as far from nihilism as possible: it specifically protects and promotes the freedoms and well-being of everyone who could otherwise be victimized by the condemned. It defends the right to life itself.

So defined, such execution should be rare. As legal execution is practiced, however, it can be used in a misguided fashion. It might be employed in mistaken or corrupt attempts to placate angry mobs; to save resources which would be used for investigation, legal defense, and imprisonment; to justify or conceal corruption; or to propagandize. The fact of these occurrences should not be taken as proof of their legitimacy. The protection of human rights is always paramount, and never to be subordinated to ideas of what is justly deserved, what is punitive, or what is likely to engineer a desired outcome.

The theistic cultures you mention are particularly prone to these errors, because they codify into law precepts of religion, which is proto-philosophy. These precepts are often incompletely or incorrectly justified, and may be based on contradictory logic. Who fails to notice the irony of the religious exhortation to "serve justice" by killing those deemed "deserving" juxtaposed with the bleating condescension that "only God can truly pass judgment." When such philosophical confusions contaminate law and the death penalty is used incorrectly then legal execution can certainly be nihilistic, in the sense that it serves no legitimate purpose, and does not protect the rights of anyone, including the condemned.

Why do theistic cultures engage in nihilistic behavior? Because they hold nihilistic views. Despite much contradictory doctrine about the sanctity and beauty of life, any religious code espousing a reward in the afterlife that trumps life in the here and now, and preaching self-destructive behavior such as self-sacrifice and derision for mortal existence, has as an end result a condition of being anti-life, anti-truth, and anti-humanity.
I think a major source of confusion here is that you're (quite naturally) associating the creator with a https://en.wikipedia.org/wiki/Neoplatonism Neo-Platonic image of the One God as the unity of all perfections.  However, although this passage definitely refers to a version of the "One" (which Plato here calls the "Eternal Essence") Plato isn't calling it the creator.  The creator https://en.wikipedia.org/wiki/Demiurge is just a craftsperson who makes the world in imitation of the Eternal Essence (just as, in Ion, poets make poems, or in The Republic, statesmen make city governments, in imitation of that same Essence, imitations which inevitably fall short). There's no strong suggestion that Plato actually believes this creator/demiurge even exists, it just appears in the story as a tool to help people interested in accounts of creation reinterpret the appearances of the universe as reflections of the Eternal Essence.  To compound the confusion, some places where Plato appears to be talking about the creator ("he was" versus "he is") only make sense if we take them as solely referring to the Eternal Essence instead (even though the Essence is not otherwise personalized here).

As far as the terms, I'm not a Greek scholar, but Plato always uses words in an idiosyncratic way in any case, so an exact translation of any word can only be at best a starting point. I follow an approach to interpreting Plato that takes everything he writes as an attempt to explain his concept of the Eternal Essence (more often called the https://en.wikipedia.org/wiki/Form_of_the_Good Ideal of Good) as explained through innumerable metaphors aimed at different audiences.  The core belief is that there is a perfect, eternal godlike ideal in a kind of conceptual heaven.  That core ideal is surrounded by increasingly imperfect copies.  In what, if nothing else, is a wonderful example of form matching function, this leads him to a certain sloppiness in language that can be perplexing to those used to philosophical precision.  Since Plato believes the perceptible surface expression is always an imperfect attempt to point to the perfect but imperceptible meaning, he's quite willing to play fast and loose with the superficial details.  Thus, each time he uses a term meaning eternal here, it has a slightly different connotation, which we have to glean from context, not from the actual word choice.

This particular dialogue is an original creation myth, presumably aimed at an audience of mystical theologians, and using terms and concepts that would have been familiar to them.  As always, however, Plato tweaks those terms to support his own unique vision of Ultimate Reality. As I understand this passage, the general idea is that the Eternal Essence is both everlasting and not directly perceptible --transcendent, if you will.  It lasts forever and never changes.  The heavens are a higher order copy of that ideal, they last forever, but they are not perfectly unchanging. Humanity is a lower order copy of the ideal, we are neither eternal nor unchanging.  When we see the heavens, they are a bridge between ourselves and the imperceptibly transcendent Eternal Essence.  The heavens are an image of perfection, but are not themselves perfect, because no image is perfect (every image is an imperfect copy).  Where the Eternal Essence is everlasting because it is entirely outside time, and therefore never changes, the heavens are everlasting within time.  They are cyclical ("revolves according to a law of number"), which is what everlasting looks like when you combine it with change. They are therefore not eternal "in its fullness," which is necessarily static. The reason for creating the heavens is so we can see what something eternal looks like, but in a form that changes like we change, so we can identify with it.  That helps us understand that we too are formed in imitation of the Eternal Essence.
No God cannot create a rock that he cannot lift. But just because he can't do this doesn't mean he's not all powerful, just that he can't do the logically impossible. 
From https://en.wikipedia.org/wiki/Logicism#Intent.2C_or_goal.2C_of_logicism Wikipedia:


  The overt intent of Logicism is to reduce all of philosophy to symbolic logic (Russell), and/or to reduce all of mathematics to symbolic logic (Frege, Dedekind, Peano, Russell). As contrasted with algebraic logic (Boolean logic) that employs arithmetic concepts, symbolic logic begins with a very reduced set of marks (non-arithmetic symbols), a (very-)few "logical" axioms that embody the three "laws of thought," and a couple of construction rules that dictate how the marks are to be assembled and manipulated—substitution and modus ponens (inference of the true from the true). Logicism also adopts from Frege's groundwork the reduction of natural language statements from "subject|predicate" into either propositional "atoms" or the "argument|function" of "generalization"—the notions "all," "some," "class" (collection, aggregate) and "relation."
  
  As perhaps its core tenet, logicism forbids any "intuition" of number to sneak in either as an axiom or by accident. The goal is to derive all of mathematics, starting with the counting numbers and then the irrational numbers, from the "laws of thought" alone, without any tacit (hidden) assumptions of "before" and "after" or "less" and "more" or to the point: "successor" and "predecessor." Gödel 1944 summarized Russell's logicistic "constructions," when compared to "constructions" in the foundational systems of Intuitionism and Formalism ("the Hilbert School") as follows: "Both of these schools base their constructions on a mathematical intuition whose avoidance is exactly one of the principal aims of Russell's constructivism" (Gödel 1944 in Collected Works 1990:119).


I think whoever told you that the goal was to not use axioms meant that the goal was to avoid "numerical" or "algebraic" axioms.
Two thoughts: 


In the case of schisms like the Sunni/Shia or Catholic/Protestant, both sides claimed to have been holders of the original unadulterated truth - as a continuation of the original pure form of the ideology, while the other camp had somehow corrupted or lost its connection with the true doctrine. In the case of Marxism vs Capitalism, at least in the original formulation of Marx, Marxism has to come after Capitalism, it is not some reversion to an earlier purer stage in human social evolution, but a new stage which is going to be better than all other past stages. (On a fun note, can you imagine a Sunni thinker claiming that society has to go through a primitive Shia phase before it moves on to a more evolved Sunni phase?)
Ideally movements like Capitalism and Marxism shouldn't consider themselves to be dogmatic the way religions do (although in practice adherents of those movements do behave dogmatically), so the the schism analogy doesn't work here either in the sense that one can either be Sunni or Shia, the positions are mutually exclusive, whereas for theories like Marxism and Capitalism, the most successful governments are those that adopt a little bit of both, instead of sticking dogmatically to one position or the other. One could take this idea deeper and see that taking a religious position on a specific denomination is usually driven by deontic considerations, while taken a position on Marxism vs Capitalism should be done on a consequentialist/utilitarian considerations. 


In so far as they can be considered Schisms, they could be considered divergent schools of thought stemming from the Enlightenment, as well as being different takes on materialism. 
The quote is from the preface to the first edition of Capital, although similar things can be found elsewhere in Marx's writings.

To take a stab at the relation: The last sentence seems to reiterate a bit of the point of the preceding paragraph, namely that there are natural laws that guide economic and social development. The first paragraph more or less lays out that there are stages to this development that must be followed. The last sentence adds to this the claim that from the point of view of the development of society, individuals are not terribly important. Of course, society is a collection of individuals, but those individuals are who they are in part by being members of a specific society at a specific point in its development. Put a different way, Julius Caesar, brought up in 19th-century London would probably bear little resemblance to the historical Julius Caesar.
Yes, it is sort of possible through the practice of https://en.wikipedia.org/wiki/Lucid_dream Lucid dreaming.

You can experience both falling asleep into dream sleep and waking up from dream sleep.

From my personal experience, falling asleep feels like a roller coaster or an earth quake of the senses, in particular with a lot of noise. Then things become quiet and when you next open your eyes you may find yourself in your dream world.

Waking up is usually more gentle, possibly with the visual field momentarily turning black right before waking up.

Some people report momentarily experiencing the famous sleep paralysis before finally waking up.

If you are interested in the moment of losing and gaining consciousness then that is probably not it, since consciousness is maintained throughout the process.

There is a very interesting phenomenon related to waking up, called https://en.wikipedia.org/wiki/False_awakening false awakening, in which the brain induces one to believe he has woken up, when in fact it is merely the onset of a new dream. Bertrand Russell reports such an experience in one of his books.

The experience of becoming conscious within dream sleep is very interesting in itself. Particularly in the first several times that it happens, it is a moment of great wonder and exhilaration, akin to a powerful spiritual experience.

Richard Feynman recounts his experience with Lucid Dreaming in his book Surely You're Joking, Mr. Feynman! In particular he writes that his motivation was exactly to catch the moment of falling asleep:


  After I had written the theme I continued to be curious, and I kept practicing this watching myself as I went to sleep. One night, while I was having a dream, I realized I was observing myself in the dream. I had gotten all the way down into the sleep itself!


The practice of Lucid dreaming is a lot of fun, but note that it may come at the cost of disturbing your habits and patterns of sleeping, and may therefore affect your health.
In a few words, the argument of the brief https://en.wikipedia.org/wiki/Discourses_of_Epictetus Discourse, I,4 : http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.01.0236%3Atext%3Ddisc%3Abook%3D1%3Achapter%3D4 Of progress or improvement, is the following :

Progress (προκοπῆς, to improve) is not to be able to read the books of the philosophers (like the Stoic https://en.wikipedia.org/wiki/Chrysippus Chrysippus), but instead in following his precepts: to lean towards virtue.

If virtue is the goal of perfection, progress is sistematically approaching this goal.

We have to measure it (progress or improvement) not so much in the "theoretical" knowledge of what is teached in books, but in the "practical" application of the said knowledge into daily actions.

What actions ? First of all into the sphere of desire and aversion, according to the principle that:


  happiness and tranquillity are not attainable by man otherwise than by not failing to obtain what he desires, and not falling into that which he would avoid.


An then into the spheres of pursuit and avoiding, to avoid error, and of assent and suspension of assent, in order not to be deceived. 

The first is the most necessary, because 


  if you are in a state of fear or pain [trembling and lamentation: τρέμων καὶ πενθῶν] you will not be able to judge correctly and thus you will choose what is not good [falling into that which he would avoid].

You are looking for a fallacy that could result from this statement, not for a fallacy in the statement itself. 

An obvious fallacy that could result from this statement would be to make the wrong assumption that "thy neighbours" means explicitly only people living nearby or who are personally close to you, and that it is perfectly allowable to spread lies about people who live further away. 
I would say that metaphysics is of paramount importance and is the foundation of philosophy for without it - without a coherent worldview - we would be hopelessly lost and helpless to deal with reality.  We have to have this groundwork and the axioms that accompany it. Reality exists and is absolute. That is, I don't accept the premise that reality is all just an edifice or rather, that reality is all in the mind. There is an objective, physical reality that exists outside ourselves and we better learn how to deal with that reality (or suffer the consequences).  Metaphysics provides that foundation.
Western thought boils down to dedication to ownership - copyrights, patents, fences, etc.  More broadly, human behavior is not unlike other mammals.  Dogs sniff one anothers butts, just as humans do.  Any media executive knows that what people subscribe to is dirty laundry, sex, and violence.  Women know men respond to the display of sexuality.  Men know women respond to financial wealth.  This behavior is rooted in what is the essence of mammals - reproduction with a desirable mate.

So, how is automation ever going to free man from his essence - desire?  I suppose it depends on what culture you are speaking of.  In the West, even if all essential labor is automated, the automation will be owned by someone.  In many ways, "work" is a means to reproduction (copulation); a means to differentiate yourself from the many.

The scary part of this automation is already evident vis-à-vis character assasination.  Mob mentality exists and we are all sinners, all do wrong, and will do wrong again.  Automation gets to a point where all wrongs are recorded and published.  Then what?  The Kübler-Ross model?
Humans tend to track time in a cyclical manner (clocks, seasons, calendars, etc) because that is how we experience it.  The earth spins around the sun in a stable orbit, causing our environment oscillate through a predictable pattern of environmental states.  https://en.wikipedia.org/wiki/Pattern_recognition_(psychology) And people are really good at identifying patterns.

But that is just our earth-bound perspective, biased heavily by our position on a spinning, wobbly rock.  A society living on non-orbiting https://en.wikipedia.org/wiki/Rogue_planet rogue planet would likely have a very different view of the passage of time, and I doubt it would resemble our cyclical time/date keeping devices.

(tl;dr, our way of measuring time has little to do what time actually "is," as opposed to our perspective of it.  Whether time is a block or a parrot, our view from the inside makes it difficult to accurately determine much about it.)
Your first observation sounds like the principle of parsimony, stated cynically, if you are looking for a name.  The principle is that the most compact theory is preferred over any more complicated theory that explains the same data.  And yours, among other, more aesthetic, considerations is the basic argument supporting the principle.

But the connection implied in the second part is just not true.  In general, philosophers have tended to avoid long strings of old arguments as a way of introducing new theories.  They try to build positive arguments 'low' and close to the ground of intuition.  The long-chain arguments based on centuries of refinement, outside of fairly dead traditions like Scholasticism, appear primarily when criticizing positions and motivating changes or refinements.  But avoiding an obstacle does not incorporate the obstacle itself into your theory, even if the statement of the obstacle becomes part of your work, as an excuse for the lack of parsimony.

So what is given by the archaeology is a broad range of counterarguments and test cases one should consider while building.  It is not source code, so much as regression tests, and does not produce fragile arguments, but robust ones.
It might be helpful to think of this by considering each of the disjuncts of a disjunctive statement as containing unspoken implications. Consider, for example, the following disjunction:


  Either no storm will come, or the boat will sink.


For each of the disjuncts, we can assert the following implications:


If no storm comes, no storm comes.
If a storm comes, the boat will sink.


It's intuitively true that either a storm will come or not. Therefore, we can put all that together to derive the following, which is a logical consequence to the first statement:


  If no storm comes, no storm comes; or if a storm does come, the boat
  will sink.


The first part is redundant, so this can be simplified to:


  Either no storm comes; or if a storm comes, the boat will
  sink.


From this it can be seen that disjunctive statements can be thought of as having conditional statements hidden within their elements.

Vacuity

It might be argued that it is vacuous to insert an antecedent into the disjunction in that way. For example, it could be argued that any antecedent could be inserted, such as:


  Either no storm comes; or if the moon is made of cheese, the boat
  will sink.


Although it is true that that logically follows from the premise, there's an important difference to be noted. The antecedent "if a storm comes" complements the other disjunct, whereas "if the moon is made of cheese" does not. This involves the important difference that the simpler conditional follows logically from the disjunctive statement:


~A ∨ (A → B) implies A → B
But, ~A ∨ (C → B) does not imply C → B


In other words, it cannot be concluded that if the moon is made of cheese, the boat will sink; but, it can be concluded that if a storm does come, the boat will sink.

Edit:

Due to a question in a comment, I'm adding the following proof:


{1}      1.   ~A ∨ (A → B)                Prem.
{2}      2.   A                           Assum.
{3}      3.   ~A                          Assum. (1st D)
{4}      4.   ~B                          Assum.
{3,4}    5.   ~A & ~B                     3,4 &I
{3,4}    6.   ~A                          5 &E
{2,3,4}  7.   A & ~A                      2,6 &I
{2,3}    8.   B                           4,7 RAA (1st C)                       
{9}      9.   A → B                       Assum. (2nd D)
{2,9}    10.  B                           2,9 MP (2nd C)
{1,2}    11.  B                           1,3,8,9,10 ∨E
{1}      12.  A → B                       2,11 CP    


The best way to prove an implication is usually to start by assuming the antecedent of the implication to be concluded  (line 2). To eliminate the disjunction, I also have to assume each of the disjuncts (lines 3 and 9). The first disjunct contradicts the assumption in line 2, and given a contradiction, you can essentially conclude whatever you want. I needed to conclude B, but it should be noted that I didn't get that conclusion for free; it depends on the assumptions of lines 2 and 3 which will have to be eliminated (line 8). The second disjunct also lets me conclude B using modus ponens. Since both disjuncts imply the same conclusion of B (line 11), I can eliminate the assumptions of lines 3 and 9. The assumption on line 2 led to the conclusion on line 11, so I can eliminate it and conclude that A → B.

  If intuition has to conform to the constitution of the objects, then I do not see how we can know anything of them a priori; 


= approximately if our thoughts about objects have to come from objects themselves, we cannot them without experiencing the objects (here a priori is the opposite of "from experience."


  but if the object (as an object of the senses) conforms to the constitution of our faculty of intuition, then I can very well represent this possibility to myself. 


= If on the other hand, our "thoughts" about objects come from our thinking, then I can know something about objects without encountering them in the world.


  Yet because I cannot stop with these intuitions, if they are to become cognitions, but must refer them as representations to something as their object and determine this object through them, 


If I'm really going to "think" about objects, then I can take representations (= appearances) and get to objects


  I can assume either that the concepts through which I bring about this determination also conform to the objects, and then I am once again in the same difficulty about how I could know anything about them a priori,


Here, I have a choice. I can either think the representations come from the things out there ... which will mean I cannot know them without experiencing those things.


  or else I assume that the objects, or what is the same thing, the experience in which alone they can be cognized (as given objects) conforms to those concepts, 


Or I can see the representations as matching my concepts.


  in which case I immediately see an easier way out of the difficulty, since experience itself is a kind of cognition requiring the understanding, whose rule I have to presuppose in myself before any object is given to me, hence a priori, which rule is expressed in concepts a priori, to which all objects of experience must therefore necessarily conform, and with which they must agree.


And this works, because all of my experience follows a prior rules.


  As for objects insofar as they are thought merely through reason, and necessarily at that, but that (at least as reason thinks them) cannot be given in experience at all - the attempt to think them (for they must be capable of being thought) will provide a splendid touchstone of what we assume as the altered method of our way of thinking, namely that we can cognize of things a priori only what we ourselves have put into them (Kant, Critique of Pure Reason, B xvii).


= the objects don't come from experience; they come from me thinking. So I can think about that sort of thinking and learn about objects and representations.



tl;dr - in Kant's view we don't have direct access to things in our world. Instead, we experience representations (whitish thing appearing in front of me)  and objects (macbook air) based on categories and forms of sensibility that come from us.

Basic pattern = object -> representation -> thing. Object is something we can really think about. Representation is something we see/sense. Thing is something we don't encounter. (Again, his technical terms).

Representation = the German word Vorstellung. In Kant's case, this is something we can sense and that we experience as within space and time (we bring space and time to the thing for Kant's view).

Thing = the German word Ding. In Kant's case, this is often going to be "thing-in-itself." It's not something we encounter or can experience. Instead, we experience representations of it and think about it when rendered as an object. It's a distant cousin  to "prime matter."

For Kant, a priori (non-experience-based) is the prize, because then we can have certainty. If we have to depend on encountering them, then he sees that as a problem (not explained in this passage).
I symbolize what happens in the passage roughly as follows (I've bracketed the subargument from 3-5):


Piety = Dear to gods "what is dear to the gods is holy  and what is not dear to them is unholy" (6e-7a)
gods disagree about piety (7b)





Some disagreements lead to discord (7b)
If a disagreement is empirically resolvable, it does not lead to discord (7b)
Disagreements about justice, truth, and beauty lead to discord (7d)





Ergo, since the gods are in discord, they must substantive disagreements about justice, truth, piety, etc. (7e-8a)
Finally, 6 & 1 are contradictory so something must be wrong in the argument (8a)




Starting from 6d-e, the argument is framed by Euthyphro's claim that what unifies the things we call holy (despite their differences) is



The latter half of 7b which you quote in part is the beginning of a subargument:


  But what things is the disagreement about, which causes enmity and anger? Let us look at it in this way. If you and I were to disagree about number, for instance, which of two numbers were the greater, would the disagreement about these matters make us enemies and make us angry with each other, or should we not quickly settle it by resorting to arithmetic? (7b-c) ... Then, too, if we were to disagree about the relative size of things, we should quickly put an end to the disagreement by measuring?  ... weighing? (7c)


I take this line of questioning to mean that we don't waste our time disagreeing about minor things that we can simply or empirically resolve.

Conversely, Socrates and Euthyphro accept that we can wind up with 


  a disagreement [that] we could not settle and which would cause us to be enemies and be angry with each other (7c)


And that this would be about questions like:


  Is it not about right and wrong, and noble and disgraceful, and good and bad? (7d)


= substantive disagreements would be about things like right/wrong and notably about things that are not empirically or simply resolvable are the sort of things that can lead to discord. In other words, it's things like the Forms (which makes sense considering this dialogue is about Piety).

Note that from 7b to the middle of 7d, Socrates is not talking specifically about the gods. 



At the end of 7d, he bridges it back to his main point by saying that gods would disagree about matters of import which are not resolvable by measurement or simple math. Moving to 7e, I don't think his point is the symbolization you suggest.

Specifically, I take the part at 7e to express "discord if and only if disagreement is about substantial things" -- i.e. I take it to express that the gods aren't in discord over something minor but rather they are in discord because they disagree about the nature of piety, etc. in a fundamentally irresovable way.

Why then does Plato make this argument (since he already said they were in discord)? I take it that the point is to block out the option of just saying "god A is correct for reason of knockdown argument B or reason of empirical fact C." Instead, it's point out that there's a fundamental incapacity to define piety by appeal to the gods -- since the gods are in discord and this means by definition that they do not agree for empirically and logically non-resolvable reasons about the nature of piety.
(First of all, at the risk of being a bit catty, to some degree isn't all of Nietzsche, Nietzsche on Nietzsche, especially in "The Gay Science"?  Even when he is addressing global issues like the overall development of moral sentiment, or the nature of Greek drama, or how post-Classical music really ought to be, everything is introspection, or his insight is so quirky that his interpretation of otherwise objective facts is really about him.)

As I read "The Gay Science" the most painful problem for him in a lot of places seems to be a wavering commitment to being outside the race and desperately wanting to work an effect upon it from within.  (The pain is palpable... unless I am projecting it onto him.)

To put it theoretically, there is an issue in his model of what the herd is, as to whether there is any possible continuity upward from the noble alpha leader of the herd to the independent creator free of human baggage. If there is one, Nietzsche is vying for it.  And he hates himself for doing so, since he has gone so far as to say the herd-bond is something that must be overcome.  If he gets what he wants, he is theoretically wrong.  (His greatest dangers are in compassion.)

He wants a transfiguration of values, but he seeks for such a thing in a natural history: The Genealogy of Morals, and leading forward from there would be choosing to be driven and shaped by social forces so as to be able to capture the intelligence of those around him.  (What he loves in others are his own hopes.)

But by his more raw logic a la Beyond Good and Evil, he should more highly value a deeply personal perspective that would uniquely express his distance from those same forces.  ('You should become who you are.') 

(To address the issue with the word 'nobility': Nobility has a 'peerage', a standard that allows it to be respected in a social context by others who are similarly noble. This definition of heroism is personal and individual. This kind of hero may very well not be noble. He basically cannot be noble if his remapping of values is entirely unique.

So Nietzsche has the Groucho-Marxism problem in reverse:  He himself wants to be noble, whether or not he should be by the standards of any peerage he would choose to validate his nobility.)

So there is a constant pain of pursuing the greatest calling he can tolerate, knowing there are theoretically greater challenges, which might even be easier to overcome, but those would not answer to his need.  And of course, that pain is there only because of his own self-imposed morality, which may or may not have any real value, if he has to struggle both for and against it.

Those two sides (continuity and jumping forward / nobility and freedom from the good) may very well represent Nietzsche's suffering, and his hope.
Hard line libertarians like Rand and Nozick would likely deflect and find some way not to answer this question with a direct answer. They could say that as a result of the local officials forcing the old man to give up his medicine, in the future the villagers are less likely to plan ahead and buy medicines for themselves, believing that in a worst case scenario they can rely on other's medicine to be given to them. In the next year, not just one but 3 babies get sick and the families ask the local officials to make the old man hand over some medicine. However as a result of what happened last time, the old man has decided not to restock his supply of medicine. The 3 babies die. If force hadn't been used in the first place the parents of the other babies would have been more likely to stock up in medicine and their deaths could have been avoided. 

The majority of people would say that the old man should be coerced into handing over their medicine as it would have a minimal impact on his life while enabling a life to be saved, and that the family should afterwards replace his medicine. Hard line libertarians like Rand and Nozick believe that this kind of thinking will eventually lead to an authoritarian police state, as they see the world in black and white. Although I believe Rand and Nozick are both minarchists rather than anarchists which means they do believe that some coercion is okay - as long as it doesn't involve wealth redistribution. 
Great question. I will preface this with the qualifier that from a political perspective it means many things to many people. At a basic level Classical Liberalism vs. Modern Liberalism is:


Philosophy: Individualism vs. Collectivism
Economics: Free market capitalism vs. Communism/Socialism
Politics: Libertarianism vs. Socialism


This is not a commentary or valuation on which is better, but the observed "preference" for the two movements. Please correct me if you feel that I am being unfair or accidentally oversaw something.

Classic Liberalism

A little history: Mentioned by Greek Philosophers, although it is much older, the Classical Trivium was a secular method of learning from ancient Greece. It consisted of 7 principles, the first 3 called the Trivium, the final 4 the Quadrivium:


Grammar: Gather, Ordering, and Systematizing facts
Logic: How to determine what is true
Rhetoric: How to communicate the truth
Numbers as symbolic references (arithmetic),
Numbers in space (geometry)
Numbers in time (music)
Numbers in space safety and time (astronomy)


Using the ideas mentioned above, in the 18th-19th century people in the US / Europe used them and ancient Greek philosophic ideas as the basis of what people usually refer to as Classic Liberalism. Generally these ideas


Freedom, as long as it doesn't impede on someone else
Justice, Equality before the law (not equality of outcome) 
Liberty, Voluntary exchange goods and services in free markets
VERY Limited government, government had no powers except what was explicitly noted. The majority of the power must be 
Free speech
Freedom of Religion
Individualism over collectivism
Individual Property rights
No taxation without representation


As a modern reference, these are the same principles to a large degree as the current ones voiced by the Libertarian party in the US.

Neo-Liberalism
A historical clarification I originally left out to prevent confusion: 

In the early 1900's people attempted to institute a middle ground between pure collectivism and individualism which had some aspects of Modern liberalism, such as big government, and some aspects of Classical Liberalism, such as free market economies. 

From an Economic perspective these are incompatible beliefs and so Neo-Liberalism lost it's original meaning as it quickly evolved into Modern Liberalism some time around the 1930's. Words change over time for various reasons so to understand what is meant by a concept sometimes you have to ask what it meant for a given period of time. since about 1990, Neo-Liberalism is a synonym or slur for Modern Liberalism.

Modern Liberalism

Modern is the antithesis (or basically the opposite view of) of Classic Liberalism. Many people are inspired by Marx or others, although certainly not all modern liberalism is. It is guided more towards the ideals of the ultimate fairness. 

Its guiding principles tend to be:


Safety, infringe on peoples privacy for the safety of the collective
Social Justice, Equality of Outcome (vs. Equality before the law) 
Fair Trade, Prevent unfair losses or companies from unfairly making more than others.
Large government, Government is responsible for the people
Free speech, as long as it doesn't cause conflict or hurt feelings.
Beliefs, Everyone's beliefs are to be observed
Collectivism over Individualism
Role of the state is to grow and do everything it can to protect people through prevention, experts, laws, regulation, etc.
Taxation and Regulation to prevent unfairness


Some References:


https://www.lp.org/platform Libertarian
https://en.wikipedia.org/wiki/Modern_liberalism_in_the_United_States Modern Liberalism
https://en.wikipedia.org/wiki/Neoliberalism Neoliberalism

The question is what would libertarian morality say to a person who  wonders whether it is morally permissible for him to save his own life by taking a bottle of water, which belongs to someone else. The situation is such that the parched person cannot gain the consent of the bottle owner (either the owner is not there or refuses to give him although she does not need the water), and he plans to compensate the bottle owner with a new bottle asap.   

The answer by Guill is called hard (or hard-line) libertarianism (term a la Richard Arneson), which is majorly associated with Ayn Rand's idea. For hard-line libertarianism, the consent of the right holder is sacrosanct. The parched man cannot obtain the consent of the bottle owner, thus taking the bottle is morally impermissible. The hard-line libertarian will have to say that the parched man may not take the bottle, and the morally right thing for him to do is to die of thirst.  

Surely, hard-line libertarians are cold-hearted, as Jobermark remarks, "If you keep water from someone dying of thirst, even if they manage not to die in spite of you, you are not welcome to be an American." Not only being callous, hard-line libertarianism is impractical. Things happen in life where obtaining consent is infeasible when one tries to bring about morally desired or permissible acts (e.g., the right holder is unconscious, demented, deranged, or absent). 

Does this mean that, as alanf asserts, "you can take anything you want. You might have to pay compensation afterward or something like that." Can compensation replace the absence of consent for liberatarians? That is, is it morally permissible to infringe upon the rights of others on the condition that full compensation to the injured right-bearer is made? This is the question that Nozick, an academic libertarian as opposed to the populist libertarian Ayn Rand, tackled in his Anarchy, State, and Utopia. 

Noizick  understands that the infringement of some rights without the consent of the right holder sometimes is morally permissible if appropriate compensation is made.  Nozick, however, asserts that compensation cannot substitute for the omission of consent. The reason, according to Nozick, is that the allowance of after-the-fact compensation will distort the system of fair distribution of the benefits of voluntary exchange, which is the backbone of Nozick's entitlement theory of distributive justice and private property. Once you took my stuff and used it, it becomes hard to determine what is the appropriate level of compensation. The shape of transaction before and after the event will be quite different. The parched man might have gladly paid $10 for the bottle Nozick owned, but now that he is no longer thirsty, he might offer Nozick $1 as a compensation, the price at a grocery store. This transaction, according to Nozick, is unfair. 

Given the potential conflict with his entitlement theory, Nozick avoids to offer a clear guideline for the moral permissibility of right infringement in a non-consent situation with full compensation. The current goal of libertarians is how to become a bleeding heart libertarian (e.g., Matt Zwolinski and John Tomasi).    
If we never chose anything we should not, by some objective standard, how would that be "will" of any variety, or "free" anything? The existence of suboptimal choices seems to put a lower bound on free will, rather than an upper one. We are free to be stupid, because we are free.

On the other hand, the continuation of a total war is perfectly logical.  If you stopped fighting to ask the question as to whether to sit down and talk, you would most likely be killed. You are on a treadmill with a minimum speed, and you can't get off unless you break it completely and you would most likely die in the process.  In your example, WWII, at least one side was well-prepared for mass genocide.  Making peace with them too readily might just get you collected up and done away with.  There was no better option for them, since their entire agenda was total safety for a given race of individuals, in a way that would be infringed by the mere existence of anyone safer.  When you have two choices, and annihilation is one of them, the other one is probably optimal.

The ability to evade that logic and actually end the war despite the apparent logical loop you are in seems to indicate free will much more than the fact that the deterministic loop holds control as long as it does.
Nothing is a 'thing' like any other. A conceptual construction   that relates to another - something - directly. Something doesn't have to come out of nothing on average, stochastics can create the world within nothing. 
I guess one of the way this quote can be interpreted (I don’t want to claim it’s the only way) regards getting the “semantic of the language” (the meaning of terms) N. will use to explain his philosophy, which is a fundamental step to understand someone’s point. 
Here N. simply defines the “hero” as the center of the “tragedy sphere”, the “demigod” as the center of the “satyr-play sphere” and the “God” as the center of the “World”. 

While heroic nature is inherently linked with tragedy main concepts of unfulfillment and struggle against faith, the demigod nature goes beyond the idea of “struggling against faith to death” and it comes closer to the idea of “getting into the flow of faith” 

The “Also sprach Zarathustra” has been structured as Satyrspiel (made of 4 parts: 3 tragic acts and 1 final satyr-play act) as Zarathustra is a demigod (in a Nietzscheian sense, see above) just like Christ: both are not tragic heros. 
Of course it depends on what framework you are asking about.

For Marxists, the proletariat is an international entity, so its struggle with the bourgeoisie is likewise.

Equally, you can http://www.tandfonline.com/doi/abs/10.1016/0191-6599%2892%2990056-I?journalCode=rhei20 google your favourte liberal philosopher's take on nationality.

It seems to me though that you are trying to derive your political philosophy from ethical principles. The fact that something is practically impossible surely doesn't mean we have absolutely no duty toward it. Isn't that the nature of Kant's imperfect duties, that they cannot be entirely fulfilled? 

Liekwise, http://plato.stanford.edu/entries/moral-dilemmas/ moral dilemmas admit of the messiness of practical morality.


  Ethicists as diverse as Kant (1971/1797), Mill (1979/1861), and Ross
  (1930, 1939) have assumed that an adequate moral theory should not
  allow for the possibility of genuine moral dilemmas. Only recently—in
  the last sixty years or so—have philosophers begun to challenge that
  assumption. And the challenge can take at least two different forms.
  Some will argue that it is not possible to preclude genuine moral
  dilemmas. Others will argue that even if it were possible, it is not
  desirable to do so.


In conclusion: the difficulty of the issue in the question surely won't imply, on its own, anything about what is morally right. 
The theory itself can be reasonable, but it needs further premises to justify it. The argument itself is certainly fallacious, however that does not mean that the theory is. The biggest issue I see with this discussion is the following phrase: "no evidence can be adduced against this theory: because the cycles are enormously long we have no hope to survive till the next cycle so that we might check whether it is identical to ours or not".

The above phrase is an appeal to ignorance, as has been mentioned in the comments: just because we can't (or don't) know that it is not true, doesn't mean that we can be in any way sure that it is true. Additionally, the theory itself has not been presented in its entirety. The position might be a direct consequence of the theory, but it has not been shown to be so you have a jump in logical reasoning as well.
It is difficult to place confucianism in either Virtue Ethics or Deontology, since in his teaching there is a high emphasis on both( Analects 5.7 & 14.17 ). Although trough my study and understanding of The Analects I believe that the answer is Virtue Ethics. Also the question you have asked , does suit Zilu specifically well : 

Analects 15.4. 


  The Master said, "You [Zilu], there are only a few who understand
  virtue [de]."


This tells us that Zilu is someone who has the capability to understand virtue since a few pages after this we read :

Analects  15.8.  


  The Master said, “Not to speak to a man who is capable of absorbing
  what you say is to let the man go to waste. To speak to a man who is
  incapable of absorbing what you say is to let your words go to
  waste...”


Confucious' views on this topic are not always clear but in his comments and defense of Guan Zhong whose actions were not align with what was considered his duty are strong argueements that Confucious leans Virtue Ethics : 

Analects 14.17 


  Zigong said, “Guan Zhong was not humane. When Duke Huan had Prince Jiu
  killed, he chose not to die, and instead he decided to serve Duke Huan
  as his counselor.” The Master said, “When Guan Zhong served as the
  counselor of Duke Huan, he saw to it that Duke Huan would stand as the
  lord protector among the regional rulers, drawing all the states
  together under one empire. To this day, people [of all the Chinese
  states] still benefit from what he accomplished. If not for Guan
  Zhong, we would be [like the barbarian tribes,] wearing our hair


And in Analects  5.7 we can find insights into Confucious' and Zilu's stance on whether duty trumps the moral way :


  The Master said, “If I cannot practice a proper way here in this
  world, then I shall take to the open sea and drift around on a bamboo
  raft. The person who will follow me would be You [Zilu].” Zilu was
  overjoyed when he heard these words..."


Here in 5.7 I argue that we have a denunciation of deontoligy without the moral way. Since if Confucious found that he could not practice the moral way in this world that he would turn away from the world and his duties and sail the sea. Also worth noting is that out of all his disciples he picks Zilu to come with him on this rhetorical journey.

Zilu is one of the three standout early students (Yan Hui, Zigong, Yan Hui) who followed Confucious into his exile. On Yan Hui we have very little probably since he passed away early but he is mentioned in the Analects to Confucious' best student someone who's knowledge might even surpass Confucious( Look Analects 5.9 ), Zigong who has often protested when he did not agree with Confucious( As in 14.7 ), but Zilu is mentioned as a very faitful student who tried to apply Confucious' teaching as mentioned in 5.14


  Before Zilu was able to put into practice what he had heard, he only
  feared that he might hear something else.


Based on this I believe that Zilu's philosophy is reflective of Confucious'. Since we can say that Confucious' philosophy is definitively leaning to Virtue Ethics, we can assume the same for Zilu's.

At the same time we can not deny the presence of deontology :

Analects 4.1.


  The gentleman is conscious of [not breaking] the law, while the common
  man is conscious of what benefits he might reap [from the state].”


The idea that Zilu comes to realize in Analects 18.7 is a core belief in Confucious philosophy, that public service is a part of the moral way. The word Junzi can also be translated as a person of high standing, or ruler. But not everyone who is in public service is a moral person similar as in :

Analects 14.4 


  The Master said, “A person who has integrity is sure to have something
  to say, but a person who has something to say does not necessarily have integrity."


Further understanding of what a Junzi is, and how public service is a part of the moral way can be found in Analects 14.2 where Confucious is again talking to Zilu :


  Zilu asked about the gentleman [junzi]. The Master said, “He
  cultivates himself in order to acquire a respectful attitude.” “Is
  that all?” “He cultivates himself in order to give ease to those
  around him.” “Is that all?” “He cultivates himself in order to give
  ease to the people. To cultivate oneself in order to give ease to the
  people—even the sage rulers Yao and Shun found it difficult to do.”


And the final sentence is something I have not yet understood myself but Zilu it is very much reflective of Confucious again, as in Analects 14.3 ( With Zilu again ) 


  Zilu spent the night at the Stone Gate. The gatekeeper asked him,
  “Where did you come from?” Zilu said, “From the Kong family.” “Is that
  the person who knows that what he is working toward simply cannot be
  realized?”


The gatekeeper's comment is in refference to Confucious. 
The answer is option 4. because a pure utilitarian would only consider the outcome such as the overall happiness in the world. Since both options would lead to the same amount of happiness. A utilitarian would not pick the morally right one because it might result in a overall negative happiness. So the logical answer would be D.
Given the premises, it is an example of affirming the consequent. If we put the argument into statement form, and by a little natural deduction, then it is easy to see!

For,

A=They plan to kill me, B=They care that I see where we are going, C=They blindfold me

From your argument, we have:


A ⇒ ¬B (Premise, "If they plan to kill me, then they don't care that I see where we are going)
¬C ⇒ ¬B (Premise, "If they don't blindfold me, then they don't care that I see where we are going")
¬C (Premise, "They don't blindfold me")
¬B (2,3 Modus Ponens, "So, they don't care that I see where we are going")
A (1,4 "They plan to kill me" only by Fallacy of Affirming the Consequent)

Yes, there are decidable arithmetics. But Gödel's original 1931 proof was in the framework of Russell's Principia Mathematica, chosen because it was the most developed logical framework for reproducing all of mathematics at the time. Later he simplified the proof and showed that the Peano Arithmetic was enough.

Along the lines of your first suggestion, there is the https://en.wikipedia.org/wiki/Presburger_arithmetic#CITEREFFischerRabin1974 Presburger arithmetic, introduced in 1929, about a year before Gödel obtained his result. It has addition, equality, and even induction, but no multiplication. The absence of multiplication precludes the definition of https://en.wikipedia.org/wiki/G%C3%B6del_numbering Gödel numbering, and therefore the construction of Gödel sentences. This is not a proof of completeness, but it explains why it holds retroactively, Presburger himself produced an explicit deciding algorithm. An algorithm it may be, but it is not too easy, Fischer and Rabin proved in 1974 that the computational complexity of the decision problem is doubly exponential. An interesting factoid concerning the difference between the two arithmetics: https://arxiv.org/abs/1602.03580 Glivický and  Kala recently produced a model of Presburger arithmetic where the Fermat Last Theorem fails, and there are infinitely many counterexamples. It is believed that this can not happen for the Peano arithmetic, although this does not technically follow from Wiles's proof, see https://math.stackexchange.com/questions/1873482/are-there-non-standard-counterexamples-to-the-fermat-last-theorem/1888100#1888100 Are there non-standard counterexamples to the Fermat Last Theorem?

It is not so easy to implement the other two suggestions because finiteness is  property of a model, not of a formal theory. Attempts to write finiteness into (first order) axioms, a la Dedekind for example, produce something which is not what it intuitively means (there are infinite models of theories which "claim" in axioms to be finite). If we settle for a model with finite domain instead of a first order theory though, that of course will be decidable, because one can check all possibilities by exhaustive search. 

There is a kind of arithmetic with finite models, which preserves all the resources of the Peano arithmetic, but replaces the classical logic with the paraconsistent logic LP. These are https://www.jstor.org/stable/30226609?seq=1#page_scan_tab_contents Priest's inconsistent arithmetics. Note a subtlety in the notion of completeness for inconsistent models: while there is a decision procedure that assigns true/false to each sentence, there will be some to which it assigns both, called http://plato.stanford.edu/entries/dialetheism true contradictions or dialetheias. The reason we can have a finite model is that we can have "inconsistent integers" for which n=n+1, this leads to a true contradiction but does not trivialize the theory, paraconsistent that it is. In fact, for all numbers smaller than the least inconsistent number N the model is identical to the usual Peano arithmetic, and Priest argues that we can not possibly know what is "true" of objects in our world if N is exorbitantly large, see his http://virthost.vub.ac.be/lnaweb/ojs/index.php/LogiqueEtAnalyse/article/view/1326 What could the least inconsistent number be? 

This vindicates http://www.jstor.org/stable/2183788 Wittgenstein's paradoxical opinion that incoherence is not a problem for calculational mathematics (or any language game), and his anticipation of paraconsistent logics:


  "Something tells me that a contradiction in the axioms of a system can't really do any harm until it is revealed. We think of a hidden contradiction as like a hidden illness which does harm even though (and perhaps precisely because) it doesn't show itself in an obvious way. But two rules in a game which in a particular instance contradict each other are perfectly in order until the case turns up, and it's only then that it becomes necessary to make a decision between them by a further rule... Well then, don't draw any conclusions from a contradiction; make that a rule." 

Glad you asked this question here. Mumford and Anjum are my favorite contemporary Philosophers, bar none. Their work on causation, I take to be seminal work. First and foremost one must understand that the necessity operator is an operator. Mumford and Anjum argue that the notion of necessity (the operator) is much more obscure than causation itself. Anjum and Mumford put forward what they call Antecedent strengthening. This is something they've gained from Anscombe or Geach's work, I'm not too sure, but I do know that Geach has a paper on it somewhere. I've not read their short introduction, but I am familiar with their work in http://rads.stackoverflow.com/amzn/click/0198709625 Getting Causes from Powers and elsewhere.

The key focus of the Anjum-Mumford thesis is that we use the necessity operator recklessly and this obfuscates everything. Quotation from p. 47, Getting Causes from
Powers:


  *Even if you strike the match exactly right, there may be some external factor, outside your control, that prevents the match from
  lighting. You still have no doubt that when the match does light, the
  striking was the cause, or at least a cause. Does that mean that
  striking necessitates the lighting in just some cases, namely, the
  successful ones, but fails to do so on other occasions? That seems
  like a misuse of the concept of necessity. If someone were to say that
  in some cases, being water necessitated being H2O, but in other cases
  it did not, prima facie it would seem as if they did not understand
  the meaning of necessity. In the causal case, it seems
  more plausible in such circumstances to say that particular a caused
  or produced particular b without necessitating it. That a caused b
  suggests that a made b happen (Woodward 2003), but why should that
  automatically mean that a necessitated b? Could there not be an
  account of causal production without necessitation? Is necessitation
  rather more than is needed for causation? Isn't causation between a
  and b already a strong enough connection? The philosophers who try to
  account for causation in terms of necessity are, we argue,
  over-bidding in their theories. 


Anjum and Mumford are targeting what it means for the notions of sufficient conditions as applied to the case of causation. It is a necessary condition for my peanut plant to receive sunlight in order to grow, but it is not a sufficient condition. A necessary condition is some event or condition without which we would not have the effect, and sunlight is a necessary condition. However, this necessary condition doesn't guarantee the effect. It seems that a sufficient condition would guarantee the effect. They then move on to the argument that there is never a sufficient conditions for an effect, and thus against a cause ever necessitating its effect.

Two quick things. Propositions do not cause anything. Propositions entail certain things. Entailment is different from the relation of necessitation, they are simply said, two different categories. A rock (by the traditional definition) means by definition, that it's something which is a non-thinking substance. Being a rock doesn't necessitate that it is a non-thinking substance, it entails it. When you unpack the meaning of words and propositions, certain things entail the premises, but this is not to be confused with necessitation. 

Causal Necessitation is the thesis that if certain conditions are met, then the effect follows out of necessity, that there is no chance of it being prevented or interfered with.

Anjum and Mumford take an issue with this because of the following;

(1) Antecedent Strengthening. The challenge is that, If A necessitates B, then, if A + ∅, for any ∅, then B.

To put it in other words, if a cause necessitates any effect, it necessitates it simpliciter. There are no added conditions to it, the moment you do so, you're leaving Causal Necessitarianism (CN). So when they say that it could have been interfered with, and thus stopped the causal production, they take this to go against the thesis of CN above defined. People usually read this and say, "Well, that's an easy challenge to meet, let's just give it enough conditions and remove the kind of conditions that could interfere with an effect, and thus CN will be redeemed."

Suppose an effect e has four causes, c1, c2, c3, c4. An instance of c1-c4 produces e. The question is not whether c1-c4 caused it, but whether it caused it by means of necessitating it. So if there is a possibility of it being interfered with, it cannot be said to have necessitated the effect. Because there could always been a causal interferer (CI). As such, most of all causation seems to fail the test of necessity. It should be added that they are saying something like, "Give us any cause or event, and let us see whether or not that passes our test." If it doesn't pass their test the cause doesn't necessitate its effect, if the effect is ever produced. Suppose that you can show some (for the sake of argument) causes in nature that do pass their test, that would only mean that those specific causes are necessary causes while the rest of all causation is without necessity. CN should also not be confused with determinism which concerns the fixity of the future, and can be achieved or argued for even without CN (though I think that is wrong on different grounds).

(2) Negative state of affairs cannot be converted to causes. Absences are not causes per se. There is no such thing as causation by absence. Suppose I'm suffocating, the absence of oxygen causes my suffocation, or so we say. A lack, or nothingness is not something else in disguise. The problem is that apparent nothingness is involved in causation. Causation by absence claims are false.

(2a) Phil Dowe (2001) invokes counterfactuals in place of absences as causes. Statements like "Absence of A caused *B," what we have in mind is that should A not have occurred, B would not have been the case. So in me being suffocated, it's not that the absence of oxygen that causes me to suffocate, but rather, had I received oxygen, I wouldn't have suffocated. Since Anjum and Mumford subscribe to the Powers theory of causation, it is in virtue of the powers present in my body that cause me to suffocate. Me breathing finely was a state of equilibrium by intaking oxygen among other things to breathe. Certain facts about me always disposed towards my suffocation. So in the cases of the absence of oxygen, the remaining powers of my substance-hood did all the causal lifting to cause me to suffocate (though the absence of oxygen plays an explanatory role, it doesn't play a causal role). You would need truthmakers for the kind of counterfactuals I've mentioned above, but I'll refrain from putting them here. 

(3) Analysandum? Suppose someone touches my hand when I'm numb, someone has touched my hand. Isn't it always the case that when someone mentions a cause that a cause and effect are being related? No. Anjum and Mumford deny this and spend their whole book on finding out what a cause is. This example is a prime case of a cause happening, that is, someone holding my hands, but due to my defective senses, fails to have the effect of me feeling their warmth. A cause should not be looked at as always producing an effect, but should be seen as something which makes certain effects possible by increasing their possibility. They spend their whole book on 'What does it mean to be a cause?' after decisively taking down Causal Necessitarianism, there is simply way too much to go into in order to show how they succeed in doing this, so my best bet is to ask you to read the book in due time :). I've only mentioned the things I've suspected you're having problems with, the bulk of it, I wouldn't dare go into over here. It would be too much to do, feel free to ask me questions though.
See https://en.wikipedia.org/wiki/Kripke_semantics#Semantics_of_modal_logic Semantics of modal logic :


  A Kripke frame or modal frame is a pair ⟨W,R⟩, where W is a (possibly empty) set (the set of worlds), and R is a binary relation on W (the accessibility relation).


A class of frames is a collection of frames sharing some "relevant" property of the accessibility relation.

For example, if we "impose" the frame condition on R of reflexivity, we have that all the frames of the corresponding class satisfy the axiom


  □A→A.

Long comment

The relation of denotation holds between a word of the language and an object of the world "out there".

We use the word (an expression) "apple" in the object-language that denotes an apple in the world. If I say "The apple is red" I'm speaking in the object-langauge and I'm using the word "apple" to speak of the world (the apple on my desk).

But we cannot reverse the relation : the apple out there does not denote the word "apple".

Thus, when speaking about language we use the meta-language to speak of the object-language: now the words of the object-language are the "objects" out there.

We have to use some "trick" to avoid mixing the two languages, like e.g. use German (selbst) for the meta- and English for the object- (self).

A usual trick is to use quotation marks :


  "self" is a four-symbol word.


I think that it is not a good practice to conflate the relation of denotation with that of identity.

If we say :


  "self" denotes self


it is quite clear that we cannot "reverse" the relation, while :


  "self" is self


looks symmetric.

But we have to use meta-language to speak of the object-language and not the other way around.
This is an interesting but also very complex question.

On the simplest level, my answer is no for most of your list (specifically, metaphysics, epistemology, ontology to which I might add ethics, social philosophy, every era in the history of philosophy). Instead, these are the things that people research rather than techniques used for doing research.

Dialectics is a hard one depending on what is meant by the term. By and large, contemporary philosophers will associate this with Hegel's philosophical method  or with Marx's -- both of which are (largely though not universally) despised by the majority of philosophers.

Logic is for most philosophers a key part of their tool kit. Here, this should be taken to mean sentential logic, categorical logic, analogies, and (to differing degrees) modal logic. (For those who specifically study logic or philosophy of math as an area of research -- I believe we had one researcher who answered a few questions here for a bit -- the may also study more esoteric things like tri-valued logics or deontic logic which are not a part of the universal toolkit).

Having given the answer, no, I should explain several ways that this could prove to be an inadequate answer.

First, I'm working from my experience plus how I've seen other philosophers work. I can think of four types of philosophers I've encountered: contemporary analytics, contemporary continentals, historical figures or periods - translation / exposition, and historical figures or periods - comparative. For all categories, a major component of research is reading.

Maybe it might be easiest to start with the last two categories in terms of how the research process works. For historical translation / exposition philosophers, a good deal of what they do is read texts in the original language, provide translations, and argue about interpretations of the arguments. For historical comparative philosophers, they work with historical texts and contemporary texts to suggest either contemporary solutions to historical problems or historical solutions to contemporary problems (there's a good deal of variation where you could replace "solution" and "problem"). They key thing that makes this philosophy rather than history is that they are focused on offering arguments.

For contemporary analytics, most of their reading is going to be contemporary, and comparatively, they will have taken more logic. Also, some of them are going to need to be up to speed on research in other fields -- like neuroscience, chemistry, or psychology. The point is that they are offering arguments using logic and analogies to support positions on issues that matter to them.

Contemporary continentals sometimes do research like historical philosophers do. Others have what at least to me looks like a religious interest in some contemporary philosopher (for instance Judith Butler or Julia Kristeva or Martin Heidegger) where they mostly argue with others in their sub-discipline about interpretations or implementations.

All of that being said, people who write about ethics, social philosophy, aesthetics, or other similar things may often also include metaphysics/epistemology/etc as tools. As in they may give an account of art based on Kant's ideas in epistemology and art. Or they may give an account of morality building on Aristotle's account of human persons. The same pattern can also happen with epistemologists building on preferred metaphysics and then metaphysics people building on more fundamental metaphysics and logic. But it's also possible that they are positing something that is simultaneously metaphysics and epistemology rather than using any of these as a tool.

Others may have a different account of the sort of methods professional philosophers undertake... If so, I'll gladly defer to clearer accounts of how this works.



Maybe to make it more practical, here's what I do in my own research:

Type A


read a whole lot
notice something interesting in primary literature
focus in on secondary literature to see if I've got something interesting to say
compile the paper
revise and refine its arguments
submit, rinse, repeat


Type B


Have an insight that I think would make a good paper
Work on the argument / read papers in the vicinity of what I'm hoping to say
Either be convinced I have something worth saying and revise / add sources OR give up.
Further refinement
Submit, rinse, repeat


(Of course once it's accepted, there may still be a lot of work to do on it).

This takes months or even years in actual time (though actual time is interrupted by many other obligations).

If there's a better method that would get me either (a) better publications or (b) more publications for my time, I'd love to hear it.
Your title allows for better answers than your example.  And I will answer from the title question, rather than limiting myself to the plane.

You know where the centerpoint of a parabola is, even though it extends infinitely far away from there in both directions -- it is the point closest to the focus, the point of maximal curvature.  It is a center in a http://www.solitaryroad.com/c405.html specially defined sense which recognises a sense of the symmetry a center should confer.  Similarly a cubic has the opposite kind of center, a uniquely flat point.  However you rotate the curves, these central references remain obvious, and they are historically relevant enough that the ordinary sense of center is often extended to include them.

A hyperbolic paraboloid has a https://en.wikipedia.org/wiki/Saddle_point saddle point where its tangent space splits it into ascending and descending parts, and that makes it a centerpoint of the space in important ways, again related to symmetry rather than distance.

So in the sense of the point that everything is intuitively situated in terms of, like a city center, certain infinite spaces have centers.  If our own universe is "too light", it may have a hyperhyperboloid shape, with the third-dimensional equivalent of the saddle point, and in this sense a relative center.
Terminology changed somewhat, and much of what used to be called "logic" as late as early 20th century is now called epistemology, for more details see https://philosophy.stackexchange.com/questions/37276/what-are-the-differences-between-philosophies-presuming-one-logic-versus-many-lo/37279#37279 What are the differences between philosophies presupposing one Logic versus many logics? Posterior Analytics covers mostly that epistemological part of logic. What Aristotle describes is what later was coined into https://en.wikipedia.org/wiki/M%C3%BCnchhausen_trilemma Agrippa's trilemma from the exposition of Pyrrhonism in Sextus Empiricus (more recently also Münchhausen trilemma): any justification of knowledge (episteme, Latinized as scientia) either rests on "first principles", or is circular, or involves an infinite regress (technically, this is not a trilemma because the possibilities are not mutually exclusive). Agrippa, according to Sextus, does not have "first principles", but adds three more possibilities, not considered by Aristotle: knowledge is merely hypothetical (this is closest to the "first principles"), knowledge is relative, and knowledge is uncertain and reduces to opinions. 

The position Aristotle staked out for himself is now called http://plato.stanford.edu/entries/justep-foundational/#1 foundationalism (after the "first principles" being the foundation of knowledge), and the regress of justifications is a classical argument in its support. In modern times foundationalism was reasserted by Descartes, and came in two flavors, rationalist and empiricist, depending on whether the source of "first principles" was purely sensual (Locke, Hume, Mill, Mach) or some sort of rational insight was involved (Descartes, Leibniz, Kant, Husserl). 

The outright rejection of foundationalism now came to dominate both current analytic and continental philosophy, including philosophy of science (in the modern sense). Its origin is associated with Hegel, who incidentally also called epistemology Logic, or Science of Logic. Hegel rejected foundations in his famous https://www.marxists.org/reference/archive/hegel/help/mean06.htm dialectic of immediate/mediated. In "Agrippa's" terms, he is opting for the infinite regress of sublations of "immediate" givens (albeit denouncing the http://www.blackwellreference.com/subscriber/uid=1145/tocnode?id=g9781405106795_chunk_g97814051067953_ss1-6 "bad infinity"):


  The facility we attain in any sort of knowledge, art, or technical expertness, consists in having the particular knowledge or kind of action present to our mind in any case that occurs, even, we may say, immediate in our very limbs, in an outgoing activity. In all these instances, immediacy of knowledge is so far from excluding mediation, that the two things are linked together - immediate knowledge being actually the product and result of mediated knowledge [...] Abstract immediacy is no doubt a first; yet in so far as it is abstract it is, on the contrary mediated, and therefore if it is to be grasped in its truth its foundation must first be sought. Hence this foundation, though indeed an immediate, must have made itself immediate through the sublation of mediation. 


Heidegger abandoned his early Husserlian foundationalism in late works, and Adorno explicitly employed Hegelian anti-immediacy arguments in his broad "meta-critique" http://rads.stackoverflow.com/amzn/click/B00HFTZF1S Against Epistemology, which anticipates many postmodernistic themes. 

On the analytic side anti-foundationalism was assimilated through Peirce ("My philosophy resuscitates Hegel, though in a strange costume", "[science] is not standing upon the bedrock of fact. It is walking upon a bog, and can only say, this ground seems to hold for the present. Here I will stay till it begins to give way"), Lewis, and his perhaps better known students Quine and Sellars, see http://www.klemens.sav.sk/fiusav/doc/filozofia/2014/4/332-341.pdf Misak's Exploding a Myth. Quine's http://plato.stanford.edu/entries/epistemology-naturalized naturalized epistemology is perhaps the most influential form of analytic anti-foundationalism today, and it openly admits that all knowledge is hypothetical and undergoes potentially unending revision of its "foundations", including methodology. It embraces even the element of circularity the latter entails. https://books.google.com/books?id=bsmqdTaGejAC&source=gbs_navlinks_s Philipse's paper Edmund Husserl and the History of Classical Foundationalism (in Husserl and the Sciences volume) is a good historical survey:


  "According to many present-day epistemologists, the justification
  of scientific theories is relative in at least two respects... New empirical data may top the balance in favour of an existing rival theory, or a new
  rival theory may be designed that performs better... The model of justification by competition must be applied also at the meta-level of justifying epistemological theories [...] in Heidegger's time, the research programme of classical foundationalism had reached the stage of its final decline, dragging down in its bankruptcy the notion that philosophy is fundamental to the sciences. Its most promising rival as an epistemology of the empirical sciences is not coherentism [e.g. Hegel's], but competitive empiricism... Within the framework of competitive empiricism, the problem of the first principles simply does not arise."


P.S. I do not think there is much of an analogy between Aristotle's reasoning and Gödel's. Aristotle concludes that "axioms" are needed to support deductive chains that derive truths of knowledge (and he was an empiricist about their source). Gödel shows that (sufficiently rich but first order) axiomatic system can not derive all (Platonist) "truths" due to self-reference issues. The reasons involved are completely different, and Aristotle might even reject Gödel's form of the conclusion of the incompleteness theorem on anti-Platonist grounds, as intuitionists did.
we cannot do controlled experiments in astronomy or paleontology, to name just 2 genuine but non-experimental sciences.  so the fact that historians cannot do controlled experiments does not mean that they cannot produce genuine knowledge.

one could argue that all knowledge, including scientific knowledge, is historical.  when a physicist studies data from a super-collider experiment, she is in fact studying a historical record. physicists learn their craft by studying how it has been done in the past.

the study of history does not produce laws, but it can produce knowledge.  when parents teach their children, they're not going by laws, they're going by experience - history - including what they learned from their parents.

just think of contemporary economics.  even the most abstract theories are inevitably based on historical studies. that's where the evidence is.

hth

  this puzzles me. personally, I think Chomsky is the antithesis of a good scholar. I can't think of a single thing he has ever written that is not a piece of ideology, or even proganda.


Are you confusing Chomsky the linguist with Chomsky the political hack? Yes, they coexist in the same person, but they are quite different from one another(1).

It is impossible to ignore Chomsky the linguist, never mind how much you hate Chomsky the pundit. That's not to say that his linguistics are above criticism, but to realise that criticism of his linguistics is only possible due to his own linguistics. They are the state of art in liguistics, or were so not long ago, and progress in linguistics is not going to happen without a very sound and thorough analysis and refutation of his contributions.

(1) They are so much incompatible with each other that while Chomsky's politics are quite left of the centre (though not so much as rabid right-wingers suppose), his scientific contributions are based on a quite right-wing trope, the idea of an instinctual, hard-wired, ability to learn languages.
in the passage you cite, the word "logical" does not mean logical.  it means something like sensible or satisfactory.  this is a very common use of the term in ordinary speech; we often call things that don't make sense to us "illogical" when what we really mean is "nonsensical" or the like. but this is a misuse of the term if you mean genuine logic. Logic is not in the explaining business. the central concern of logic is the notion of consequence  (note: not truth), or maybe inference, depending on whom you ask.  So Lewis might say "the inference from my unsatisfiable desires to the proposition that I am made for another world is logically valid; moreover it is the only logically valid inference from those premises".  The problems with that should be fairly obvious  (from a logical perpsective).

what sense there is in the original quote comes from content, not logical form.  and logic is about form, not content.
Since alienation is at the very kernel of capitalist relations, I don't think it is possible to approach the issue from a pro-capitalist point of view except by denying its existence, or fundamentally misunderstanding it as something different. A critique like you hint at, "socialism and communism would only exasperate alienation if one considers them to be anti-individualistic ideologies" would be an anarchist criticism, or perhaps a primitivist/anti-civilisation one.

But this doesn't mean that a right-wing critique of alienation is necessarily impossible - as long as such right-wing is based upon what Marx & Engels call "reactionary socialism", ie, a critique of capitalism based upon nostalgia of older social relations, feudalism, or simple commodity production. This is indeed not a rare thing, the criticism of commodification of social relations as a defence of the "good old times" when capitalist relations of production hadn't yet penetrated and destroyed older, "idyllic" relations - especially family ties, proper respect for the elders, and a sense of "natural" hierarchies.
As worded, I'm not sure if this is a great question, but there's a good deal of very recent literature on the precise question you seem to be raising.

Worded at it's simplest, the question is 
1. Assume there's a God
2. Assume this God is "omniscient"
3. Assume "free will" means that individuals can make choices that are not wholly determined by prior influence.

Then the question becomes does "omniscience" refute the possibility of free will?

At least among different groups of Christians, there's four ways that I'm aware of in which people resolves this debate (There's a somewhat older volume from IVP called Four Views on Divine Foreknowledge):


Paul Helm and many "Calvinists" resolve the debate by rejecting this definition of free will. They are fine with our choices being only "compatibalistically" free -- that is to say they think we "choose" them but what we will choose is determined in advance ("would you like the chocolate cake or the azuki bean cake?" --> in my case, chocolate every time).
Open Theists deny that "omniscience" includes knowledge of future choices, because it denies that such things are knowable. Ergo, they would not be included in the account of knowledge. So God is "omniscient" on these views because he knows everything that is knowable which would not include the choices of free individuals.
Molinists has a rather sophisticated (=complex) view of how this works. They maintain that what God has is counterfactual knowledge of all possibilities. God knows what would happen if you were to make certain choices and what would follow from that. If I understand the view correctly, God even knows all of the dominoes that will fall but God doesn't pick any expect insofar as God chose to create a world that leads to all of that -- but does not know them factively.
Traditional Libertarian theism maintains that God knows what will happen but that knowledge is not determinative.  On this view, the main idea is that you're still making choices but God has access to what you will choose.


A separate and related issues is theories of time and their relation to theism. In general, views 2 and 4 are committed to an A-theory of time for God and the world whereas view 1 is committed to a B-theory of time. (See McTaggart's theories of time for more). 
This is a deeper and more difficult question than it seems on the surface --it's also one with less consensus than you might expect.

The study of the structure of language, as opposed to the meaning, is called https://en.wikipedia.org/wiki/Syntax syntax, of which grammar is a part.  Typically, the rules of grammar are considered consensus objects of the community of speakers, rather than as natural types (in other words, this is good grammar because we all agree it is good grammar, not because we discovered this rule engraved on a tablet of gold somewhere).  However, there are theorists who believe there are underlying rules to grammar that have their own independent reality similar to that the https://en.wikipedia.org/wiki/Philosophy_of_mathematics#Platonism rules of mathematics (putatively) possess.  Conversely, https://en.wikipedia.org/wiki/Interactional_linguistics others prefer to describe grammar as an https://en.wikipedia.org/wiki/Emergentism emergent phenomenon.

Even if one does accept grammar rules as just a consensus-based functional artifact of language, there are still a range of philosophical issues relating to the social matrix of the language.  For example, grammar is quite typically a marker of social status, with different grammars dominating the dialects of the upper and lower socioeconomic classes.  Is it correct https://medium.com/i-m-h-o/why-i-stopped-being-a-grammar-snob-aac6634d79af#.rglvt23we to privilege the upper-class grammar as correct?  These and many other questions are unresolved within the field.
It's been said that "https://ia902303.us.archive.org/17/items/NoamChomskySyntcaticStructures/Noam%20Chomsky%20-%20Syntcatic%20structures.pdf colorless green ideas sleep furiously" but this is nonsensical - possibly poetic.


  Are Concepts https://chomsky.info/wp-content/uploads/195609-.pdf Colorless?


Yes, concepts have http://alpha-leonis.lids.mit.edu/wordpress/wp-content/uploads/2014/07/chomsky_LSLT55.pdf no color. It would be a https://ia802703.us.archive.org/7/items/conceptofmind032022mbp/conceptofmind032022mbp.pdf category mistake to describe them as so, else it is poetry. Unlike color, which is prismatic range, concepts do not exist - they are only to be found in language.

Is the list of all cats a cat? No. http://dec59.ruk.cuni.cz/~kolmanv/Begriffsschrift.pdf Is the list of all lists a list? Yes. Is the list of all lists that don't list themselves a list? That's a question worth answering in http://isites.harvard.edu/fs/docs/icb.topic1219929.files/FregeRussellCorr.pdf letters...
This sounds like an example of equivocation, which https://en.wikipedia.org/wiki/Equivocation Wikipedia defines as follows 


  the misleading use of a term with more than one meaning or sense (by glossing over which meaning is intended at a particular time). It generally occurs with polysemic words (words with multiple meanings).


However, the term equivocation is mainly used for using two senses of the same word within a single argument, rather than a debate. See also http://www.logicalfallacies.info/ equivocation on LogicalFallacies.info. 
The https://books.google.it/books?id=JeUDUWYD5eQC&pg=PA177 quantifiers rules can be more generally specified with terms.

Terms are : variables, contants or "complex" ones (like e.g. x+0 in arithmetic).

The reason why is that every first-order theory has an ulimited supply of variables, while constants are usually few : one or none.

If we consider https://en.wikipedia.org/wiki/Peano_axioms#First-order_theory_of_arithmetic first-order arithmetic, we have only one constant : 0.

Thus, if we restrict the rules for quantifiers to constants, we are in trouble with e.g. the "instantiation" of the true sentence : ∃x (x ≠ 0).



Also the https://books.google.it/books?id=JeUDUWYD5eQC&pg=PA121 equality rules can be specified with terms :


  (=I) : we may derive (t = t) with no assumptions
  
  (=E) : if φ is a formula, s and t are terms substitutable for x in φ, and we have derivations D of (s = t) and D' of φ[s/x], we may derive φ[t/x]. The undischarged assumptions are those of D together with those of D'.




With the rule : 


  from Fx and ¬Fy, derive : ¬(x=y),


you can apply it with Rax as Fx.

Thus, Raa is Fa and ¬Rab is ¬Fb and you can conclude with : 


  ¬(a=b).

I don't think that Existentialism is an artistic affectation, or 'a mood', nor even that it is particularly subjective.  But its objectivity is psychological.  It can be achieved only by visiting a lot of emotional states that humans share and building an understanding, rather than starting from a conceptual summary.

The whole approach looks back at older philosophy and notes that most formal definitions take place in bad faith.  So there is a good reason for Sartre, or anyone representing him never to answer your question.  And I am not even going to try.

Good faith requires negotiation of the situation, so setting an understanding down in stone is simply manipulation done beforehand.  What you consider melodrama is meant to be an honest picture of human thought in extreme circumstances, where these negotiations have urgency.  (Only the objective circumstances in which they take place conspicuously lacks actual urgency, so we are watching real life in slow motion.)

As a mathematician and an engineer, used to getting to the point quickly, I also find him exhausting to read.  It is annoying to be pushed back and forth by his scenarios and negotiations, but that just means that people like us are withholding the patience that we would easily afford someone who wrote the way we like.  That does not make our bad taste his flaw.

What you don't get is that all human interactions are based on implicit assumptions, even those that pretend otherwise.  Philosophy is a human interaction.  So get used to it, instead of putting a value judgment on an inescapable fact of life.
Unfortunately, you can't put intuition into words for the simple reason that intuition is prelinguistic (although perhaps "sublinguistic" is a more apt description?) That said, I will try and describe the basic idea of "if P, then Q" which is also known by "P implies Q", "P then Q", "P → Q" and such.  

Each term [P, Q] can evaluate to either and only (true or false).

We can then rewrite the set of terms [P, Q] as a redundant collection of term conditions: [(true or false), (true or false)].

Note that with (true or false) we are using the logical constant "or" in an exclusive sense, not an inclusive sense. For example, if a parent tells a child they can have either a hamburger or a hot dog for dinner and the child requests both or neither, they have not met the condition established with the parents use of exclusively either a hamburger "or" a hot dog. When the child requests only a hamburger, the dinner choice established by the parent (the condition) is satisfied. When the child requests only a hot dog, the condition is satisfied. Four choices only: two fail (both, neither), two satisfy (hamburger, hot dog).

In the case of the inclusive sense of the logical constant "or" when the parent asks the child if they want peas or carrots with their dinner and the child says neither, they have failed to satisfy the condition established by the parents inclusive use of either peas "or" carrots. When the child requests only peas, only carrots or both, the parents condition is satisfied. Four choices only: one fails (neither), three satisfy (peas, carrots, both).

What is to be made of "if (true or false), then (true or false)"?  

What is to be made of "(true or false) implies (true or false)"?  

What is to be made of "(true or false), then (true or false)"?  

What is to be made of "(true or false) → (true or false)" and such?  

For ease of investigation, I will limit the next section to the P → Q notation and we can look at all the possible combinations:


true   →  true.
true   →  false.
false →  true.
false →  false


So here then is my "intuitive" sense of these options.

1) "If true, then true"
We start with a true proposition and we end with a true proposition. Seems pretty straightforward that the entire statement is true. In the expression of "true implies true" it is tempting to imagine that the truth of the former 'true' implies the truth of the latter 'true, however, "implies" is misleading in this senses of "causes the latter to be true" and "causes the supposition to be true." It seems awkward to imagine any positioning of two true propositions that would result in false, so this supposition made of to two 'true's is true simply that we start with true and "...then true." At the very least the statement values are consistent.

2) "If true, then false"
We start with true and end up with false. Why would we end up with false if we start with true? That seems confounded. In the expression of "true implies false" this feels almost embarrassing without even imagining that "implies" means "causes." In the sense of "true, then false" it is as if a mistake has been made or something working has broken; an intermittent problem has returned; the lights have gone out in the neighborhood. How could this supposition be other than false?

3) "If false, then true"
Hmm... at first I feel like starting out false, it is disingenuous that we end up with true, but there we are: "then true." Can we not start in ignorance and confusion and come to knowledge and analysis by distinction of utterance as true or false? "False implies true" seems counter-intuitive in the incorrect sense of implication as cause, but "false then true" is as if the lights in the neighborhood, the television, refrigerator and all things electrical have started working again. How could this supposition be other than true?

4) "If false, then false"
We start with false and end with false and that we end up with what we started with, this feels true. "False implies false" in the incorrect sense of implication is not so troublesome here in that it is true that false is false. "False, then false" is at the very least consistent and it is true that these are both false. See how we have come to truth from falsehood?

And such is my statement of an intuitive sense of supposition and two logical constants. I will leave it to you to consider the remaining forms with these descriptions of my intuitive senses.

What follows will be a more explicit articulation of supposition.

The supposition "if a proposition, then an other proposition" can be analyzed by explicitly articulating conditions which would satisfy the truth or falsity of the supposition.

For the purposes of this examination the previous sentence is equivalent to, "The supposition 'if a proposition, then an other proposition' can be [analyzed; considered; evaluated; computed] by conditions which would satisfy *its* truth or falsity." Please note the former expansion in the brackets and the latter italicized reduction as well the removal of "explicitly articulating". We shall examine the constituent propositions and their relation. For ease of distinction "a proposition" may hereafter be referred to as the "former proposition" and "an other proposition" may hereafter be referred to as the "latter proposition". 

The constituent propositions boundaried by the supposition (or, suppositional form) may be either true or false. Within the scope of this consideration I will consider any proposition with a nil truth value to be false. So far we have a supposition constructed from two propositions: a proposition, the former, and, an other proposition, the latter. The two propositions are distinct and not equivalent or identical. Keep this in mind as I shall reduce the propositions to true or false and may not always explicitly state "true proposition" and "false proposition". Lastly, the two propositions may be only either exclusively true or false neither proposition may be both.

In addition to the constituent propositions, the supposition expresses a relationship of the two propositions. This relationship is "if true proposition or false proposition, then true proposition or false proposition" and the aim of this investigation: how then shall we render a truth value from the supposition of two propositions which may be either exclusively true propositions or false propositions? I will also address - tho likely not convincingly - the question of, what does the suppositions truth value mean for the constituent propositions? (Hint: nothing whatsoever) I.e. my aim is also at the question, does the supposition change the truth value of the constituent propositions? In short, no, it does not. Also, in doing so I will comment upon the question, does the supposition cite logical (or physical) cause? The answer here as well is no.

For purposes of this investigation we are only considering a unidirectional relationship such that the resulting truth value of the supposition may sufficiently be said to be derived from the formal positioning (relationship) of the former propositions and the latter proposition. The suppositions truth value has not one iota of relevance to the relationship of the content of either the former or latter proposition. Also, we are not here concerned with whether or not the latter proposition necessarily implies the former proposition, i.e. we are not investigating the suppositionally bidirectional conjunction "if a proposition, then an other proposition, and, if the latter proposition, then the former proposition". Lastly, for the purposes of this investigation, it may also be said that the supposition expresses a relationship between or of or bounded to the two propositions by the suppositional form, but, as stated just prior, we are not investigating every relationship between or of or bounded to these two propositions when placed in proximity within the suppositional speculation. again, it is the suppositional speculation that binds the two propositions together and constructs a boundary within which the suppositional truth value can be rationally assessed. So on with rationally assessing the constituent propositions and then to rationally assessing the supposition.

The former proposition may be either true or false.

The latter proposition may be either true or false.

Is it enough to state that, "if the former is true and the latter is true, then the implication expressed by [derived from] the supposition 'if a proposition, then an other proposition' is also true."? Have we only presumed as much? Are we not simply expressing the conclusion redundantly by repeating the supposition "if something, then some other thing"? It may appear so. Such is a pernicious difficulty with the fundamental and trivial. Note that I do not use trivial in the pejorative sense of pertaining to useless information but in the sense that stating that the statements "the statement that 'Obama is President' is true" and "Obama is President" are true statements, and yet the two statements are distinguishable by the trivium of logic, reason and rhetoric.

Another strategy to avoid conjecturing the suppositional conjecture that "'if true proposition, then true proposition' is true" is to simply state example cases where both propositions which the supposition is constructed with are true, i.e. examples following the form "if true proposition, then true proposition", and then assess if the suppositional statement is true. In stating the shortened form of "if true, then true" we can immediately see that this makes trivial sense (in the pejorative sense). But are we convinced that "if a true proposition, then an other true proposition" is true? Maybe not. So before we conclude that "if true, then true" is true, let's examine a couple examples which fit the form.


if all dividends require financing, then an Euclidian circle is all points upon a plane equidistant from a central point.
if the Sun is ~93 million miles from the Earth, then Angelina has filed for divorce from Brad Pitt.


It is trivially (in the sense of the trivium) worth noting that the first example is axiomatic (the former self-evident by definition and the latter axiomatic) and the second empirical (the former brute and the latter institutional); and, that all four propositions are true.

It is non-trivially worth noting by these examples that a supposition is not citing cause - whether physical or logical. The former does not cause the latter to be true in the way that the cold may cause someone to shiver. That the cold may cause someone to put on a sweater, however, we can see that the relationship which the supposition provides a minimal bound upon results in a rationally assessable, if not trivial, truth value. I will leave it to you to decide upon this most recent sense of "trivial". How then to cite proof that this rational assessment is reasoned by logic and not an imposed rationalizing of the psychopathological varietal? It is said that axiom is only true because we do not allow it to be otherwise, but is logic nothing more than dogma? Let us consider the following instead of the standard "if..., then..." expression.

Here I offer a formulation of a supposition without the logical constants "if" and "then": "I suppose that because [since] the Earth is an oblate spheroid that when an object gets dropped mid-air it will fall to the ground." Note that this supposition does not correlate to cause tho the constituent propositions are true and the content they describe have causes. What of the speculative supposition then? Do not these kinds of statements presume uncertainty? Do they presume uncertainty even when certainty may be achieved (I am hesitant to say "obtained" as tho knowledge of the empirical and axiomatic may be obtained, knowledge is not a dissolutive salve for every skeptics every doubt.) Also, if enough to inspire doubt, is the mere form of supposition enough to convince of a falsity where there is otherwise a truth? These are not questions this investigation seeks to address conclusively, tho I do ask that they be considered inasmuch as the reader is unconvinced of the rationally assessable truth values of suppositional propositions of the form, "if a proposition, then an other proposition". At this point I think we've reached a limit of useful investigation by only considering the former and latter propositions when they are both individually true propositions. What of "if true, then false"? For example:


If dividends require financing, then 2+2=5.
If Obama is President, then all swans are white.


Whether or not there is logical or physical cause (and there isn't), the truth value of a supposition which concludes a falsehood cannot be true. We simply do not allow it. Note that what we are not saying with this supposition may shed some light on the computational logistics of rendering truth value: we are not saying "if true then true must be false". We are saying that the former proposition is true; that the latter proposition is false; and that the relation expressed by the "if..., then..." supposition boundary containing "the former is true" and "the latter is false" is a false relation. This last point might make more sense in ordinary language expressed in a different order: that the relation expressed by the "if..., then..." supposition boundary containing "the latter is false" and "the former is true" is a false relation. It might not.

What of "if false, then true"?


If 2+2=5, then dividends require financing. 
If all swans are white, then Obama is President.


In both cases that the latter is true the supposition is true. Again, is this merely a reformulation of an "if..., then..." offering circular proof that "if..., then..." is true (because it's true?)? No. It is demonstration. Note here that a suppositional proposition is not an argument and all we are examining here is the relation of the two statements bound in the suppositional form. We are not saying "if false then false must be true." We are not citing cause, i.e. dividends requiring financing does not make 2+2=5. While "imply" in this instance might seem to suggest that "if false, then true" means "false implies true" or that "'if false, then true' is true" means true supposition makes false proposition true. Neither of those implications are implicit to the propositional relationship in a suppositional condition.

What of "if false, then false"?


If all bachelors require pedicures, then 2+2=5.
If CarrotTop is President of these United States, then all ravens are orange.


How, it must be asked, could it be reasonably asserted that any supposition constructed from false propositions be true? Simply by noting that it is true that both propositions are false. 

At this point I will leave it to you to consider the equivalence cases and hope that my answer is enough to convince you that while I appreciate apprehension regarding formalities, their is much to be gained from the expediency of the formal notation, and, something to be gained by laboring their point.

Q.E.D.
I can't think of a specific term, but the closest one that I remember is called the fallacy fallacy: dismissing an opponent's conclusion as false/unworthy of consideration merely because fallacies were present in their argument.
From your referenced answer:


  However, one way of thinking about it is that "P implies Q" is
  logically equivalent to "(P and Q) or (not-P)", which is at least
  somewhat intuitive--either P is true and therefore Q is true as well,
  or P is false so it doesn't matter if Q is true or false.


...the author here is making note that the only case where P is true and the supposition "if P, then Q" is true is when Q is also true in the "if P, then Q" supposition. If P is false then "(P and Q) or (not-P)" will evaluate to "(false and Q) or (true)" and since (false and Q) will evaluate to (false), we are left with ((false) or (true)). The "or" here is an "inclusive or" ("exclusive or"s are usually explicitly denoted as "xor") and so long as one of the constituent propositions, or operands, in an evaluation proposition with an "inclusive or" operator is true, then the expression evaluates to true. Hence, "[when P is false] it does not matter if Q is true or false."

Apologies if this is already familiar to you, but note that "P is false" is not the same as "not P" - "not P" only evaluates to true when "P" is false. If "P" is true, then "not P" evaluates to false. If "P" is false, then "not P" evaluates to true.

To get an intuitive sense of this, it might help to note that when there are two propositions (for ease of discussion I will use the capital letters P, Q to represent non-identical, non-equivalent propositions) and each proposition has only one of two aspects (in this case, either "is true" or "is false" such that P is exclusively true or P is exclusively false) then the maximum count of possible arrangements is equal to the number of propositions to the power of the number of aspects. In other words, there are 2 propositions (P, Q). There are 2 possible aspects ("is true", "is false"). The total number of possible combinations is two propositions to the power two aspects, or 22 and 22 = 4. Note that when there are 3 propositions with only two aspects, there are 23 and two times two times two is eight.

Note: it is not necessary to only calculate for "is true" or "is false" - these are arbitrary considerations. You could arbitrarily do the same for the number of possible values when rolling two six sided dice. 2 dice, 6 aspects to each die, total number of potential outcomes when each roll results in exclusively one of the six aspect values amounts to each roll of two dice having 62 possible combinations, or, 36 "outcomes". Three dice have 63, or 216 possible combinations with every roll.

Back to our set of propositions [P, Q] and our set of aspects ["is true", "is false"]. For this next illustration I will shorten ["is true", "is false"] to [T, F]. We can then compose a compact visual shorthand for comparing the propositions and their aspects - a "table" if you will pardon the expression - like so:

P  |  Q  
---|---
T  |  T  
T  |  F  
F  |  T  
F  |  F  


Note that there are several ways to arrange these elements which display the same relationship, for example:

P  |  Q  
---|---
T  |  T  
F  |  T  
T  |  F  
F  |  F  


or

Q  |  P  
---|---
T  |  T  
T  |  F  
F  |  T  
F  |  F  


or

Q  |  P  
---|---
T  |  T  
F  |  T  
T  |  F  
F  |  F 


or

Q  |  P  
---|---
T  |  T  
F  |  F  
F  |  T  
T  |  F


...and so on.  

It's worth noting that the familiar alphabetical order of the letters p and q have no bearing on the relationship of any propositions represented by and which have been shortened to P and Q. Also note that I am not examining the relationship of the content of propositions to each other, only the rendered values of exclusively either "is true" or "is false". For example, comparing the truth values of "Ceasar had epileptic seizures" and "Henry VIII had gouty arthritis" is not a comparison of the rulers medical conditions, nor conjecture whether or not they did suffer these maladies. Comparing the truth values of the two statements is a comparison of the set of statements equivalent to ["that it is true that Ceasar had epileptic seizures", "that it is true that Henry VIII had gouty arthritis"] and for the purposes of demonstrating logical relationships it is enough that this set of statements logically equivalent to [("is true" exclusively or "is false" exclusively), ("is true" exclusively or "is false" exclusively)].

P  |  Q   |"not P"|"not Q"  
---|------|-------|--------
T  |  T   |   F   |   F
T  |  F   |   F   |   T
F  |  T   |   T   |   F
F  |  F   |   T   |   T


Note here that we are not now discussing two propositions [P, Q] and four aspects ["is true", "is false", "is not true", "is not false"] or 24 total combinations due to the logical constant "not" resulting in an identical equivalency of terms, i.e. ("is true" <=> "is not false") and ("is false" <=> "is not true"). We are simply visualizing the counter-propositions, the "opposite" truth values, the propositional "negation" or "inversion".

Lastly, for a visual example, if we were explicitly articulating every combination of the truth or falsity (two aspects) of three propositions(23), note one way we could draw them all to coincide with our convention for the drawing of 22 propositional aspects:

  X  |  B  |  R
-----|-----|-----
  T  |  T  |  T
  T  |  T  |  F
  T  |  F  |  T
  T  |  F  |  F
  F  |  T  |  T
  F  |  T  |  F
  F  |  F  |  T
  F  |  F  |  F


So, how then to compare P, Q, not P, not Q, P --> Q, P and Q, P or Q inclusively, P or Q exclusively and all the possible variations? Well, this is where truth tables come in handy to make a visual representation which gets at expressing an intuitive or explicitly articulated sense of the logical relationship of propositional truth values.

As discussed https://philosophy.stackexchange.com/questions/39047/how-can-you-intuit-that-p-%E2%86%92-q-%E2%89%A1-%C2%ACp-%E2%88%A8-q-and-%E2%89%A2-p-%E2%88%A8-%C2%ACq/39050#39050 here, we can visually represent "If P, then Q" (i.e. P --> Q, P implies Q, P then Q, etc.) like so:

P  |  Q  |  if P, then Q  
---|-----|---------------
T  |  T  |       T
T  |  F  |       F
F  |  T  |       T
F  |  F  |       T


Before we can compare [if P, then Q] to ["not P" "inclusive or" (P and Q)], let us evaluate the constituent propositions in ["not P" "inclusive or" (P and Q)], specifically I will show "P and Q" in a truth table:

P  |  Q  | [not]P  |  P and Q  | P [inclusive]or Q | 
---|-----|---------|-----------|-------------------|
T  |  T  |    F    |     T     |        T          |
T  |  F  |    F    |     F     |        T          |
F  |  T  |    T    |     F     |        T          |
F  |  F  |    T    |     F     |        F          |


Side note: this is a good time to also display the differences of "inclusive or" and "exclusive or":

P  |  Q  |  P and Q  | P [inclusive]or Q | P [exclusive]or Q |
---|-----|-----------|-------------------|-------------------|
T  |  T  |     T     |        T          |         T         |
T  |  F  |     F     |        T          |         F         |
F  |  T  |     F     |        T          |         F         |
F  |  F  |     F     |        F          |         T         |


...and I will comment on this later.

We can now evaluate ["not P" "inclusive or" (P and Q)]

P  |  Q  |    P and Q    |  [not]P | [not]P [incl]or (P and Q)  
---|-----|---------------|---------|--------------------------
T  |  T  |       T       |    F    |          T
T  |  F  |       F       |    F    |          F
F  |  T  |       F       |    T    |          T
F  |  F  |       F       |    T    |          T


...and here we have demonstrated the equivalence of "if P, then Q" and "not P inclusive_or (P and Q)"

P  |  Q  | "not P"  | (P and Q) | "not P" incl_or (P and Q) | "if P, then Q"  
---|-----|----------|-----------|---------------------------|---------------
T  |  T  |    F     |     T     |            T              |      T
T  |  F  |    F     |     F     |            F              |      F
F  |  T  |    T     |     F     |            T              |      T
F  |  F  |    T     |     F     |            T              |      T


Lastly, as I suspect the difference between the logical constants "inclusive or" and "exclusive or" may be causing some confusion (and I may be completely incorrect on this account) I will also provide a visual representation of "if P, then Q" and "not P exclusive_or (P and Q)"

P  |  Q  |"not P"|  (P and Q)  | "not P" Xor (P and Q)  
---|-----|-------|-------------|---------------------
T  |  T  |   F   |      T      |           F
T  |  F  |   F   |      F      |           F
F  |  T  |   T   |      F      |           F
F  |  F  |   T   |      F      |           F


To sum up: "if P, then Q" is logically equivalent to "[not]P [inclusive]or (P and Q)".

Q.E.D.

You might find these videos from Computerphile useful:
https://youtu.be/UvI-AMAtrvE https://youtu.be/UvI-AMAtrvE
https://youtu.be/XETZoRYdtkw https://youtu.be/XETZoRYdtkw  
I can only give you a partial answer on rousseau's true freedom. I know that in his book Du Contrat Social, he explains how we go from our natural freedom to our civil freedom and that our natural freedom is the freedom of doing anything without the law. Which means the natural freedom is living a savage life. Therefore there is no evolution to ths human race. So a civil freedom is more important for Rousseau because it gives the people a way of living and being with the help of the law. He explains in details the concept of the law as scarier than anything for the citizens and explains why it gives us evolution in his book. 
Im sorry if i dont completely remember my readings but I loved the book and I recommend everyone to read it.
This question needs to be taken in two parts, one relating to authenticity and the other to Kant's rigorism about lying. 

AUTHENTICITY

Kant does not use any term corresponding in sense to 'authenticity'. But this does not mean that he has nothing like a concept of authenticity. One can have and use a concept without having a specific term for it. 

A concept of authenticity is present in Kant. Briefly, Kant recognises that one can be true to one's rational nature. This means (a) treating oneself and not only others as ends; it also means (b) acting on self-legislated, universalisable moral rules, and (c) overriding 'heteronomous' motivation - motivation induced by external constraints imposed by others or acting on mere impulses of nature. It is very natural, whatever Kant's language, to say that 
someone who observes (a) - (c) in their life is being faithful to their rational nature and in that sense, according to Kant's view of persons, is acting authentically as a rational being. Whether we accept Kant's view of persons is another matter. 

LYING

Kant's rigorism about and against lying cannot be denied. It is obtrusively present in the Groundwork, in the Critique of Practical Reason, in the Metaphysics of Morals and in the essay 'On a Supposed Right to Lie'. It makes Kant look like a moral dogmatist, inflexible and insensitive to the complexities and nuances of the moral life. 

A methodological point should be noted, though. Whatever the strengths and merits (or otherwise) of Kant's ethical theory, Kant is no infallible or even privileged authority on its applications. His ethical theory does not necessarily imply what Kant thought it did, especially concerning 'the madman at the door'. 

A universalisability criterion works (sort of) against borrowing on the basis of a lying promise to repay. If everyone borrowed on this basis, then no-one would lend : lying would be counter-productive and destroy the very institution, that of lending, which it exploits. (I say 'sort of' because, while it would be highly odd if lending continued under these conditions, it is not logically impossible for it to do so. It is not logically impossible for the maxim, 'lie whenever you want money and can get it by falsely promising to repay', to be universalised.)

Now, about lying to the murderer at the door - there are two moves we can make against Kant here, both derived directly from his ethical theory. 

The first is that in the Metaphysics of Morals Kant tells us concerning duties to ourself : 'The negative duties forbid man (sic) to act contrary to the end of his nature and so have to do merely with his self-preservation' (6 : 418 : M. Gregor tr., 1964). So there is a duty of self-preservation. This duty may require me to lie as the only effectual means of fulfilling it. If I may lie in order to secure self-preservation - perhaps my life is at risk from unjust aggression* - there is no relevant difference between myself and another (the murderer's potential victim) which forbids me to lie in order to secure their preservation. The maxim, 'If I can preserve another person's life from unjust aggresssion only by lying, then lie' is perfectly capable of universalisation without contradiction. It involves no logical impossibility of universalisation.

The second is that if Kant still insists that we have a duty not to lie, then we have a conflict of duties: in order to be fulfilled the duty of self-preservation (logically extended to another person) may require a lie, yet moral rigorism imposes a duty not to lie. But Kant denies the possibility of a conflict of duties; it is indeed implicit in his 'ought implies can' principle. If two or more duties conflict, they cannot both be fulfilled but as duties we ought to do them. The situation is incoherent. 

Agreed, it remains open, if we have a duty to lie to the murderer at the door (as I have argued) and a duty never to lie (as Kant repeatedly insists), which duty has precedence. But Kant gives no grounds - rationally or morally - for giving precedence to the 'never lie' rule. 


The phrase is Michael Cholbi's in 'The Murderer at the Door: What Kant Should Have Said',  Philosophy and Phenomenological Research, Vol. LXXIX No. 1, July 2009, 17. 

These questions about applying logical paradoxes to God appear in this SE very frequently and they always amaze me. Why do people assume that God is subject to reason?

And in particular why do people who do not believe in God believe that that God in which they do not believe must be subject to reason?

And it makes no difference if the person contemplating is a student or a renowned philosopher.

The answer is quite simple. Imagine a God that transcends reason and now your question becomes nonsensical.

Here is https://plato.stanford.edu/entries/maimonides/ Maimonides on the transcendence of God:


  all people, both of past and present generations, declared that God cannot be the object of human comprehension, that none but Himself comprehends what He is, and that our knowledge consists in knowing that we are unable truly to comprehend Him. — https://www.sefaria.org/Guide_for_the_Perplexed,_Part_1.59.2?lang=en Guide for the Perplexed, I 59:2


And as Osho put it in The Discipline of Transcendence Volume 2:


  all great religious assertions are paradoxical. They may be in the Vedas, in the Upanishads, in the Koran, in the Bible, in the Tao Te Ching. Wherever, whenever you will find truth, you will find it paradoxical - because the truth has to be total; totality is paradoxical.
  
  A doctrine is never paradoxical, a doctrine is tremendously consistent - because a doctrine is not worried about reality. A doctrine is worried about being consistent. It knows no reality. It is a mind game, and the mind is very, very logical. And the mind says don’t allow any contradiction in it.
  
  Everything God-made is contradictory. That’s why people go on arguing about God.


And if you don't like to have it from Osho, then take it from Chomsky who argues that existence is mysterious in the sense that it transcends our capacity of understanding: https://www.youtube.com/watch?v=l-E0IEyS4qw https://www.youtube.com/watch?v=l-E0IEyS4qw
David Chalmers takes the reasoning you describe and flips on its head: Levels of complexity can never account for the purely ontological nature of consciousness (his famous http://www.iep.utm.edu/hard-con/ "hard-problem of consciousness"), and therefore if physicalism is true, then consciousness must be fundamental, i.e. it has to be a basic property of matter like electrical charge or mass. Otherwise some for of dualism is true. I suppose this what you are alluding to in point (1). 

For possibility (2) one can start from http://www.cambridge.org/us/academic/subjects/philosophy/philosophy-mind-and-language/realistic-empiricism-mach-james-and-russell-neutral-monism-reconceived James and Russell's neutral monism. From what I understand, Russell arrived at this position from the idea that relations are more fundamental than substance.

The reason why I think Russell's monism is relevant to your question, is that the only way it would make sense to speak of a "real" ontology of properties is if one takes the stance that the fundamental constituents of nature are relations, not substances - https://plato.stanford.edu/entries/structural-realism/ see also structural realism. Then it becomes possible for different classes of relations (according to different levels of complexity) to have distinct "real" ontologies. To put another way: if relations are what the world is really made of, then differences between classes of relations are ontologically real differences, not mere abstract differences as you put it.     
See http://www.iep.utm.edu/moore/#SH2d Moore's shift, locution probably due to https://en.wikipedia.org/wiki/William_L._Rowe William Rowe; see : https://www.kul.pl/files/57/nauka/Rowe_The_Problem_of_Evil.pdf "The Problem of Evil and Some Varieties of Atheism", American Philosophical Quarterly (1979).

The source of the argument are https://plato.stanford.edu/entries/moore/ George Edward Moore's studies: http://www.ditext.com/moore/common-sense.html A Defence of Common Sense (1925) and https://books.google.it/books?id=y6q3AwAAQBAJ&pg=PA150 Proof of an External World (1939), both reprinted into G.E.Moore, https://books.google.it/books?id=y6q3AwAAQBAJ&pg=PA15 Philosophical Papers (1959). 

A reference to the locution is in Hilary Putnam, https://books.google.it/books?id=wfE6xy-SNS4C&pg=PA280 Words and Life (1994), page 280.
In this context it's really more of a http://tvtropes.org/pmwiki/pmwiki.php/Main/EvilVersusEvil trope than anything else; but the philosophical reference might be to Nietzsche (battle not with monsters, lest ye become a monster, from https://en.wikipedia.org/wiki/Beyond_Good_and_Evil Beyond Good and Evil).
It is easier if we just look at a less ambitious subset of absolute freedom of speech: absolute freedom to publicly defend a certain thesis.

Because this would exclude a lot of obnoxious stuff which is prohibited everywhere, including countries arguably maintaining a high respect for free speech, e.g. the US (contrary to Europe).

Still, even this subset is problematic, because of libel laws. And libel laws are something dictators always abuse first, for example Hitler endlessly sued newspapers for libel before he was in power.

But formally we can differentiate the US from a dictatorship, because at least any opinion, which is not about single individuals, can legally be publicly defended. You can, for example, legally deny the holocaust.

For European democracies this is much more difficult, probably impossible.

For example, what is the difference between criminalizing http://en.a1plus.am/1247764.html Armenian genocide denial (France) or criminalizing the claim that the Armenian genocide happened (which counts as the crime of “insulting Turkishness”, article 301 of the Turkish penal code)?

Formally there is no difference. Of course, I believe that the Armenian genocide happened and so that Turkey's law is horrible, while I am relaxed about France's law. But if I argue that way, I leave the meta-level which tries to be neutral of the validity and worth of an opinion.
Aside from the absolute impracticality of the radical approach, there really is no way to refute the argument. If I told you that green is a flavor, you would correct me by reminding me (first of all, that the first step to recovery from drug addiction, is admitting I have a problem) that green is a color not a flavor. As the skeptic, my argument would HAVE to be, "To your knowledge green is a color only, but your knowledge is limited to what you know. Perhaps somewhere in the other end of the universe, green is actually a flavor. You don't know." Ultimately, the only clear basis for radical skepticism is what you can't possibly know. I would assert that, while there is no argumentation to refute it, it holds no place in a conversation. The skeptic does not transcend, rather he falls to the bottom of the barrel where the irrelevancy of his argument belongs. It's not hunting if the deer pulls the trigger itself.
Do you mean Max Stirner?


  On the Contrary, Communism, by the abolition of all personal property, only presses me back still more into dependence on another, viz., on the generality or collectivity; and, loudly as it always attacks the "State," what it intends is itself again a State, a status, a condition hindering my free movement, a sovereign power over me. Communism rightly revolts against the pressure I experience from individual proprietors; but still more horrible is the might that it puts in the hands of the collectivity.


Max Stirner, The Ego and Its Own, ed. David Leopold (Cambridge: Cambridge University Press, 1995)
Someone like Quine would embrace that it's circular. Naturalized epistemologists tend to be coherentists, who tend to get charged with having circular (or criss-crossing-but-never-essentially-grounding) justifiers.
If I am not wrong about the definition of determinism, it means that the course of action of anything in the universe is predetermined. For inanimate objects, such as a chemical reaction this is true always as it will follow a path such that the entropy of the system is decreased, however as soon as we are faced with an animate object or an object which has free-will (discussed later) we are faced with a few problems.

Objects with a free-will have a tendency to perform in order to attain a particular set of goal, that can be proving a point or reaching a certain level of satisfaction, happiness; hence we can argue that their will is not so free after all; because the action of 'people' are determined by a set of boundaries:


Desire (the end goal)
Environmental effects (situations and all)
Will-power 
Capability 


(A few factors might have been missed out as well)
In the end we are similar to a chemical reaction in which everything is prejudged or determined.
However, the points 3, 4 can be changed by making their improvement an end goal. Improving point 3,4 will automatically affect point 2 and will make our environment more favorable to the end goal. Hence, the universe with all its inanimate and animate objects is deterministic but we can change the equations or the factors governing the determinism.

if you want I can try a case study for the particular suicide case as well. :)
I'd think that the 'fallacy' of Cherry Picking would actually summarise each example and is indirectly caused by priority bias;

Cherry picking (suppressed evidence, incomplete evidence) – act of pointing at individual cases or data that seem to confirm a particular position, while ignoring a significant portion of related cases or data that may contradict that position.

But I also think that the reason there is no fallacy that encompasses the priority bias requested here is that there is a fallacy for arguing that one's own bias proves it is false, Bulverism.

Bulverism (psychogenetic fallacy) – inferring why an argument is being used, associating it to some psychological reason, then assuming it is invalid as a result. It is wrong to assume that if the origin of an idea comes from a biased mind, then the idea itself must also be a falsehood.
I agree: the adjective Victorian is inappropriate for Mill. And not only for the reason that you pointed out. Mill can, as a matter of fact, be better described as anti Victorian! Consider the given characterization:


  Mill had the somewhat Victorian view that people who have sampled these higher pleasures inevitably prefer them.


Is this a description of a Victorian view? I think not. https://en.wikipedia.org/wiki/Victorian_morality Victorian morality is usually associated with https://en.wikipedia.org/wiki/Puritan Puritan restrictions, such as https://en.wikipedia.org/wiki/Bathing_machine separate beaches for men and women. This Puritanism can be expressed as the view that


  the lower pleasures need to be restricted, because people who have sampled them will in likelihood prefer them.


which is really the opposite from Mill's liberal, optimistic view, that


  people who have sampled the higher pleasures inevitably prefer them.


Therefore, Mill's view was not Victorian, but rather anti-Victorian.
As it stands, it's a bit self-contradictory, because you're encouraging them to make different life choices, while simultaneously denying that they have the ability to do so.  It's a bit of an anti-existentialist viewpoint because it denies the central existentialist claim that people are always and ultimately free and responsible for their actions.  Therefore, you might look up critiques of existentialism, such as this one: https://benjaminstudebaker.com/2012/09/05/a-critique-of-existentialism/ https://benjaminstudebaker.com/2012/09/05/a-critique-of-existentialism/
In your question you seem to be touching on the https://en.wikipedia.org/wiki/Analytic%E2%80%93synthetic_distinction Analytic/Synthetic distinction, and on https://en.wikipedia.org/wiki/Hume%27s_fork Hume's relations of ideas vs matters of facts, https://en.wikipedia.org/wiki/A_priori_and_a_posteriori and Kant's a priori/a posteriori distinction. 

Some definitions: 


Analytic statements are those which are true by definition: all the information in the statement is already contained in the definitions of the word used in the statement. 
Synthetic statements which contain more information than just what is contained in the definition. 
A Priori statements are those which use reason and logic alone, and are independent of observation. They come before experience,  hence they are "prior" to experience. 
A Posteriori statements are those that require observation, hence they come after we have an experience, they are "posterior" to experience. 


Based on these definitions, we end up having four types of statements : 

https://i.stack.imgur.com/xfdYD.jpg 

Hard https://en.wikipedia.org/wiki/Empiricism Empiricists like Hume or Wittgenstein believed that only the types of statements in the blue and purple quadrants are possible, and those in green in yellow are impossible. 

Kant (and presumably other https://en.wikipedia.org/wiki/Rationalism rationalists) disagree and think that statements in the green quadrants are possible as well. Kripke takes this a step further and thinks that even statements in the yellow quadrant are possible. 

When you say that all statements in English cannot be original because they are just combinations of  existing terms, you are essentially saying that all a priori statements (those based on logic and reason) can only be analytic, they cannot be synthetic. To put it otherwise, for a given well formed statement in English, all of the information in the statement is already contained in the definitions of the words used in the statement. 

So you are agreeing with Empiricists that only the blue and purple quadrants are possible and that the green quadrant is not possible.  

Kant however disagrees: One of his most important results is that a priori statements can be synthetic. And expression can indeed contain more information than the mere definition of the terms that build it. His main examples are mathematical equations: An equation such as:

(a - b)² = a² - 2ab + b² 

contains more information in it than the mere definitions of a and b. And if this is possible for mathematical equations, in can be extended to the English language as well (if only by expressing mathematical relations in plain English).   

To summarize: An original thought would correspond to someone coming up with a valid synthetic a priori statement, and if you are an Empiricist, that is not possible, but if you are a rationalist, it is. 

See https://plato.stanford.edu/entries/rationalism-empiricism/ Rationalism vs Empiricism. 
Your criticism of Mill is right under the social choice perspective. The general happiness is warranted only if the lexical order of preferences of individuals is the same. I like Chinese over Mexican, and you too, so going to a Chinese restaurant maximizes our general happiness. But if you like Mexican over Chinese, then which restaurant should we go to maximize our general happiness? Kenneth Arrow earned an economics Nobel Prize by proving the impossibility of a decision procedure that aggregates all preferences of differing lexical orders. Under the social choice view, Mill can be argued to be mistaken when he conjoined the two statements that you highlighted.

Mill's conjoining the statements however can be defended from a different angle, without the postulate of altruism. In fact, Mill believes that altruism is unnatural. Mill was affected and impressed by the communist movement of his time (19th century London is a place to visit!). Marx lived in the same town as Mill, and requested the acquaintance of Mill, which Mill declined. Mill even proposed his own socialist society in his Principles of Political Economy. To Mill, communism would fail since it is founded on unnatural view of human nature: altruism. To Mill, human nature is self-interested, not altruistic. The protection of one's interest by oneself is one of the reasons Mill argued for democracy. (cf. Considerations on Representative Government)

Mill believed that, when we reflect on maximizing our own self-interests, we inevitably realize that our utility calculation sometimes turns out to be wrong or is uncomputable due to inherent complexities (e.g., my preference order might change in the future). So it is prudent for each individual to champion general happiness as an insurance. Thus, Mill's society guided by the general happiness principle is based on this enlightened self-interest. 
I should imagine a fairly simple explanation would be that in past epochs judgement of art was solely in the consumer. If one made a pot which was more aesthetically pleasing than another, that pot would be preferred by the consumer of pots over the other. Contrast this with our current distinction of art as a thing judged by a set of standards contained within a fairly small set of selected judges (art critics). The aesthetic of the thing produced under our modern definition of art is largely redundant, certainly as judged by the consumer of the art. Other factors (not immediately relevant to the more utilitarian 'craft') like novelty, shock value etc are considered and their relative weight a matter for appointed judges, not consumers.
This answer is a bit technical, but I think the OP will find it interesting.

Let me first recall a bit about the history of the incompleteness theorem (IT). How IT is usually stated is:


  If PA (or any recursively axiomatizable theory extending PA) is consistent, then "PA is consistent" is undecidable in PA.


However, this is not what Goedel originally proved! Goedel's proof required an additional assumption: that PA is reasonably correct (specifically, that PA is https://en.wikipedia.org/wiki/%CE%A9-consistent_theory $\omega$-consistent). This is of course an unfortunate hypothesis; besides making the theorem weaker, it also brings in a hopefully-unnecessary bit of Platonism. (OK, let's say you're fine with Platonism; why should you care about theories which are consistent but false? See below for an answer to this.)

Specifically, Goedel could easily show that "PA doesn't prove Con(PA)," but showing "PA doesn't disprove Con(PA)" required the additional assumption. So strictly speaking, Goedel's original argument certainly contained an unprovability theorem, but arguably fell short of a full undecidability (i.e. unprovability and undisprovability) theorem. 

Goedel left it as an open question whether this assumption could be done away with. This was resolved, leading to the usual statement of IT, https://en.wikipedia.org/wiki/Rosser's_trick by Rosser, who showed how a technical trick could improve Goedel's argument. So that lifted Goedel's proof to a genuine undecidability theorem.

Rosser's improvement didn't just lead to a "more formalist" version of IT; it also had real consequences, relevant to your question. Specifically, it shows:


  Unprovability is incomputable: there is no algorithm which can determine if a given sentence in the language of arithmetic is unprovable from PA.


Why not? Well, suppose A were such an algorithm. Then we could construct a consistent complete recursively axiomatizable extension of PA (contradicting Rosser's version of IT!) as follows:


Enumerate the sentences of arithmetic in a reasonable way as P_1, P_2, P_3, ...
Define Q_i inductively as follows:


Q_1="Not P_1" if P_1 is unprovable in PA, and Q_1="P_1" otherwise.
Having defined Q_i, we let Q_{i+1}="Not P_{i+1}" if the sentence "(Q_1 and Q_2 and ... and Q_i) implies P_{i+1}" is unprovable in PA, and Q_{i+1}="P_{i+1}" otherwise.



Assuming the existence of A, the sequence Q_i is computable. Now consider the theory T=PA+{Q_1, Q_2, Q_3, ...}; this theory is recursively axiomatized, extends PA, and (by an easy induction argument) is consistent; whoops! 

Now note that T is probably wrong about many things! At no point in the construction of T did we refer to the truth of sentences of arithmetic, merely their (un)provability. So this argument really needed the full strength of Rosser's version of IT; yet the conclusion, that PA-provability is incomputable, is of interest even if we adopt a fully Platonistic viewpoint and have no a priori interest in incorrect theories of arithmetic.



Now on to the meat of the question: some reasons for undecidability. 

The point above - that unprovability is incomputable - can be modified to "undecidability is incomputable" without too much effort. Intuitively, this says that there are many reasons for undecidability (or unprovability), and that we will never have a full understanding of what drives the phenomenon. Interestingly, this clashes with the general fact - mentioned by jobermark above - that almost all currently known examples of undecidability come from self-reference issues.

There are instances of unprovability which do not come from paradoxes, however, and for which there is reasonable philosophical evidence for undisprovability; let me give an example of one of these, https://math.stackexchange.com/questions/2088575/the-reason-why-the-existence-of-inaccessible-cardinals-cannot-be-proven-in-zfc/2088704#2088704 which I learned from Asaf Karagila. This is an instance of undecidability, not from PA, but rather from https://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory ZFC ( = standard set theory; this is a first-order theory, despite being about sets, and https://math.stackexchange.com/questions/1366560/why-does-g%C3%B6dels-first-incompleteness-theorem-apply-to-zfc Goedel's theorems apply to it). In particular, the relevant language is different - rather than working in the language ${+, \times, <, 0, 1}$ (or similar) of arithmetic, we're working in the language ${\in}$ of set theory.

An inaccessible cardinal is a particularly large infinite cardinal. Specifically, it is a cardinal which is bigger than the powerset of any cardinal below it, and also satisfies a more technical https://en.wikipedia.org/wiki/Regular_cardinal "regularity" condition. Intuitively, inaccessible cardinals cannot be "built out of smaller cardinals".

Let P be the sentence "There is an inaccessible cardinal" (it is not hard, but somewhat tedious, to express this in the language of set theory), and let's think about P in the set theory ZFC. There are a number of philosophical arguments for the consistency of ZFC together with P; see e.g. Penelope Maddy's article "Believing the axioms". So let's for the moment take Con(ZFC+P) for granted, that is, that ZFC doesn't disprove P. How can we show that ZFC doesn't prove P either?

The usual proof of this is via Goedel's theorem: show that ZFC+P proves Con(ZFC). However, there is a proof avoiding this! Suppose ZFC did prove P. Then let V be a model of ZFC. Since V is a model of ZFC, and ZFC proves P, there is some k in V that V thinks is (i) an inaccessible cardinal, and (ii) the least inaccessible cardinal (since V satisfies Regularity, for any definable property there is a least cardinal with that property if any cardinal with that property exists in the first place).

But now consider V_k, the kth level of the https://en.wikipedia.org/wiki/Cumulative_hierarchy cumulative hierarchy of V. It's not hard to check that V_k satisfies the ZFC axioms. But V_k can't have an inaccessible cardinal! This is because any inaccessible cardinal m in V_k would also be an inaccessible cardinal in V (this isn't obvious, and takes a short argument; in particular, this fails if we replace "inaccessible" with a https://en.wikipedia.org/wiki/List_of_large_cardinal_properties more complicated large cardinal notion!), and would be less than k (since every cardinal in V_k is less than k); but k was by definition the least inaccessible cardinal in V. So this is a contradiction.

Note that at no point did we invoke IT! This is an example of an unprovability phenomenon which arises for "purely mathematical" (that is, non-metamathematical) reasons. Of course, the distinction is a very subjective one, and reasonable people much smarter than me may very well disagree with the claim I made in the previous sentence; but I still think it's interesting.



Incidentally, it's also worth pointing out that the incompleteness theorem itself has a proof which doesn't really hinge on the paradoxes: namely, http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&id=pdf_1&handle=euclid.ndjfl/1027953483 Kripke gave a proof which in certain respects is similar to the argument about inaccessibles I outlined above. See https://mathoverflow.net/questions/72062/what-are-some-proofs-of-godels-theorem-which-are-essentially-different-from-t/72151 this question of mine at mathoverflow for some more proofs of incompleteness.
It's not a new idea. https://en.wikipedia.org/wiki/Haileybury_and_Imperial_Service_College#History Haileybury School in England was set up by the East India Company to train civil servants to administer India. By its standards it was very successful, the school still exists but obviously not for this purpose.

Note, though, that it's not at all clear that the people administered by the alumni of Haileybury necessarily agreed that they did a great job. This, I think, hints at the flaw in the idea. 

By necessity, if you train all your civil servants in one school/college, they'll have an outlook that reflects that training. That's presumably the point of doing it. This requires, however, that the curriculum and ethos of the college instills the right outlook. But what is right in this regard? Is there one true way to govern? Would we not be better with various viewpoints and outlooks? I don't think the answer is at all clear cut.
The fact that some alternatives may result in bad consequences or punishment does not limit free will. This is shown by the fact that humans often make the choice that they know will result in bad consequences. In your reference to the Garden of Eden, if Adam and Eve did not have free will, they would have been unable to disobey God and thus would never have eaten the forbidden fruit.

What you appear to be getting at is that bad consequences can discourage people from exercising their free will in certain ways. This is true, but it doesn't refute the existence of free will. You can also rightly claim that if an authority imposes punishment for certain actions, they are influencing people's exercise of free will, but does not eliminate free will.

Regarding your religious beliefs, since this is a philosophy forum, I will limit what I say here to this. The Christian teaching of free will refers to the human capability to choose right or wrong, but it doesn't imply that people should be able to choose wrong without consequences. Indeed, it states the contrary. Now if you are saying that your philosophy values unrestricted freedom without punishment, you would be right in saying that it conflicts with orthodox Christianity.
This is a rather tricky question to answer, there is always a different view point.

The 'present' is what you can experience

Present is best described by experience (though this is also slightly tricky). You cannot experience the past or the future, only the present. 

Of course light, sound and other experiences take time to reach you so any event takes time to reach you. So once you experience it the event is in the past...right? https://en.wikipedia.org/wiki/Minkowski_diagram General relativity agrees that you experience something which originates from an event in the past. However what I would argue you experience is the light of that distant star hitting your eyes. The moment it hits your eyes is the present, that is your experience. The idea of the star, your inferred information about that star etc are all secondary to the actual photons. 

The line of the present is thin*, yes, but it is where we live so we cannot discount it's existence or you wouldn't be able to distinguish past from future.

*The thinness perhaps defined by your reaction time (like the shutter speed of a camera).
Like every -ism, also https://en.wikipedia.org/wiki/Historicism Historicism can be used as an over-simplifying label.

Having said that, the starting point must be https://plato.stanford.edu/entries/history/#HegHis Hegel's Philosophy of History; Hegel's philosophy is complex and his Philosophy of History is a relevant part of his system.

A key point is the:


  attempt to discover meaning or direction in history. Hegel regards history as an intelligible process moving towards a specific condition — the realization of human freedom. “The question at issue is therefore the ultimate end of mankind, the end which the spirit sets itself in the world”.


Marx and Engels, into https://plato.stanford.edu/entries/marx/#4.1 The German Ideology as well as in the notes https://en.wikipedia.org/wiki/Theses_on_Feuerbach Theses on Feuerbach, contrast their new materialist method with Hegel's idealism: 


  The materialist doctrine that men are products of circumstances and upbringing, and that, therefore, changed men are products of changed circumstances and changed upbringing, forgets that it is men who change circumstances and that the educator must himself be educated. Hence this doctrine is bound to divide society into two parts, one of which is superior to society.


But, common to Marx-Engels and Hegel is the assumption that history has laws: we can "find reason in history".

Be it idealist or materialist, the science of history can discover the rational "drivers" of historical changes and uses them to explain/understand and predict future developments.

Karl Popper (with an excessive simplification) in his books The Poverty of Historicism and The Open Society and Its Enemies uses historicism referring to: 


  an approach to the social sciences which assumes that historical prediction is their primary aim, and which assumes that this aim is attainable by discovering the 'rhythms' or the 'patterns', the 'laws' or the 'trends' that underlie the evolution of history". Karl Popper wrote with reference to Hegel's theory of history, which he criticized extensively. 
  
  Popper attacks "historicism" and its proponents, among whom (as well as Hegel) he identifies and singles out Plato and Marx. The objection he makes is that historicist positions, by claiming that there is an inevitable and deterministic pattern to history, abrogate the democratic responsibility of each one of us to make our own free contributions to the evolution of society, and hence lead to totalitarianism.  




We have to consider also https://en.wikipedia.org/wiki/Historical_materialism#Marxist_beliefs_about_history Historical materialism as well as https://en.wikipedia.org/wiki/Dialectical_materialism#Lenin.27s_contributions Dialectical materialism; these doctrines fit well with Popper's critique but we can hardly found textual support for them into Marx's original works; see e.g. https://en.wikipedia.org/wiki/Antonio_Labriola Amedeo Bordiga, https://it.wikipedia.org/wiki/Georgij_Valentinovi%C4%8D_Plechanov Plechanov, https://en.wikipedia.org/wiki/Leninism Lenin ans https://en.wikipedia.org/wiki/Dialectical_and_Historical_Materialism Stalin.
I recently came across term https://en.wikipedia.org/wiki/Morpheme Morpheme


  In linguistics, a morpheme is the smallest grammatical unit in a
  language. In other words, it is the smallest meaningful unit of a
  language. The field of study dedicated to morphemes is called
  morphology. A morpheme is not identical to a word, and the principal
  difference between the two is that a morpheme may or may not stand
  alone, whereas a word, by definition, is freestanding. When it stands
  by itself, it is considered as a root because it has a meaning of its
  own (e.g. the morpheme cat) and when it depends on another morpheme to
  express an idea, it is an affix because it has a grammatical function
  (e.g. the –s in cats to indicate that it is plural).[1] Every word
  comprises one or more morphemes.


Also, relating to the concept of a word, it's interesting to note the term in a https://en.wikipedia.org/wiki/Word_(computer_architecture) computer science context where word size is considered.


  In computing, a word is the natural unit of data used by a particular
  processor design. A word is a fixed-sized piece of data handled as a
  unit by the instruction set or the hardware of the processor. The
  number of bits in a word (the word size, word width, or word length)
  is an important characteristic of any specific processor design or
  computer architecture.

It is possible, at least, to establish a criterion for evaluating relative superiority in artists, for example:


  Where x and y range over people, x is a better artist than y if artworks created by x are overall better than artworks created by y. 


This criterion may seem dependent on the ability to evaluate artworks, but technically speaking, that is a different question.  This question is specifically and narrowly about artists.
Treating the Law of Causality as a ladder doesn't mean there're no effects, or that we can't think of effects at all. I don't see how this conclusion would follow.

At any rate, Wittgenstein's point here seems to be just another instance of the overall idea of the Tractatus: that a Law of Causality (formulated in a particular language) would attempt to speak of that which can only be shown.

There may well be effects. There may well be causes. Types of causes may well be necessarily and sufficiently related to types of events. Still ...

Still, it is presumably nonsense on Wittgenstein's view to formulate in one's language a proposition saying that all events have causes (a Law of Causality). Why? Because a Law of Causality (as formulated in a particular language) would give the logical form of any possible empirical causal law (in that language). And, according to the Tractatus, for semantic reasons, a language cannot speak of its own logical form. Thus, a fortiori, it cannot speak of the logical form of empirical causal laws formulated in it.

Empirical causal laws (gravitation, evaporation of water, etc.) by relating causes to effects manage to exhibit or show what a Law of Causality would like to speak of---that events have causes.

Having thrown away the ladder, we can still do science (think about the causes and effects of, say, evaporation). What we will no longer want to do is metaphysics and philosophy of science (think about causation and the nature of empirical laws).
One view is that Ockham invented his Nominalism in order to justify his being against the papacy.

The Thomist semiotician John Deely, in his https://books.google.com/books?id=zAsjkHJ8aP8C&pg=PA394#v=onepage&q&f=false Four Ages of Understanding pp. 394 ff., shows how the http://www.newadvent.org/cathen/13539a.htm Great Western "Schism" lead to the adoption of Ockham's nominalism, despite its weaknesses.

Ockham, a Franciscan, wrote—"at the end of his letter to the General Chapter in Assisi in the spring of 1334" (cf. https://books.google.com/books?id=MOEtAAAAYAAJ&focus=searchwithinvolume&q=%22Because+of+the+errors+and+the+heresies+mentioned+above+and+countless+others%22 Tractatus de Successivis translation p. 12), defending his opposition to Pope John XXII, who opposed the (then-material) dogma that the souls of the deceased destined to heaven behold the Beatific Vision immediately after death, defined by John XXII's successor Benedict XII in http://www.papalencyclicals.net/Ben12/B12bdeus.html Benedictus Deus—that:


  Because of the errors and the heresies mentioned above and countless others, I turned away from the obedience of the false Pope and all who were his friends to the prejudice of the orthodox faith. For men of great learning showed me that because of his errors and heresies the same pseudo-Pope is heretical, deprived of his papacy, and excommunicated by Canon Law itself, without need of further sentence. … In proof thereof several volumes have been published. … For against the errors of this pseudo-Pope I have turned my face like the hardest rock, so that neither lies nor calumnies nor any persecution (which cannot touch my innermost self in any bodily fashion), nor great numbers of men who believe in him or favor him or even defend him, shall be able to prevent me from attacking or reproving his errors, as long as I shall have hand, paper, pen, and ink. …  
  
  If anyone should like to recall me or anyone else who has turned away from the obedience of the false Pope and his friends, let him try to defend his Constitutions and sermons, and show that they agree with Holy Scripture, or that a Pope cannot fall into the wickedness of heresy, or let him show by holy authorities or manifest reasons that one who knows the Pope to be a notorious heretic is obliged to obey him. Let him not, however, adduce the great number of his adherents, nor base his arguments on reproaches, because those who try to arm themselves with great numbers of lies, reproaches, threats, and false calumnies, show that they are void of truth and reason. Therefore let none believe that I mean to turn away from the recognized truth because of the great number of those in favor of the pseudo-Pope, or because of proofs that are common to heretics and to orthodox men, because I prefer Holy Scripture to a man unlearned in holy science, and I have a higher esteem for the doctrine of the Fathers who reign with Christ than for the tradition of men dwelling in this mortal life.


The Church never condemned Ockham's theories, although Ockham was excommunicated for leaving Avignon without permission.

W. Turner writes in the old Catholic Encyclopedia "http://www.newadvent.org/cathen/15636a.htm Ockham" entry:


  Ockham's attitude towards the established order in the Church and towards the recognized system of philosophy in the academic world of his day was one of protest. He has, indeed, been called "the first Protestant". Nevertheless, he recognized in his polemical writings the authority of the Church in spiritual matters, and did not diminish that authority in any respect.


See also http://plato.stanford.edu/entries/ockham/ this SEP article on Ockham by the Catholic logician http://pvspade.com/ Paul V. Spade

Also, Ockham is known as the Venerabilis Inceptor ("Venerable Beginner") because he was a drop-out who remained a bachelor, never having obtained a higher degree.

Modified from my Christianity StackExchange question "https://christianity.stackexchange.com/q/52360/1787 Was William of Ockham the first sedevacantist?"
Possible source : http://www.lexido.com/EBOOK_TEXTS/BEYOND_GOOD_AND_EVIL_.aspx?S=3&WSD_HL=368#WSD_HL Beyond Good and Evil (1886), Chapter 2 The Free Spirit, §30: 


  "Books for the general reader are always ill-smelling books, the odour of paltry people clings to them. Where the populace eat and drink, and even where they reverence, it is accustomed to stink. One should not go into churches if one wishes to breathe pure air."

Pythagoras was interested in the application of mathematics to problems of cosmology; this is a discipline now called cosmology.

Aristotle was interested in questions of space, time, place, matter and continuity; this discipline is now called physics.

Plato was interested in questions of what constituted good governance, this is the discipline that is called political philosophy and ethics.

As for the negative in philosophy, one might usefully think on the following remarks by Chantal Mouffe, the Belgian political theorist, in her book Agonistic Poltics:


  To think politically is to recognise the ontological dimension of negativity...


Meaning


  Full objectivity cannot be reached


Thus


  Society is permeated by contingency...and any order is hegemonic - an expression of power


We can rephrase and refit this to philosophy:


  To think philosophically is to recognise the ontological dimension of negativity; hence full objectivity cannot be reached; thus philosophy is permeated by contingency; and any philosophical order is hegemonic - an expression of power

For Kant motives other than duty are morally unworthy. He hold this view, because these other kinds of motives are depending on some condition. He calles them hypothetical Imperatives. The generally have the form:

If you want object x and action h is sufficent for x, you have to do h.

But these imperatives are always dependent on our desire for x (this might be recognition from others, pleasure or a place in heaven). Kant argues that moral laws cannot depend on specific desires, but are categorical. This means they are obligating for every rational being without condition.

Applied to your specific case I have a quote from The Critiqe of Pratical Reason, First Chapter §8


  the happiness of other beings can be the object
  of a rational being's will. But if it were the maxim's determining basis,
  then one would have to presuppose that we find not only a natural gratification in the well-being of others but also a need, such as the sympathetic mentality brings with it in human beings. But this need I cannot presuppose in every rational being (and in God not at all).
  
  Therefore the mere
  form of a law, which restricts the matter, must at the same time be a basis
  for adding this matter to the will, but not for presupposing it. Let the matter
  be, for example, my own happiness. This happiness, if I attribute it to every
  one (as in fact I may in the case of finite beings), can become an objective
  practical law only if I include in it also the happiness of others. Therefore
  the law to further the happiness of others arises not from the presupposition
  that this is an object for everyone's power of choice, but merely from [the
  fact] that the form of universality, which reason requires as condition for
  giving to a maxim of self-love the objective validity of a law, becomes the
  determining basis of the will. 

Nothing(ness) definitionally is being not Being. It therefore not is, ontologically. It is just that "not", the refusal to be this or that concrete X. Sartre often characterizes for-itself and its activity (choosing, i.e. running from a fact towards a possibility) as "being by mode of non-being".

Nothingness should not be understood as something which is absent here still potentially is present somewhere else (real or imaginary - no matter). Nothing is what is nowhere. Or, rather, it is here as the pure negation/attenuation of any state of identity in "i is X"; that bold "is" is what gets negated. Nothingness emerge (due to human Consciousness making choices) as holes bored through on the body of Being, to attenuate self-identity of things.

Because, for a thing (phenomenon) to have any sense/meaning it must be weakened in its sameness with what it is - for the sake of tying with some chosen possibility. For example, a red ball appears meaningfully "red" to us because its redness is being rejected in exchange of some potentiality in the red quality of the ball. Venus de Milo "has no arms" to us meaningfully only because it could have arms, i.e. be what it is not; however, that "could have arms" is firstly not another state or being, it is the possibility which exists by mode of nothing because it does not change the Venus de Milo to another identity, it just attenuates its present identity by loosening. Only due to that attenuation (negation) of the statue's being without arms it can appear meaningfully as having no arms.

There is nothing (no anything) that separates the Venus as it appears from its identity of Venus armless, yet it is not equal to it. Simultaneously, there is that same nothing that separates it from the possibility of armness, yet having arms is not any guaranteed, even not under consideration. (Nothingness does separates by no miles or millimeters, and it does link by no bridges or molecules.)

Consciousness opens things as phenomena (appearances). That is, it acts as negation and brings nothingness to things. It attenuates a thing's being what it is, due to which the thing can appear what it is. To appear means to be X with potentialities, while being is just to be X - the state of closed and dense identity where no meaning could arise and even the statement "i is X" can't linger as intelligible. Sartre's concept of Nothing/Negation is sharply dialectic, it owes to Hegel.

  Only when in technology body and image so interpenetrate that all
  revolutionary tension becomes bodily collective innervation, and all
  the bodily innervations of the collective become revolutionary
  discharge, has reality transcended itself to the extent demanded by
  the Communist Manifesto. For the moment, only the Surrealists have
  understood its present commands. They exchange, to a man, the play of
  human features for the face of an alarm clock that in each minute
  rings for sixty seconds.


Benjamin's essay praises surrealism as the only bourgeoisie
ideology that follows the "present commands" of the Communist Manifesto (the article is written in 1929), and tries to "awake" the mind by becoming an alarm clock (check surrealism's use of scandal and similar means to achieve awareness of the importance of politicization), that alarms 60 times per minute (all the time). Benjamin obviously was concerned about the world situation and the upcoming second world war. I think Benjamin in this essay does not say anywhere that a communist revolution is meaningless. He just critics surrealism under the ideas of Marxism. 
It seems to me that https://books.google.it/books?id=_wusCvC4yOcC&pg=PA130 Augustine's argument must be rephrased differently.

The first part of the argument is aimed at establishing that:


  whatsoever things are, are good.


This means : every substance must "partake" of the Good. 

In particular, this is so for a corruptible substance, because corruption is deprivation of (some) good.

Now, the conclusion is straightforward: evil is not a substance, because if so it must be 


  either an incorruptible substance, that is to say, the highest goodness; or it would be a corruptible substance, which would not be corruptible unless it were good.




You can see:


Paul Rigby, https://books.google.it/books?id=EauwBgAAQBAJ&pg=PA71 The theology of Augustine's Confessions, Cambridge University Press (2015), Ch.4 Evil, Suffering, and Dualistic Wisdom, page 71-on.

The EI rule formalizes the fact that if we know that ∃xP(x), we are licensed to give to "that P" a name.

But we have to avoid that the said name is not already "in use" because, if so, it may denote an object that has some properties incompatible with its "being P".

This intuitive restriction is formalized with the proviso : the term (variable or constant) must be "fresh", i.e. not already used in the context of the proof involving the EI rule.



There is no reason why EI must always precede UI.

The "trick" is: if we introduce a term a by UI applied to e.g. ∀xQ(x), then - due to the above restriction - we cannot use the same a in an application of EI to e.g. ∃xP(x) : intuitively, the fact that an object whatever satisfy Q does not mean that it must be "the P".

If instead we introduce a "fresh" term a by EI, we can use it later in applying UI to e.g. ∀xP(x). The reason is simple: whatever a is, if P holds for all, it necessarily holds also for a.
Assuming for the sake of discussion the fact that clouds are the cause of rain, this does not mean that "if there are clouds, then there is rain" is correct.

From the fact that clouds are the cause of rain we have:


  "if there is rain, then there are clouds".


A good exercise is to replace the "if..., then___" construction with a different one using "when".

We can rephrase the above assertion as : "when there is rain, there are clouds" and also with : "there is rain, only when there are clouds".

The last version is more perspicuous : we cannot have rain without clouds.

But nothing is said about the converse : we cannot have clouds without rain.

Thus, if we cannot have rain without clouds, but we may have clouds without rain, it is quite clear that clouds are the necessary condition for rain : no clouds, no rain.

We have also that rain is the sufficient condition for clouds; but this must not be read as "rain causes clouds".

Again, if we cannot have rain without clouds, this means that from the evidence of rain, we are licensed to infer the presence of clouds: this is the "sufficiency".



Regarding "logical" analysis of causation, see https://plato.stanford.edu/entries/causation-counterfactual/ Counterfactual Theories of Causation as well as https://plato.stanford.edu/entries/causation-probabilistic/ Probabilistic Causation.
In inductive logic/probability theory a set of betting rates is called coherent if it's not open to a sure-loss contract (called a Dutch Book). 
Interestingly you can prove that: 

(1) A set of betting rates is coherent iff it satisfies the rules of probability. 

If I understand your question correctly, you are asking if it's possible to prove a similar sort of result for rules of logic: So give somehow an analogous definition of coherence for a set of assignments of truth values to some set of sentences, and then prove that such an assignment is coherent iff it satisfies (in some sense) the rules of logic. 
"Rules of logic" here should refer to an axiomatization of logic, since in the case of probability it's similarly the axioms that betting rates have to satisfy to avoid a Dutch book. The obvious idea would be to define coherence as follows: 

Df. A set of truth assignments to some sentences is coherent iff there is a truth valuation that gives the same truth-values to the sentences as your assignments do.

(The above definition means that coherence guarantees that your truth assignments are not open to a sure error, i.e. you could be right in your assignments of truth values.) 

Define a set S of sentences as follow: if your assignment assigns 1 to a formula  F, then F∈S, if your assignment assigns 0 to a formula F then not-F∈S. Let's call this set S the set determined by the truth assignments. 

It's now easy to show that a set of truth assignments to some sentences is coherent iff the set S determined by those truth assignments is satisfiable. 
Now since the soundness and completeness theorems tell us that a set S is satisfiable iff S is consistent (relative to the rules/axiomatization of logic), the analogue of theorem (1) is as follows:

(1)* A set of truth assignments is coherent iff the set determined by the  truth assignments is consistent (relative to an axiomatization of logic) 

You can think of this as a version of the soundness and completeness theorems.
The source is https://plato.stanford.edu/entries/medieval-syllogism/ Medieval Logic.

According to :


Joseph Maria Bochenski, https://books.google.it/books?id=QXoIAQAAIAAJ A History of Formal Logic (1961), §32:



  L. Minio-Paluello has recently made the big discovery of an early attempt to construct syllogistic mnemonics, in a MS of the early 13th century. [...] 
  
  This is a very primitive technique, but at least it shows that the highly developed terminology of https://plato.stanford.edu/entries/peter-spain/ Peter of Spain (who became Pope in 1276, under the name of John XXI; but see footnote : This can not have originated with him) had antecedents in Scholasticism itself. 


See https://books.google.it/books?id=re9OAAAAcAAJ&pg=PA64 Summulae Logicales, Tractatus IV De Sillogismis, §13 (page 64v).

Thus the origin is probably unknown in the first half of 13th Century.

We found it "fully blown" into Petrus Hispanicus' standard textbook on logic, the Tractatus, called afterwards https://books.google.it/books?id=Qi8QAQAAIAAJ&pg=PR43 Summule logicales; see https://books.google.it/books?id=Qi8QAQAAIAAJ&pg=PA52 page 52.

Another source is https://plato.stanford.edu/entries/william-sherwood/ William of Sherwood's logical treatise https://books.google.it/books?id=f3uMdwDVvL8C&pg=PA66 Introductiones in logicam, written in the middle of the 13th century. 
There are many suggested solutions to the Liar paradoxes, mostly invoking complex logic, but there is no current concensus around any one of them. You can see a classification of solutions in the https://plato.stanford.edu/entries/liar-paradox/ SEP article on the Liar. Two notable types of suggested solutions are (1) solutions that involve https://plato.stanford.edu/entries/liar-paradox/#ParaA paracomplete logics, i.e. that hold that Liar statements, such as "I am lying now", belong to a special class of statements which are neither true nor false. And (2) solutions that involve https://plato.stanford.edu/entries/liar-paradox/#ParaB paraconsistent logics, i.e. that hold that Liar statements, such as "I am lying now", belong to a special class of statements which are simultaneously both true and false.
One traditional way of modeling adjectives ontologically is as sets of things that satisfy the property identified by the adjective.  'The beautiful' would be the collection of all things that are beautiful.

Classical philosophers working in Greek or Latin tend to do this extensively because it is very natural in Classical languages to have weak boundaries around the parts of speech, much the way English sometimes does: e.g. 'running' is an adjective (running water), a noun (the running of the water past us) and a verb (the water is running).  So it is easy for us to identify the activity of running, the state of being in the process of that activity, and the set of all things or people taking part in that process all as a single complex of ontological entities that we can treat as closely related nouns, or even as different perspectives on a single thing.

The same notion applies to 'beautiful' or 'chaotic', though the verb form is absent, and it results in a less flexible category.

To the extent that you stay away from the boundaries around your sets, so that vagueness and paradoxes of similarity do not undercut you, that model works well for simple logic.
One problem that enters into this situation that does not apply to the case of human drivers, and that may hold this process up for some time is the diffusion of what is now individual responsibility into the corporate domain.  This is a general problem with the deployment of artificial intelligence, and we will face many versions of it soon.  But so far, the problem has always been mapped back onto humans.  In the case of an autonomous vehicle, this would be quite difficult.

Corporations take responsibility the same way individuals do, but they are able to shift the parts that compose themselves around to evade apparent responsibility or to hide resources available for remediation from those to whom they would be owed.  They have been known to dissolve completely, escaping liability by having no assets while a 'different' corporation is constituted with the exact same human members, free of historical ties to the past behavior of the same group of people.

As it is (at least in the U.S.) determining who is at fault in an accident is a legal process between insurance companies representing individuals.  The facts are ascertained from eyewitnesses, if only in the form of the two drivers themselves.  Approximately equal resources and equal process will be deployed for both drivers, and they are aggregated by the requirement of mandatory insurance into large enough groups that if a large settlement is determined, the individual will not be financially destroyed (though they may never again be able to get insurance and thus may no longer be allowed to drive.)

If a machine makes an error, and the passenger is not in a position to take responsibility for knowing what happened, we are left with a difficulty assigning blame.  The contest of attempts to prove fault is vastly unfair, strangely it is so to either party, but in wholly different ways.


The corporation and its machine can expect very little empathy from
humans, who will constitute the jury or magistracy making the decision; but
The same resources cannot possibly be deployed on behalf of the
human that will automatically come forward to defend the machine.


We have no clue how to insert equality here.  We don't know which party is more disadvantaged, and we don't have faith that if the car company is just put out of business the existing cars already produced will not become unfortunate burdens upon their owners.

(The German government raised the same issues with respect to open-source software back when it first became an important force in the computing industry: that it proposed a problem of responsibility that had no parallel in earlier law, and it was unclear what would constitute fairness.

Elaborate networks of proxies and escrow schemes were finally instituted to buffer the court system against the risks of getting this wrong.  A similar situation might arise here, with auto-insurance companies basically changing in form in a way that simply removes the issue by convincing the courts that this not so bizarre, after all.
)
The short answer is no, as used today it is a much weaker concept. The use of  "agency" evolved quite a bit from the original meaning in the somewhat cryptic passage from Aristotle's De Anima about https://en.wikipedia.org/wiki/Active_intellect "agent intellect". What is meant by "agent" today is any kind of entity that can initiate actions for a purpose (real or perceived). While "initiating actions" might suggest ability to start new causal chains, as in "agent causation" and "free will", the common use is much more permissive. For instance, an animal acting on instinct is an actor with a purpose, and therefore an agent, but, assuming that instinctive actions are automatic, no free will or self-causation is involved here. 

In fact, the language of agency is often used as a way of getting on with practical research while avoiding the perennial controversy over the empirically moot questions, like the "nature" of causality, consciousness, free will, etc. In other words, whenever it is practically useful to employ teleological and/or intentional explanations, the language of agency can be applied. "Actors with a purpose" can be plants (sunflowers move their leaves to face the sun), animals (dog is looking for a bone), animal colonies (ants are trying to surround the intruder), ecosystems, organizations, machines (my car is acting up), robots, etc. It is an admission that there is similarity enough with "truly intentional" human action for the language to be useful, but in and of itself its use presupposes nothing about ontology. Indeed, it may indicate nothing more than antropomorphic stereotypes about animals, or "delegation" of human intentionality to machines.

Allison Adam surveys the recent uses of "agency" in https://books.google.com/books?id=IVLmW1C7oGEC&source=gbs_navlinks_s Artificial Knowing:


  "Hanging onto intentionality points to one of the last refuges of enlightenment thinking, the uniqueness of the human animal... Dennett’s intentional stance offers a get-out clause, a way of acting as if certain objects have intentionality without worrying about whether they actually do have it. Taking an intentional stance towards something is a way of granting it some level of agency... Both in the popular sub-domain of distributed AI (DAI), where knowledge is distributed through several knowledge bases, or where intelligent agents act in concert to solve a problem, and also in robotics, it is curious to see that the language of agency and intentionality abounds, possibly much more so than in other areas of symbolic AI. 
  
  ...using the language of agency permits a use of intentional language, almost by sleight of hand. If you call something an ‘agent’ then you can use intentional terms without examining them, without justifying them and indeed without grounding them. Such terms can be used in a purely operational way and then the metaphor of their functionalism can be allowed to slip into a reality... A recent robotics paper gives a computational definition of agent:"Embedded agents are computer systems that sense and act on their environments, monitoring complex dynamic conditions and affecting the environment in goal-directed ways". The definition is full of intentional terms - ‘sense’, ‘act’, ‘monitor’, ‘affect’, ‘goal’. Yet at the same time the definition is purely operational or functional; it says nothing about what it means to have a computer system sense, act, monitor and so on."


Among others, https://books.google.com/books?id=AcwR-Vsp4KkC&source=gbs_navlinks_s late Quine in Pursuit of Truth came to accept pragmatic use of such "mentalistic" or "intensional" language despite his original physicalism:


  "The residual oddity of these mentalistic predicates de dicto is purely semantic: they do not interlock productively with the self-sufficient concepts and causal laws of natural science. Still the mentalistic predicates. for all their vagueness (§27) have long interacted with one another, engendering age-old strategies for predicting and explaining human action. They complement natural science in their incommensurable way... Read Dennett and Davidson."


Of course, one could still wonder when there is more to the use of "agency" than linguistic convenience, and people keep arguing about the borders between life and non-life (https://www.scientificamerican.com/article/are-viruses-alive-2004 are viruses alive?), sentience and non-sentience (are dolphins sentient?), philosophical zombies, etc. But the situation seems to be reminiscent of Hume's analysis of causality. There are no  individual facts of the matter about causation, we can not tell from a single event, or even a sequence of them, if X caused Y. We infer causation holistically, if the event falls into a template that our theories use causal laws to predict. It is similar with "agency": there can be no individual "Turing tests" for it (hence the failure of Turing tests for AI). The agency should be assigned holistically on pragmatic grounds, when the use of mentalistic predicates in our theories leads to better predictions overall.

  If one element of a conjunction is false, is the whole statement false?


Yes. A conjunction of two propositions is only true when BOTH propositions constituting the conjunction are true.  

This is the truth table for conjunctions:
https://i.stack.imgur.com/oyXn3.jpg 

This is a technical point but instead of "element" the term you are asking about is the "https://en.wikipedia.org/wiki/Operand operand". In a conjunction statement such as "φ ∧ ψ" there are three elements, two operands (φ and ψ) and the conjunction (or connective) operator (∧). Your question could also be phrased, "If one [statement, proposition, assertion, premise, etc.] in a conjunction..." (Note that the ampersand is not as common anymore, but along with ∧ and •, & is an acceptable symbol for the "and" operator of a conjunction.)


  If one element of a [disjunction] is false, is the whole statement false?


No.  

The answer is different if you mean an inclusive disjunction or an exclusive disjunction. In both cases they are false when both operands are false, but the exclusive disjunction is also false when both operands are true. (See the truth table below)


  Take the statement: "Either Brown is in Barcelona or Jones owns a Ford." 


First of all, that statement is not a http://www.philosophy-index.com/logic/symbolic/conjunction.php conjunction statement, it is a http://www.philosophy-index.com/logic/symbolic/disjunction.php disjunction. This is the truth table for disjunction, "inclusive" - a more common "or" statement" - is on the left and "exclusive" disjunction is on the right:
http://www.philosophy-index.com/logic/symbolic/conjunction.php 
To be clear, the "aVb" column is "inclusive or" and the "a V̲ b" column is "exclusive or" (sometimes indicated by "xor").


  I know that if one element of the conjunction(sic) is true (Jones owns a Ford, for example), then the whole thing is true.  


Given your example is a disjunction, I am presuming you meant your question about disjunctions.

In an inclusive disjunction with only two operands, If only one operand is true, or, both operands are true, then the whole thing is true:
http://www.philosophy-index.com/logic/symbolic/disjunction.php 

Only if no more than one operand of an exclusive disjunction with only two operands is true, is the exclusive disjunction statement true:
https://i.stack.imgur.com/FMqfl.gif 


  Does the same thing apply for falsity? If one element is false, is the whole thing false?


Yes for conjunctions.
No for disjunctions.
Aristotle resolves the argument in http://dhspriory.org/thomas/Physics4.htm#4 Physics bk. Δ On Place, ch. 3 (210b):


  Zeno's problem—that if Place is something it must be in something—is not difficult to solve. There is nothing to prevent the first place from being 'in' something else—not indeed in that as 'in' place, but as health is 'in' the hot as a positive determination of it or as the hot is 'in' body as an affection. So we escape the infinite regress.


For an in-depth treatment of the "problem" of place, see "Part II: Place" of:


Duhem, Pierre Maurice Marie. https://isidore.co/calibre/browse/book/4757 Medieval Cosmology: Theories of
Infinity, Place, Time, Void, and the Plurality of Worlds. Edited
and translated by Roger Ariew. Chicago: University of Chicago Press,
1985.

An important question in philosophy of science is how scientific knowledge grows. Philosophers until Thomas Kuhn were convinced that there must be some logic in scientific discovery as well as scientific justification. If Kuhn is right, there is no logic in scientific discovery. But then how is scientific discovery made?   

A set of scientific facts is always'theoretically (model-wise) inconsistent' in the sense that there are anomalies or facts that disobey going scientific laws. In the normal science situation as Kuhn uses the term, these facts are mere outliers. But when these outliers become meaningful puzzles or core questions for the scientific community, a crisis in science is impending. Who will be the hero in this revolution? 

History of science reveals that only those equipped both with imagination and sagacity have been the heroes. This observation is called scientific serendipity. Sagacity (scientific training and knowledge) is necessary. But knowledge is analytical and fragmented. To solve the puzzle, one should be able to see the whole, all-encompassing picture (to think outside the box, so to speak). We call this ability imagination. The set of possible solutions is factually limited by the ability to imagine. 

"Imagination is more important than knowledge," in this light, is to explain the genesis of scientific heroes.
We believe in time because it agrees with our observations, and furthermore plays a prominent role in our (very well empirically verified) physical theories of the universe.

We would need a good reason to stop believing in time; an empty "what if?" question is not enough to cast doubt on the notion.

  Also, if someone thinks this is prone to being opinion-based, then what exactly makes some economic thought non-opinion? I have the view that not all economics is on par with empirical natural science in its verification. For example Ludwig Von Mises has written about economics being "a priori" science, which means "science done without observation". 


Mises' position was that we know that people act purposefully in a way that is different from how we know about the motion of electrons. We can only work out the laws governing electrons by observing electrons from the outside. But we can know that human beings act purposefully because we have first hand knowledge that we act purposefully:

http://www.peterleeson.com/Was_Mises_Right.pdf http://www.peterleeson.com/Was_Mises_Right.pdf

Economics starts from the fact that human beings act purposefully and explores the consequences of that fact.


  A priori on its own makes me skeptical of economics' usefulness and to perceive it more like armchair philosophy. Still there's more to some economics, some economics is practical.


Other economists, especially neoclassical economists, like to act as if there is a quantity called value and people somehow assign this quantity to stuff. And we can draw continuous curves representing the amount of value and do calculus with them. And this allegedly allows us to do all sorts of mathematical tricks to predict and control people.

This is a ludicrous and impractical idea. Any real choice is a choice among alternative courses of action. It consists not of assigning a continuous value but of saying 'I prefer state of affairs X over state of affairs Y and so I will act to bring about X.' There is no continuous quantity, there are no curves. Pretending that such curves exist is 'practical' only as a means of fooling credulous people willing to accept to any old nonsense provided people present it in conjunction with a number that includes a decimal point, e.g. - see the fuss made over values assigned to the Keynesian multiplier. These numbers typically refer to aggregates, like all the socks bought in Washington or whatever. Such aggregates are not particularly useful since there is no particular transaction that is explained in terms of such aggregates. Rather, the price of socks is explained in terms of individual transactions not the other way around. False 'accuracy' and 'precision' is a sign of intellectual and moral bankruptcy, it is not evidence that economics is actually a quantitative science.

  If we take Aquinas' first way, for example, the inference that a chain of movers exist, is readily made, but no defense for this assumption is given.


He proves "that everything that is moved is moved by another" (quidquid movetur ab alio movetur) and "that in movers and things moved one cannot proceed to infinity" more at length in https://isidore.co/aquinas/ContraGentiles1.htm#13 Summa Contra Gentiles I cap. 13 than he does in https://isidore.co/aquinas/summa/FP/FP002.html#FPQ2A3THEP1 Summa Theologica I q. 2 a. 3.

Here are his proofs of quidquid movetur ab alio movetur from https://isidore.co/aquinas/ContraGentiles1.htm#13 Summa Contra Gentiles I cap. 13 [5]-[10]:


  [5] The first of these propositions [quidquid movetur ab alio movetur] Aristotle proves in three ways. The first way is as follows. If something moves itself, it must have within itself the principle of its own motion; otherwise, it is clearly moved by another. Furthermore, it must be primarily moved. This means that it must be moved by reason of itself, and not by reason of a part of itself, as happens when an animal is moved by the motion of its foot. For, in this sense, a whole would not be moved by itself, but a part, and one part would be moved by another. It is also necessary that a self-moving being be divisible and have parts, since, as it is proved in the https://isidore.co/aquinas/Physics6.htm#5 Physics [VI, 4], whatever is moved is divisible.
  
  [6] On the basis of these suppositions Aristotle argues as follows. That which is held to be moved by itself is primarily moved. Hence, when one of its parts is at rest, the whole is then at rest. For if, while one part was at rest, another part in it were moved, then the whole itself would not be primarily moved; it would be that part in it which is moved while another part is at rest. But nothing that is at rest because something else is at rest is moved by itself; for that being whose rest follows upon the rest of another must have its motion follow upon the motion of another. It is thus not moved by itself. Therefore, that which was posited as being moved by itself is not moved by itself. Consequently, everything that is moved must be moved by another.
  
  [7] Nor is it an objection to this argument if one might say that, when something is held to move itself, a part of it cannot be at rest; or, again, if one might say that a part is not subject to rest or motion except accidentally, which is the unfounded argument of Avicenna. For, indeed, the force of Aristotle’s argument lies in this: if something moves itself primarily and through itself, rather than through its parts, that it is moved cannot depend on another. But the moving of the divisible itself, like its being, depends on its parts; it cannot therefore move itself primarily and through itself. Hence, for the truth of the inferred conclusion it is not necessary to assume as an absolute truth that a part of a being moving itself is at rest. What must rather be true is this conditional proposition: if the part were at rest, the whole would be at rest. Now, this proposition would be true even though its antecedent be impossible. In the same way, the following conditional proposition is true: if man is an ass, he is irrational.
  
  [8] In the second way, Aristotle proves the proposition by induction https://isidore.co/aquinas/Physics8.htm#7 [Physics VIII, 4]. Whatever is moved by accident is not moved by itself, since it is moved upon the motion of another. So, too, as is evident, what is moved by violence is not moved by itself. Nor are those beings moved by themselves that are moved by their nature as being moved from within; such is the case with animals, which evidently are moved by the soul. Nor, again, is this true of those beings, such as heavy and light bodies, which are moved through nature. For such beings are moved by the generating cause and the cause removing impediments. Now, whatever is moved is moved through itself or by accident. If it is moved through itself, then it is moved either violently or by nature; if by nature, then either through itself, as the animal, or not through itself, as heavy and light bodies. Therefore, everything that is moved is moved by another.
  
  [9] In the third way, Aristotle proves the proposition as follows https://isidore.co/aquinas/Physics8.htm#9 [VIII, 5]. The same thing cannot be at once in act and in potency with respect to the same thing. But everything that is moved is, as such, in potency. For motion is the act of something that is in potency inasmuch as it is in potency. That which moves, however, is as such in act, for nothing acts except according as it is in act. Therefore, with respect to the same motion, nothing is both mover and moved. Thus, nothing moves itself.
  
  [10] It is to be noted, however, that Plato, who held that every mover is moved [Phaedrus], understood the name motion in a wider sense than did Aristotle. For Aristotle understood motion strictly, according as it is the act of what exists in potency inasmuch as it is such. So understood, motion belongs only to divisible bodies, as it is proved in the https://isidore.co/aquinas/Physics6.htm#5 Physics [VI, 4]. According to Plato, however, that which moves itself is not a body. Plato understood by motion any given operation, so that to understand and to judge are a kind of motion. Aristotle likewise touches upon this manner of speaking in the https://isidore.co/aquinas/DeAnima.htm#311 De anima [III, 7]. Plato accordingly said that the first mover moves himself because he knows himself and wills or loves himself. In a way, this is not opposed to the reasons of Aristotle. There is no difference between reaching a first being that moves himself, as understood by Plato, and reaching a first being that is absolutely unmoved, as understood by Aristotle. 


Also, from http://scholastic.us.to/ here, see these articles related to quidquid movetur ab alio movetur:


  
  http://www.thomist.org/jourl/1974,%20vol.%2038/April/1974%20April%20A%20Moreno%20web.htm The Law of Inertia and the Principle Quidquid Movetur ab Alio Movetur by Antonio Moreno, O.P.
  
  α.  https://isidore.co/calibre/browse/book/3904 The Aristotelian definition of motion and the principle of inertia, a thesis by McLaughlin, Thomas J., University of St. Thomas (Houston), author of "https://isidore.co/misc/Physics%20papers%20and%20books/Philosophy%20&%20History/McLaughlin%20(@%20St.%20Vianney%20Theological%20Seminary)/Nature%20&%20Inertia%20(Thomas%20J.%20McLaughlin).pdf Nature and Inertia" in The Review of Metaphysics, Vol. 62, No. 2 (Dec., 2008), pp. 251-284
  


cf. https://isidore.co/misc/Physics%20papers%20and%20books/Philosophy%20&%20History/McLaughlin%20(@%20St.%20Vianney%20Theological%20Seminary)/ these other articles by McLaughlin, who is an expert on Aristotelian motion and the principle of inertia.


  Usually the argument is interpreted so, that all the actualizations of the potentialities happen instantaneously. There exists no temporal ordering between the different movements of the corresponding movers. But how can we be so sure that no such temporal ordering exists?


As mentioned https://christianity.stackexchange.com/a/34621/1787 here, in https://isidore.co/aquinas/summa/FP/FP046.html#FPQ46A2THEP1 Summa Theologica I q. 46 a. 2 ad 7,


  St. Thomas distinguishes between causal series ordered per accidens ("accidentally") and causal series ordered per se ("essentially"). https://edwardfeser.blogspot.com/ Edward Feser's https://isidore.co/calibre/browse/book/4991 Aquinas: A Beginner's Guide (ch. 3 "Natural Theology," § "The First Way") describes the difference.


The full quote from Feser is https://christianity.stackexchange.com/a/34621/1787 here. Feser says "Causal series ordered per accidens are linear in character and extend through time" and "Causal series ordered per se are paradigmatically hierarchical with their members acting simultaneously". It seems you only think St. Thomas is speaking of "Causal series ordered per se."

See also William Wallace's "http://scholastic.us.to/Aquinas%20on%20the%20Temporal%20Relation%20Between%20Cause%20and%20Effect%20(Wallace).pdf Aquinas on the Temporal Relation Between Cause and Effect."


  And if it does exist, what justification can we give to reject such loops of movements? Why can't a mover induce a change in the “moved”, which in turn again leads to the “moved” inducing a change in the original mover, and assume such a loop goes on ad infinitum?


In other words: "Why can't 'quidquid movetur ab alio movetur' be false?"
Not exactly. You are trying to map Kant into modern cognitive psychology, which is a natural thing to do, but can only give us an idea of what Kant might have been getting at from our modern perspective, not how he actually thought about it. In his own mind he was not working with introspective data, nor was he trying to build a dynamical model of mental cognitive processes. In the Preface to Metaphysical Foundations of Natural Science he explicitly writes that "the empirical doctrine  of  the  soul”  will never be  "a  properly  so-called natural science", see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.710.9947&rep=rep1&type=pdf Steinert-Threlkeld's Kant on the Impossibility of Psychology as a Proper Science.

In his mind Kant reasoned from characteristics of knowledge (of the kind available to us) to functional elements that must be in place to make it possible, these are his signature "transcendental arguments". These elements included sensibility, productive and reproductive imagination, understanding, reason, the cryptic "transcendental unity of apperception", and of course the a priori forms of intuition. Characterizations like "highly momentary un-reflected state of passive receptivity", or anything else like that, would sound insufferably psychologistic to Kant. "Spontaneity" is not anything psychologistic either, it refers to the fact that concepts are not read off from empirical input, or seen through intellectual mindsight, as most philosophers thought before him, but rather are produced by the subject herself, as part of those functions necessary for having knowledge. Kant does mention in https://archive.org/stream/immanuelkantscri032379mbp/immanuelkantscri032379mbp_djvu.txt Critique of Pure Reason (A78/B103) that productive imagination is a "blind but indispensable function of the soul, without which we should have no knowledge whatsoever, but of which we are scarcely ever conscious" (A78/B103), but he is far from concerning himself with whether it is controlled, transitory, etc.

Now what of intuition? It helps to put it into the context of Kant's time as well. It has little to do with the modern colloquial meaning, something like what Peirce called "instinct for guessing right". https://books.google.com/books?id=soawvEGmA8wC&source=gbs_navlinks_s According to Adams, the Latin term intuitio was introduced by scholastic authors:


  "[For Duns Scotus] intuitive cognitions are those which (i) are of the object as existing and present and (ii) are caused in the perceiver directly by the
  existing and present object. [...] According to Ockham, an intuitive cognition of a thing is that in virtue of which one can have evident knowledge of whether or not a thing exists, or more broadly, of whether or not a contingent proposition about the present is true."


But by the time of Kant belief in such special faculty of immediate knowledge was severely undermined by nominalists and then empiricists. Neither Platonic/Aristotelian theories of direct perception of forms, nor "rational intuition" based on "innate ideas" a la Descartes, etc., had much credibility left. So Kant's notion of intuition is much reduced compared to its predecessors. Here is http://www.cairn-int.info/load_pdf.php?ID_ARTICLE=E_RIP_224_0057 Hintikka's description of how Kant understood intuition:


  "The only notion of intuitiveness that was alive for him was a diluted one amounting to little more than immediacy. But Kant gave this immediacy a special interpretation. He thought that our representations (Vorstellungen) could relate to objects in two different ways, either indirectly, via the general characteristics (Merkmale) they have, or else directly, as particular objects. Thus intuitiveness came to mean for Kant simply particularity...
  
  As a consequence, Kant does not normally speak of intuitive knowledge. Intuitiveness is for him in the first place an attribute of representations (Vorstellungen), not of items or kinds of knowledge. For him, intuitions in the minimal sense of the word are nothing but singular representations in contradistinction to general concepts. Intuition was not a source of truths or insights, but merely the medium of representing particulars, and intuitive knowledge was for him, not knowledge proclaimed to me by a special oracle called intuition, but simply knowledge obtained by means of such representations, especially by the method of exhibiting general concepts by means of their
  particular representatives... There was for Kant no definitory link between intuition and sense-perception or imagination. Purely symbolic algebraic symbols could be "intuitive" merely because they represent particular numbers."


Kant himself talks not as much of intuition being the medium of representing particulars ("undifferentiated manifold of sensation" is more of that for the sensory cognition) as of individual intuitions as particulars there represented. The intuition/concept duality is explicitly analogized in the Amphiboly of Concepts of Reflection to Aristotle's matter/form. So it is as hard to put a finger on what intuitions by themselves are as on what Aristotle's prime matter/pure potentiality might be, divested of all form. In CPR A68/B93 we read that "whereas all intuitions, as sensible, rest on affections, concepts rest on functions", which suggests that intuitions might be akin to what is now called "qualia", but without the subjective/psychological connotation. However, as http://www.sciencedirect.com/science/article/pii/0039368179900025 Pippin remarks in Kant on Empirical Concepts, the role of intuitions remains murky. He does try to offer a reconstruction:


  "That is, relatively little attention, either in Kant or in the literature, has been devoted to the positive details of his theory of empirical knowledge, the exact way in which human beings are in fact ‘guided’ by the material of sensible intuitions... Any intuited ‘this’ can be a ‘this-such’ or ‘of-a-kind’, or, really determinate, only if a rule is applied connecting that intuition (‘synthetically’) with other intuitions (or remembered intuitions)
  ‘in one consciousness’. Or, finally, to say that ‘one’ concept includes
  or refers to ‘many’ representations is not to assert a problematic relation between one abstract entity (like a universal) and many other entities. It is only to express that a rule can be applied in many different instances of intuiting. More generally, we can say that concepts thus do not refer to anything; they classify conceptual activities and are thus used universally and do not name a universal.’"

There is an assumption here, that there is such a thing as "post truth" world, as an unprecedented phenomenon. The fact that a concept exists with its own term does not make the phenomenon it describes a fact. For all we know, this might be a temporary moment where systematic alterations of truth are being used to influence masses, such as there have already been several in history (not the least the European authoritarianisms of the 1930s).

But supposing we were entering a post-truth period where "objective facts are less influential in shaping public opinion than are appeals to emotion and personal belief", then this would be trouble for a philosopher or intellectual. A much more mundane term would be that "post truth" is the reflection of obscurantism ("a policy of opposition to enlightenment or the spread of knowledge" -- Wordnet). 

What post-truth describes, is not people acting under their own rationality or observation, but reacting to appeals to faith or emotion. Clearly, this tendency of people, would be called "intellectual nonage (minority)" as Kant described in his essay http://www.columbia.edu/acis/ets/CCREAD/etscc/kant.html What is Enlightnenment: "Laziness and cowardice are the reasons why such a large part of mankind gladly remain minors all their lives, long after nature has freed them from external guidance. They are the reasons why it is so easy for others to set themselves up as guardians. It is so comfortable to be a minor." Indeed, what post truth generally describes is people acting irrationally under the influence of fear (of economic difficulties, immigration, terrorism, etc.). This intellectual nonage would be opposed to enlightenment, the ability of an individual to think for oneself, which requires an individual ability to observe facts and analyze them independently (sapere aude = dare to know).

What this would describe is a society where individuals would no longer be citizens (something that requires the courage to assume independence of mind), but subjects. Elections and votes (and thus democracy) would therefore lose their meaning, since people would vote according to suggestions they are receiving instead of according to their reason.

Separation of powers would be hurt, since neither justice nor the parliaments could work serenely. Republic (as Kant or as we understand it) would deperish, since power would be held by people who are capable to manipulate emotions and personal beliefs (i.e. superstitions). The result of this individual disenfranchisement would be tyranny.

In a post truth context, the position of a philosopher, intellectual or any person who seeks to practice their freedom of knowing (enlightenment) would be difficult in a largely comformist society, and liable to be restricted by law (typically laws preventing lèse-majesté against the ruler, the government or the status quo). This is nothing particularly new for thinkers, as they would face the same challenges as from authoritarianisms of the twentieth century or from the absolute monarchies of Europe.

If they were true to the traditions of American or European democracies, they would have to defend freedom of thought and expression. I imagine however that they would split in two, like they did in the 19th century: those who feel that the cause of "one-human-one-vote" is lost (as this would lead to ochlocracy, the rule of the mob) and would advocate the rule of an elite minority who are worthy of governing the post-truth people (https://www.ahdictionary.com/word/search.html?q=hoi%20polloi oi polloi); and those who advocate that in spite of everything, "the inherent dignity and the equal and inalienable rights of all members of the human family is the foundation of freedom, justice and peace in the world" (Preamble of the Universal Declaration of Human Rights).

These would be existential questions!
Free will is not the ability to do whatever you want if was like this then try to fly!

Free will is the ability to make a choice. If this wasn't true we are in trouble:


  Man has free-will: otherwise counsels, exhortations, commands,
  prohibitions, rewards, and punishments would be in vain.
  
  man acts from judgment, because by his apprehensive power he judges
  that something should be avoided or sought


This is just an extract but have a read on I answer that of: http://www.newadvent.org/summa/1083.htm Summa Theologiae, Question 83, Thomas Aquinas
He continues:


  Now particular operations are contingent, and therefore in such
  matters the judgment of reason may follow opposite courses, and is not
  determinate to one. And forasmuch as man is rational is it necessary
  that man have a free-will.


click on the link to examine in depth the question on the relative oppositions.
The enterprise of reducing mathematics to logic is called https://plato.stanford.edu/entries/logicism/ Logicism. There have been two different goals in this enterprise, the first is to reduce just https://en.wikipedia.org/wiki/Natural_number#Formal_definitions arithmetic of natural numbers, which in many ways is the easiest and most basic part of mathematics. The other is to reduce all of mathematics, or at least as much as we can, to a set of axioms (consider something like https://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory ZFC set theory). 

Logicism, historically, was lead by https://plato.stanford.edu/entries/frege/ Frege, https://plato.stanford.edu/entries/dedekind-foundations/ Dedekind, and https://en.wikipedia.org/wiki/Giuseppe_Peano Peano among others. Peano is most famous for giving https://en.wikipedia.org/wiki/Peano_axioms a set of axioms that allow for the construction of the natural numbers and arithmetic, while Dedekind is arguably most famous (at least in terms of this conversation) for discovering what are called https://en.wikipedia.org/wiki/Dedekind_cut Dedekind cuts, partitions of the rational numbers which allow for the construction of real numbers. Frege set out to just form a logical foundation for arithmetic, while also developing the tools and languages of modern logic in the process: 


  https://plato.stanford.edu/entries/frege-theorem/ In his book of 1879, Begriffsschrift: eine der arithmetischen nachgebildete Formelsprache des reinen Denkens, he developed a second-order predicate calculus and used it both to define interesting mathematical concepts and to state and prove mathematically interesting propositions. However, in his two-volume work of 1893/1903, Grundgesetze der Arithmetik, Frege added (as an axiom) what he thought was a logical proposition (Basic Law V) and tried to derive the fundamental axioms and theorems of number theory from the resulting system. Unfortunately, not only did Basic Law V fail to be a logical proposition, but the resulting system proved to be inconsistent, for it was subject to Russell’s Paradox.


Logicism has been subjected to a number of set backs, some so devastating that many philosophers believe that the program cannot ever succeed. One of them is the weakness of second order logic and how Frege's Basic Law V failed to do what he had hoped it would, derive all of arithmetic. Even if the law were not subject to Russell's paradox, it still has a glaring ontological issue: https://www.jstor.org/stable/42971198?seq=1#page_scan_tab_contents the Julius Cesar problem. In essence, the problem says that something like Hume's principle (which is very similar to Basic Law V) cannot provide enough of an epistemic reason as to why we should pull numbers out of our arbitrary definitions:


  https://plato.stanford.edu/entries/frege-theorem/#6.5 [Gl, §55:] 
  … but we can never – to take a crude example — decide by means of our definitions whether any concept has the number Julius Caesar belonging to it, or whether that conqueror of Gaul is a number or is not. [from the Austin translation in Frege 1974]


Ultimately, many believe Frege's original conception of logicism is not a paradigm that can work (although there is renewed interest, see https://mally.stanford.edu/Papers/neologicism2.pdf neo-logocism).

There are two, maybe three, other glaring problems for reducing mathematics to logic. They come in the form of Gödel's https://plato.stanford.edu/entries/goedel-incompleteness/ two incompleteness theorems and Tarski's https://en.wikipedia.org/wiki/Tarski%27s_undefinability_theorem undefinability of truth. 

Peano's axioms turn out to be subjected to Gödel's two incompleteness theorems. The first theorem (to be brief) states that any formal system, meaning a set of axioms within a deductive logic, is subject to what are called Gödel sentences. These sentences that are true (semantically) but unprovable (syntactically) within the system itself. Gödel accomplished this theorem by giving a generalized way to construct these sentences in any formal system that is strong enough to formalize https://en.wikipedia.org/wiki/Robinson_arithmetic Robinson arithmetic (a weaker form of arithmetic than Peano's axioms). https://en.wikipedia.org/wiki/Presburger_arithmetic Presburger arithmetic is a formal system of arithmetic that does not contain multiplication and is not subjected to Gödel's first incompleteness theorem. 

This brings up something important. What is really of note here is that, Gödel's result is not necessarily about mathematics itself (unless you believe that mathematics is strictly logic in disguise); in essence, his results are about the formal systems themselves, or the logic itself. The results are syntactical, meaning that they are about the syntax, the rules of the system, and not about the semantics, the meaning we ascribe to the system. Formal systems are just a bunch of arbitrary rules and symbols until we give them meaning, and Gödel's results basically say "If you have this set of rules or anything stronger than it, you can derive this set of sentences." It doesn't matter what meaning we give to them, that the system is talking about numbers and arithmetic. Before we introduce any sort of semantic content to the theory, the Gödel sentences will still be there because they are constructed in a purely syntactical way. This is a major issue for logicism, because it shows that any sort of logical system will have true statements about the natural numbers, statements we know are true, but are unprovable in our theory. Logicism does not abide that. 

Gödel's second incompleteness theorem says that "no consistent set of axioms (with enough strength) can prove it's own consistency." Another way to read it is that "any, sufficiently strong, axiom system that can prove its own consistency is inconsistent." The two results combined say that "Any consistent system with at least enough strength to define Robinson arithmetic cannot be complete due to its Gödel sentences and it cannot prove its own consistency." The system might be consistent, but we cannot formulate a proof of that within the system itself. 

As a result of these two theorems, we, as mathematicians and philosophers, have to treat our axiomatic systems with caution. Many believe that Peano arithmetic and ZFC set theory are consistent, however we only believe that because we have been spending so many years studying them and have yet to find an inconsistent sentence. We make that judgement purely due to induction (and a little bit of meta reasoning, it seems very unlikely that ZFC is inconsistent) but we have no formal proof within the systems themselves that they are consistent. You can, however, chain consistency proofs of smaller, weaker systems but this only pushes the epistemic problem of consistency higher up the chain. ZFC can prove the consistency of PA; a different set theory called https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Bernays%E2%80%93G%C3%B6del_set_theory NBG is consistent if and only if ZFC is consistent; an even stronger set theory called https://en.wikipedia.org/wiki/Morse%E2%80%93Kelley_set_theory MK can prove the consistency of ZFC; and so on. However, at each step we have to assume that the higher theory is consistent in order to believe the consistency proof of the lower theory. Eventually, the systems we get to are so big that we cannot have reasonable assumptions about their consistency. Due to Gödel's second incompleteness theorem, there will never be a ceiling theory that can prove its own consistency and can be used to prove all of the weaker theories. 

Tarski's undefinability theorem is very similar to Gödel's theorems, except that it focuses on the definability of truth. Just like how Gödel shows that a formal system cannot show its own consistency, Tarski shows that a predicate that defines when a sentence is true cannot be formulated within a system itself and must come from some other, "meta" system. The study of metasystems of this kind, the kind that allow for a definition of truth, is called https://en.wikipedia.org/wiki/Model_theory model theory, which Tarski spearheaded. His results, though, ultimately show that there can never be one theory that contains the means to show that its sentences are true because the "truth" of its own sentences can never be defined within itself. 

So, the enterprise of Logicism has run into a few snags. Some people, namely neologicists (myself included), believe that the results of Gödel and Tarski don't necessarily preclude an ultimate reduction of mathematics to logic; more so it is believed that there will always be a few things left out of the theory and some assumptions we have to make but cannot prove. The Stanford Encyclopedia of Philosophy article linked in the beginning of this answer adds a lot more detail to the philosophical objections to logicism theories and is worth reading in order to obtain a better grasp of this subject. All this being said, the consistency of ZFC is widely believed to be true and mathematicians have no problem, in practice, of trusting this assumption. It is almost universally considered a true mathematical proof if you can formulate your theorem as a derived sentence of ZFC. There are some logicians who don't believe ZFC is consistent, however. The recently passed logician and mathematician https://en.wikipedia.org/wiki/Jack_Silver Jack Silver was very vocal about his opinion that ZFC is inconsistent and he worked vigorously to construct a proof; however, he was unsuccessful. 

Ultimately, many believe that it is not possible to entirely reduce all of mathematics to logic, given Gödel and Tarski's results. Some still do; however, as of this moment, no logicist program has done exactly what those like Frege and Peano wished it would do.
The traditional role of a https://en.wikipedia.org/wiki/Taboo taboo is prohibition of an action, not of discussion, but the two are often mixed when the term is used loosely, see e.g. http://www.academypublication.com/issues/past/tpls/vol03/12/23.pdf Gao's study of English "taboo" words. Taboos against homicide or incest had obvious biological/social benefits. Volume 3 of a classical comparative study of mythology and religion, https://en.wikipedia.org/wiki/The_Golden_Bough Frazer's Golden Bough, is called https://archive.org/details/goldenboughstud03fraz Taboo and the Perils of the Soul, and freely available online. https://en.wikipedia.org/wiki/Totem_and_Taboo Freud's Totem and Taboo is now considered discredited by antropologists, although some modern authors see residual value in it.

Ellis authored an essay https://www.brainpickings.org/2016/02/26/havelock-ellis-love-sex-taboos The Function of Taboos, where he argues that taboos play an adaptive evolutionary role and are found even in animal communities:


  "Among wild birds in a special phase of bird-existence it is taboo to remain close to humans. That taboo is strictly analogous to human taboos; it is an adopted custom. It is not found everywhere among birds. When men first visit Virgin islands of the southern seas there are birds who do not regard human beings as taboo. The taboo is introduced later when human beings have become destructive to the bird society. It is, of course, completely unnecessary to be aware of the reason for the taboo, and if birds ever acquired speculative minds they would invent reasons. That is, as we know, exactly what human societies do. 
  
  [...] Life is livable because we know that wherever we go most of the people we meet will be restrained in their actions towards us by an almost instinctive network of taboos. We know that they will allow us the same or nearly the same degree of freedom and privilege that they claim for themselves. The individual in whom the taboos necessary for such organization are not either automatic or self-imposed is an anti-social individual, and his elimination would be for our benefit... Old taboos can only be replaced by new taboos... If they are thus to become of the nature of taboos they must be few in number, indisputable in value, and so urgent that they are felt to be on the way to become instinctive. Sex taboos are at the centre of this process...


Even the "should be open-minded and free to discuss all topics" view, common in Western liberalism, is far from universally accepted. In some cultures it is criticized for leading to social and political instability, for example. And even Western liberalism has taboos of its own, against racism, sexism, etc. Despite the opposing backgrounds both seem to fall under Ellis's description of the function of taboos as maintaining social cohesion. See also http://www.newappsblog.com/2012/09/%C5%BEi%C5%BEek-and-kant-on-philosophical-taboos-or-on-the-demise-of-philosophical-history.html Schliesser's post Žižek and Kant: on Philosophical Taboos.
I don't know if this works for fitch, but the key is conditional proof:


  
  A → B   Assumption
  


Here's the conditional proof:


   2. | ¬B  Assumption 


Then, if you can use modus tollens:


   3. | ¬A  MT 1,2 
 4. ¬B → ¬A CP 2-3


If you cannot use modus tollens:


   3. || A  Assumption 
 4. || B  MP 1,3 
 5. || B & ¬B &I2,4 
 6. | ¬A RAA 3-5
 7. ¬B → ¬A CP 2-6


The names of your tools might be different. Here's what I'm calling things:


Assumption = to start the proof or a sub proof
| the vertical bar to indicate when we are in subproofs
MP  which might be called conditional elimination
MT  which might also be called conditional elimination or be absent from your system
&I for conjunction
RAA for "reductio ad absurdum" -- meaning you hit a contradiction in a subproof and can reject the assumption that took you there.
Some proof systems require you to use R (repetition) when using something from outside the subproof. (The most pedantic versions even require you always have two things that take two lines immediately be repeated before you take the step (i.e., 4. Q MP 1,3 is not acceptable). I haven't done so here.




Some general thoughts. If you see a conditional as your goal, then usually you will want a conditional proof. Otherwise it's a pain to get a conditional back in there.

Also, what you're proving is called "contraposition" so there should be lots of proofs for it.

If you're coming from truth tables, you can somewhat translate what you learned there into proofs especially if you learned how to short-circuit the table (in that case, each step can generally become a step in a proof).
Since the author doesn't explain what they mean by a rights-based ethics, it's a little hard to tell.  But rights are often understood as only "negative rights," what you call "rights to be left alone in doing certain acts."  Ever since https://en.wikipedia.org/wiki/Two_Concepts_of_Liberty Isaiah Berlin's "Two Concepts of Liberty," academic political philosophers frequently associate "positive rights" with "positive liberty," and are at least hesitant to see entitlements (say, to a minimum income or health care) in terms of rights.  For example, in John Rawls' A Theory of Justice, redistribution is justified by the difference principle rather than notions of liberty or rights.  Some libertarian philosophers argue explicitly that rights must only be understood as negative rights.  

By contrast, public discourse about rights often includes both positive and negative rights.  For example, right now proponents of universal public health care in the US often frame their argument in terms of a right to health care.  

Since the author is an academic philosopher, it's probably safe to assume that they're assuming that rights are only negative rights.  "Positive rights" would be understood as duties; so members of my community have a duty to provide me with enough food for me to survive, but this isn't a (negative) right to food.  
As I understand Aristotle's "Natural slavery," he makes a distinction between those humans that don't have cognitive powers,and those that do.
Those that don't, he would call "natural slaves."
Those that do, if enslaved, would rebel and cause enmity.  

In your first statement, you are agreeing with Aristotle by thinking that one should submit to other humans that are in a higher position, wealthier, etc., "...because they can help us achieve our desires".  

In the second statement, you imply that if we are not "slaves" to God (",,, if we don't do enough labor..."), we will get nothing from Him.  This statement would also reinforce Aristotle's premise - if true.  However, it is not true!  Whatever we get from God, it is due to God's generosity,  not because we "...labored hard for it."  Therefore, we are not God's "slaves"! 
I think this sort of thing happens all the time. For example, in some calculation or other for the height of say a telegraph pole I may need to extract a square root.

Now, there are two square roots, one the negative of the other; for example, the square root of 25 is 5 or -5. 

For the problem at hand, -5 makes no obvious physical sense; in what way is a telegraph pole -5m in height? So I throw out that solution, and keep only the 5m solution.

The moral of this little story, is that the epistemology here is that much abused term, physical intuition.
So far as I know, there is no major theology that combines these two distinct concepts, which, strictly speaking, are mutually exclusive in that they represent two distinct forms of maintenance of the immortal soul.

In the west you see a mythology of revenants (which is to say corporeal regeneration in the same body) going back potentially to Mesopotamia, and certainly in Egypt and Europe. (https://mythology.stackexchange.com/a/2444/2892 Freyja had the power to bring back the dead, and the https://mythology.stackexchange.com/a/2147/2892 Mabonogion has a very famous example of a cauldron with similar power. In Egypt, you have figures such as https://en.wikipedia.org/wiki/Osiris#Mythology Osiris, albeit a god, but physically resurrected, like https://en.wikipedia.org/wiki/Zagreus Zagreus/Dionysus, and some scholars link this to the subsequent resurrection in Christian lore.) 

By contrast, Eastern mythology is filled with avatars in both Indian and Chinese mythology. (This is widely understood in regard to Indian philosophies, but the https://en.wikipedia.org/wiki/108_Stars_of_Destiny 108 Stars of Destiny is one of many examples from Chinese folklore.)  

I suspect the reason you don't see these concepts merged is that physical regeneration of the dead is fundamentally incompatible with transmigration of the soul in the sense that, you either regenerate the original vessel, or the soul shifts to a new vessel. (Sort of a "choose one or the other" situation;)



That said, there is a line from Pindar that https://en.wikipedia.org/wiki/Fortunate_Isles may suggest the concept of reincarnation was present in Ancient Greece (for although a god was resurrected, it was not something available to humans, whose souls either went to Hades or, later, the Elysian Fields):


  Those who have persevered three times, on either side, to keep their souls free from all wrongdoing, follow Zeus' road to the end, to the tower of Cronus, where ocean breezes blow around the island of the blessed, and flowers of gold are blazing, some from splendid trees on land, while water nurtures others. Source: http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.01.0162%3Abook%3DO.%3Apoem%3D2 Perseus


I was certainly taught that souls in Elysium could be reincarnated, but would need to look into this more deeply. 
I will write Nx for "It is necessary that x". In Meaning B your premises are N(p→q) and p, from which nothing can be derived (by https://en.wikipedia.org/wiki/Modus_ponens modus ponens) without additional assumptions. A very commonly accepted axiom of modal logic is that necessity distributes over implication: 


  N(p→q)→(Np→Nq) https://plato.stanford.edu/entries/logic-modal/#ModLog (Distribution Axiom)


Assuming that, premise 1) does entail Np→Nq. But even with that to derive Nq we need Np as premise, not just p. In terms of your example, in the B meaning it is not enough to assume that God knows that you will eat lentils tonight, but that God knows that necessarily. 

The necessity of the consequence vs necessity of the consequent distinction was used to argue that God's foreknowledge does not exclude free will, or at least that this argument fails to prove otherwise. This argument in the context of  free will was discussed by St. Augustine (On Free Choice of the Will) and Boethius (The Consolation of Philosophy), in ambiguous language. The flaw was later pointed out by Aquinas and others, see https://plato.stanford.edu/entries/omniscience/#ForeHumaFreeActi SEP article on Omniscience:


  "Subsequent philosophers, however, beginning at least as early as Aquinas, identified a flaw in the argument. According to Aquinas (Summa contra Gentiles, I, 67, 10), the first premiss is ambiguous between the “necessity of the consequence” and the “necessity of the consequent”... On the former interpretation [meaning B] the premiss is true, but under that interpretation the argument is invalid, that is, the conclusion does not follow. Interpreting the premiss in the second way [meaning A] results in an argument that is valid, but this premiss is false. Just because God knows a proposition, it does not follow that the proposition is a necessary truth; God knows contingent truths, as well. In either case, the argument fails."


Of course, the theological fatalism argument, as this is called, can be rephrased without involving necessity, so this distinction does not resolve the issue, see https://plato.stanford.edu/entries/free-will-foreknowledge SEP's Foreknowledge and Free Will.
Gender roles have a deep, long history that are in fact strongly tied into biology. In a nutshell, in primitive societies men were hunters, and women stayed home, talking with other women, and caring for children. Multiply this social reality over many hundreds of thousands, if not millions of years, and you'll see fundamental biological differences between men and women, averaged out.

For most of history these gender roles have played a significant role in our species survival. Women are great at keeping children alive, men are great at keeping everyone fed.

All of that said, how we define what a successful gender is, is a moving target. What it meant to be a woman in the 13th century is not the same as what it means to be a woman in the 21st century. So what we'll see happen as time progresses are new traits becoming selective for each gender.

For instance, if suddenly it matters that women are capable of holding down a good job, then women who aren't financially successful start getting weaned out of the gene pool, and what it means to be a 'fecund' woman changes.

So to get back to your question, gender roles do matter in the sense that if you're good at filling the typical role you're more likely to pass on your genes. But the caveat is that gender roles, and eventually biology (over hundreds of thousands of years) aren't static. So society will, in time, be more open to a wider ranging definition of various genders, or at least a changing range.
Okay, with regard to logic, something can be valid but not sound. Validity expresses the idea that the logical structure leads to the conclusion. If the premises are true, then the conclusion is necessarily true. That's what validity is supposed to regard.

That's not enough for an argument to be sound though. In order to be sound the premises must also be true.

SO,for example:


All men are mortal
Socrates is a man
.:therefore socrates is mortal


The two premises (1 and 2) lead necessarily to the conclusion (.:). This is a valid argument. It is also sound because the premises are true as well.

That said, we could construct a structurally valid argument that is not sound.


All men are thin.
Socrates is a man.
.: therefore socrates is thin.


The structure of this argument is valid; which is to say that IF the premises were true, the conclusion would necessarily be true.  But the premises aren't true and the conclusion is not true.
What makes you think that Adorno is suggesting any solution to the problem? I've not read his entire works, but what I have read provides me with no indication that Adorno saw himself in any way responsible for solving or providing solutions to the problems he laments.

His definition of the role of the culture industry in controlling our emotional and critical responses is no different to the role of a jailor in constraining our freedom of movement. It is not sufficient to simply become aware that you are thus constrained, you are no less restricted.


  The phrase, the world wants to be deceived, has become truer than had ever been intended. People are not only, as the saying goes, falling for the swindle; if it guarantees them even the most fleeting gratification they desire a deception which is nonetheless transparent to them. They force their eyes shut and voice approval, in a kind of self-loathing, for what is meted out to them, knowing fully the purpose for which it is manufactured. Without admitting it they sense that their lives would be completely intolerable as soon as they no longer clung to satisfactions which are none at all.


From "The Culture Industry Reconsidered" (1975)

If a solution were in any way implied here (and I'm not sure it is) it would be that consuming the products of modern culture even whilst "seeing through it" is exactly the problem, the solution being no longer consuming those products, but this is akin (in the example of the Jailor) to suggesting "no longer be jailed"as a solution. It is possible to escape a prison but it is not a philosophical act alone.
As mentioned in the comments, philosophers don't use the word proof as rigorously as mathematicians do. More often they speak of arguments, not proofs. 

Some examples:  


https://en.wikipedia.org/wiki/G%C3%B6del%27s_ontological_proof Godel's ontological proof for God's existence (although I don't know if Godel's proof counts as canonical).  
https://en.wikipedia.org/wiki/Tractatus_Logico-Philosophicus Most of Wittgenstein's Tractatus; In fact Wittgenstein was a major forbearer of what later became known as Analytic Philosophy and his style of arguing in the Tractatus was significant influence on that school. 
http://www.ditext.com/quine/quine.html Quine's Two Dogmas of Empiricism and in particular sections I-IV of the paper, where he dissolves the analytic/synthetic distinction is a very good example of an analytic argument, even if doesn't use a formal notation like Godel or Wittgenstein.  

Some remarks:


"A" and "B" generally represent formulas. Hence, on its own, "A ⊨ B"  is a just scheme. You can fill in specific formulas to get an evaluable statement, e.g. "P, P ⊃ Q ⊨ Q", which is true (modus ponens), or "P ⊨ (P ∧ Q)", which is false.
At least given standard terminology, "A" and "B" therefore are not free variables. Free variables are a matter in predicate logic. In propositional logic, however, there are no free variables at all.
The double turnstile (⊨) does not mean semantic equivalence, but mere semantic entailment. So a statement of the form "A ⊨ B" means that whenever A is true, B is also true (in propositional logic, any assignment that makes A true also makes B true).
Semantic equivalence means that (given two formulas A and B), both A ⊨ B and B ⊨ A. In other words, semantic equivalence means that A and B entail each other, or in propositional logic, that A and B are true under exactly the same assignments.

Not really, photon is not "choosing" to appear at some point over other. Quantum Mechanics is ultimately a model of reality, and a damn good one, in fact, the most accurate model of reality we have at present. However, it is not reality itself.
Photon is simply following the laws of physics, which to us may forever be hidden, but we can still model their behaviour through probabilities, which is enough for all practical purposes.
Both of these questions have to do with Quine's idea that the structure of scientific knowledge is a “web of belief.” The web metaphor suggests that beliefs are connected to one another. The connections can be understood as resulting from how the definition of any term (whether a scientific term or not) can only be given in terms of other terms. So, the web is partly about the connections among beliefs by virtue of the meanings of sentences being connected, in so far as sentences are built from words, and words get their meanings only by relationship to other words and sentences. The connections among beliefs in a web of belief are also justificatory, given how we build beliefs on top of other beliefs. 

The semantic (which is to say, related to meaning) and justificatory connections among our beliefs produce a hierarchy, where some sentences are more fundamental than others, in so far as others are based on them. Quine would have us think about these more fundamental beliefs as being at the core of our web of belief. Beliefs about logic and mathematics, for instance, are beliefs one which nearly all other justified beliefs are ultimately based. Laws of nature depend on those more fundamental beliefs, but are only slightly less fundamental. Then, as we build out from this core to the periphery of the web of belief, we find at its edges sentences which depend on many others, but on which few or no other beliefs depend. On the very edge of the web might be beliefs about ordinary observations, like that a donut costs $1.79 at the store nearest me. 

This exposes another kind of relationship among the sentences in the web, which might be its most interesting feature. Given the falsification of one of our beliefs, we have options about what to reject. We can reject only the most superficial edge beliefs, or we can reject more fundamental beliefs. We have a general psychological preference for making the most superficial revisions possible to our web of belief, but this is not justified by logic so much as preference. The implication of that is that even mathematical beliefs could in principle be revised in the face of a rejection of a belief about something observable (which is to say that the traditional analytic/synthetic distinction is blurred). If I am told that donuts at the store cost $1.99, my disposition is to give up the belief that I read the sign correctly. I could, however, give up beliefs about the definition of donuts, or the laws of nature, or addition. 

I hope this explanation of the relationship between the core and exterior of the web of belief answers most of your questions except the last one about nominalism. One way this is all connected to nominalism is that (against nominalism) Quine believes that there are natural kinds. However, his idea of what a natural kind is is quite weak. Any set of things that share any natural property at all form a natural kind. Given belief in the web of belief, one can make sense of why we might very easily revise what kinds of things (or as you say, elements) we believe exist by adjusting how we lump things together. Ordinarily this sort of acceptance of casually lumping things together into sets might be a sign of being nominalist rather than realist about kinds. But given Quine's weak definition of "kind" it is not, for him. 
This looks like a "lame terms" redux of Plantinga's "victorious" ontological argument from http://www.difa3iat.com/wp-content/uploads/2014/08/Alvin_Plantinga_The_Nature_of_NecessityBookZZ.org_.pdf The Nature of Necessity. Here is Plantinga's explanation of why if a maximally great being exists in some possible world it exists in every possible world. He attributes the idea to Findlay (p. 214):


  "Those who worship God do not think of him as a being that happens to be of surpassing excellence in this  world but who in some other worlds is powerless or uninformed or of dubious moral character. We might make a distinction here between greatness and excellence; we might say that the excellence of a being in a given world W depends only upon its (non world-indexed) properties in W, while its greatness in W depends not merely upon its excellence in W, but also upon its excellence in other worlds. The limiting degree of greatness, therefore, would be enjoyed in a given world W only by a being who had maximal excellence in W and in every other possible world as well. 
  
  And now perhaps we do not need the supposition that necessary existence is a perfection; for (as I argued in Chapter VIII ) a being has no properties at all and a fortiori no excellent-making properties in a world in which it does not exist. So existence and necessary existence are not themselves perfections, but necessary conditions of perfection.


According to Plantinga himself, the argument is directed at those, who, while unconvinced that God actually exists, are willing to concede at least that his existence is possible. But why they should accept such custom made definitions of "excellence" and "greatness" is unclear. The explanation itself begins with appealing to sensibilities of those who worship God, but they presumably do not need the ontological argument to convince them of his existence. 

Moreover, there is also a technical problem with making greatness in a world dependent on excellence in all other worlds. It is the same problem as with the  equivocative "smallest positive integer not definable in under sixty letters" of the https://en.wikipedia.org/wiki/Berry_paradox Berry paradox. What the integer is depends on which integers have already been defined in under sixty letters, and due to the self-referential nature of the sentence, as is, it defines nothing at all. It is the same with possible worlds, we are supposed to populate them with objects that possess certain properties. If we start making those properties dependent on what happens in all other worlds we will never finish defining even a single world, let alone all of them. This should not be surprising. The "being than which no greater can be conceived" of Anselm's original argument is already self-referential in a similar way. In mathematics such a "definition" leads to the incoherent "ordinal of all ordinals" of the https://en.wikipedia.org/wiki/Burali-Forti_paradox Burali-Forty paradox, the ordinal than which no greater can be constructed.

See also https://philosophy.stackexchange.com/questions/37532/what-makes-leibnizs-definition-of-perfection-unintelligible/37539#37539 What makes Leibniz's definition of perfection unintelligible? on problems with perfections, and https://philosophy.stackexchange.com/questions/24484/is-there-a-suppressed-premise-in-anselms-ontological-argument/24487#24487 Is there a suppressed premise in Anselm's Ontological Argument? on another Plantinga's reconstruction of the argument.
When he talks about something that can be entitled or recognized as beeing 'great things', he is probably talking about the facts, events or ideas of most important influence, like morals, or, of things with most 'gravitas' in society, so: about things that really affect the life of the people.

The most of people look and interpretate that 'great things' as being an weight in their lives, literally in the negative way; so, when Nietzsche says that we need to speak about those things "cynically and with innocence", he is saying: All of that negative weight, that unecessary and really serious vision about the facts, needs to be complete destroyed by a interpretation, or, by an discourse that literally clean the 'Nihilist' content in the speaking about the 'great things'. 

If you want to achieve the Active Nihilism, you need to learn how to transvaluate values ​​(questioning what's the real point with that fixed values -> are they really powerfull, or are they decadent, in a way that disagreggates you phisiology and your psyche creating ressentiment? - That is the process to create your own values) with more facility, and looking at the reality with more stronger eyes and, at the same time, innocent: not letting that the 'great things' of your individual life or of your social and coletive life be an torment to your psyche.

Observation: Sorry for the bad english, i'm from Brazil and not a advanced english speaker.
Observation²: I have a version of the Will to power that explain in details the use of that two words, 'Cynically and Innocence' in that context, but is in brazilian portuguese. When i get more time i can do it for you. 
Wittgenstein's lifetime concern was how language relates to the world. He offered two ways to answer the question: the early Tractatus way, and the later Philosophical Investigation way.  

In the Tractatus era, Wittgenstein, still influenced by Vienna Circle and logical positivism, regarded the world as being composed of atomic facts. He thought that there was a one-to-one correspondence between a proposition and a fact.   

In the Philosophical Investigation era, Wittgenstein gave up on the Tractatus approach, and proclaimed that linguistic meaning obtains, neither through references nor through mental images, but through the use of language itself. Insofar as members of a linguistic community understand how to use a given word properly, according to him, they can be said to understand the meaning of the word. 

If you want to know about the Important Wittgenstein, you should just read the Investigation. The work influenced many other academic fields (poli sci, sociology, e.g.).   
As a Kantian (A necessary condition for a moral agent is rationality), Rawls does not think cows' lives matter. But he might have something to say about food ethics (the production and distribution of food for human consumption in the society). 

The question is whether it is morally wrong to produce meat, given that the production of meat requires more resources than vegetables. 

Rawls' system of just society is supported by several moral principles (axioms). Two principles are relevant to address the question: Pareto Principle and Difference Principle.


Pareto Principle


Pareto Principle, a la Rawls, states that it is immoral to stay in the status quo when we can make someone better off without making anyone else worse off. 

Under this principle, if someone is dying of hunger while someone else is eating Korean BBQ, the social arrangement of the society is immoral. The food production system of the society needs to be changed.


Difference Principle


Difference Principle, a la Rawls, states that the difference in wealth among people is morally permissible (or recommended??) insofar as the inequality maximally benefits the least advantaged class. If Mr Gates makes billions of dollars and uses that money to assist the poor in the society, his wealth is morally justified. 

Under this principle, there is no moral wrong when Mr.Gates eat Korean BBQ and the poor eat tofu.  
The answer is a simple yes. If you have only finitely many sentences, then you can just list them in your definition. It would be something like:


  x is true iff (x=x1 & p1) or (x=x2 & p2) or ... or (x=xn & pn)


where x1..xn are sentence names and p1..pn are sentences.

To see that, recall why the notion of satisfaction was needed in the first place. If the language has infinitely many sentences, then the definition of truth has to involve something like recursion. But truth cannot be directly defined recursively, since truth applies only to complete sentences, and sentences have parts which aren't necessarily sentences themselves. Satisfaction, however, can be defined recursively, since it applies to sentence parts as well. But if your language is finite, then you don't need recursion.

Here's what Tarski says about this, right after presenting Schema T in "The Concept of Truth in Formalized Languages", pp. 188-189:


  If the language investigated contained a finite number of sentences fixed from the beginning, and if we could enumerate all these sentences, then the problem of the construction of a correct definition of truth would present no difficulties. ... But the situation is not like this. Whenever a language contains infinitely many sentences, the definition constructed automatically according to the above scheme would have to consist of infinitely many words, and such sentences cannot be formulated either in the metalanguage or in any other language.

Michael used the fallacy of equivocation. The fallacy happens when the same word is employed to refer to different things or ideas. Michael's rhetorical goal is to appeal to the emotions of the listeners that they should not listen to Toby since Toby is a loner who belongs nowhere. For this, Michael employs 'family' equivocally. 

Michael used 'family twice. His second use of 'family' is what 'family' commonly means: mommy, daddy,..  His first use of family is quite thin notion of family (e.g., community-feeling).   
No; there is no error.

With only two sentences, it is quite easy to verify the general schema.

From one side, we have the "natural" condition:


  "The table is round" is true iff the table is round.


The general schema, instead, is:


  For every sentence x (in the language L), x is true iff (either
  the table is round, and x is identical to "The table is round", or
  the carpet is purple, and x is identical to "The carpet is purple").


Consider now one (of the only two possible) instantiation of the schema; what we get is:


  "The table is round" is true iff (either the table is round, and "The table is round" is identical to "The table is round", or the carpet is purple, and "The table is round" is identical to "The carpet is purple").


Clearly, the disjunct: the carpet is purple and "The table is round" is identical to "The carpet is purple", is false and we can discrad it.

What we get is:


  "The table is round" is true iff (the table is round and "The table is round" is identical to "The table is round").


But P ∧ t=t is equivalent to P and finally we get:


  
    "The table is round" is true iff the table is round.
  




Presumably, the term conjunction comes from the consideration that in a finite universe, an universal quantification is equivalent to a conjunction:


  ∀xPx is equivalent to Px1∧...∧Pxn. 

The CLT has no implications for knowledge or reality or existence unless you make the assumption that the universe consists of random variables.  If you make that assumption, it says a lot about what can and cannot be.  However, that assumption is not an easy one.  As far as I know, it is generally assumed that all macroscopic "random" events are not random variables, but the interaction of non-random events that we cannot see.  For such cases, the CLT can only be used on models of the universe, not the universe itself.

In quantum mechanics, we currently believe that the universe is well modeled as random variables, under the Copenhagen Interpretation.  As such, many scientists currently believe that you can draw conclusions about the universe using the CLT.  It is used, for example, to explain wavefunction collapse.  However, that's all science.  We don't actually know.  The next major advancement in particle physics may uproot the idea that the world is well modeled as a statistical system.

The real power of the CLT in our lives is that in many cases, we are comfortable making assumptions that some of the universe is well modeled as random variables.  We can make very good approximations and predictions using it.  However, philosophically, those would not be considered knowledge.  They're just really convenient shortcuts.
The answer is obvious, you kill the murderer. The process by which you came to that conclusion is irrelevant because you have extremely limited information on which to base your decision. You have no foreknowledge of the future so the butterfly effect is irrelevant. Morality aside, the man who performs a useful function should automatically be saved. If you want to assign worth to a life then yes I would argue a volunteer is worth more than a murderer because he adds something positive to the world rather than something negative. Morality is too relative and subjective, but functionality is universal. 
I don't interpret Marx as reducing the importance of the individual. His focus is certainly on the collection of individuals, but as such it is formed by individuals uniting. In his understanding, many (or likely a majority of) individuals are being exploited. This results from historical precedence in how societies have formed, the heritage of power, and the inequitable access to both capital and the "means of production". He argues that these factors create an exclusivity that enables the exploitive class, "the Bourgeoisie", to utilize their position to accrue and concentrate wealth for themselves, and within their own class *1. However, Marx points out that the process of production that generates wealth could not be accomplished without the labor power of the excluded class, "the Proletariat". 

Since the Bourgeoisie require the labor power of the Proletariat, it seems uneven that the Bourgeoisie should reap a significantly inequitable amount of the rewards of the production. This concept of equity is derived from a mathematical approach of quantifying labor and value, pointing to less labor being done by the Bourgeoisie and, conversely, less value being rewarded to the Proletariat. This inequity is felt by each individual of the Proletariat class, when they are struggling to survive due to a lack of wealth and access to basic needs (food, shelter, clothing - arguable health, satisfaction, recreation, etc.). Without power, capital, or the means to produce without the Bourgeoisie (initial capital - money - needed to purchase tools, materials, etc.), the Proletariat is beholden to the Capitalist system and has little leverage to change the system. This is exacerbated by the fact that the access to capital is not historically a result of effort, but instead has been received through entitlement and heritage *2.

However, the leverage is gained through the collective unity of the Proletariats. By banning together, they control an integral part of the Capitalist equation for free, i.e. the Labor Power. This labor power is created from the efforts of each individual, and has no external cost that would require initial wealth for any individual to acquire it for themselves. Each individual controls their own labor power, but it is only as valuable as the marketplace determines. If you withhold your labor power in negotiation of a higher value, but someone else is willing to offer it for a lower value, your negotiation will be weakened. For Marx, the only way to "raise all ships" in the labor power marketplace is to unite the laborers to prevent undercutting in this way. That is why when he refers to the collective, it is not in the general sense of everyone as a single entity, but is actually the shared needs of many individuals and raising the value of each individual to a more equitable exchange of labor for value.



*1 I find that this position is antagonistic to both classes, and I would challenge that "being in the Bourgeoisie" does not necessitate an interest in exploitative practices. Though, the proof is in the pudding and it is only if the Bourgeoisie takes it upon themselves to fairly allocate the profits to both themselves and the Proletariat workers in a more reasonable distribution that they would set a different precedent and possibly dissuade someone with Marxist leanings.

*2 Bare in mind that the concepts of society and wealth Marx was exposed to predates the modern social setting. Changes in society have enabled new results - for example, concepts like the "American Dream" of self attained success through hard work demonstrate a pathway to break this exclusivity. However, a Marxist (or Conflict Theory sociologist) would argue the ability to achieve social and economic ascension is still impeded by many of the same (and new) institutionalized hurdles; i.e. access to education, the access to financial opportunities (loans, etc.), social connections (business connections resulting opportunities).

  I heard all 'interpretations' of quantum mechanics give exactly the same answer to every measurement so they are all equally correct.


It is common for physicists to say that the interpretations all give the same results, but they are wrong.

The interpretations fit into a couple of different categories. One interpretation takes the equations of motion of quantum mechanics, e.g. - the Schrodinger equation or Heisenberg equations of motion. That interpretation is called the many worlds interpretation of quantum mechanics (MWI). That term is used because it predicts the existence of structures each of which approximately resembles the universe as described by classical physics:

https://arxiv.org/abs/quant-ph/0107144 https://arxiv.org/abs/quant-ph/0107144

https://arxiv.org/abs/quant-ph/0104033 https://arxiv.org/abs/quant-ph/0104033

The MWI is experimentally testable, false claims to the contrary notwithstanding:

https://arxiv.org/abs/1508.02048 https://arxiv.org/abs/1508.02048

Some other interpretations are distinct physical theories that make different predictions and might in principle be distinguished from quantum mechanics by experiment, such as the grw collapse theory and the pilot wave theory:

https://arxiv.org/abs/0911.2823 https://arxiv.org/abs/0911.2823

https://arxiv.org/abs/1204.4325 https://arxiv.org/abs/1204.4325

The other interpretations, the Copenhagen interpretation (CI) and statistical interpretation (SI), are just bad philosophy dressed up as physics. 

The CI claims that quantum mechanics should be used to calculate some stuff but is incomprehensible so you have to describe other stuff in terms of classical physics. But this position is deemed by fiat somehow to be equivalent to quantum mechanics, i.e. - the MWI. However, since any experimental result is an explanation of what happened at a particular place and time, not just some figures arbitrarily written on a page, the claim that quantum mechanics is incomprehensible rules out making any experimental predictions using the theory. If it is not possible to explain what events are taking place in an experiment, then it is not possible to tell whether the experiment is working. As such, the CI makes no experimental predictions. 

The SI claims that quantum mechanics just makes predictions about probabilities. In reality, the quantities that are commonly described as probabilities only obey the rules of probability in some specific situations and break those rules in many experiments:

https://arxiv.org/abs/math/9911150 https://arxiv.org/abs/math/9911150.

So the SI appears just to be contradicted by reality. The SI's adovcates like to claim science is just about predicting experimental results. This strategy is not viable since experimental results have to be explanations not just stuff some guy wrote down for reasons explained previously.
I'm not sure that there's a name for the fallacies involved in your two examples. I'm also not sure it matters. Some fallacies get names because they are particularly common - for instance, denying the antecedent. But simply being able to recite a pat little name for some fallacy is not very useful in rational discourse. What's helpful is being able to identify instances of bad reasoning and being able to explain why they're bad. If you can do that, who cares if there's a name for that kind of bad reasoning?

For instance, in example 1 the inference (if it's intended as a deductive inference) is bad for the reason you identified. Who cares if we have a name for that failure? What do we gain with a name? My answer: not much.
I have added what I think is a solution in Fitch

https://i.stack.imgur.com/APdq6.png 

Any comments would be appreciated.
My attempt seems much longer than the http://logic.stanford.edu/intrologic/notes/chapter_08.html Stanford Proof (8.3), which talks about "the power of free variables". I think I need to post another question concerning Fitch, free variables, and arbitrary constants.
I would have posted this as an edit to my original question, but being a new user I am restricted to two links
False dilemma fallacy (see https://en.wikipedia.org/wiki/False_dilemma Wikipedia entry).


  A fallacy in which something is falsely claimed to be an "either/or"
  situation, when in fact there is at least one additional option


While accusing the other party of the false dilemma fallacy, be careful you yourself are not falling into the gray fallacy (see https://en.wikipedia.org/wiki/Argument_to_moderation Wikipedia entry).  Not every debate has an "in-between" position.
As I read this:

Even if r1 and r2 are integers, this idea creates an infinite number of points in space that have names, the (1-D) grid of candidates for object b that puts object b N meters plus-or-minus 1 centimeter away from object a.

These points are named things in space, but any physical realization of this naming (labeling the points) would fail, because there can be only finitely many physical objects to assign as names.

Numbers have to be something other than an abstract representation of a possible physical labeling scheme.  Because they represent a labeling scheme that is impossible to make physical.  You need at least a notion of naming that allows for a construction or checking procedure that may need to be executed an arbitrarily large number of times.  And that means there has to be more going on than naming as we encounter it normally.

Therefore: Physics itself requires concepts that cannot be captured by physical realization and simple naming of objects.

As I see it, the argument seems far too obvious to require this level of detail, but overkill forestalls future wasted negotiations...

Strength


Popper got his name recognition among logical positivists for his falsification theory of testing hypotheses. Popper criticized confirmation theory for being logically invalid, as it commits the logical fallacy of affirming the consequent. Popper's falsification method is logically valid (as it employs Modus Tollens), which he regarded as the model for testing a hypothesis.  

Confirmation theory (affirming the consequent)

If this hypothesis is true, then we should observe this phenomenon.

We did observe this phenomenon.

Therefore, this hypothesis must be true.  

Falsification theory (Modus Tollens)

If this hypothesis is true, then we should observe this phenomenon.

We did not observe this phenomenon.

Therefore, this hypothesis must be false.


Weakness


While deductively valid, falsification theory is subject to the criticism from the Duhem-Quine Thesis that we cannot test a target hypothesis singularly. That is, testing a hypothesis is involved with many auxiliary hypotheses (and assumptions) which are woven into the target hypothesis. So even if the falsifying observation is not made, it is not clear which hypotheses are at fault.

Objection from the Duhem-Quine Thesis

If this hypothesis and all relevant auxiliary hypotheses (and assumptions) are true, then we should observe this phenomenon.

We did not observe this phenomenon.

Therefore, either this hypothesis or some of the relevant auxiliary hypotheses (and assumptions) must be false.
As a Muslim (and a theist student of philosophy after all), I recall an interesting Quranic verse which suggests something very similar but with an additional qualifier: "You will never attain goodness until you give out in charity from things you like!" And I'm gonna take this as the starting point of a rather long metaphysical contemplation of the question!

Grand thesis

What does the last qualifier suggest? I think it is there to rule out those acts of charity which are not selfless and self-disinterested. Because ultimately it is the things that we like (or our interests) that determine our true motives. So if you give out in charity for any other purpose than doing good to a fellow human being, for example if you do that for the purpose of wining popularity etc, then that's not an act motivated by true moral incentives (regardless of particular benefits rendered to the recipient). In our religious traditions, this is condemned as "hypocrisy" which however can affect any "good deed."

But this thesis already poses a number of challenges. How can we be convinced and motivated to do something that in no way benefits us personally even if in the sense of a moral satisfaction about our own personality? Other than this realistic "selfish" objection, one could also say if morality is fundamentally about goodness (distinct from acts of goodness as its extension), what justifies depriving one individual (that is ourselves) to benefit another? An intermediate solution could be that in charity the person giving out and the person taking it are not equal in terms of their life satisfaction or wealth. It is the haves that should give out to the have-nots. But this notion already presumes justice and equality as imperative, principles that entail some sort of redistribution of good which involves people relinquishing (either by force of law or consent) obtained interests for the deserving others. Here one can argue that moderation of justice assumes that some interests have been obtained immorally at the cost of others (i.e. the havenots) so justice only restores the rights. But one can't deny that even interests obtained "immorally" still benefit the illegal owner. Hence the dichotomy stands. 

And there's a still a more radical form of charity that completely negates self-interest, that is acts of total sacrifice, like one person risking his life to save someone else from fatal danger. 

So how do we resolve the realistic conflict between parties' interests that morality as generally understood entails? 

I my view only religion can at least reasonably claim to hold the keys to these challenges based on its premises. When you do an act of good you are actually participating in the perfect goodness of God. So in some sense you're just projecting an existing ontological goodness, (essentially distinct from particular instances of worldly interests), on the fellow humans who are less-benefited by the goodness of God! But by doing so, even though you seem to be doing a moral sacrifice which is nonetheless true in appearance, you're in (ontological) reality not! Since participating in Divine goodness, enhances your own personal goodness (with you being an immortal soul) so self-benefit as a realistic basis for morality is also realized. 

Hence morality is not in reality the unjustifiable drop of good to be picked by another, with that understood in terms of quantitative discrete distribution of things, but rather multiplying an existing good towards others enabled by the infinite goodness of God endlessly supplying the moral acts! Hence goodness is not distributed discretely so as to result in conflict of interest.

"But all of this sound just pure religious rhetoric!" Could be, but regardless of our personal beliefs about religion, only religion seems to put forward a solution that is at least internally coherent and practically realistic. But to those with ever a https://en.wikipedia.org/wiki/Religious_experience religious experience the above wisdom is deeply intuitive and hence immediately verifiable! 

Now going to your particular question, I can elaborate further the potency of the above thesis to address difficulties in moral debate.

Answer

I argued that essence of morality is not charity but rather goodness with goodness being an ontological reality embracing us all (but let's just forget about the problem of evil for now if it is occurring your mind. We just want to show how well the thesis works regardless of other theological problems). And charity is an act of extending, multiplying goodness to/for others. 

When the above is established, on can then hardly determine when charity is "enough". Participating in infinite goodness allows for extending goodness indefinitely (although not infinitely since we are all mortal and practically restricted in doing so by our internal and external circumstances). 

But what then dictates how much charity we give out? The extend to which we have personally realized goodness! That is only so far as we have actualized goodness in ourselves we can extend it to others! This explains why there are those human angels and saints who can surprise us with their "unending" generosity and why there are villans who can't do but bad! 

Are we then hypocrites? We are hypocrites to the extend that claim to be good without having an internally realized goodness necessary for supporting the envisioned act of goodness! That is without a realized goodness, engaging in charity is an impossibility. If it seems otherwise then we can be sure that there are profane selfish motives disguised under generous pretensions with the remarkable consequence that goodness is not actually multiplied, hence the hypocrite having to extract goodness from somewhere else to compensate the relinquished good! This is a feature of all "profane" hypocritical acts of goodness! (Profane is meant to mark the ontological dynamics behind what religions actually suggest with the concept. It is never meant as to dismiss acts of good by the non-religious).

As for the question of duties to close ones. An important note first: Duties are only conventions aimed at enforcing a minimum degree of participation in the infinite good as deemed by the law-giver (state or religious law) for individuals! Hence saints don't define their "duties" by the conventions for general humanity. They pour out goodness so large as their deep participation in the absolute goodness enables them! But they also do it wisely, not to waste it! What this means would take another post of this length so let's move on! 

Now should we value those closer to us? Practically there are "good" arguments for this ruling as well as ontologically (since no practically feasible convention is without underlying ontological reasons)! Families and relatives are areas of our worldly existence where perfect goodness has already manifested itself most prominently hence they are areas that are essentially more conductive for further participation and projection of the perfect goodness! Hence religions encourage you to start charity, care and benevolence from your close ones, the neighbors and then the strangers! Families are the loci from where the good garden of humanity should blossom and populate! Peace!
To answer your question, yes, it is a leftist ideology. To take it one step further, I think whether it is good or not to be flexible on your morals is also relative and can not be a sweeping decision. Right-wing people still bend on their morals in their daily lives to some degree. The individual decides what to let pass and what not to depending on the importance of said thing in their own reality. Bending on a diet is not the same as bending on religion, etc.
In Duns Scotus' philosophy some forms are active principles and have the power to produce an effect. There are two kind of powers qua efficient causes, natura and voluntas, But he distinguishes between the aptitudo and the excercitio of those powers. Talking about natural efficient powers, a form can have an apptitude but no excecises it because theres no subjet in potency near to activate her. So a form can be in actuallity on a subject by way of apptitude.
With the benefit of millenia of hindsight, I believe the point of the arrow paradox can be summed up, for example, as the observation that if


you consider the discrete topology on the real numbers 
you only work with the values of a function at points


then you can't do any nontrivial calculus; in particular, there is no reasonable notion of derivative, and no fundamental theorem of calculus to let you compute how much a function changes value over an interval by integrating its derivative.

It's only a paradox if:


you look only at point sets and underestimate the importance of some notion of topology to glue all of the points together (e.g. the ordering and distance function between real numbers)
you don't consider retaining more information about a function at a point than just its value


Regarding the second point, you can do quite a bit of calculus completely local to a single point if you remember not just the value of a function at a point, but the value of its derivative (or all of its derivatives!). 

Or, from a more physical point of view, the fundamental variables of motion should include both position and momentum at all times, rather than position alone!
Putting aside the issues that have arisen in the comments about the terminology in your question, if we focus on "where the possible interpretations of the text are as valid as the author's actual intent" then a common example would be Kripke's analysis of the rule following paradox present in Wittgenstein's https://en.wikipedia.org/wiki/Philosophical_Investigations Philosophical Investigations. 

In https://en.wikipedia.org/wiki/Wittgenstein_on_Rules_and_Private_Language Wittgenstein on Rules and Private Language, Kripke presents a paradox that arises out of Wittgenstein's arguments that the language games played by interacting people are governed by a family (as opposed to a rigidly defined class) of rules. Why this is an example of "the possible interpretation being as valid as the author's actual intent" is because it is generally agreed upon that Wittgenstein himself would not have believed all of the opinions that are necessary to formulate the paradox, while neither does Kripke. Instead, it has become common to attribute the belief in this rule following paradox to a third philosopher called Kripkenstein. From the Stanford Encyclopedia of Philosophy's article https://plato.stanford.edu/entries/private-language/#KriSceWit "Private Language":


  Kripke (p. 5) denies commitment to the identity of this sceptical figure with its historical source, and, appropriately, his account has spawned a literature of its own in which discussion often proceeds largely independently of the original private language argument: Kripke's Wittgenstein, real or fictional, has become a philosopher in his own right, and for many people, it is not an issue whether the historical Wittgenstein's original ideas about private language are faithfully captured in this version. 


Finally, here is a quote from G.W. Fitch's https://philpapers.org/rec/FITSK Saul Kripke:


  First of all, Kripke explicitly states that the arguments and positions that he presents in this book are not to be taken as his views. He says "It deserves emphasis that I do not in this piece of writing attempt to speak for myself, or, except in occasional and minor asides, to say anything about my own views on the substantive issues" (WRPL: ix). Because Kripke explicitly denies offering his own views in this essay, it would be natural to assume that his foal is to provide a correct historical account of Wittgenstein's views. It is not clear, however, that Kripke is claiming to provide us with a piece of Wittgensteinian Scholarship: 
  
  
    In the following, I am largely trying to present Wittgenstein's argument, or more accurately, that set of problems and arguments which I personally have gotten out of reading Wittgenstein... So the present paper should be thought of as expounding neither 'Wittgenstein's argument nor Kripke's': rather Wittgenstein's argument as it struck Kripke, as it presented a problem for him. (WRPL: 5)
  
  
  Thus, the primary goal is not historical exegesis but, as Krikpe says in the preface, "The primary purpose of this work is the presentation of a problem and an argument, not its critical evaluation" (WRPL: ix).

I don't think you'll necessarily agree with this answer, but in the spirit of Wittgenstein, he'd probably view this as a confusion over language. Take an adjective like colour. We know adjectives can be used to describe nouns. We know the basic adjective noun relationship is "X is y" where "X" is a noun and "y' is an adjective. Knowing that colour adjectives describe nouns, we can say things like "tigers are striped" or "polar bears are white". These are all fine. You could then get confused, wondering what happens when you apply colours to other nouns. " The singer's voice was purple" or "London was indigo". These sentences are excluded from the language by the grammar of colour words. These sentences do not have a use within the language. When you look at your question, you're asking why can't you apply "pretend" in situations like "he pretended to move his feet". I don't really think there is an explanation out there for this kind of question. It's really one of those things that you see or you don't. You understand English so you know the exact situations in which it is acceptable to use the word "pretend". So what purpose would an explanation serve? Perhaps you are looking to see, what is common to all the cases in which you use the word " pretend". The thing is, there may not be one thing in common to all the uses of pretend. As for why the falsehood of x precludes the appearance that x is true? There is no answer to this question apart from restating the same thing in different words. I think it might be easier to see in the colour example - do you think it is a difficult problem to get over, how do we know when to apply colour words correctly? What are the set of criteria that mean you can use one? I think the answer to this problem is not in finding a solution, but reaching a point where you realize where the problem came from and seeing it no longer is confusing. It's really right in front of you all along, assuming you know English.
The question of what constitutes harm for the laws of robotics would be the root problem at codifying the three laws.  The problem of programming those laws is generally overlooked - but in reality how you define any of those laws in the first place, in strict terms a computer brain can follow, this is an extremely complex task.

Is it "harm" if a robot working in a fast food franchise serves french fries with extra salt to a human who's got high blood pressure?  Or to sell candy to a diabetic?

At the simplest definition 'harm' means injury but does a person who enjoys the pain get 'harmed' when he receives a level of pain that he finds enjoyable and which does no lasting damage?

At the end of the day, harm is a subjective term with clearly objective edges.  Me killing you is harm.  Me killing you to spare you suffering for years in constant pain from a debilitating disease is mercy.

A sufficiently well programmed sex-robot designed to serve as a dominatrix would need to be able to understand the differences between superficial harm (pain w/o lasting damage) vs. serious harm (permanent injury) and be able to accommodate its "clients". 
I do not think there was anything necessarily naïve in the content of the Tractatus - or that argument has yet to be made to me convincingly. But perhaps the Philosophical Investigations involved a new method on Wittgenstein's part in conveying his ideas - deliberately anchoring philosophy in an examination of the usage of language. In the Tractatus, perhaps the subject matter was logical form, whereas in Philosophical Investigations, perhaps the subject matter was the discipline of philosophy's relationship to ordinary language. Those two projects would be related, and the results of each project may not necessarily be incompatible with each other. I do not think Philosophical Investigations necessarily involved a revision of the substance of the Tractatus, though Wittgenstein almost certainly revised his method of engaging the discipline of philosophy.
I would guess that Socrates' definition of the good would be more like "being" than a secondary substance. However, I also think it would exceed the limits of "being"; to me, it seems like Socrates' definition of the good would have been something that could also become an attribution of process. On plato.stanford.edu, Aristotle is supposed to have thought that the definition of the good is particular to the object you are describing, so "the good" is not stable in its definition (https://plato.stanford.edu/entries/aristotle/#EssHom https://plato.stanford.edu/entries/aristotle/#EssHom). I do not think Socrates would have subscribed to this version of defining goodness. Parmenides seems to have defined being as something completely stable; what is, can be known by definition (https://plato.stanford.edu/entries/presocratics/#ParEle https://plato.stanford.edu/entries/presocratics/#ParEle). I think Socrates would have defined the good as something that really is, in a stable way - but would not necessarily have connected this with its automatic know-ability. Rather, perhaps Socrates would have connected the know-ability of goodness with adherence to a sincere process of inquiry. One of Socrates' target I think was men believing they had privileged access to a definition of virtue, and yet because they would not adhere to a sincere process of inquiry, they necessarily missed out on understanding the nature of goodness, as it is independently of men's vanity
You might be thinking of "tu quoque"-- "You also." The fallacy appears when Person A responds to criticism from B by pointing out that B does the same thing. The response does not prove or negate anything; its purpose is to silence. This particular line of thinking is routine in international disputes, especially over human rights.
It seems like you're arguing in circles. Nothing personal - it's just the nature of the free will argument.

You suggest that if there's no free will, a woman might be forced to focus on the CONSEQUENCES of her actions. So she does something intelligent - she avoids the actions you describe as "inevitable." If those actions are "inevitable," how is she going to avoid them? It sounds to me like she's exercising free will.


  Are there any other dilemmas when accepting the premise of no free
  will?


You've already suggested the most obvious problem: Individuals drop their standards, reasoning that they're predestined to do bad things, anyway.

As a political activist, I'm wondering "What's the use of trying to fix things or save the human race if people don't even have free will?"

In fact, it often seems like there is indeed some cosmic force limiting socio-political reform, and free will may well be part of it. But if I knew for a fact that the entire human race was nothing more than a giant ant colony with no individual free will, I'd probably be persuaded to give up on my political crusades once and for all.


  How reasonable are my solutions to the two problems above?


I'm confused by your comments on crime and punishment. You believe in punishment - not because we want to punish the individual but because we want to impact "the mental state of all society." But then you state that when a person thinks about doing something bad, they'll worry about the punishment they're going to receive.

So you go from the individual to "all society," then back to the individual. Or are you suggesting that the individual's second thoughts before committing a crime result from a society-wide perception of punishment?

Also, it isn't clear to me how your suggestion is radically different from the status quo. I'm no fan of the justice system in the U.S., which is horribly corrupt and embraces an enormous double standard.

But I think it's based largely on the premise that punishment is a deterrent to crime. You're obviously in favor of punishment, but I guess you just support it with a supposedly different philosophy.

I may be going off on a tangent, but I think punishment is important not just as a deterrent but to give society a sense of justice. If a psychopath murders a dozen people and isn't punished, then a lot of friends and loved ones are going to be in even greater pain.
I don't think we extract art like we do iron ore.  I would expand on your point "vitality". Culture is a byproduct of civilization, it is essentially sublimated libido. Why would we need to turn our endless sex drive into art/culture?  Civilization requires us to self-govern our instincts. We are not self-transparent, there is always a part of us which motivates us "behind our back" so to speak. 
Use an unfair dice.

For example, supposing six is success, and all the rest are are fails, 'program' a dice to choose at random the throw on which it will display a six, and on all other throws any other number. 

This will then display the characteristics you want; such a dice is hard to build and program, admittedly, but one can quite simply simulate such a situation on a computer, it's child's play to do it.

More interestingly, is there a naturally occurring such situation? No, I don't think so, merely because most natural things are actually finite. 
Background

Before answering for your specific case, there's an important prior issue related to what "fallacy" means. This matters, because many people think fallacy is a magic word. And there is a context where a certain type of fallacy is a magic word, but in most contexts fallacies are fuzzy things and their presence/absence doesn't change much about an argument.

The first distinction to be aware of is between formal and informal fallacies. A formal fallacy is a mistake in reasoning in a formal proof system. Committing such a fallacy when one is making a formal proof wholly invalidates the argument. (Examples include: affirming the consequence, denying the antecedent) This is usually what people seem to think all fallacies do.

Most arguments, however, are not formal proofs. In such arguments, fallacies can also occur, but these are informal fallacies. An informal fallacy is an error or flaw in the reasoning that undermines the argument. The problem, however, is that a large portion of these informal fallacies are open to debate -- both as to whether they are occurring in a specific case and whether this breaks the argument where they occur.

Answer

As I read it, there's an equivocation happening in an implicit argument related to what you're quoting there.


"Dictatorship" is bad. (or if you prefer, if something is a "dictatorship," it is bad).
Rule by the proletariat is a "dictatorship." 
Therefore, rule by the proletariat is bad.


Dictatorship in 1 is a bad thing definitively whereas in 2 it just means "rule".

This does not, however, prove that those who apply the term to socialist states are making a terrible argument and trying to equivocate. Since this is an informal argument (and informal fallacy), it is quite likely their arguments are more subtle.

To just off the top of my head, give a more thorough example:


Anything is a "dictatorship" if it involves imposing the will of one group (of one or more members) upon the whole.
Socialism imposes the idea that government should work for the good of society upon the countries in which it happens.
Therefore, socialism is dictatorship.


Then one could simply add that it is "of the proletariat" because that group is the majority (even if it is a democratically decided majority).

n.b. I am not here trying to make the argument. Instead, I'm trying to point out that in informal contexts, whether something is fallacious is (almost always) arguable and hinges on (1) identifying the argument some intends to make and (2) hashing out whether what they did argue is flawed in some relevant way. At this point, whether that mistake is a named fallacy or not really loses all relevancy. This stands in stark contrast to formal fallacies in formal arguments (e.g., a proof in pure math) which are damning for the argument.
I think the "trick" to understanding Nietzsche's critique of group morality would be to link his idea of strength with the idea that one "is" through "becoming" - those who continue to subscribe to group morality, or who were historically complicit in its development, are weak because they will not subscribe to this idea of strength; the source of "strength" for Christian group morality is precisely its weakness, because the point of man's weakness is the point where God can display His grace towards man - it is necessary to know that one is weak, in order to know God's strength, therefore the strength of the Christian comes from outside of him or her ... to the Christian, Nietzsche's idea of strength as sufficient daring to consider strength and weakness in terms of the individual setting himself deliberately against group morality, does not really make sense. One could regard Nietzsche's interpretation of the strength/weakness axis as a deliberate subversion of the idea of strength and weakness inscribed in Christian group morality; for Nietzsche, strength is an attribution of the individual who sets himself against group morality, and weakness is subscription to an idea of strength which places Christian believers at the mercy of God who asks them to glorify in their "weakness", because that is how He can display His strength in their lives
I imagine the line in the song is derived from the quote Gordon provided, but I would associate the sentiment in the song to Plato's famous allegory of the cave - presumably "thinking free" allows you to escape the web/cave. 

Another philosophical/religious doctrine of which that line reminds me is Gnosticism, since Gnostics believe they have a kind of knowledge which allows them to see through the inherent unreality of the material world to see the true spiritual realm. Presumably the creator of the material world (the Biblical God in some Gnostic traditions) would be riled up by our seeing through the illusion.

However, most importantly, this song was released during the acid-fueled '60s, and the Moody Blues were one of the most popular psychedelic rock acts of the time. These lyrics seem to owe a lot to the classical psychedelic experience, as well as law enforcement's disdain for trippers.
You are not alone in thinking that the categorical imperative is flawed in that it can be circumvented simply by additional specification. Alasdair McIntyre concluded that it "Imposes restrictions only on those insufficiently equipped with ingenuity", by which he meant exactly the point you are making, that your maxim can always be sufficiently specific to your current circumstances to be universalizable. Kant strove to remove this problem by the division of Hypothetical and Categorical imperatives, putting the problem down to one of conditions, but this does not entirely satisfy McIntyre who argues that such conditions could be present in all actual moral dilemmas, making Kant's system useless in the real world. Supporters of Kant frequently 'adjust' the application of the Imperative to obtain the results from moral dilemmas that fit their intuition using this exact feature. Whether you see this as a problem or a merit to the theory depends largely on whether you care to have your decision supported by a philosophical luminary or not.

Joel Kupperman also dismisses the imperative as lacking any plausible logical argument (seeming to have no trouble identifying the meaning of the word plausible). He echoes Schopenhauer's argument that whilst the imperative may be useful, it is little more than the Bible's "Do to others as you would have them do to you.", a manifestation of our intuition that moral decisions we make now will impact on those we might need to make in the future.

As to your direct questions;

There have, of course been numerous attempts to lever Kant's ethics into some sort of practical application. I will avoid the ideological Kantian's who simply use McIntyre's 'ingenuity' to make Kant fit whatever they will, but a couple of philosophers have attempted to modify it to something usable with varying degrees of utility. William Ross proposed a set of prima facie duties, which, when used as a categorical input into Kant's ethics, avoids many of the problems in attempting to rationalise those duties at first. Thomas Scanlon's Contractualism owes much to modifications of Kant's Ethics, largely basing it more on a more normative understanding of existing moral intuitions.

Kantianism is, perhaps more than most philosophies, something of a religion and evokes a similar fervour among it's supporters, criticisms of it's formulations are generally not well received and, as much of it is extremely ambiguous (one it's major criticisms), in a field which is already extremely ambiguous at it's best, I wouldn't expect a great slew of rational answers.
I read that article years ago; the main problem as I see here, is the problem of 'false consciousness', the mendacity of propaganda, as well as the economic problem, for example student debt, housing - all of which means mortgaging ones future merely to stay afloat in an inimical social, political and economic situation; if a man or a woman has to struggle merely to live, to survive, then it is not suprising that their higher hopes and dreams are suffocated, and then bequeathed to a generation behind them. 

The problem then is not to attack the symptoms of the situation but it's root causes so that human flourishing can actually flourish instead of being just faked.
In the scientific arena, animals generally aren't even associated with ethics. I'm not sure I agree, but science is supposed to be objective. (Some biologists won't even give their subjects names for that reason.)

In the philosophical arena, we might think of ethics as something that embraces at least some animals other than humans.

In this spirit, the wolf and man both eat sheep in order to survive. Merely eating sheep doesn't make either one unethical.

However, you point out that the wolf preys on the slow and weak, thus weeding out individuals that need to be weeded out. The man does the opposite. This reminds me of trophy hunters who only shoot animals with huge tusks or horns. This may result in the evolution of animals with smaller tusks or horns - hardly a good thing.

Whether or not this is an unethical practice is largely a matter of opinion. It's obviously bad for the species and therefore the environment, which makes it unethical in my eyes. But should we make an exception for an ignorant trophy hunter who isn't aware of his impact on the gene pool?

P.S. It would be interesting to know how the philosophical community in general regards non-human animals in terms of ethics. There was one famous philosopher who believed that animals had no souls; if you kicked a dog and it howled in pain, it was just an automatic reaction, like a piece of wood breaking if you bend it. But I would imagine some philosophers have imagined animals to have souls, which might imply that they also have ethics. Moreover, some animals will ostracize members of their groups if they do the wrong (e.g. "bad") thing.

Second, humans are animals. Which begs the question, if we went back in time to a point before our ancestors had learned to make clothing or tools or build fire, would they still be "superior" to animals and therefore ethical? Or would we have to go further back in time to a point where the human brain was too small to really think ethical matters?
There is a hierarchy of possibilities. Provided that my choice of the fundamental possibility was free (and it always is so) my choice of subordinate actions are less free because these actions are implied by the fundamental project: it demands them.

When I'm running cross-country I make certain body movements and breath controls which are "natural" to do as long as I'm engaged in the undertaking the run to the finish (and probably good run). I'm still free to amplify or decrease the pace of legs or to breath deeper or shallower, but free only to the extent that will help to run, because in the current actuality I've chosen my body to serve the aim to get to the finish at my best.

While I'm monitoring/controlling by muscles/breath by my consciousness I do not reflect on my possibility to seize the movements as long as I'm engaged in the project to race to. I only am considering ways or subordinate possibilities how to optimize the movements to reach that aim. In order for me to reduce the steps and turn away and kneel on the ground I have to redirect my self suddenly to another basic aim instead (for example "I'm too old, I want to be a retired sportsman doing easy jogging with my dog every morning" [that thought convoluted first, just intuition, a pin prick]). That re-decision is spontaneous and free, but it (its meaning) logically calls me to stop now and to lie on the grass, and these particular actions won't be free actually - like my treads/breath control weren't also two seconds ago. They are - like those were - free only within the project - and now the project "retired old sportsman" - and they are bendable by me as long as they serve it within its framework.

For many people, profound discussions on "free will" are projects of discourse or arguing where hands movements are implied or even necessary because they serve something (for example, to facilitate self-convincing property of the words spoken out or to show the audience that the topic is so ample, etc.). In doing these gestures they may pay some attention how to do them best, but they aren't currently free to stop doing them until they spontaneously (freely) drop out from the mood "doing discourse".

Note that I didn't speak of free will. I understand "will" in the narrow sense of reflective thought "I did it by myself" or "I must decide to do it". That thought is necessary for some people to feel their freedom, but not for others, who are equally free. Freedom is pre-reflective spontaneousness; people are free, not that they all have will.
Most folks you are pointing out on the right, from Mussolini's notion that each race has its own truth to Karl Rove's dismissal of 'fact-based people' are not really post-modernists, they are relativists in a degenerate way which is actually based in the realpolitik of how easy intellectual manipulation is for a cult of power in an atmosphere with too many sources of information.  This idea has been around at least since Machiavelli, and does not rely on any reduction of essentialism at all as its basis.  So it really isn't post-modern in origin or content.

Blaming this on post-modernism is just pretense, both by the people doing it, and by the folks taking them at their word.  Which just proves their point, you are being successfully manipulated by their lies.



More general notes in reaction to the comments:

(Sorry to be a little bit ranting.)

The relativism of the current era is not a consequence of the loss of a single standard rooted in an essentialist base.  That shallow reading of the problem of meaning appeals to a process that was already doing fine on its own.

Our failure to really converge on decisive shared structures is a result of a fearful, despondent modern pattern that remains essentialist to its very core, and pays lip service to the impropriety of essentialism only when it chooses not to be challenged so that it can take individualism as an essential value. Since individual choice independent of immersive context is exactly the wrong thing to value, in a post-modern view, since it is pretty much a complete illusion, This is not post-modernism.  People just use post-modernist language, without its content, as a mask for its own insecurity.
The place to go is presumably https://www.gutenberg.org/ gutenberg.org.
They even have a philosophy bookshelf https://www.gutenberg.org/wiki/Philosophy_(Bookshelf) here
Arguments that often show up are not necessarily correct. Compare the frequent mistake of reverting an implication. According to my experience, in particular politicians and journalists often conclude that from "If A then B" it follows that "If B then A".

First your argument assumes that Y is a (necessary or very probable) consequence of X. That is not always the case.

Here is a simple example. Let X: You are jogging. That's good: Sports in fresh air. Let Y: You are killed while jogging. Is jogging bad now? No. It was not X that got you half way to Y. It was the presence of a murderer who also might have caught you at home.

But even if Y is a consequence of X you cannot blame X of being bad. 

Here is the simplest example: Let X: You are living. Let Y: You will die. Is living bad for that sake?
Logicians distinguish two kinds of bad arguments, unsound and invalid, see http://www.iep.utm.edu/val-snd IEP's Validity and Soundness. A fallacy is a flaw in logic that makes an argument invalid. Unsound arguments, on the other hand, may well be logically valid, but argue from false premises. 

The problem pointed out in the OP, that the world referred to by the arguers is unrealistic, means that the premise is false in our world. Given that, however, B's point is well-taken, i.e. plausibly valid, it is similar to the logic of "in the land of the blind the one-eyed man is king". A, on the other hand, has a problem with his logic on top of the unsoundness. Defending yourself does not amount to killing people at random even if others are killing people at random. It would at most amount to killing people who are a threat, and even that is not given, since self-defense does not necessarily require the killing.

There is also another problem with the A's reasoning. "There is nothing wrong with killing people at random" is a value judgement, not a description of fact. Even in the world where "everybody" is killing people at random that alone does not make it right, does not mean that they ought to be doing it. After Hume many philosophers consider inferences from is to ought statements to be generally invalid, it is known as the https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem is-ought guillotine or the https://en.wikipedia.org/wiki/Naturalistic_fallacy naturalistic fallacy.

This last point touches on a connection between logic and ethics. "If everybody did it" hypotheticals are important in what is called meta-ethics, the study of ethical systems. They express what is called https://en.wikipedia.org/wiki/Universalizability universalizability of ethical norms, and many ethicists consider it an important requirement that a reasonable system of norms must meet. Perhaps, its most famous expression is https://en.wikipedia.org/wiki/Categorical_imperative#The_First_Formulation:_Formula_of_Universality_and_the_Law_of_Nature Kant's categorical imperative:


  "Act only according to that maxim whereby you can at the same time will that it should become a universal law."


In other words, any norm of ethical behavior must be such that it would be rationally acceptable if everybody acted according to it. A's "norm" of killing people at random apparently fails to meet this requirement.
Don't know if it will fit your specific needs, but there is a science devoted to the deductive study of human action: Praxeology.

Praxeology rests on the fundamental axiom that individual human beings act, that is, on the primordial fact that individuals engage in conscious actions toward chosen goals.

Let us consider some of the immediate implications of the action axiom. Action implies that the individual's behavior is purposive, in short, that it is directed toward goals. Furthermore, the fact of his action implies that he has consciously chosen certain means to reach his goals. Since he wishes to attain these goals, they must be valuable to him; accordingly he must have values that govern his choices. That he employs means implies that he believes he has the technological knowledge that certain means will achieve his desired ends. Let us note that praxeology does not assume that a person's choice of values or goals is wise or proper or that he has chosen the technologically correct method of reaching them. All that praxeology asserts is that the individual actor adopts goals and believes, whether erroneously or correctly, that he can arrive at them by the employment of certain means.

All action in the real world, furthermore, must take place through time; all action takes place in some present and is directed toward the future (immediate or remote) attainment of an end. If all of a person's desires could be instantaneously realized, there would be no reason for him to act at all. Furthermore, that a man acts implies that he believes action will make a difference; in other words, that he will prefer the state of affairs resulting from action to that from no action. Action therefore implies that man does not have omniscient knowledge of the future; for if he had such knowledge, no action of his would make any difference. Hence, action implies that we live in a world of an uncertain, or not fully certain, future. Accordingly, we may amend our analysis of action to say that a man chooses to employ means according to a technological plan in the present because he expects to arrive at his goals at some future time.

The fact that people act necessarily implies that the means employed are scarce in relation to the desired ends; for, if all means were not scarce but superabundant, the ends would already have been attained, and there would be no need for action. Stated another way, resources that are superabundant no longer function as means, because they are no longer objects of action. Thus, air is indispensable to life and hence to the attainment of goals; however, air being superabundant is not an object of action and therefore cannot be considered a means. Where air is not superabundant, it may become an object of action, for example, where cool air is desired and warm air is transformed through air conditioning. Even with the absurdly unlikely advent of Eden (or what a few years ago was considered in some quarters to be an imminent "postscarcity" world), in which all desires could be fulfilled instantaneously, there would still be at least one scarce means: the individual's time, each unit of which if allocated to one purpose is necessarily not allocated to some other goal.

Such are some of the immediate implications of the axiom of action. We arrived at them by deducing the logical implications of the existing fact of human action, and hence deduced true conclusions from a true axiom. Apart from the fact that these conclusions cannot be "tested" by historical or statistical means, there is no need to test them since their truth has already been established.

For further reading on topic:

http://ww.mises.ch/library/Rothbard_PraxeologyAsTheMethod.pdf Praxeology as the Method of the Social Sciences by Murray N. Rothbard

https://mises.org/library/human-action-treatise-economics Human Action: A Treatise on Economics by Ludwig von Mises
Opinions vary, but I suspect that Zeno was arguing against an atomic theory of the continuum. This is one possibility discussed by the entry in the SEP. His argument may not be overwhelming, but he was clearly correct to say that our usual idea of the continuum is paradoxical.

The SEP entry makes the interesting point that the Stadium paradox can be resolved by assuming that moving objects are like light bulbs in a series, where each bulb lights up in turn but nothing travels from one bulb to the next. I believe this is what Zeno was trying to say, that in order to make sense of motion we must abandon our usual idea of objects and how they move. That is to say, I read his paradoxes as an argument against naive realism and materialism. 

If we run his thought-experiments using Plank-lengths and imaging how they move we soon run into trouble.           
There is no contradiction in the answer; the issue arises from your interpretation of duty. It's just not the case that all duties are necessarily absolute.

Imagine you're walking down the street with a piece of trash in your hand when you see someone falling out of a tree in front of you. You heroically catch the falling person, but you only by dropping the trash along the way. When you turn around the trash has blown away in the wind.

Now: did your duty to not litter go away just because it conflicted with a more important duty, saving people from injury? No, of course not. You shouldn't litter, but you didn't really have a choice in this situation.

You say in a context where it's overridden, there's no penalty for breaching the duty. By definition, if there is no penalty for breach, that means there is no duty. But both of these statements are false. First, there is a penalty for littering---the planet is a little bit more polluted because of your actions. And second, your definition of duty is one I have never heard of. A duty is a responsibility or an obligation. You'll have a tough time proving that in every single case of a duty there is a penalty for breach.

Even if you are right, though, the point is, your view is far from obviously true. And a very good response to someone making the editorialist's argument would be "on the standard account, many duties bind relatively, and the duty to protect one's family might be one of them."
In the specific context you mention. Russell's view was that people who follow the powerful with blind obedience are doing so as a consequence of the same desire for power that motivates the leader. The only difference being that they have judged themselves to be incapable of leading (owing to intellectual or physical weaknesses) and so they use the only currency they retain (obedience) to benefit from a little of the power their chosen leader has accrued.

Response to such a theory was, however, far from supportive, with many critics suggesting that Russell had simply ignored the results from modern social psychology.

More clinical approaches still do not agree, ranging from the quite extreme views of psychologist Margaret Singer who considers cult leaders to be truly capable of 'brainwashing', to Simply blaming low-self esteem.

Interestingly for the critics of Russell's earlier work, psychologist Philip Zimbardo (of the Stanford Prison fame), later reached much the same conclusion as Russell, that it was the attraction of delegated power (together with the alteration of normal social rules) that caused people within cults to carry out whatever their leader requested.
Though you didn't define the word 'universe' clearly, I shall try to reach the answer in two ways.

1.  Focusing on omniscient/omnipresent

I believe you have put everything in the word 'universe'.  So I can use this word and omniscient/omnipresent synonymously.  Then the first and the last words (whether omniscient/omnipresent is logical) become the sensitive part of your question. But logic, since it can't deny the material world, can't deny matter and energy.  On going exploration into matter may compel logic to accept the word--'omnipresent'.  Since it is logic 'consciousness' becomes essential to get a meaning to the word omniscient.  And since logic can't accept that word (omniscient), this route will seem to be blocked here.  Also the complete ignorance of the limits and limitations of 'consciousness' creates another block that prevents completely from moving forward. 

Though this block can be overcome only by Truth Realization, it is not possible in most of our case.

2.  Focusing on logic

(If logic accepts the words omniscient and omnipresent 'sensible')

When you ask whether something is logical (or skim off 'logical'), you treat the rest as 'illogical'. Then (If the answer is: "Yes. It is logical") what you considered as omniscient/omnipresent won't come under 'illogical'. In other words, when you say "Yes", what you considered as omniscient/omnipresent won't be so (since it is absent in 'illogical').  Similar is the case if the answer is: "It is illogical".  That means, if something is omniscient/omnipresent it must be both logical and illogical.

When we use logic we depend on our intellect which actually emerges from our ego. This ego is the main obstacle in the path that is related to omniscient/omnipresent.

So, if you can't consider logic in a broader sense, when you treat omniscient/omnipresent you had better not pursue logic while going along the path of truth. If omniscient/omnipresent is the Truth a 'great' logic that transcends time will compel you to go beyond all the 'duals' including logic and illogic when you enter into it.  I mean (since logic itself compels) we will have to consider the logic that accepts both logic and illogic.

The great men who entered it had taught the world based on their 'complicated logic'.

In short, we can say it is logical only if the word 'logic' is treated in a broader sense.

Even though it seems as a deductive reasoning you may refer what the Upanishad says:


  As is the atom, so is the universe; As is the human body, so is the
  cosmic body; As is the human mind, so is the cosmic mind; As is the
  microcosm, so is the macrocosm


See the verses in this link also:  http://greenmesg.org/mantras_slokas/vedas-om_purnamadah_purnamidam.php http://greenmesg.org/mantras_slokas/vedas-om_purnamadah_purnamidam.php
I think where you're getting mixed up is that there are different kinds of conditions. Normally, when philosophers discuss necessary and sufficient conditions, they mean for the application of a predicate to an individual. For example, What conditions are necessary and sufficient for X (some individual) to be bread (where "being bread" is a predicate). Equivalently: under what conditions, for any X, does X count as bread?

Another kind of condition is causal or circumstantial. This is the kind of condition one means if one asks, what conditions are necessary for fire to start? What conditions are sufficient. When the original question (and Heinrich's answer and PeterJ's comment) discuss conditions, they mean what conditions are necessary for bread to come about, for bread to exist? That is different. 

The first (definitional) kind of condition concerns when a predicate can properly be applied to a thing. The second (causal) kind of condition concerns when something can exist.

I am not a baking expert, but to give necessary and sufficient conditions for X being bread, we can say something like:

For X to be bread, it is necessary that it:


be made with flour;
be made with water;
be made with a leavening agent;
have its ingredients mixed;
have its ingredients baked.


Each of these predicates is individually necessary for being bread. That means that a thing can't be bread if it lacks any one of them.

These predicates are also jointly sufficient for being bread. That means that anything that meets all of them is bread.

However, there are also many other conditions not on this list which are sufficient for being bread. Being Wonderbread is a sufficient condition for being bread. Being sourdough bread is a sufficient condition for being bread. Being a bagel is sufficient condition for being bread. And so on.
Plantinga uses the concept of non-trivial properties in his transworld depravity defense of God's benevolence, see https://philosophy.stackexchange.com/questions/16301/how-does-free-will-defense-of-gods-benevolence-work How does free will defense of God's benevolence work? Ciprotti in http://nome.unak.is/previous-issues/issues/vol3_1/TC.pdf Theological Compatibilism and Essential Properties discusses Plantinga's trivial and non-trivial properties with PDO (power to do otherwise, a.k.a. free will) as central example:


  "According to him [Plantinga], a property P is trivial iff it constitutes a necessary condition for some thing to exist, e.g.  being self-identical, being P or not-P, and the like. To the contrary, PDO does not seem so:  for x to exist it is not required that x be free."


The reference for the definition is to Plantinga's Nature of Necessity (1974), Clarendon Press, NY, pp. 60-61. The notion of trivial is similar to what is called https://plato.stanford.edu/entries/essential-accidental "essential property" by Kripke, but the sense of modality is strengthened from metaphysical to something close to logical. If an "essential property" is taken away from x it  would not be x anymore, but what is "left" can logically exist, while removing a trivial property makes even that impossible. Plantinga intends it to be somewhat stricter than just logical, e.g. "being a creature" might still be trivial in his context.
https://books.google.com/books?id=vs4LCmY_N-8C&lpg=PA153&vq=all%20words%20classify&pg=PA24#v=snippet&q=%22a%20word%20is%20a%20universal%22&f=false Words are universals, i.e. all words classify. "Cat" denotes a class of similar animals. Suppose there is a cat whose name is Garfield; it is possible that you saw or imagined this particular cat. But no one ever saw cat or a cat; no one can even imagine cat or a cat because our sense experiences are particulars.

Dictionary definitions depend on a minimum vocabulary, the definitions of which must be https://books.google.com/books?id=vs4LCmY_N-8C&q=ostensive#v=snippet&q=ostensive&f=false ostensive in order to assign meanings to these words. 

Most people were taught the word "cat" by someone who pointed at different animals while uttering "this is a cat." After several illustrations, most people can recognize the similarity and identify other similar animals as cat.

Most children, who learned alphabet from the blackboard, have no problem with recognizing much smaller prints on paper. Few people say I do not recognize this "A" because the "A" I learned is a lot bigger than  this one. The human brains have the ability to classify.

Suppose you are speaking with someone whose definition of "cat" is the same as yours and you want to define your cat. In order to do this, all it takes is to point out a quality that is possessed by your cat and not by other cats. 

For further discussion, see https://books.google.com/books?id=vs4LCmY_N-8C&lpg=PA153&vq=all%20words%20classify&pg=PA24#v=onepage&q=%22What%20is%20A%20word%22&f=false "An Inquiry of Meaning and Truth" by Bertrand Russell.
It seems to me like you're asking about social science methodology, rather than the philosophical use of these terms.  Let's start with three important distinctions:  


quantitative / qualitative:  Quantitative research uses numeric data.  These could be numeric measurements (e.g., the number of people working in a particular industry or living in a particular place) or numerical representations of non-numerical phenomena (e.g., asking people whether they like or dislike Trump and representing the responses as 1 or 0).  Qualitative research uses non-numeric data.  Often these data are transcripts of conversations, between the people being studied or during interviews.  Mixed-methods social science research uses both quantitative and qualitative data.  Recent work in computational social science often applies computational methods to qualitative data, such as text mining.  
observational / experimental:  Observational research gathers data with no/minimal/no intended influence on the people or situation under study.  Experimental research makes deliberately intervenes on the people or situation under study, in order to understand the effects of that intervention.  
inductive / deductive:  As these terms are used by social scientists, deductive research uses a more-or-less well-developed and articulated theory to collect data and interpret it.  In statistics, this is often called "confirmatory research":  there's a clearly-stated hypothesis, and the aim of the study is to confirm (or disconfirm) it.  Inductive research doesn't have a well-developed or articulated theory.  Often this looks like what statisticians call "exploratory research":  the researchers gather some data, then examine it for patterns, trying to identify phenomena and usually suggest a potential hypothesis that might explain it.  


Note that philosophers use the terms "inductive" and "deductive" differently.  Specifically, in logic, deductive arguments (attempt to) guarantee the truth of their conclusions, given the premises; they provide certainty.  Inductive arguments don't offer this kind of guarantee.  Deductive methods used by social scientists will often be inductive in the philosophers' sense:  the assumptions of the theory don't guarantee that the data must be analyzed in a certain way.  And exploratory data analysis (an inductive method, in the social scientists' sense) involves mathematical analysis of data, which is deductive in the philosophers' sense.  

To respond to your question, these three pairs of distinctions are independent.  You can have qualitative, observational, deductive research; or qualitative, observational, inductive research; or quantitative, experimental, inductive research; and so on.  Specifically, observational research (what you call "descriptive research") can be quantitative and deductive.  But it could also be quantitative and inductive.  Or qualitative and deductive.  Or qualitative and inductive.  
Your point, "Determinism and free will are not discernible from the mortal perspective" is indeed the third antinomy (paradox) of Kant. According to Kant, human capacity for knowledge is innately limited by his 12 categories. The categories function like a fish net. Those that are caught by the net constitute human knowledge, and those that go though the net are something we will never know. Kant calls those uncapturable things transcendental (or Ding an Sich). According to Kant, if we try to gain the knowledge of transcendental things, we will always arrive at a contradiction, thus impossible is the knowledge of the transcendental stuff. Kant proposes that there are four such transcendental objects, the third of which is free will. Our sense of free will could be like a rock thinking that it is flying when I throw it to the air.
This site is not a place for personal philosophy, so in theory asking people to poke holes in their theology is out of scope.  However, I see some issues with how the argument is presented which I think could prove valuable to others, so I choose to answer rather than vote to close the question.  I think there's value in having examples of how to look at the structure of an argument, while not explicitly agreeing or disagreeing with the outcome.

The primary issue I see is how hard it is to find a conclusion.  You list 5 very substantial givens.  Then the body of the argument consists mostly of defenses of the givens.  The only statement I could find in the body of the argument that wasn't a defense of a given was "Hell, being defined as the complete opposite of Gods attributes, would be the right place to send those who do not follow to the perfect process."  I can only presume that was the conclusion.

You also have several unstated givens.  These are things which you assumed, but chose not to enumerate as givens.


"forcing someone to do something is unjust" -- This starts to re-define justice.  As an example, modern secular justice does indeed include the concept of compelling someone to act, such as revealing a password.  There is a special clause in US law known as the 5th amendment which permits one to refuse to incriminate themselves, but you can be compelled to incriminate someone else.  This suggests that there is a very high likelyhood that your listener's concept of "just" is different from your own.
"God by definition is omnipotent, omniscient, and just."  Defining God is tricky business.  These adjectives are actually at the root of many major philosophical paradoxes regarding God, so they certainly should receive their due status as givens, along with exacting definitions of what "omnipotent" and "omniscient" actually mean.  For example, "omnipotent and "forcing someone to do something is unjust, so he must" are often considered to be conflicting.  Omnipotence and omniscience are tricky beasts indeed.
"...would it be reasonable to refer to God and the process of humans becoming perfect through God as perfect?" You ask this phrase as a question, then continue the argument on the assumption that it is true.  This pattern typically is indicative that there's more thinking to be done here.
The structure you define for Hell very likely permits a counterargument that the Devil is perfect, and those who do not follow his process are sent to heaven, which is defined as the complete opposite of the Devil's attributes.  This may be desired, but theological arguments tend to avoid framing things symmetrically enough to permit this sort of argument.


From there, one could challenge the givens, which some of them are quite demanding ("perfection must exist for imperfection to exist" is a really hard one to defend), but that gets into the discussion of whether or not the argument is sound, which is outside of Philosophy.SE for sure.  I'll stick to discussing the structure of the argument.
I can understand your difficulty but I wonder if the key to the mystery of Aquinas' meaning lies in the sense he attaches to 'self-love'. I think this means happiness or beatitude. There is no necessary implication of self-centred, selfish love. My happiness and your good are quite consistent : part of my happiness might consist in promoting your good. 

Aquinas's language of concupiscence and friendship is hardly pellucid but there is no necessary opposition between the two. They can combine. If, for instance, my happiness includes friendship with you, this love (friendship-love, 'philia' as the Greeks called it) can prompt a desire to help you. You urgently need a bandage to protect an injured arm. Accordingly I urgently desire to procure a bandage and this desire is a form of concupiscence in Aquinas' wide understanding of the concept. I have a strong desire to get hold of a bandage and this is love (concupiscent-love, in language one would never use nowadays). 

The self-love that Aquinas identifies as the primary basis of human action is only a desire for happiness or beatitude. It is a desire for (what I perceive as) my good. That good can include friendship; and within friendship there can be, with no tension or contradiction, both friendship-love and concupiscent-love. Indeed, when I rush to get a bandage for you the two loves are combined : I desire to get the bandage (concupiscence) because I love you as a friend. Concupiscence and friendship are two sides of the same coin of action. 

Perhaps this will throw a little light on your textual problem. 
There are no considerations of cause and effect or the passage of time in mathematics. (These are in the realm of science.) This is shown most clearly in how logical implications are used in mathematics where P implies Q does not mean that P causes Q, or that Q causes P. It means only that we do not have both P being true and Q being false. We could have both P and Q being true, or both being false. We could even have P being false and Q being true. By saying that P implies Q in mathematics, we are only ruling out that both P is true and Q is false.
Any reflection on the moral character of an action would have to take the environment into consideration, particularly the dominant norms. This principle should also remain valid if one does not regard them as absolutes, or even in the case one disagreed with their legitimacy (freedom of thought). 

Hence you might want to divide the question into two distinct situations according to the environment: the state of nature and the state of society (a concept that traces back at least to Hobbes, but see also the Social Contract by Rousseau). This dichotomy might be useful.

In the state of nature1 where there is no police and no justice (and supposing that could really exist, since some state could still claim jurisdiction on the location) the decision would be in principle strictly personal, by definition; in other words down to the individual's own sense of ethics (or more likely, and at a lower level, survival instinct). This would, consciously or inconsciously involve weighing chances of survival when selecting courses of action; or in the extreme it would boil down to killing with one the various techniques animals use in nature (pursuit, ambush, face-to-face duel, poisoning, stealing food, etc.).

In the state of society the functions of police and judicial have been delegated to the state. According to the social contract, it is not up to an individual to make that type of adjudication. So a citizen who reasons like this would be in breach of the social contract and would undermine the rule of law.

In a state of society, this "thin line" you are contemplating is the laws of the land, specifically the criminal code, which explicitly forbids this kind of behaviour. On top of this, this runs against the dominant moral codes of most human societies, which consider killing bad per se.

Indeed, acting by pre-emptively killing someone would qualify as assassination, which carries among the highest penalties in criminal codes. Since those law codes are consciously written by people who carefully ponder a "scale of represession" (or whatever it would be called), this is an indication of the extent to which such a behaviour is considered a dangerous transgression for a society. 

Going back to a similar situation in a state of nature, let us remember that an individual would also probably want to go back to "civilization" which (still and regardless of the specific conditions) enforces its dominant set of values. If the behaviour of the individual had violated those rules, the individual would also have to live later with it privately, or else need to justify themselves to their fellows; including (because of the practice of territorial claims, or even extraterritoriality) in front of courts.

And then the "thin line" would be back to the only admitted exception, i.e. self-defense. Perhaps with some allowances due to mitigating circumstances (due to the harshness of the conditions), as well as the presumption of innocence.




"A primitive state of existence, untouched and uninfluenced by civilization or social constraints: when people lived in a state of nature." https://www.ahdictionary.com/word/search.html?q=nature American Heritage

Art is a vague term without definite boundaries.  People use the term for many things, including representing something meaningful in some way or a sophisticated thoughtful way of doing something.  Some people believe it requires some sort of developed skill to create something sensually stimulating with the intent of being art, although others can disagree about its status as art and its quality based on personal preferences. Usually, it is a set of stimuli for the intent of evoking some kind of reaction, pleasant, meaningful, or something else. Although it is also used to describe an application of skills.  For example, some say psychotherapy is some science but also an art form when it is done well.

If the average unskilled person can easily do it and it isn't anything original or interesting, it probably wouldn't be considered art by very many (e.g., destructive or criminal activities). 
Some words that may describe the concept you seek:


charity: if the resources are given freely to the poor
https://en.wikipedia.org/wiki/Noblesse_oblige noblesse oblige: formally, the belief that nobility has a responsibility to others in society, including the poor; informally, the belief that all rich people have this responsibility.
social justice: if you believe people are poor due to circumstances beyond their control, society has an obligation to help them
social welfare: the belief that society has an obligation to help the poor, regardless of why they are poor


Many religions make giving to the poor mandatory:


https://en.wikipedia.org/wiki/Tzedakah Tzedakah in Judaism
https://en.wikipedia.org/wiki/Zakat Zakat in Islam
https://en.wikipedia.org/wiki/Vand_Chhako Vand Chhako in Sikhism, a mandatory form of https://en.wikipedia.org/wiki/D%C4%81na Dana
doubtless many others


and many others regard it as a virtue.

Many countries also tax the rich to support the poor through https://en.wikipedia.org/wiki/Welfare social programs

To summarize, the concept that the rich have a religious, moral and legal duty to help the poor exists in many forms with many names.
Aristotle is said to have asserted that all fallacious arguments essentially commit Ignoratio elenchi (= ignorance of argumentation or missing the point for moderners). Since some logicians categorize ignoratio elenchi under the non sequitur (= does not follow), we could say that your observation that all fallacies are essentially non sequitur is right. 

The problem with your assertion however is that scholars deeply disagree on the categorizations of fallacies and the scope of each fallacy. They cannot even offer a precise definition for 'fallacy': at most they agree that a fallacy is a defect in reasoning. Even Aristotle himself used ignoratio elenchi in the above broadest sense and a very narrow sense where the concussion simply is irrelevant to the premises, which is neither a straw man nor a red herring  (e.g., "Abuse of the welfare system is rampant nowadays. The conclusion is obvious: we must abolish the system altogether.") Presently, Non sequitur is usually limited to the cases that produce a comical effect due to breaking the cliche or expectations: e.g., "My wife and I were happy for 20 years....Then we met." 

Formal logic has been unhelpful to understand fallacies since many perfectly valid arguments are fallacious. Informal logic that is informed by critical thinking, rhetorics, communications and AI have been far more helpful to understand the categorization of fallacies. Under the informal logic,
it is now clear that many fallacies are fallacies for the reason other than relevance (broadly, non sequitur): e.g., weak induction, illicit presumptions. Viewed in this light, your assertion can be said to be false. 
(This is a short unsourced answer for the time being, when I have the time later, I will update it with sources and details)

From a Marxist point of view, UBI doesn't solve the problem of exploitation. Nor does free housing, universal health care, or food stamps for all, etc....all of these are corrections to capitalism, which aim at keeping capitalism in place, but making it better at handling problems like poverty, unemployment, and hunger. 

Marx believed that capitalism was fundamentally flawed. The problems of exploitation and alienation were baked into the basic workings of capitalism, and as long workers didn't own the means of production, there was no escaping these problems. No set of adjustments to capitalism would solve them, the only solution was to overthrow the whole system.



(Update) 

For the first part: 


  Yet, if a (sufficiently generous) universal basic income (UBI) were to be implemented in a given country, workers would not need to offer their labour in the market. Anyone who does so, would do it freely and voluntarily. This [...] not only eliminates the "slavery" side of the argument [...] 


The main problem with this is that it is very difficult to define "sufficiently generous" so as to cover what constitutes the basic needs of a worker. Marx mentioned that the worker is forced to do so in order to avoid starvation, back in his time a house with running water and electricity was considered a luxury. Nowadays, in the developed world, people don't starve (thanks to food stamps, soup kitchens, etc...), yet someone living without electricity or running water is still considered to be living in abject poverty. A worker forced to work to pay his electric and water bills would be considered exploited, and the slavery component persists. At which point exactly does a worker no longer "need" to offer their labor on the market? Provide enough food and shelter to everyone, and we simply move a level up in https://en.wikipedia.org/wiki/Maslow's_hierarchy_of_needs Maslow's hierarchy of needs: The working class is forced to work to find love and belonging while the bourgeois class enjoys esteem and self actualization. The UBI would have to be such that everyone can move to the top of Maslow's pyramid at will  - Marx alluded to this in his famous quote from https://www.marxists.org/archive/marx/works/1845/german-ideology/ch01a.htm "The German Ideology": 


  For as soon as the distribution of labour comes into being, each man has a particular, exclusive sphere of activity, which is forced upon him and from which he cannot escape. He is a hunter, a fisherman, a herdsman, or a critical critic, and must remain so if he does not want to lose his means of livelihood; while in communist society, where nobody has one exclusive sphere of activity but each can become accomplished in any branch he wishes, society regulates the general production and thus makes it possible for me to do one thing today and another tomorrow, to hunt in the morning, fish in the afternoon, rear cattle in the evening, criticize after dinner, just as I have a mind, without ever becoming hunter, fisherman, herdsman or critic. This fixation of social activity, this consolidation of what we ourselves produce into an objective power above us, growing out of our control, thwarting our expectations, bringing to naught our calculations, is one of the chief factors in historical development up till now.   


Only then can we argue that workers are entering freely into any labour agreements they sign up for, without any coercion. 

For the second part: 


  but it might also reduce (albeit not eliminate) the level of surplus value extracted to the worker (because, essentially, is giving more power to the latter).


A UBI doesn't eliminate the likelihood that the wages a worker receives from a capitalist will be unfair. Sure, a worker getting a UBI will not worry about food and might be working to afford the occasional movie ticket and trip to Disneyland, but then the capitalist is raking up all the profits and using them to fly to the Maldives in his private jet. The unfairness comes not from the coercion alone, but from the fact that the capitalist is reaping a benefit that is disproportional to his contribution, while the workers are getting only breadcrumbs. As long as a few people benefit disproportionally at the expense of many, there is unfairness. The only way to insure a faire distribution of the profits is if the workers get paid directly for their labor, which happens only if they own the means of production. Marx says in the communist manifesto: 


  “But modern bourgeois private property is the final and most complete expression of the system of producing and appropriating products, that is based on class antagonisms, on the exploitation of the many by the few.” 


One might envision a UBI so high that everyone gets to live an upper class lifestyle, but then that ends being the same thing as communism anyway. 
Normally these types of indifferences are inadmissible.

One issue you mentioned in your question can't be solved by a single person alone if he has no power to do that. Did you notice that?


  Is it "OK" for a person to stand by while another is harassed or
  assaulted?


Most people don't interfere in the quarrel among drunkards.

When a person has a great aim to accomplish in his life (e.g. to save the lives of so many people), sometimes he will ignore some issues. 

Sometimes the harassment may be the reaction of an action.  

The person may not be willing to react due to his bad condition (e.g.: very weak due to some illness). 

Sometimes, if the person responsible to solve the problem is there we usually do not react quickly.


  Is it "OK" for a person to have multiple homes and others homeless?
  
  Is it "OK" for a person to have access to thousands of tons of food
  for years and another starves?


The persons who destroy the homes, food etc without allowing anybody to use it, are certainly traitors.


  Is it "OK" for a person to have unlimited leisure and another an
  indentured slave?


The authority to stop such issues are also responsible for these.  Then whose behavior would you blame/name first?

Here we can see at least three persons: 


the person who is responsible to stop such activity  
the person who enjoys unlimited leisure
the indentured slave


But we usually consider two persons only and name his/her behavior.  

When there are more than two persons and when the reference also changes, the name of his/her behavior also changes.

You may try to name the 2nd person's behavior more precisely without considering the 1st person and considering the 1st person. Are they the same?

[This test is applicable also to the two questions given above.]


  Is there any word for this type of behavior?


Here a one-word won't suit everywhere.  We need to name such behavior according to the situations.

The persons in your questions may be rude, introverted, selfish, thoughtless, inconsiderate, domineering etc.   

The following link may help you to clear one of your doubts. Sometimes you can connect it to other doubts also.

http://www.holy-bhagavad-gita.org/chapter/3/verse/35 http://www.holy-bhagavad-gita.org/chapter/3/verse/35

[You are searching for a suitable word.  This site deals/analyzes ideas very deeply.  So I don't think this site can suggest a suitable word considering different situations.  IMHO you should migrate to a suitable site.]
I'm not sure that this is the best description about what prayer is about; for example, in the collection of Hadith by Al-Bukhari there is the following:


  Abu-Baqr As-Siddiq said to the Prophet (pbuh) "O, Allahs Messenger! Teach me an invocation with which I may invoke Allah in my prayers"
  
  The Prophet said, "Say: O Allah! I have wronged myself very much (oppressed myself) and none forgives the sins but You; so please bestow Your Forgiveness upon me. No doubt, you are the Oft-Forgiving, Most Merciful."
  
  narrated by 'Abdullah bin 'Amr


This is not very different from the Lords Prayer in Christianity which I was taught at school; and is close to how Piomicron described the function of prayer in the comment to the other answer - to create change within. 
The fourth verse of the Gita Dhyana Sloka reads as follows:


  Sarvopanishado gaavo dogdhaa gopaalanandanah;
  Paartho vatsah sudheer bhoktaa dugdham geetaamritam mahat.
  
  All the Upanishads are the cows; the milker is Krishna; the cowherd
  boy, Partha (Arjuna), is the calf; men of purified intellect are the
  drinkers; the milk is the great nectar of the Gita.


So IMHO, it will be a futile effort  if one tries to find objections to its basic ideas by taking one or two verses from the Gita.

From a first/normal reading one can find many contradictions in the Gita ....Skimming or scanning won't be enough if the aim is a clear understanding.

I think those who realized the Ultimate Truth couldn't find any objections to it; but they had tried to reword it.

From your question we are likely to think that Karma only has importance to achieve spiritual freedom.  If so, why there are other paths to achieve moksha? 

So we should know why Krishna said so.

Please read the words of  Sri Sankara:


  ”Sat-sanghatve nissangatvam
  
  nissangatve nirmohatvam
  
  nirmohatve nischala-tattvam
  
  nischalatattve jivan mukti”
  
  This verse says that through association of ‘sat’- the devotees of the
  Lord, one becomes free from the modes of material nature. Then
  ‘nir-mohatvam’ or the subsequent stoppage of illusion, because we are
  free from the association of material modes. Further there is
  ‘nischalatvam’. This means that the flickering mind becomes steady
  once the illusion is dispelled. A steady mind makes one ‘jivan-mukta’
  or a liberated soul.


All the verses in the Gita are not answered standing from the very base. But some are. Some verses suit both.

FYI, Eg.

http://www.holy-bhagavad-gita.org/chapter/2/verse/20 Verse 2.20

http://www.holy-bhagavad-gita.org/chapter/3/verse/5 Verse 3.5

http://www.holy-bhagavad-gita.org/chapter/4/verse/18 Verse 4.18

http://www.holy-bhagavad-gita.org/chapter/4/verse/20 Verse 4.20

http://www.holy-bhagavad-gita.org/chapter/13/verse/24 Verse 13.24

http://www.holy-bhagavad-gita.org/chapter/13/verse/31 Verse 13.31

One can find so many like this.  I think all these verses can heal 'the wound' you found.
No; reduction to absurdum is not expressible with a syllogistic form of argument. 

https://en.wikipedia.org/wiki/Reductio_ad_absurdum Reductio is a more "basic" argument: a propositional one.

We can express it either as a "law" or axiom:


  ⊢ (¬ϕ → ¬ψ) → ((¬ϕ → ψ) → ϕ)


or as a rule:


  if we have the derivation of a contradiction from ¬ϕ, we may infer ϕ.


In more formal way:


  if Γ, ¬ϕ ⊢ ψ and Γ, ¬ϕ ⊢ ¬ψ, then Γ ⊢ ϕ.


https://plato.stanford.edu/entries/aristotle-logic/#MetProPerDedConRed Aristotle uses reductio in his theory:


  he “reduces” (anagein) each case to one of the perfect forms and that they are thereby “completed” or “perfected”. These completions are either probative (deiktikos: a modern translation might be “direct”) or through the impossible (dia to adunaton).


In other terms, he uses it to derive the otehr fugures from the first one, considered “perfect” or “complete” (teleios) i.e. that needs no otehr argument  to show that the conclusion necessarily results from the premises.

We may say that he uses the perfect form as axiom and reductio is a rule of inference in his system.



In modern first order logic, we can prove Barbara from "basic" axioms and rules:

1) ∀x (Px → Qx) --- premise

2) ∀x (Qx → Rx) --- premise

3) Pa → Qa --- from Quantifier axiom: ∀x α(x) →α (t/x) and 1) by Modus Ponens

4) Qa → Ra --- --- from Quantifier axiom and 2) by Modus Ponens

5) Pa --- (temporary) assumption [a]

6) Qa --- from 5) and 3) by MP

7) Ra --- from 6) and 4) by MP

8) Pa → Ra --- from 5) and 7) by Deduction Theorem, discharging temporary assumption [a]


  9) ∀x (Px → Rx) --- from 8) by Generalization Theorem (or Gen rule).


Thus, 1)-9) shows:


  
    ∀x (Px → Qx), ∀x (Qx → Rx) ⊢ ∀x (Px → Rx)
  


i.e. we have proved Barbara from propositional and quantifiers axioms and inference rules.
Maybe a "free" translation from: http://www.danielmartin.eu/Textes/Existentialisme.htm L'existentialisme est un humanisme (1946):


  Et en voulant la liberté, nous découvrons qu'elle dépend entièrement de la liberté des autres, et que la liberté des autres dépend de la nôtre. Certes, la liberté comme définition de l'homme ne dépend pas d'autrui, mais dès qu'il y a engagement, je suis obligé de vouloir en même temps que ma liberté la liberté des autres, je ne puis prendre ma liberté pour but que si je prends également celle des autres pour but. En conséquence, lorsque, sur le plan d'authenticité totale, j'ai reconnu que l'homme est un être chez qui l'essence est précédée par l'existence, qu'il est un être libre qui ne peut, dans des circonstances diverses, que vouloir sa liberté, j'ai reconnu en même temps que je ne peux vouloir que la liberté des autres.


English translation:


  And in thus willing freedom, we discover that it depends entirely upon the freedom of others and that the freedom of others depends upon our own. Obviously, freedom as the definition of a man does not depend upon others, but as soon as there is a commitment, I am obliged to will the liberty of others at the same time as my own. I cannot make liberty my aim unless I make that of others equally my aim. Consequently, when I recognise, as entirely authentic, that man is a being whose existence precedes his essence, and that he is a free being who cannot, in any circumstances, but will his freedom, at the same time I realize that I cannot not will the freedom of others. 

This is a type of https://en.wikipedia.org/wiki/Zebra_Puzzle zebra puzzle, also known as Einstein's Puzzle or a https://en.wikipedia.org/wiki/Logic_puzzle#Logic_grid_puzzles logic grid puzzle

As noted in the page above, they can usually be solved using logic grids. Two website w/ more info:


http://www.logic-puzzles.org/ http://www.logic-puzzles.org/
https://www.brainzilla.com/logic/logic-grid/ https://www.brainzilla.com/logic/logic-grid/


Of course, since the puzzles involve basic prepositional logic, there are other ways to solve them as well. In particular, computer languages such as https://en.wikipedia.org/wiki/Prolog Prolog have been designed to solve problems like these without looking at all possible combinations of variables (the https://en.wikipedia.org/wiki/Brute-force_search brute force method)
Well semantically propositions have a definition that may be different in maths and science.  So this means varying answers depending on which department did the teaching.

In philosophy i was taught all propositions have a truth value.  You are now brining up awareness of the truth value which sounds like science approach.  Because i dont know which value proposition x holds does not mean the proposition has no value. The proposition has a value but you are currently unaware of said value. To say the proposition has no value because you are unaware contradicts the standard definition that propositions must have a value of true or false and no other possibility.  To conclude propositions have no truth value because of ignorance does not seem well formed.

Free will expresses that one has alternatives available.  Christians have free will because neither God or Satan can force them to behave a certain way.  That would be possesion.  As far as predestination goes --this comes up because of future propositions --technically is all psychological.  God knows the outcome but we dont.  Our awareness would not be able to change the value even if we had it.  If i am set to die 2 days before my next birthday this is true independant of any human being.  With or without your existence this proposition is true or false.  What makes the proposition true is not human awareness.  Today scientists claim to know that there is a super massive black hole at the center of each galaxy.  Is one to believe this was not true in Aristotle's time because they were unaware?
Is there some physical phenomenon in this toy-universe that requires a time dimension in the theories describing it? If no, then time is not physical in this universe. You can of course introduce time in any timeless theories, but it would not add any explanatory power...
In the case of the Hebrew Bible/Old Testament, there is no inconsistency, because sin is restricted to humans. At the bottom https://www.blueletterbible.org/lang/lexicon/lexicon.cfm?Strongs=H2403&t=KJV of this page is a list of all HB occurrences for 'sin' (חטאת). Also interesting would be https://www.blueletterbible.org/niv/gen/6/1/t_conc_6005 Gen 6:5 in the story of Noah:


  The LORD saw how great the wickedness of the human race had become on the earth, and that every inclination of the thoughts of the human heart was only evil all the time. (NIV)


Even though god regrets having made "the human race ... and with them the animals, the birds and the creatures that move along the ground", wickedness (רע) is only reserved for humans (v. 5).

So, abstracting, you see that there does not need to be an inconsistency if you reserve the concept of sin for humans.

Whether the Jewish/Christian god thinks homosexuality is a sin is another issue that is not on topic here.
Various pacifists (including my favorite version of Starhawk) have also put forward this basic notion.

Its theoretical practicality relies upon an assumption that 'We are psychologically more like bonobos than dogs'.  (This is not entirely obvious.  We are genetically more like bonobos, but we created the psychology of dogs to be like our own from very early in our history.  Many dogs, and few bonobos, understand what it means when you smile playfully, or when you point at something.  But the genetic distances make it highly likely.)

Various theorists have suggested, largely based upon the differences between chimpanzees and bonobos, that competition to have more 'stuff' than your neighbors is a trained response and not an intrinsic one.  Other theorists have reinforced this by arguing for the apparent egalitarianism of tribes at the height of the paleolithic era, suggesting that differences that afford domination, like gender and size, do not seem to have predicted better individual health in that period of prehistory.  From this point of view, human competition is properly social in nature: about mating opportunities or enforcement of will in a more abstract sense, and not really about resources.

But we are raised in a culture that emphasizes scarcity as a primary social motivation.  We are trained to value ourselves through providing resources to those about whom we care, or through demonstrating that we can and will do so when the time is right, because much of human history after the period of Paleolithic Affluence has involved continual scarcity and particularly has involved forced deprivation of the socially disapproved.

Even taking that as a given, so the state is possible, the issue remains whether whether there is any path to it.  We cannot simply dismantle a basic aspect of all human cultures, even if we know that underlying the resulting dysfunction is a different motivation that would not be as destructive.

This ultimately faces the major obstacle to all forms of pacifism.

Unless we all abandon manipulation through unnecessary competition at once, some backward cultures will still create artificial scarcity by pretending to play along, but really harboring their old motives.  Then they can take advantage of the fact that others are not working against them to hoard security without limit, and consequently create artificial scarcity.

It is not clear we can get there by half-measures.  Many schemes have been put forward, but they all seem to require either incredible luck, or virtually infinite intelligence.

I think the Venus Project people are basically believers in what Kurzweil called 'The Singularity' -- the point at which technology amplifies intelligence into something so readily adaptable that its only limitation is the maximum rate at which things can change.  At that point, it might as well be infinite.  So, from that POV, there will be a time very soon, when they can address this limitation with technology.
An example I have seen is to compare dogs with your dog (or any other pet).  Your dog is a dog because it meets the characteristic requirements of the type dog.  Your particular dog is a token of that type.
To illustrate further let us consider a piece of art.  Say you have some oil paint on a piece of wood.  This is an oil painting (Type) and a particular piece of art (Token).  If the artist then adds other media to the wood (say cloth, metal, string, etc.) it stops being an oil painting (Type) and becomes mixed media (Type).  It is still the same piece of art (Token) though. 
Yes, the probability of finding an electron at a given distance from its nucleus is analytically derived. 
I cannot speak for Platonists who argue along the lines you mentioned above. I personally find the indispensability argument has no more value than the ontological "proof" of God, namely that God could not be the superior being without existing (whereupon Kant answers "equally well a merchant could add some zeros to his account in order to improve his economical situation").

But mathematicians believing in set theory have an indispensable reason to be Platonists, at least when they are consistent: According to set theory there exist uncounbtable sets, i.e., sets with more elements than ever can be described, defined, mentioned, imagined individually by inhabitants of the universe. So, if existing, these elements do not exist in human mathematics (monologue, dialogue, discourse) but at most in God's knowledge. By the way, that is what Cantor believed from the scratch.
To answer the second part of your question 'it seems that the solution was found and then the question answered' Yes, that is the way it's done most of the time because it is much simpler once you know the outcome. You can simply do Sherlock Holmes eliminate all the impossible until all you're left with is the possible.
And that would be a good approach I would say it is a better way than how scientists handle problems today. They did not eliminate the possible they actually attempted to explain reality with the possible even though it is impossible, such as dark energy and basically everything else in science
The issue I have with this question is that perhaps the use of the word consciousness is imprecise in this case. What I think you're really asking about is awareness.

Let's conduct a quick thought experiment.

Take everything you know; every piece of knowledge that you possess, all the experiences, everything you've seen and heard, and put it on a hard drive for safe keeping. Is that drive conscious? Of course not. Is it aware? No. It's an inanimate storage device that contains data it doesn't understand and does not have the faculties or potential to do so, largely because it's static.

Conversely; take a new born baby and place it in a sensory deprivation chamber for 20 years. Feed it intravenously but restrict it from having ANY contact through senses with the outside world. Is the 20 year old conscious? Most certainly. Is it aware, or at least self aware? Highly unlikely. New born babies are conscious according to our definition, but they aren't aware. It's not until they are about 2 years old (generally speaking) that they exhibit behaviours that indicate that they have become aware of themselves as a separate entity from their carers.

From this, we can infer that awareness is more than just knowledge, but consciousness is more an 'always on' state of input and consolidation of the stimuli around us.

To be sure, not all knowledge will lead to awareness, and the structure of the knowledge we leave behind for the next generation is what has allowed humans to develop so quickly in this regard. If we had to learn everything from scratch for ourselves rather than being able to short cut the process by quickly absorbing the knowledge of others, we would not have the tools we need to build our awareness even today (in my opinion). That we can order and categorise our knowledge and apply a set of rules to it in order to build upon it is what has given us this ability.

So; perhaps we can say that consciousness is the engine of self awareness, and our knowledge and processing frameworks (like language, logic, maths etc.) are the fuel.
If every person has a creator, it does not follow that there is a single creator that creates every person. Theoretically every person might have a separate, different creator. It also does not follow that if there is a single creator, that creator is God : I know you don't say that it is but the mistake is often made. 

If there is a single creator, your problem simply moves up a level. Either nothing caused the creator's existence or the creator caused the creator's own existence. The latter would make the creator 'causa sui', self-created. How the creator could cause the existence of the creator is not apparent.
If you're talking about the final toss in a sequence of 100, where 99 have already come up as heads, then the odds are STILL 50%. Whether the tosser (sorry, we may have to come up with a better name for him) realises this or not is largely due to the fact that his mind is geared towards pattern matching.

The human mind is very good at finding patterns in nature and then trying to ascribe some meaning to them. In short, we don't tend to believe that patterns can be random, but they can be every bit as probable as sequences that don't have an obvious pattern to them.

Someone trained in probability mechanics will see that. Someone without that training will struggle with the need to find meaning behind the pattern, even though (in this case) there isn't one. This is a challenging point for many and (arguably) is how faith is born; not just in any specific religion, but more in the idea that there is a power behind the patterns that we don't understand, and therefore can't understand.

In short, it may look like a miracle, but so do many things we see in nature until we apply a scientific method to them.
It doesn't sound 'amusingly facile at all ! You're intrigued by a topic and this is the place to ask questions about it. Good for you. Here's my contribution.


It's perfectly possible for someone to believe that morality is not for them. Overall, it does not pay, they decide. So, they reason,  morally good things are exactly inimical to their self-interest, and therefore (judging what is good for them purely in terms of self-interest) the (morally) good is not the (self-interested) good. From this viewpoint, 'doing "good" things is not good'. 
It is also, less dramatically, possible to regard what are commonly regarded as 'good things' as not really good at all. They are products of self-consciousness, careless thinking, or whatever. So if these are the 'good things' in question, doing "good" things is not good.

Schopenhauer was at war with Hegel and, after his death (1831), with anybody who did not consider him to be the most important living philosopher. The 'bad writers' are the Hegelians which were sufficiently numerous as to be seen as forming at least two factions: https://en.wikipedia.org/wiki/Young_Hegelians Young Hegelians and older ones, but also situated on the 'Left' or the  'Right'.  Rather directly he targets them by mentioning their journal Halleschen Jahrbücher für deutsche Wissenschaft und Kunst  (Halle’schen), later Deutsche Jahrbücher which appeared from 1838-43. Most of the contributors' names are forgotten (one would have to look up if Marx or Engels are among them).
As Schopenhauer did not suffer from modesty he mention as deplorable writers also Fichte, who was from an earlier generation, and Schelling, who was his contemporary.

It is seen that Schopenhauer's rhetoric launches  at least three accusations:  (1)nothing to say, (2) obscurity, (3) despicable motivation (money and/or fame). Morphing them one into another leaves no escape for any target.
[Subsequent to DeeDuu's https://plato.stanford.edu/entries/envy/#1.2 link to the relevant SEP entry, I've inserted excerpts from that which more concisely/rigorously convey some points I was 'grasping' at.  All emphasis in these excerpts is mine.]

SonOfThought covered the basic distinction that I prefer to maintain, not out of pedantry but to encourage distinction itself.  I've never known envy to be commonly used in conversation, whereas it seems increasingly common for people to say "oh, I'm so jealous" when they're merely coveting something they don't have.

From the SEP:


  While it is linguistically acceptable to say that one is jealous upon hearing about another’s vacation, say, it has been plausibly argued that one is feeling envy, if either, in such a case.


I'll start from a more vague concept of entitled, "grasping" behavior:


jealousy is grasping tightly what one already 'has';
envy is grasping for what one doesn't have but supposedly should have;
for extra contrast we add a third, avarice/acquisitiveness, which is sheer greed: grasping for more, and more, and more (of whatever), no rationalization required, compulsive.



  both envy and jealousy are three-place relations; but this superficial similarity conceals an important difference. Jealousy involves three parties, the subject, the rival, and the beloved; and the jealous person’s real locus of concern is the beloved, a person (or being) whose affection he is losing or fears losing. The locus of concern in jealousy is not the rival. Whereas envy is a two party relation, with a third relatum that is a good (albeit a good that could be a particular person’s affections); and the envious person’s locus of concern is the rival. . . . Roughly, for the jealous person the rival is fungible and the beloved is not fungible. So he would be equally bothered if the beloved were consorting with someone else, and would not be bothered if the rival were.



Envy regards possessions and advantages as inappropriately distributed - e.g. "That guy doesn't deserve his good fortune!  I would do so much more with it!"  This overlaps with avarice because "I should have that", but diverges in that envy presupposes a strong resentment of the "have-not" situation.


(The SEP sets a distinction between resentment and envy, and even further separates envy into 'invidious' and 'benign' varieties; I will emend the conflation by saying that the invidious sort was the only one I had in mind to begin with, and place the other distinction after the following paragraph.)

In its role as a 'deadly sin', envy is essentially thoughtcrime; though it is possible for actions like thievery to be informed by one's envy, it's the attitude itself that is sinful:  the insistence (whether or not you ever voice it) that you deserve those things, and they don't deserve them.  It is much easier to frown upon The Envious during periods of extreme and unquestioned class disparity - societies in which it is a 'sin' to be dissatisfied with your 'lot in life'.  In fact, I might go so far as to suppose that envy has fallen out of common usage and reflection precisely because at least half of that ambition ("I deserve better") is more widespread in societies that promote equality as an ideal - i.e. it is less of an 'attitude problem' than ever.


  Even those who deny that “benign envy” is a kind of envy will grant the existence of cases in which people want to have skills or other traits that are possessed by another person, and are pained by their lack, but in which they have no desire at all for the other person to lose those traits. Call such a state “emulative desire.”



Jealousy is zealous possessiveness; the most suitable overlap with envy while keeping them distinct is arguably the most destructive manifestation:  "If I can't have _____, then nobody can."  The overlap with avarice is a hoarding mentality.  The unique side of jealousy is that it is an attitude to which many divine entities (not just the scriptural Judeo-Christian god) are entitled!


Yes, of course it is possible to flog either of these into a shape that might as well be the other - as with any 'deadly sin' or 'negative emotion', really.

With the above in mind, I agree with SOT that jealousy is worse in character, but mostly just because I associate it with harmful action, much moreso than I associate envy.  However (and I can only go by anecdotes here), I think that 'bottling up' either one of them can proverbially 'eat you up inside', but that it may be easier to wean oneself off [unexpressed] jealousy than [unexpressed] envy, rather because of that difference.

Unsurprisingly, someone else has put it better.  From https://en.wikipedia.org/wiki/Jealousy#Comparison_with_envy Wikipedia:


  Gerrod Parrott draws attention to the distinct thoughts and feelings that occur in jealousy and envy.
  
  The common experience of jealousy for many people may involve:

   Fear of loss
   Suspicion of or anger about a perceived betrayal
   Low self-esteem and sadness over perceived loss
   Uncertainty and loneliness
   Fear of losing an important person to another
   Distrust

  
  The experience of envy involves:

   Feelings of inferiority
   Longing
   Resentment of circumstances
   Ill will towards envied person often accompanied by guilt about these feelings
   Motivation to improve
   Desire to possess the attractive rival's qualities
   Disapproval of feelings



I see far more toxic possibilities related to jealousy (fear, anger, suspicion) than to envy (longing, desire, ill will "often accompanied by guilt").
For institutions, this often happens due to a the form of fiduciary responsibility. If an institution represents a wide range of people with different ethical opinions, to choose one of them makes it not representative of the others. If it becomes less effective at its stated goals in a way that is not representative of all those participating, it is breaking the agreement that it do what is specified in good faith to its participants.

The concept of a 'fiduciary' applies to all corporations with investors, for-profit, governmental and otherwise. This may not cover all of what you mean, but it is the case for most institutions, since those are most of the institutions.

Corporations often also include the right to look at wider ethical concerns in the agreement that founds them. Then to ignore it would be counter-fiduciary. But that often makes them specifically uninteresting to a wide range of investors.

In fact government agencies are generally not bound by this constraint. If a moral question is not religious, there is no reason it cannot be part of a law. Publicly-funded educational settings are often among those most free in our current culture to address moral issues directly.

It is private firms with investors and public-serving groups with a stated charter that are not allowed to moralize with anonymous money or to choose one form of morality over another in a way that excludes or disadvantages potential participants with different agendas.

For individuals, there is no such concept, and no such moral escape.  There is just a habit of humans acting like corporations because we are used to assuming that life is business and this is he normal way to do business.
As mentioned in one of the comments, you should first search for 'different' Gods on different websites and select each God and verify whether there is anything irrational in all those Gods.  After that, you could choose one 'Rational God' and ask this question.  Otherwise it'd become a beat around the bush.  

If you choose one or more things as the idea or concept of God, you will have to regard all the other things as the idea or concept of another God. [We can't rule out the possibility of another God or gods (since there are many similar creations or concepts in this world)].  Which God would you choose then for this question?  

If you choose one particular idea, concept, category or religion only as the concept of God, that would also become a folly....since the supplement for that concept and the complement of that concept must be of another God's. Then also there must be another God or gods.

So, when we think of an (external) creator of ideas or concepts (God), some contradictions pop up.

We perceive this world through our senses.  Knowingly or unknowingly we admit only the things perceived through our 5 sense organs (Some forms of lights, sounds, smells etc that we can't perceive with our sense organs are amplified or transformed in another form.  But they also are for helping these senses only.) 

The senses, brain etc create a feeling that there is creation here.  Five is a small number.  What about the situation if the number of our sense organs were below or above five?  Then, would our understanding be like this...?  Actually, we can't even imagine such a situation.

If you can imagine these senses, brain etc as somebody's creations, ideas or concepts, you will have to search their bases also.  This is not possible with your senses.  

The things, ideas and concepts that we understand with our mortal sense organs and brain are never the Ultimate Truth. 

So, if you believe (this logic) or not, you will have to assume that there is no creation.  When you realize yourself you will understand whether there is any real creation here.  Then you wouldn't need to ask this question.


  The notion that mAyA has no reality in itself, and that brahman is the
  only real, allows the sRshTi-dRshTi vAdin to "graduate", so to speak,
  to ajAtivAda, the view that no creation really occurred ever.


http://www.advaita-vedanta.org/avhp/creation.html http://www.advaita-vedanta.org/avhp/creation.html

If the aforementioned is difficult to digest, the following mantra would be useful in our daily life.

https://www.swami-krishnananda.org/upanishad/upan_04.html Isavasyam idam sarvam yat kim ca jagatyam jagat
I think we can do a bit of work to help the questioner here. The quick answer is that there are elements, prefigurations, of deism in Aristotle's ontology, his account of reality. 

▻

Deism I take to be the view that God, separate from the universe, creates a universe fully determined by a set of invariable laws. By initial impetus God sets the universe going but has no further concern with it. 

Theism I take to be the interventionist view that God, separate from the universe, creates a universe in which God is continuously active. 

Deism generally posits a physical universe in which, none the less, human beings are special - exempt from deterministic laws to the extent of having free will.

▻

The Aristotlian universe is generally considered to be 'aion', timeless, which would appear to mean that it was not created by God or anything else. The Aristotelian God does not intervene in the universe but acts in a sense to be explained just below as the 'unmoved mover'. God is perfect; there is no other perfect object for God to contemplate than Godself; and contemplation is the perfect activity. Therefore God does nothing but contemplate Godself (Aristotle, 'Metaphysics', Book Lambda, ch. 9. 

However, Aristotle has a teleological view of nature. All nature strives for such perfection as it is capable of. Everything therefore is moved to aim at its own perfection. Nature has an intrinsic 'telos' or goal of imitating God as best it can. This explains all change and motion in nature. So, while God does not intervene, God provides (with no intention) the impetus to movement and change; God is the first, unmoved mover (to proton kinoun akineton : 'Metaphysics, Lambda 8). Motionless, God initiates motion through the need, the inherent tendency, of nature to imitate God's perfection as best it can. If this seems a God of surpassing strangeness, it probably is. 

▻

Back to your question. Aristotle's God is definitely not theistic since God is not active or interventionist in the universe. God is not quite deistic because God does not create the universe but there is a strong parallel with, or prefiguration of, deism in God's separation from the universe and non-intervention in it. 

Hope this helps. 
While not a criminal case, you do allow for "ideas."

The Trolley Dilemma is a classic in the realm of ethics. If not familiar with it; the general idea is there is a trolley on path to strike and kill 5 people. You have the ability flip a switch in order to switch tracks before the catastrophe, although on that track is one person who would consequently be struck and killed. The choice and the reasoning behind it can be attributed to several different notions of ethics and morality. 

This website gives an overview, options you have, and the corresponding view of morality associated with said options.

http://www.trolleydilemma.com/ http://www.trolleydilemma.com/
Given the sheer complexity of modern physics and the amount of energy being spent in refining it, I'm always suspicious of books that use phrases like 'in contrast to the current orthodoxy among physicists' as that orthodoxy represents a great number of productive and refining man-hours that (so far in my reading) is not matched by the author making such claims.

Another example that I often come across is the Heisenberg Uncertainty Principle, where many pages of text are devoted to the idea that if 'the act of observation affects the outcome' that we have the ability to change our universe with thought alone. This is a clear lack of understanding of what the principle is actually saying.

A simple thought experiment; You're playing billiards in a well lit room, and you sink a red ball. You know this because you can see it. You can see it because the room is bathed in photons, which bounce off the ball and reach your retinas. Do these photons affect the movement of the ball? Yes, but the difference is so slight that it can be safely discounted.

But, turn the lights out. Can you see the red ball sink? No. But, if you have some very small ball bearings, you can flick them along the table and listen out for them impacting the ball as it travels. Does this affect the movement of the red ball? Yes, and more than the photon, but also negligible if the ball bearing is light enough and travelling slowly enough.

What if all you have is other red balls? That's definitely going to change the path of the red ball being observed.

In this case, we're increasing the size of the particle used for the observation. In reality, we're decreasing the size of the particle being observed, but the effect is the same because Heisenberg's principle really boils down to 2 things;

1) All observation is really just particles colliding with each other
2) The closer in size proportionally, the more of an impact the observing particle will have on the trajectory or nature of the particle being observed.

The point I'm trying to make with this example is that science already does a lot of self-checking. While scientists often use a short-hand of understanding like 'the act of observation impacts the outcome' this phrase has a very specific and deeply understood application. Where science often fails is in explaining the nuances and specificity of such phrases to the general public, who then in turn interpret them via a more common semantic context. As @Conifold explains in his comment, this has happened here as well.

In this instance; all we can say for sure is that if the universe does follow a classical deterministic model on a temporal path, then there is a point at the very beginning of the universe where all our understanding of spacetime simply breaks down and we don't currently have sufficient understanding of what happened before that point, or even if there was a point 'before' that first point where the universe is in a configuration we can understand with modern science. Mathews puts forward a 'theory'. I look forward to any convincing proof either way on the subject through conventional scientific methods.
I'm not sure really if I understand your question, so you should see the following as a comment on it.

Ruskin, an English artist wrote Unto this Last (which had a strong influence in Gandhi) in 1860; it's a work on political economy and claims that an ethical dimension cannot be excluded from economic argument; his central premise is this:


  Among the delusions which at different periods have afflicted mankind, perhaps the greatest - certainly the least creditable - is modern economics based on the idea that an advantageous code of action may be determined irrespectively of the influence of social affections


In this he was in agreement with Adam Smith, who is usually understood, wrongly, that a pure economics is possible. 
The first part of this question is not entirely correct; but I can break it down from a physics perspective to show why.

What is true is that we can only 'remember' in one direction of time. This is because of the ONLY law of physics that seems to be dependent on time as an axis; the 2nd Law of Thermodynamics, commonly known as the Law of Entropy (In any closed system, the internal stated moves from more ordered to less ordered over time).

But wait you say; if I have MORE memories over time, then my brain is MORE ordered over time, is it not? True. But, the order in the universe is ever so slightly less because laying down those memories release a lot of heat into the environment (this is why wearing a beanie in a snowfield actually helps you stay warm). In other words, your brain is not a closed system; the universe is generating higher local order at the price of lower global order.

BUT, scientists believe we can predict not only the future, but those parts of the past we've never had the capacity to see. At least, on the universal scale. We have the Big Bang Theory for instance, a wealth of evidence for Evolution, and we are pretty sure we know how the earth will die as the sun expands, and how the universe will eventually end.

Why is this? Determinism.

We've seen enough of how the physical world works over time to determine certain laws like Special and General Relativity, Quantum Mechanics, and even Entropy. If these laws are 'true', then it means that the universe runs as an algorithm.

Algorithms are a special branch of mathematics that basically relate to complex sets of rules that if applied to a starting condition, will result in a known end condition. If the universe is algorithmic by nature, that means that if we perfectly know the state of the universe at any point in time, we can predict every other point (forward or backward) simply by applying the algorithm to the known data state.

This is how we know the Big Bang happened. It's also how we know that the universe is heading to a 'cold death' in the very distant future.

The problem here is that if we can perfectly 'predict' the future, it means that our future can also be perfectly predicted, because we are part of the universe. That means that everything we're about to do is already set. No free will.

So mathematicians like Roger Penrose postulate that the universe is non-algorithmic in nature, and that by expanding that definition, our free will can be restored by proving that the human mind and our consciousness operates in a non-algorithmic manner. This model means that the universe is mostly-deterministic; all the normal physical rules we've already discovered apply (because most of the universe operates algorithmically still) but it's also a blank canvas that we can change at will.

Let's assume for a moment that Penrose is right; it would seem to imply that the universe itself can still be predicted (especially into the past for things like the Big Bang) but that we can't be predicted, because we operate in a non-deterministic way. The problem with that theory is that if it's true, it means that the universe can no longer be predicted into the future because one day we might have the technology to change the universe on its own scale; at least change enough of it (say this galaxy) to preserve our lives in some manner.

Imagine a distant future where we've learned to mine black holes for exotic materials and energy. Imagine that we can alter the gravitational constant, bringing the universe either into a stable size (or even bringing it back in a bit first, to make interstellar travel easier). Imagine that we can put a whole bunch of mass together, split it apart into hydrogen, then compress it on solar scales to make our own stars and solar systems.

In such a future, we've now altered the universe beyond its deterministic constraints.

Even worse, if the human mind isn't deterministic, it means it's possible that the universe isn't either. That means everything we know about the beginning of the universe onwards might be wrong.

So; my take on all this is that we can either have the penny or the bun; either the universe (including us) is deterministic, meaning we can predict the future (although not remember it) but we lose all hope of free will being possible; OR the universe is NOT deterministic, meaning that our free will may not be an illusion, but the price is that we lose any certainty around being able to predict our past, let alone our future. Adding in even the smallest 'random' element, when you're going back 14.5 Billion years, may well be enough to make the Big Bang wrong, not to mention all of the physical laws we currently understand. (The probabilistic nature of Quantum Theory is not non-deterministic per se and has a special application whose description is out of scope of this answer)

Ultimately, until we have conclusive evidence one way or the other, it's up to us to choose what we believe; the math or our own experience. Trust me when I say that's not an easy choice.
In philosophy, these are concepts of "modality" and still hotly disputed. You've provided a very nice example of how epistemology and metaphysics can lead to greater degrees of questioning... then (maybe) have applications in real life mathematics or scientific deduction.

If you're looking for an amazing - yet wildly inaccessible to most readers - discussion about this look at https://plato.stanford.edu/entries/quine/ Quinne.

To summarize / bastardize: 


  "what sort of logical proposition exists, such that we know "the sun
  will rise tomorrow"?"


Well. We don't. We never know that. And we can't ever know that. But, does that matter?

The question becomes whether that's a function of our language, understanding of the world around us, or something completely different. https://plato.stanford.edu/entries/russell/ Russell provides a number of avenues to this end that sort of bridge the gap between math, language, knowledge, etc. And, he writes well. 

https://plato.stanford.edu/entries/david-lewis/ David Lewis is sort of a hallmark (for me anyway) in these discussions. You could summarize "degrees of truth" through the notion of "possible worlds" in which a statement like "I believe the moon is made of green cheese" means that you're committing to the actual existence of moon made of green cheese, just in another time and space. Something like a "square'd circle," couldnt possibly exist.
People in the nearby area would likely contact emergency services. As a matter of policy, emergency services would conclude that you are demonstrating behavior consistent with a person who is severely mentally ill. Because you have become a hazard to yourself, they would pursue emergency psychiatric care. This would involve being taken to a hospital or other facility, where you would undergo screening and a battery of tests. This process is usually no shorter than 72 hours, but can be significantly longer if medical officials believe that you a persistent hazard to yourself.


  ...in front of everyone and see how they react.


In horror. They just watched a person perform severe self-harm in a public setting. They would believe that you are mentally ill.


  My only concern is if this is illegal...


Self-harm is not strictly illegal in all jurisdictions, but you would be taken into protective custody by police in most, if not all, jurisdictions.

I don't fully understand the philosophical nature of your question, since we have lots of instances of this sort of behavior being responded to in a fairly consistent fashion.

  The Law states that “no energy can be destroyed or created..."


Not quite. In its classical formulation, the 1st law says that energy is constant in a closed system. As this isn't entirely true, it has had a number of reformulations to include rest energy and virtual particles. I'm not a big fan of them, scientifically speaking, as they require you to measure the energy content of the universe to verify.


  Do you think this aligns with many of the teachings ... Eastern philosophy


It really doesn't. The religions you mention are very well developed and absolutely are not talking about energy in the thermodynamic sense. There are, of course, some points of crossover but it's generally superficial.


  and death being non existent


Minor point but they tend to see death as a transformation rather than not actually existing.

And a comment on the attempt to link scientific theories to most extant religions. Please exercise caution here. These religions are very well established, very well documented and very well understood. They are not enhanced or validated in any way by superficial linking to modern science. The same goes with similar attempts in Christianity, usually with Genesis.
Surprisingly little appears to have been written on the purely mathematical reception of Husserl's ideas, so one might surmise that he has not received much official acknowledgement. Richard Tieszen has written numerous papers on Husserl and maths but they are mostly philosophical. There is a 72-page article in French on https://arxiv.org/abs/1311.1524 arxiv
"Husserl, Cantor & Hilbert: La Grande Crise des Fondements Mathematiques du XIXeme Siecle". A popuar story about Husserl and Hilbert is told by Pierre Cassou-Noguès (available at diff. places).

In a nutshell: Husserl in his Philosophy of Arithmetic was critical of Frege who in turn wrote a negative and influent review. Husserl definitely turned from maths and set theory towards philosophy but he still knew most of the important figures in the maths world and exchanged many letters with them. Cantor is said to have congratulated him for his Habilitationschrift. 

Between 1901 and 1913 he was at Gottingen, the department of philosophy housing there the mathematics faculty, that is Hilbert and Klein. Hilbert has had many discussion with Husserl but does not appear to have said anything notable (either good or bad). However many thought Husserl close to Brouwer who was not well seen by mathematicians. The exception is Hermann Weyl who for a few years has been very enthousiastic about both.

From a contemporary standpoint, the most impressive acknowledgement of Husserl's ideas is due to Godel who studied them and wrote about them but did not publish anything (see Tieszen for an extensive tratment).
http://www.learnersdictionary.com/definition/triviality Triviality: "something that is not important: trifle."

The quote is from Moore's report of Wittgenstein "new" thinking (post-tractarian):


G.E. Moore, https://www.amazon.it/Wittgenstein-Lectures-Cambridge-1930-1933-Notes/dp/1107041163 Wittgenstein's Lectures in 1930-1933 (1955), Pat III.



  In answer to the question why this "new subject " ["new philosophy"] should be
  called "philosophy " he said in that though what he was doing was certainly different from what, e.g. Plato or Berkeley had done, [...]. But he had also said that the "new subject " did really resemble what had been traditionally called "philosophy " in the three respects that (1) it was very general,
  (2) it was fundamental both to ordinary life and to the sciences, and (3) it was independent of any special results of science ; that therefore the application to it of the word "philosophy " was not purely arbitrary.
  
  He said that the "new subject" consisted in "something like putting in order our notions as to what can be said about the world", and compared this to the
  tidying up of a room where you have to move the same object several times before you can get the room really tidy.
  
  He also said that he was not trying to teach us any new facts : that he would only tell us "trivial" things [emphasis added] - "things which we all know already" ; but that the difficult thing was to get a "synopsis" of these trivialities [emphasis added], and that our "intellectual discomfort" can only be removed by a synopsis of many trivialities - that "if we leave out any, we still have the feeling that something is wrong".
  
  In this connexion he said it was misleading to say that what we wanted was an
  "analysis", since in science to "analyse" water means to discover some new fact about it, e.g. that it is composed of oxygen and hydrogen, whereas in philosophy "we know at the start all the facts we need to know". 
  
  I [Moore] imagine that it was in this respect of needing a "synopsis" of trivialities that he thought that philosophy was similar to Ethics and Aesthetics.


The conclusion is: according to W, the "new" role of philosophy was not the discovery of "deep" truths, like, e.g. the logical foundations of mathematics and the definition of number (see the tradition of Frege and Russell that is the source of the inquiries of the tractatus) but the "elucidation" of language uses.
I'm no philosopher from the academy, and no expert in English communication, but i'm quite used to observing the mind. By using critical transcendental thiking answers to respond it, I could have the possibility of silencing my thoughts, and that made me understand a whole different world. 

I reflect upon myself that this is the meaning from the cave for me, our mind is the cave. We have to transcend it to help others still in the dark, that are seeing only with their blinded mind, blinded by all false truth that make human see everything in a dualistic self created logical way.

We with the truth, can show others by communication and exemplifications, ways to free themselfes. Like Plato at his existing time, greatly inspired by Socrates and now other new age phisolophy genius, some that come from weird spiritualistic rituals such as umbanda... 

There is a line of studies going on here in Brazil, they teach a practical way of reaching unity. It is like this: nothing created by the mind is the real truth, so silence it to hear the wordless word of truth, existence itself. The real altruism is observing that we are all minds, some blinded some not, helping each other to see more clearly in this short film that is life. I introduce you to yourself, as you introduce me to myself. 

The real knowledge is not knowing only that you don't know nothing, but not knowing everything that the mind proposes to you, untill you start getting a whole diferent way of thinking without words. Practicaly be aways observing the mind in a philosofical way, understad that every thought is based on the four anchors, so respond to it, when you feel it's going to think: I DONT KNOW, MIND, that's just what you think. This is the polishing way.

Sorry for the bad english, i'm from Brazil, just started in this stackexchange...
You can probably only preach to the already converted, there will probably be a certain number in attendance at your talk who are sympathetic to your message, as for the rest you will be knocking your head against the wall. 

How to get run out of the room?  You will have to go to Freud, 1923, The Ego and the Id, "What is now holding sway in the superego is, as it were, a pure culture of the death instinct."  "As is well known, in the superego there is all of human civilization with its structures, its taboos, its laws, its ideologies."  Jose P. Miranda, Marx and the Bible, Orbis Books, 1974, p. 281.   

(The core of Miranda's book is actually Heidegger-Bultmann-Tillich, and not Marx, but there is a wrapper of Marx, so to speak, on each end of the book.).  Btw, Miranda is not writing a book about the environment, but he does write some things at the end about death, and even overcoming death. 

We can get ourselves into a narrowly rational dynamic where we tell ourselves "it" cannot be stopped, we tell ourselves that we have lost control of the object that we ourselves created. We buy into our own Frankenstein story, because All-father, daddy, or in some way the parent (all the shoulds and musts) of our civilization told us "it", this thing, was the right way to go, even unto death.  

The control of the superego acts to repress the big picture, rational talk has little chance to change the person, and forcing the issue can even result in a psychological crisis. 

The large picture of the rational, gets lost in tomorrow's small "rational" irrational acts. So death talk, suicide talk, apocalyptic talk, nihilistic talk, starts leaking out of the system.  Let's hope it that in the short term people can sustain hope, and work with the ship to turn the ship. 

To understand further what is going on in the superego, particularly the effects of the authoritarian "Daddy" on the child (and the grown up child), see for instance:  "The Broken Rebel; a study in culture, politics, and authoritarian character."Rupert Wilkinson, Harper & Row, 1972. 

But you can't do any of this today, you can't mention Freud today in polite company, you'll be lucky to even find the books cited.  You'll get thrown out of the room.  

We have to understand that some people cannot, they cannot, psychologically, face up to this problem. In our society, we can gently try to move people away from apocalyptic visions and acting out, and move them gently away from nihilism (I.e. try to prevent Thanatos from running amok in our world) , but that is all we can really do, and in the meantime work with those who agree with us that this issue is important. 

P.S. I am focused here on psychological issues which, if they have come into philosophy at all, came in from the Frankfurt School. But I am in no way suggesting that Marx qua Marx had the solution to our environmental problems, though some are trying mightily right now to make Marx into an environmentalist. Marx was in favor of our taking control of history, taking control of ends, our not being passive,  I think it's safe to say that.  In my opinion, if Marx came back today, he would first catch up on his history, then go to current events, primarily the economy. 
Spinoza is not in any straightforward way a follower of Descartes. Descartes, for instance, believes that there are two substances, mind and body. For Spinoza, by contrast, there is only one substance; thought (mind) and extension (body) are attributes of it. That's quite a contrasting picture ! It is certainly nothing like Cartesian dualism. 

Freedom for Spinoza is not exemption from causality. We are free when we understand - have 'adequate ideas' about - the causes of our actions. To be free is not to be able to do simply what we choose but to understand the nature of the desires and emotions which cause our actions. It is understanding the internal necessity for our actions - recognising why, given the nature of reality, we act as we do. We no longer see our own nature as an external constraint; and realise that there is no freedom except to act in accordance with what we really are. When we have self-knowledge we are free since we understand our actions as the inherent and inevitable outcomes of our essential natures. 

Few people have self-knowledge though it is in principle available to all. It is a product of reason. 

One caution : like Hume later, Spinoza opposes freedom not to causation but to constraint. I am free if I act causally according to an essential nature which I understand. If you prevent me from acting according to that nature, say by coercing me, then Spinoza recognises that in this respect I do not act freely. 

All this is set out in Ethics, I, Definition 7; I, Corollary 17 & Lemma 58; IV, Demonstration 67. Spinoza's 'Ethics; is a hard book to get to grips with : Stuart Hampshire's 'Spinoza' is an old book but still a lucid and broadly reliable guide. 
I think what you may be after is modeled by the class of all ordinals, which does exist, in traditional mathematical logic, but cannot be a set.

One definition of the ordinals is the model called L.

L starts by defining the integers in terms of sets:

0 = {}

1 = {0}

2 = {0, 1}

3 = {0, 1, 2}

...

omega is the union of 0, 1, 2, 3, etc.

Then every whole number is in omega, and omega is infinite.  But omega is only 'infinite' it is not 'infinity'.  We can easily create the object which is "omega union {omega}", and that object is larger than omega itself, the first 'transfinite successor'.

We can continue building from there, and get the class Omega (capital) of all 'ordinals'.  Each of these is an infinity that is also limited.  So there is no inherent conflict to that concept.

You can prove that every potential model of inclusion is represented somewhere in that class.  And any real network of sets is equivalent to a combination of ordinals.  So 'L' is a model of all of set theory.

The problem is that if Omega is a set, we could cram it into another set.  That would allow us to construct "{Omega} union Omega".  Unfortunately that would be another model of inclusion, not isomorphic to any of the ordinals.  The way modern set theory avoids this is by declaring Omega not to be a set, only a 'proper' class of sets.

But that is not losing anything from most naive notions of infinity, because one of the standard properties of a realized infinity is already that it would not fit inside anything else.

You can do a very similar and only sightly more confusing construction with pairs of sets, if you want a broader sense of 'all the numbers', which includes models of everything most folks can consider a number.  The result is the class of J. H. Conway's 'Hyperreals' as elaborated in Donald Knuth's "Surreal Numbers".
Your question inspires another question: What kind of fallacy is it where an oppressed individual who breaks the rules is automatically condemned as unethical, with virtually no scrutiny of the people who make and enforce the rules?

There is an assumption that the people who make the rules (the oppressors) are ethical and live up to the rules.

In fact, that very frequently isn't the case at all. In "Corporate America," for example, the rules are typically drawn up by corporate attorneys and politicians. The people whose lives are governed by the rules typically have little or no real representation.

On top of that, the government, corporations, etc. often break their own rules.

To put it in perspective, consider a card game. If a person you're playing with is cheating (breaking the rules), then it doesn't make much sense to continue playing, especially if you're playing for money. So a smart person would just walk away.

But in "the real world," people can't just walk away. We have to work in order to acquire the money we need to survive. We have to follow local and national laws. We have to follow company rules.

But if the people who make and enforce those rules aren't playing fair, ordinary people may have little choice but break the rules themselves.

The stakes are even higher if an oppressed individual has a family to care for. Do you follow unfair rules if doing so means your children will go hungry or receive a poor education?

Looking at it another way, instead of asking if it's ethical for an oppressed individual to break the rules, let's ask if it's ethical for a politician or corporate tycoon (insert the name of your favorite capitalist titan here) to break the rules?

EDIT

I should add that there is a big gray area here, too. If the oppressor isn't playing by the rules, does that make it OK for the oppressed to break ALL the rules? Taken to an extreme, that mentality could lead to anarchy. So the oppressed are forced to walk a tightrope, attempting to figure out which rules can or should be broken, when, by whom, etc.
Rule T here allows one to write any tautological consequence of input sentences. Every sentential logic inference rule describes a particular tautological consequence. You can see that if you write out the inference rules as sentences. For example, a rule sometimes called “reiteration” can be written as “If P then P.” That sentence is logically true, and “tautology” is another way of saying “logically true.” 

So, in this case, since the law of hypothetical syllogism is logically true, it can be invoked with the rule T. Any other sentence logic rule can also be invoked this way, as can a whole series of them. To put it in different terms, any sentence logic proof can be done with rule T in one step, using this rule, once you know what’s provable in sentence logic.

(As for what he’s doing with the unbound variables, I’m not sure. I’d have to see how he defines well-formed formulas, or what the context of this example is.)
From a simple common sense perspective, I'd guess...


Your friend is depressed.
He has another kind of mental/psychiatric problem.
He just says he wants to die; he doesn't really mean it.


From a philosophical perspective, there's probably an infinite number of reasons a person might want to die. Many religious people want to die because they're anxious to get to Heaven, Nirvana, or whatever. Buddhist monks have been known to set themselves on fire to protest war.
The word "best" implies value judgments, and can't be evaluated independent of your goals for your worldview.  But there are clear practical and pragmatic reasons why science is currently a dominant worldview.  These include:


Science is testable.  
Science is replicable.  
Science is attached to a large and growing body of useful, interconnected, internally consistent knowledge.  
Science is a foundation for a set of workable technologies that have become increasingly ubiquitous and unavoidable.  


On the other hand science does have some crucial weaknesses:


Science is amoral (note: NOT immoral).  
Science is blind to the large portion of human experience that is not susceptible to its analyses.  
Science is giving us power beyond our ability to use it wisely, thus resulting in an increasingly destructive impact on our world and each other.


I personally think it's crucial to find a worldview that addresses science's weaknesses.  But it won't go far unless it can also build on, harmonize with, compete with, or otherwise account for science's strengths.
First, the fine-tuning argument suggests that the tunable constants in the Standard Model have only got a narrow range of variation if a universe capable of bearing life is to emerge. So they can't quite be anything.

Second,  before we can find out whether a number is irrational we must measure it to infinite accuracy. In mathematics, this is a given. In physics, this is not so. A measurement with infinite precision needs to be carried out.

Thus, given the limits on accuracy given by physical measuring instruments and the actual indeterminacy at the Planck scale it seems to me that to ask whether physical constants are rational or irrational is not a physically meaningful question.

Still, it's an interesting question. 
'Akin to' is hardly a precise term; your use of 'analogy' is to be preferred. 

This is not the place to settle the mattter on legal grounds. Ethically how does the analogy stand up? It is a requirement of justice not to discriminate against persons on the grounds of an irrelevant difference. The employer who discriminates against gays does so on the basis of such a difference, as does the academic to fails a student for the same reason. This puts the two cases on a level. 

But are failing a student and assisting recruitment by the gay-discriminating employer also on a level ? I should say there is a difference. In failing the student, the academic is practicing discrimination. Assisting recruitment by a gay-discriminating employer is not itself practising discrimination; it is supporting the practice of someone else, the employer, who practices discrimination. 

Suppose one were to recommend to the gay-discriminating employer only non-gay students. This would not necessarily harm gay students, who can get other jobs. By contrast, failing the gay student is necessarily harmful to the gay student. This is another difference.

A key point is whether engaging in a practice oneself (discriminating against, by failing, a gay student) is morally equivalent to acting as a means by which someone else (the gay-discriminating employer) can engage in a practice. By what moral principle could one adjudicate this ? A foreseeable consequences rule ? Suppose (a) I harm someone directly (assault her or him). Suppose (b) I do not harm someone directly but put them in a situation where foreseeably - foreseen by me - someone else will harm them. I think morally one situation is as bad as the other. Seen in these terms, assisting recruitment and failing the student are equivalent and an analogy holds. 
I don't think there's a named fallacy for this. But it seems to be a case of : 'no perceived effect, therefore no cause'. Or 'no perception of problem, therefore no problem'. 
A relevant distinction here is between "ontological materialism" and "methodological materialism" (compare the discussion https://plato.stanford.edu/entries/naturalism/ in the SEPh article on "naturalism").  Ontological materialism is the claim that only matter exists.  (I'm assuming you're using "matter" in a broad sense that includes the kinds of energy and fields studied by physics.  Otherwise early twentieth century field theories are already incompatible with materialism!  Given this assumption, string theory and https://en.wikipedia.org/wiki/Many-worlds_interpretation the Everett interpretation of quantum mechanics are both entirely compatible with ontological materialism.)  Methodological materialism is roughly the claim that we should investigate reality by focusing on things made out of matter.  Ontological materialism requires methodological materialism; but methodological materialism is compatible with the existence of non-material stuff.  

Methodological materialism fits well with the view that Stephen Jay Gould called https://en.wikipedia.org/wiki/Non-overlapping_magisteria "non-overlapping magisteria":  science and religion are concerned with different issues, aspects, or components of reality, and therefore there's no logic conflict between traditional religion and evolution by natural selection.  However, some theologically conservative philosophers — most notably http://www.asa3.org/ASA/PSCF/1997/PSCF9-97Plantinga.html.ori Alvin Plantinga — still argued against methodological naturalism.  Presumably Plantinga's arguments would also apply to methodological materialism.  Of course, ontological materialism is flatly incompatible with most if not all traditional religions.  

http://philsci-archive.pitt.edu/12896/1/MIZWSB.1.pdf Moti Mizrahi distinguishes "strong" and "weak" senses of "scientism."  Strong scientism is the claim that "Of all the knowledge we have, scientific knowledge is the only 'real knowledge.'"  Weak scientism is the claim that "Of all the knowledge we have, scientific knowledge is the best knowledge."  A view like ontological materialism seems to point strongly towards strong scientism — if only matter exists, it's hard to see how anything other than scientific knowledge could be real knowledge.  Methodological materialism is compatible with both kinds of scientism, and could be consistent with the rejection of weak scientism depending on exactly how it's understood.  Specifically, if methodological materialism says that "we should investigate material things" but doesn't proscribe how we should investigate them, then some non-scientific forms of knowledge (perhaps https://en.wikipedia.org/wiki/Traditional_ecological_knowledge traditional ecological knowledge) could be just as good as scientific knowledge.  

So, all together, ontological materialism fits tightly with a rejection of religion and strong scientism, while methodological materialism can be compatible with both traditional religion and non-scientific forms of knowledge.  
To quote Aristotle “Affirming nonexistence of the extent, or existence of the nonexistent, is falsehood; but affirming existence of the existent, and nonexistence of the nonexistent, is truth.”
Again, the determinant of law in a Common Law culture is precedent, not logic.  Law is inherently overdetermined and seeks consistency over time through the analysis of precedents.

In the U.S. the current legal position is based on the prohibition of baseless seizure in our fourth amendment.  The law has no right to intervene based on information that it should not have.  Pregnancy is not obvious until relatively late in its term.  And it is always possible for the woman to end the pregnancy by poisoning herself.  The pregnant woman could simply conceal her state until late in the term and take emmenagogues until either she or the fetus died.  This has been common in very poor cultures throughout history.  For the sake of her health, we want her not to conceal this information or poison or abuse herself.  But we want her to be open with us willingly, so we protect whatever options she would have had if she had decided not to divulge the fact.

At the same time, we have decided that conscription is legal, even when there is no war.  So controlling someone's body relatively completely, for service to the society, is not a baseless seizure, if there is a good reason.  And we have refused to set criteria for what constitutes a good reason.  You could at relatively recent points in U.S. history be drafted based on skills, availability, random chance, specific exposure, or any number of other contingencies, including information on which basis the government could not arrest you, because being drafted is not punishment.

So while we cannot criminalize abortion, we can force someone to have the child, if we take full responsibility for her in the interim, and decide that such action is service to the society.  Given our history of conscription, deciding otherwise would create more contradictions between precedents rather than fewer.

(That splits your question up in an odd way that makes it impossible to give a real answer.  The answer is 'Always, as long as it goes about it the right way -- the way consistent with its past actions')

The overall philosophical logic here follows Kant or Locke.  A state can do whatever it is allowed to do -- it is not bound by philosophical morality.  Though in every alteration (and likewise in every failure to adapt to changing moral sentiments within its populace) it risks violating the standards of the 'national spirit' (a la Kant) or rendering the 'social contract' (a la Locke) impossible to abide by.  If it crosses that line (whichever form of it you think is really the causal factor) it is deserving of replacement by a new contract or a defection of its population to a different national form.  Removing internal inconsistencies over time is the best defense against drifting away from the motivating spirit (Kant assumes that the national character is singular and somewhat internally consistent) or driving the contract to become impossible to interpret.

(Sorry if I am coming across as a bit obsessed with the draft.  The answer to your other question reminded me of it, and it applies to this case as well.)

Valid argument (or revisably so)


'Abortion is not wrong, because women have a right to control their bodies.' This is an 'argument', from a logical viewpoint, because it deduces a conclusion, 'Abortion is not wrong', from a premise, 'Women have a right to control their bodies.' In a deductively valid argument the premise warrants or guarantees the conclusion; the conclusion cannot be false if the premise is true. Actually more than one premise is required; and as you have framed the argument a premise is missing. You need : 

i. Women have a right to control their bodies.

ii. Abortion (the availability of abortion) embodies the right of women to control their bodies.

iii. Abortion is not wrong.

This argument is valid. iii. cannot be false if i. and ii. are true. Whether they are true a matter of moral dispute. (Get clear on the distinction between the truth of premises/ conclusion and the validity of an argument. Neither yields the other. The distinction between truth and validity is widely explained online.)


Fallacy


i. All students love coffee.

ii. Jane loves coffee.

iii. Therefore, Jane is a student.

This argument is invalid. All students may love coffee but coffee is loved by other people than students. Jane may be one of these other people. Therefore it does not follow that she is a student. In other words the truth of the premises, 1. and ii. does not warrant or guarantee the truth of the conclusion. 

The argument is an example of the fallacy of affirming the consequent. You can find this fallacy set out readily online. The argument may contain some truths, e.g. maybe all students love coffee but it is invalid. 
There is no claim that it is really about you at all.  There would be an infinite succession of copies of you.  They might not be you, but they are just like you, and you should therefore empathize with them.  They together are at least as valuable as you individually.

The point is that this might be an iteration with a very small chance of an improvement.  In Nietzsche's original that could happen by your iteration still being on the converging path.  In a more modern framing, it could happen by your iteration encountering some rare 'butterfly effect' condition.

That means that if you live more like you wish, even in a very small way, that would still affect infinitely many people.  His impetus is to wash out the notion that everyone else is more important because there are just more of them than there are of you.  There are infinitely many of you, just like there are infinitely many of them, and there is no point in talking about 'larger infinities' (as long as they are all countable).  So ultimately, it is an argument for radical, prudent selfishness in every instant over utilitarianism or other moralities focused on our culture or our species.

Discounting the possibility that things can still change slightly, your friend (who echos some versions of Buddhism) is right.  This is just a cycle and all we can affect is our approach to the inevitable, we may not even be able to affect that.  All infinitely many of us live with the false hope of mattering.

By modern scientific principles, Nietzsche is just wrong.  There is no convergent path and differences would not really be rare at all.  At some point in each iteration the whole universe is compressed to a space small enough that uncertainty on the Planck length can change literally everything, and the next cycle would look nothing at all like the last.  But he was looking at this from a standpoint of science before quantum mechanics and curved space were observed.
I think there are two aspects to logic which are more important above all others.  The first is to understand what makes a valid logical argument.  At the moment, mathematics' https://en.wikipedia.org/wiki/Proof_theory Proof Theory is probably the most extreme version of that, but you don't need to go that far.  The key to this is being able to say "If I start with a set of statements that represent things that mean something true (semantic truth), then here is a set of operations I can do on those statements, regardless of what they truly mean, which result in the production of additional true statements (syntactic manipulation).

To give an example, proof theory will dig into your "2+2 = 4" because it is empirically true that if I take two pencils, and gather two more pencils, the description of that is 4, and argue that "2+2=4" is true regardless of the empirical side.  In particular, we typically do not define 4 to be the result of adding 2 + 2.  It is usually defined to be the number following the number following the number following the number following the number zero (Peano arithmetic people would write that as Su(Su(Su(Su(0)))) where Su is the "successor function").  Two would be defined as the number following the number zero (written Su(Su(0))).  It can then show that 2+2=4 using the rules of Peano arithmetic, which are all manipulations of symbols (such as 0 + a  =a and a + Su(b) = Su(a) + b).  We also use logic to show that this addition operator has consistent properties like the ones we are used to (such as a + b = b + a).

Note that that entire section was devoted to manipulation of the abstract symbols, without mention of the meaning behind those symbols.  That's one half of the story.  The other half of the story is being able to determine valid abstract symbols to represent the real life events that you are talking about.  Mathematics has https://en.wikipedia.org/wiki/Model_theory Model Theory, which is very good at handling this once you've already abstracted things to mathematical symbols, but philosophy opens the door for many opinion about what abstract symbols and what rules are "valid."

In your example, we can say "If I take two pencils, and gather two more pencils, then the number of pencils I have is well described using 2 + 2 = 4."  How do I prove that?  I have to convince you that pencils can be represented by numbers, and thus the laws of addition apply to them.

Eventually, I'd recommend everyone read about https://en.wikipedia.org/wiki/Semantic_theory_of_truth Tarksi's Semantic Theory of Truth.  It's a rather quirky little beast, which you may not agree with, but which is very good for demonstrating the nature of this process of converting meaning into symbols so that an argument can be made.

Finally, I'd pick a few famous systems of logic.  A logical proof is only valid if the person admitting the argument believes that kind of logic is true.  For example, an argument involving infinity would be rejected by a finitist.  I would argue the most influential logic in the Western world is https://en.wikipedia.org/wiki/Propositional_calculus propositional logic, so no matter what you do, it would be worth your time to be familiar with its rules and patterns.  Beyond that, it's up to you.  Myself, I find https://en.wikipedia.org/wiki/First-order_logic First Order Logic to be useful, despite its flaws, but the systems you research are really up to you.
Very briefly, Quine's doctrine of ontological commitment is the thesis that ontologically, or metaphysically, logic is not neutral because the existential quantifier, '∃', commits logic to the existence of an entity, or things, of some kind. 

Whether the existential quantifier does carry this commitment in fact, I am not sure. In 'S believes that (∃x)(Fx & Gx)' - S believes that something with F has G - the existential quantifier does not presuppose or entail the existence of either A or B. It simply reports S's propositional belief. 
One common approach in statistics and certain experimental fields (like psychology) is to distinguish exploratory and confirmatory research.  Exploratory research is open-ended; you can go in with some hunches or vague questions that shape what you'll look for, but you don't have a specific hypothesis.  Confirmatory research starts with a specific hypothesis, and is designed to rigorously test that hypothesis.  The two kinds of research involve different methods — https://en.wikipedia.org/wiki/Exploratory_data_analysis exploratory data analysis for exploratory research; https://en.wikipedia.org/wiki/Design_of_experiments experimental design and statistical hypothesis testing for confirmatory research.  This distinction is very similar to the old philosophy of science distinction between https://plato.stanford.edu/entries/scientific-discovery/#DisBetConDisConJus "the context of discovery" and "the context of justification", though I'm not sure whether there's a genealogical relationship.  

Exploratory research is flexible and open-ended, but cannot claim to have "shown" or "proved" anything.  That requires the rigor of formulating a specific hypothesis, designing an experiment and analysis plan, and only then collecting data.  Using the same data to both develop a hypothesis and claim that you've confirmed it is sometimes called https://www.ncbi.nlm.nih.gov/pubmed/15647155/ Hypothesizing After Results are Known, or HARKing (sorry for the paywall), and in the context of statistical hypothesis testing it produces incorrect inferences.  

The exploratory/confirmatory distinction doesn't apply to all fields of scientific research; it only really fits experimental research, where in principle you can conduct carefully controlled, repeatable studies to collect more data.  
In a certain sense, Russell was right...

Hilbert's "dream" was to prove the consistency of arithmetic and analisys within a system weaker than arithmetic itself (the so called finitistic fragment).

Russell shared with Frege the idea that the system of logic was all encompassing: logic is a science that applies to any topic whatever.

If so, how can we find a system outside of it to be used to argue about the consistency of the system of logic itself ?
The primary locus on Hegel's free will is the Introduction to Philosophy of Right, relevant quotes are gathered by the http://www.informationphilosopher.com/solutions/philosophers/hegel Information Philosopher, Encyclopedia of Logic, §157-9, are also relevant. Hegel is a necessitarian, his view of free will is a typical version of what is now called compatibilism supplemented by dialectic rhetoric. Concept self-legislates and produces the world, but... what it produces is necessarily the way it is. When this necessity reaches the stage of conscious subjectivity it becomes freedom:"The truth of necessity... is freedom" (Encyclopedia of Logic, § 158). That is the dialectic. Or, as Marx streamlined it:"Necessity is blind until it becomes conscious. Freedom is the consciousness of necessity" (Compare to Zeno Stoic's "When a dog is tied to a cart, if it wants to follow, it is pulled and follows, making its spontaneous act coincide with necessity. But if the dog does not follow, it will be dragged in any case").

For more nuance you can look e.g. at https://pdfs.semanticscholar.org/a6ed/6a2859b6b46dbc46df49dc8c611acb777d51.pdf Pippin's Naturalness and Mindedness: 
Hegel’s Compatibilism:


  "Unlike  many  philosophers  influenced  by  the Christian tradition, Hegel does not defend a voluntarist position on the nature of freedom,  but  instead,  let  us  say,  a  ‘state’  theory.  He  does  not  understand  the possibility  of  freedom  to  depend  on  the  possession  of  a  causal  power  of  some
  kind by an individual, the power to initiate action by an act of will in some way independent  of  antecedent  causal  conditions... Instead, freedom is
  understood by Hegel to involve a certain sort of self-relation and a certain sort of relation  to  others;  it  is  constituted  by  being  in  a  certain  self-regarding  and  a certain sort of ‘mutually recognizing’ state. This state of self-consciousness and socially mediated self-reflection, defined in a highly elaborate systematic way as a ‘rational’ self- and other-relation, counts as being free."

Most dismissive answer:
You're probably just still in unfamiliar territory. You don't have enough experience with linear algebra yet to see how all the pieces fit together. Do as https://philosophy.stackexchange.com/questions/48948/how-to-prove-using-higher-abstractions-instead-of-diving-into-axioms-or-a-little#comment125203_48948 user4894 said, keep looking at the problem from different angles; understanding and proof economy will come in time.

If you want a higher-level answer, you should try turning the car on before you open the hood to see if it works. In your example you're given that A is invertible. Stop right there. Ask yourself "What is the definition of invertible?" see if the definition provides a way forward. In this case, that's essentially the whole proof. For many exercises like these the articulation of the problem strongly hints at a clear path forward.

Alternative answer: A more useful question might be "How do you form proofs requiring fewer steps?"
I offer this as an alternative, because in an axiomatic system it is extremely common to have statements mutually depend on each other. What is seen as a "higher level of abstraction" can often be made arbitrary through axiom selection. Good examples of this phenomenon are the https://en.wikipedia.org/wiki/Axiom_of_choice#Equivalents many equivalent statements of the axiom of choice or closer to home the https://en.wikipedia.org/wiki/Invertible_matrix#Properties many equivalent statements of invertibility. So one method of making shorter proofs is to choose a stronger starting position.

One confounding element here is that what constitutes a sufficiently rigorous argument is often subjective. (e.g. professors omitting deductive steps that are deemed trivial.) So another way of making shorter arguments is to assume more on the part of the reader.

Hope this helps some! Crafting elegant arguments is an art.
While I'm not entirely convinced of the premises of the question, in general people seek out philosophies that address conditions of life as they experience it.  In the marketplace of ideas, a philosophy may thrive not as much because of its connection with deeper truth, but because of its connection with present conundrums.

In light of that, I'd submit that part of the reason for the rise in the existentialist family of philosophies --existentialism, nihilism, absurdism, and so forth --is the rise of globalization.  In a world with a diversity of culture and beliefs, it becomes more difficult for people to accept received beliefs without questioning them.

I'd agree that there is a relationship here with scientism, although I would see that more as an attempted alternative to nihilism than as an extension of it.  
The concept of the noosphere is basically that of a sphere of mind or thought that emerged in the course of evolution in the last 50,000. The idea was put together in the 1920s by Edouard Le Roy, Teilhard de Chardin and Vladimir Vernadski but it is principally associated with Chardin, who did most to elaborate and develop it.   

I have my doubts about the value of Chardin's work but the following extract from T. A. Goudge, 'Salvaging the "Noosphere"', Mind, New Series, Vol. 71, No. 284 (Oct., 1962), 543 may make things a little clearer. I think its explains the nature of the noosphere (supposing it to exist) fairly clearly - far more clearly in fact than Chardin does himself : 

 The background of my proposal is the following. It can be
 accepted as a historical fact that one species of animal on the earth,
 Homo sapiens, has outstripped all others in the magnitude of the
 changes which have occurred in its way of life during the last 50,000
 years. The changes are usually said to constitute the process of
 cultural evolution. It is also a fact that there exists at present no
 comprehensive explanatory theory of that process. The best we
 have are a few clues about some of the causal factors (e.g. tool-using,
 tool-making, communication by speech and language, etc.) which
 determined the course of human evolution from the Paleolithic
 period onward.

 Under these circumstances it is desirable to have available a
 number of theoretical models in the light of which explanatory
 hypotheses can be formulated. This is a familiar state of affairs in
 the natural sciences when they are in a formative stage, as the
 sciences of man certainly are. Now it seems to me that the concept
 of the noosphere, freed from the mystical associations of The Pheno
 menon of Man and given a certain degree of precision, might serve
 as a useful model for anthropologists, sociologists, and psychologists
 who undertake to theorize about cultural evolution.
 What does the model amount to ? Briefly, it is built on the
 classical representation in geology of the earth as a sequence of
 concentric, spherical shells or envelopes-barysphere, lithosphere,
 hydrosphere, atmosphere and biosphere. The last of these, introduced 
 by the geologist Suess, was designed to represent the envelope
 of organic matter which originated and spread around the globe
 during the Pre-Cambrian era. What Teilhard proposes is that we
 regard the process of cultural evolution as having generated another
 planetary envelope, distinct from but superimposed on the biosphere,
 a " sheet of humanized and socialized matter " which he calls the
 "noosphere". The title seems reasonably apt since the noosphere
 is exclusively the product of Homo sapiens, and embraces not only
 technological but also intellectual and social creations. Viewed
 historically, the noosphere is the ensemble composed of evolving man
 and his various cultures.


This does not explain the functionality of the concept of the noosphere. I think  the concept was intended to do two things. First, to emphasise that interacting human intelligence and culture have reached the stage where the biosphere is largely or significantly under their control. The 'noosphere' refers to this human superimposition on the biosphere. Secondly, to suggest the need for the noosphere to self-regulate in order to control its impact, increasingly harmful and dangerous, on the biosphere. We see here a clear pointer to the social and ethical imperative that drives what we now call environmentalism. It cannot be said that anything like effective self-regulation is even on the horizon. 
I've taught Critical Thinking for about 20 years, and I have to agree that there is no good textbook.

Let me tell you where I'm coming from: Yes, I've seen all the textbooks with their unending treatments of logic ... Ugh! Sure, logic is important, but why the insistence on formal logic proofs? We have logic courses for that. Indeed, just the fact that the focus is on deductive logic seems rather silly.  Most real life reasoning is not deductive and so all this logic has very limited applicability. Yes, logic teaches one to be careful and organized in one's reasoning, but let me put it this way: when it comes to people coming to bad beliefs and making bad arguments, logic is probably the least of our problems. Much more problematic are our cognitive and social biases. When you cover fallacies, you'll find that they can almost all be traced back to those biases, rather than to any logical reasoning impairment. 

I suppose I should also that say that I define Critical Thinking basically as "thinking about beliefs (especially your own!) and seeing if they make sense".  Or: how to not get caught up in bullshit and be an actual truth-seeker! That of course already goes far beyond merely analyzing some prose... it about developing a critical mind-set ... and the many, many psychological and social barriers that exist both inside and outside of us that prevent us from being genuine truth-seekers.

So, when I teach Critical Thinking, I spend a few weeks on each of the following:

Arguments: basic analysis and evaluation

Fallacies: the usual suspects ... though I emphasize rhetorical flim-flam and emotional trickery

OK, so far so good, but then:

Statistical/inductive reasoning: really important stuff! And by the way: I take a very 'anti-math' approach here as well: you can do all the probability theory and statistics you want, but in the end so many people are still convinced by some hasty generalization of refutation based on one piece of personal experience or anecdotal evidence: that's the kind of crazy thinking that I want my students learn to prevent.

Causal reasoning: super important! The way we think the world causally works translates in how we act.  And my oh my, are there a great number of pitfalls in causal reasoning!

Cognitive biases and social biases: as the great philosopher Clint Eastwood said: "A man's gotta know his limitations". Socrates reportedly mumbled something to that effect as well :)

Perception and memory: lots of crappy beliefs come from crappy perception and crappy memory

'Authorities':  Media (esp. internet!), culture, science, pseudo-science, religion, etc. 

Oh, and in case you think I'm all anti-math and don't like logic: I teach Introduction to Logic, Intermediate Logic (meta-logic; soundness, completeness, etc) and Computability and Logic (undecidability of logic, Godel results), and I love it! ... So yes, I could certainly teach a whole critical thinking course all around logic ... it would certainly be a lot easier for me to teach (and assess!) than what I do now ... I just don't think logic has all that much to offer as far as critical thinking goes.  

So, what book do I use? None. All ingredients can be found on the internet. It's not rocket science. Though I can point to a few books that have provided some valuable material: 

"How to think about Weird Things"

"How we know what isn't so"

"How to Lie with Statistics"

and there's always Carl Sagan's classic "The Demon-Haunted World"

Sorry, all more than 15 years old I'm afraid, but at least they go beyond mere arguments: there is a lot of psychology and sociology behind the formation of our beliefs, and you have to instill awareness of that in the students, or else in my eyes it fails to be a critical thinking course. If there is one key to critical thinking, it's independent thinking!

  When I hear people talk about texts, it seems so long and convoluted, and all I can help but think is "how on Earth did you glean absolutely any of that from the extremely simplistic arguments given by Plato"? 


Arguments can be very long and complicated. For any text, interpretation is needed. For most philosophical texts this isn't exactly simple. It starts with making sense of the style of the text, goes over deciphering terminology and ends with reasoning how to deal with ambiguities or issues. Furthermore philosophical texts can be dense, long, complicated, dry, badly written, etc.

For older texts a number of problems are added:
1) Any references to events or other texts we must recover with much more work, simply because we live in a different time with a different view on the world.
2) Translation is needed. In the case of Plato, translating from Ancient Greek is no easy business.
Etc.


  Is the only possible way to understand, say, Nietzsche, to read every single book he reads, and then read every author that he references as the setup to his work? If so, how does one understand any text at all? 


To understand older texts, context is especially important. Hence stuff like biographical backdrop matters. There's a concept called Hermeneutics that deals with understanding of texts, ideas, and so on. Here's https://plato.stanford.edu/entries/hermeneutics/ an article on it. The core idea of it is one take on 1) if and why such an extensive procedure is necessary to understand the text and 2) how we should go about it. Hermeneutics in particular treats understanding of texts as a process that is never finished.


  I understand how ranty this is, but it is necessary for people to understand my conundrum. It's starting to seem like reading philosophy is a completely hopeless engagement in retracing the history of every philosophical text ever written to understand the current read.


To suggest a more practical approach, why not make use of introductory texts? Of course, those need to be of good quality. But treating them as a tool that will be inaccurate, incomplete, simplifiying or wrong makes it an efficient way of building knowledge. Either way there's work involved which can not be avoided.

Also note that certain approaches don't try that hard to be faithful to the texts and that philosophy can be done with much less focus on past philosophers. A philosopher of mind in the analytic tradition can get away with not caring very much about Plato and focusing on contemporary stuff. So maybe a different focus would be better suited to your area of interest.
Galen Strawson, Richard Double, Ted Honderich, Derek Pereboom, Saul Smilansky. For links to further on these, see 2nd paragraph http://www.informationphilosopher.com/solutions/philosophers/strawsong/ here.
As explained in IEP's entry regarding https://www.iep.utm.edu/zeno-par/ Zeno's Paradox, current solution (aka https://www.iep.utm.edu/zeno-par/#H2 Standard Solution) is based on the mathematics of the infinite, developed after 17th Century.

Current mathematical solution makes sense of an infinite sum having a finite amount.

This is not so for ancient mathematics and philosophy, as well as for Aristotle: either the quantities that we have to add are zero, in which case the total of the infinite sun is zero, or the quantities are not zero, in which case the sum of an infinite of them must be infinite.

Aristotle's solution is based on the dichotomy between https://www.iep.utm.edu/infinite/#SH1a actual and potential infinite:


  For motion…, although what is continuous contains an infinite number of halves, they are not actual but potential halves. (Physics, 263a25-27). …Therefore to the question whether it is possible to pass through an infinite number of units either of time or of distance we must reply that in a sense it is and in a sense it is not. If the units are actual, it is not possible: if they are potential, it is possible. (Physics. 263b2-5).


According to A, the finite distance is only potentially infinite, in the sense that we can - in thought - imagine to divide it an infinite number of time.

But it is actually finite, and thus any mover, moving with a finite speed,  can traverse it in a finite amount of time.
A meaningful life is one that has a purpose and direction to it, one to which oneself attaches value, one in which one can trace coherent patterns in its past or project plans for the future. All these possibilities apply. The basic idea of meaningfulness here is the Sartean one of injecting meaning into one's - living authentically by values oneself has chosen. His least confusing statement of this view is given in the easily available, 'Existentialism is a Humanism'. 

There is plainly no requirement, if this is what a meaningful life is, for it to embody any particular values, least of all moral values and definitely not those of which ordinary moral thinking approves. From this viewpoint there is no paradox in a Gestapo officer's having a meaningful life but, judged from the standpoint of ordinary moral thinking, an immoral one. 

There is only a paradox if one steps outside existentialist thinking and sees the meaning of life as, say, a Catholic does : life has an inbuilt purpose which is to love and serve God, and to love and serve others (Matt 22:36, Mark 12:29, Luke 10:25). 

I offer no adjudication between these two very different views. (Not so different, however, but that some have not sought to formulate a Christian existentialism but I set that aside as involving too many issues.) On a Catholic approach there would be a contradiction in living as a Gestapo officer does and living in accordance with God's inbuilt purpose for humankind. But the perspective of existentialism removes the contradiction - of course relative to existentialist assumptions. 
Infinite regress problems are a result of a misunderstanding of epistemology. Epistemology is about how knowledge is created, how you can distinguish what ideas you should adopt and act on, and similar problems. Philosophers have commonly tried to solve this problem by saying there is a process called 'justification': a process that can make conclusions true or good or something like that - justificationism. An argument's conclusions are true if its premises and the rules applied applied to those premises are correct. So to show the conclusion of an argument is true, you must show the premises and rules are correct. To do that, you either assert by fiat that they are true, which proves nothing, or you make an another argument. If you make another argument, then you have the same problem as the original argument and you are no better off.

The notion that god somehow solves this problem doesn't make any sense. If you want to use god as a foundation then you either assert stuff about god by fiat, or you argue, which gives rise to the same problem.

Nevertheless, many philosophers ignore or deny or obfuscate this problem and spend their time arguing about induction or god or whatever. They argue endlessly about this issue and you can read vast piles of books about epistemology. People outside academic philosophy may occasionally think something along the lines that this is a difficult problem but progress is being made or something like that and point to some book or other that they haven't read or understood as being the state of the art. 

One philosopher who didn't take this way out was Karl Popper. Popper bit the bullet and said that justification is impossible. Knowledge is created by noticing problems, making guesses about the solution, criticising the guesses and using the guesses that survive this process. The truth of those guesses is not guaranteed, nor is it probable or anything like that. But you can select ideas based solely on whether they survive criticism - that is, whether they leave relevant problems unsolved. For a guide to Popper's epistemological work, see

http://fallibleideas.com/books#popper http://fallibleideas.com/books#popper
https://foucaultnews.com/2013/10/31/what-is-a-regime-of-truth-2013/ This short essay on Foucault News attempts a description of regimes of truth; a more extended elaboration of this is in https://foucaldien.net/articles/abstract/10.16995/lefou.2/ this paper, What is a regime of truth? by Daniele Lorenzini. He explains:


  The first time Foucault introduces the concept of 'regime of truth' is in chapter one of Discipline and Punish where... a corpus of knowledge, techniques, 'scientific' discourses became entangled with the practice of the power to punish...Now, what makes this concept so interesting is the fact that, through this expression, Foucault links the notion of truth to the explicitly political notion of regime... But the most interesting text, before 1980, with regard to Foucault's use of the concept of regime of truth — leaving aside a short passage in The Birth of Biopolitcs —, is without a doubt the 1976 interview "The political function of the intellectual", where Foucault argues, in contrast to
  a certain philosophical myth, that "truth isn't outside power, or deprived of power": on the contrary, truth "is produced by virtue of multiple constraints [a]nd it induces regulated effects of power". 
  
  This is to say that “each society has its regime of truth”, and by this expression Foucault means: 
  
  
  
  “the types of discourse [society] harbours and causes to function as true”. 
  
  
  “the mechanisms and instances which enable one to distinguish true from false statements” 
  
  
  “the way in which each is sanctioned”
  
  
  “the techniques and procedures which are valorised for obtaining truth”
  
  
  "the status of those who are charged with saying what counts as true"
  
  
  
  Therefore, “truth” is “a system of ordered procedures for the production, regulation, distribution, circulation and functioning of statements”; it is linked “by a circular relation to systems of power which produce it and sustain it, and to effects of power which it induces and which redirect it”. And right at the end of the interview, Foucault adds that the essential political problem for us, today, is trying to change our “political, economic, institutional regime of the production of truth” (where truth is modeled on the form of scientific discourse), in order to constitute a new “politics of truth” 


However, he later has a more nuanced view where he says that 


  precisely that these two notions — 'regime' and 'truth' — cannot go together: it is not possible to speak of a regime of truth like we speak of a political or a penal regime. 


and


  truth, if it is really true, does not need a supplement of force, an
  enforcement, a supplement of vigor and constraint to be accepted. It is the truth, and that's all: truth is sufficient unto itself for making its own law — its coercive force resides within truth itself. "Truth itself determines its regime, makes the law, and obliges me. It is true, and I submit to it".


This is in line with Arendts essay, Truth & Politics.
It's useful to remember that frequentism was rooted in Machian or positivist radical empiricism.  On this radical empiricist picture, all we can talk about are series of observations; we can't observe anything like "real chances" or stochastic causal connections, and so we should avoid that kind of language.  

So, yes, #1, that really is all the most rigorous nineteenth century frequentists like Karl Pearson mean by probability.  

Later frequentists were less rigorous empiricists, however.  For example, Fisher was an indeterminist, and sometimes used stochastic causal connection language.  The distribution of coin flip results in X can be https://en.wikipedia.org/wiki/Sufficient_statistic described completely by an unobserved parameter rho (which you can interpret as the probability that any one coin flip is heads).  For Fisher, rho has a true value, and rho stochastically causes the distribution of coin flip values that we actually observe.  By virtue of this causal connection, we can use the percentage of observed flips that are heads to estimate the value of rho.  For Karl Pearson, by contrast, this percentage is just a convenient way to summarize the data; since we can't actually observe rho, it's (roughly) meaningless to talk about its "true" value.  

So #2 is true for an indeterminist frequentist like Fisher.  There are "real chances" and stochastic causation, and we can estimate the true values of unobserved stochastic causes using the properties of long-run tendencies of sequences of observations.  
